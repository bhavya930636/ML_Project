{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf476abc-7050-4395-8cd0-e04b71d05dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "embeddings2_raw = np.loadtxt(\"second_last_layer_embeddings.txt\", delimiter=\",\")  # Shape: [6241, 200]\n",
    "\n",
    "embedding2 = torch.tensor(embeddings2_raw, dtype=torch.float32)  # Shape: [6241, 200]\n",
    "\n",
    "# Select the top 1500 rows (nodes)\n",
    "embedding2 = embedding2[:1500]  # Shape: [1500, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85d930d-635e-4ffa-85bd-b8f52788f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0588, 0.0000, 0.0902,  ..., 0.0000, 0.0941, 0.0000],\n",
       "        [0.0764, 0.0000, 0.1202,  ..., 0.0000, 0.1293, 0.0000],\n",
       "        [0.0875, 0.0000, 0.1268,  ..., 0.0000, 0.0642, 0.0000],\n",
       "        ...,\n",
       "        [0.0938, 0.0000, 0.0631,  ..., 0.0000, 0.0294, 0.0000],\n",
       "        [0.0709, 0.0000, 0.0825,  ..., 0.0000, 0.0970, 0.0000],\n",
       "        [0.0701, 0.0000, 0.0851,  ..., 0.0000, 0.0862, 0.0000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c69c62-3b01-4ab5-80e0-34ad297f0fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1500, 200])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f9f543-db38-45ea-9dfc-3f8c2cdc8271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Category  Value\n",
      "0         37      val     24\n",
      "1         53    train      4\n",
      "2        171    train     28\n",
      "3        335    train     23\n",
      "4        349    train      8\n",
      "...      ...      ...    ...\n",
      "1495  168886     test     37\n",
      "1496  168979    train     37\n",
      "1497  169087    train     16\n",
      "1498  169154    train     30\n",
      "1499  169158    train     27\n",
      "\n",
      "[1500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = \"1500_labels.txt\"  # Replace with your file path\n",
    "data = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"ID\", \"Category\", \"Value\"])\n",
    "\n",
    "# Display the data\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d43d43b-8f24-4b7b-820b-44ff8adc6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.tensor(data[\"ID\"].values, dtype=torch.long)\n",
    "splits = data[\"Category\"].values.tolist()  # Ensure it's a list of strings\n",
    "labels = torch.tensor(data[\"Value\"].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd324e2a-37d9-4449-a9ad-a60147b7c9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1500, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_embeddings = torch.load(\"gnn_embeddings.pt\")\n",
    "# Extract embeddings for the given indices\n",
    "embedding1 = gnn_embeddings[indices]\n",
    "embedding1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ddc5ab-18da-4dd3-b81f-6d91d74c29e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4802, 0.0000, 1.8834,  ..., 0.0000, 1.9623, 0.0000],\n",
       "        [3.0734, 0.0000, 0.3168,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 2.5264,  ..., 0.5769, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 3.2684,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [2.2183, 2.8732, 0.5575,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 2.3806, 0.0000, 0.0000]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a212508a-39c0-43fd-9532-0192cb8a4c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1500, 456])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 4: Concatenate the Embeddings\n",
    "concatenated_embeddings = torch.cat((embedding1[:1500], embedding2), dim=1)  # Shape: [1500, 456]\n",
    "concatenated_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a51f28-df7a-4929-a9b5-cf72a01ddec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4802, 0.0000, 1.8834,  ..., 0.0000, 0.0941, 0.0000],\n",
       "        [3.0734, 0.0000, 0.3168,  ..., 0.0000, 0.1293, 0.0000],\n",
       "        [0.0000, 0.0000, 2.5264,  ..., 0.0000, 0.0642, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 3.2684,  ..., 0.0000, 0.0294, 0.0000],\n",
       "        [2.2183, 2.8732, 0.5575,  ..., 0.0000, 0.0970, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0862, 0.0000]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fcfeedc-3b40-4505-9fb7-288a22b1afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = [i for i, split in enumerate(splits) if split == \"train\"]\n",
    "val_indices = [i for i, split in enumerate(splits) if split == \"val\"]\n",
    "test_indices = [i for i, split in enumerate(splits) if split == \"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "028d0850-1508-41fd-837b-aea263e50761",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(concatenated_embeddings[train_indices], labels[train_indices])\n",
    "val_data = TensorDataset(concatenated_embeddings[val_indices], labels[val_indices])\n",
    "test_data = TensorDataset(concatenated_embeddings[test_indices], labels[test_indices])\n",
    "\n",
    "# Step 4: Define DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd0a96e8-edc4-41b9-9546-e9f29d992677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 5: Define the model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "input_size = concatenated_embeddings.shape[1]#456\n",
    "num_classes = labels.max().item() + 1\n",
    "model = Classifier(input_size, num_classes)\n",
    "\n",
    "# Step 6: Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e56851d8-4689-466f-a0cc-2bc107e662a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 185.5250\n",
      "Validation Accuracy: 35.32%\n",
      "Epoch 2/10, Loss: 127.2754\n",
      "Validation Accuracy: 52.75%\n",
      "Epoch 3/10, Loss: 98.9980\n",
      "Validation Accuracy: 56.42%\n",
      "Epoch 4/10, Loss: 81.9642\n",
      "Validation Accuracy: 54.59%\n",
      "Epoch 5/10, Loss: 68.3719\n",
      "Validation Accuracy: 55.50%\n",
      "Epoch 6/10, Loss: 57.5482\n",
      "Validation Accuracy: 58.26%\n",
      "Epoch 7/10, Loss: 49.4468\n",
      "Validation Accuracy: 58.26%\n",
      "Epoch 8/10, Loss: 40.6731\n",
      "Validation Accuracy: 55.96%\n",
      "Epoch 9/10, Loss: 32.2804\n",
      "Validation Accuracy: 52.29%\n",
      "Early stopping triggered after 9 epochs. Best Accuracy: 58.26%\n"
     ]
    }
   ],
   "source": [
    "# Early stopping parameters\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "best_accuracy = 0  # Keep track of the best validation accuracy\n",
    "patience_counter = 0  # Counter to track how many epochs since the last improvement\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for embeddings, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for embeddings, targets in val_loader:\n",
    "            outputs = model(embeddings)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        patience_counter = 0  # Reset patience counter since we have improved\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs. Best Accuracy: {best_accuracy:.2f}%\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb1bee83-c86a-45cd-8e8c-e20e2fc076f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 52.17%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 8: Test the model\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, targets in test_loader:\n",
    "        outputs = model(embeddings)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067dbcd9-47d1-4eb5-a6b0-0a19b1dce03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5127df7-fbe6-48de-8c25-6b49d532c9cf",
   "metadata": {},
   "source": [
    "# resize and add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0f6c9fc-a16f-4835-9298-7c376a6d9013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1500, 200])\n"
     ]
    }
   ],
   "source": [
    "# Define a linear transformation layer\n",
    "linear_layer = nn.Linear(256, 200)\n",
    "\n",
    "# Apply this transformation to the embedding1 tensor\n",
    "embedding1_transformed = linear_layer(embedding1)\n",
    "\n",
    "# Check the shape of transformed embedding1\n",
    "print(embedding1_transformed.shape)  # Should be [1500, 200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14e60c15-293a-48bd-af2e-e73a985b7f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1500, 200])\n"
     ]
    }
   ],
   "source": [
    "print(embedding2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49a942a9-6cee-4c3b-b735-ede2c0c77a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_embeddings = embedding1_transformed + embedding2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db7c95cc-6486-49cd-8d48-d76854cc2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(added_embeddings[train_indices], labels[train_indices])\n",
    "val_data = TensorDataset(added_embeddings[val_indices], labels[val_indices])\n",
    "test_data = TensorDataset(added_embeddings[test_indices], labels[test_indices])\n",
    "\n",
    "# Step 4: Define DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3a68171-370c-43a0-95b9-fa32ce336b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_size = added_embeddings.shape[1]#200\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f14e073-42e8-4b00-9a5e-8573f2588edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 5: Define the model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "num_classes = labels.max().item() + 1\n",
    "model = Classifier(input_size, num_classes)\n",
    "\n",
    "# Step 6: Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d83c2c5-95e0-42b5-8a89-1c31a05d5f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 197.2795\n",
      "Validation Accuracy: 34.40%\n",
      "Epoch 2/10, Loss: 143.3461\n",
      "Validation Accuracy: 47.25%\n",
      "Epoch 3/10, Loss: 115.9702\n",
      "Validation Accuracy: 51.83%\n",
      "Epoch 4/10, Loss: 100.5291\n",
      "Validation Accuracy: 55.50%\n",
      "Epoch 5/10, Loss: 88.5624\n",
      "Validation Accuracy: 53.67%\n",
      "Epoch 6/10, Loss: 79.5167\n",
      "Validation Accuracy: 55.05%\n",
      "Epoch 7/10, Loss: 71.5351\n",
      "Validation Accuracy: 52.75%\n",
      "Early stopping triggered after 7 epochs. Best Accuracy: 55.50%\n"
     ]
    }
   ],
   "source": [
    "# Early stopping parameters\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "best_accuracy = 0  # Keep track of the best validation accuracy\n",
    "patience_counter = 0  # Counter to track how many epochs since the last improvement\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for embeddings, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for embeddings, targets in val_loader:\n",
    "            outputs = model(embeddings)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        patience_counter = 0  # Reset patience counter since we have improved\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs. Best Accuracy: {best_accuracy:.2f}%\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88038d73-bf51-429f-b130-5d2bb0842c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 48.22%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 8: Test the model\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, targets in test_loader:\n",
    "        outputs = model(embeddings)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6776f77f-2049-4634-bcb8-5a03f4b5f2e8",
   "metadata": {},
   "source": [
    "# multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47ea3808-a266-4423-8691-8f2ab20cfcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplied_embeddings = embedding1_transformed * embedding2\n",
    "train_data = TensorDataset(multiplied_embeddings[train_indices], labels[train_indices])\n",
    "val_data = TensorDataset(multiplied_embeddings[val_indices], labels[val_indices])\n",
    "test_data = TensorDataset(multiplied_embeddings[test_indices], labels[test_indices])\n",
    "\n",
    "# Step 4: Define DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "input_size = multiplied_embeddings.shape[1]#200\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Define the model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "num_classes = labels.max().item() + 1\n",
    "model = Classifier(input_size, num_classes)\n",
    "\n",
    "# Step 6: Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe0b0251-6768-4dce-991f-88a703a6e71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 226.6037\n",
      "Validation Accuracy: 11.47%\n",
      "Epoch 2/10, Loss: 186.1115\n",
      "Validation Accuracy: 22.94%\n",
      "Epoch 3/10, Loss: 166.7476\n",
      "Validation Accuracy: 26.61%\n",
      "Epoch 4/10, Loss: 154.0381\n",
      "Validation Accuracy: 32.57%\n",
      "Epoch 5/10, Loss: 144.6842\n",
      "Validation Accuracy: 32.57%\n",
      "Epoch 6/10, Loss: 135.9187\n",
      "Validation Accuracy: 39.45%\n",
      "Epoch 7/10, Loss: 130.8627\n",
      "Validation Accuracy: 43.58%\n",
      "Epoch 8/10, Loss: 124.1877\n",
      "Validation Accuracy: 40.83%\n",
      "Epoch 9/10, Loss: 119.7451\n",
      "Validation Accuracy: 45.87%\n",
      "Epoch 10/10, Loss: 112.9565\n",
      "Validation Accuracy: 46.33%\n",
      "Test Accuracy: 42.69%\n"
     ]
    }
   ],
   "source": [
    "# Early stopping parameters\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "best_accuracy = 0  # Keep track of the best validation accuracy\n",
    "patience_counter = 0  # Counter to track how many epochs since the last improvement\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for embeddings, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for embeddings, targets in val_loader:\n",
    "            outputs = model(embeddings)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        patience_counter = 0  # Reset patience counter since we have improved\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs. Best Accuracy: {best_accuracy:.2f}%\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Step 8: Test the model\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for embeddings, targets in test_loader:\n",
    "        outputs = model(embeddings)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f1b84-ffb3-45d1-baab-566847ee3a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
