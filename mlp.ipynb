{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --cache-dir .cache torch-geometric torch-sparse torch-scatter --pre\n",
        "import argparse\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv, SAGEConv\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "\n",
        "from logger import Logger\n",
        "\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.lins = torch.nn.ModuleList()\n",
        "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
        "        self.bns = torch.nn.ModuleList()\n",
        "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
        "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for lin in self.lins:\n",
        "            lin.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, lin in enumerate(self.lins[:-1]):\n",
        "            x = lin(x)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.lins[-1](x)\n",
        "        return torch.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "def train(model, x, y_true, train_idx, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x[train_idx])\n",
        "    loss = F.nll_loss(out, y_true.squeeze(1)[train_idx])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, x, y_true, split_idx, evaluator):\n",
        "    model.eval()\n",
        "\n",
        "    out = model(data.x, data.adj_t)\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    # Create a mask for the specific nodes\n",
        "    mask = torch.zeros(data.y.size(0), dtype=torch.bool)\n",
        "    mask[node_list] = True  # Set the specific nodes to True\n",
        "\n",
        "    # Ensure split indices are tensors\n",
        "    train_idx = torch.tensor(split_idx['train'], dtype=torch.long)\n",
        "    valid_idx = torch.tensor(split_idx['valid'], dtype=torch.long)\n",
        "    test_idx = torch.tensor(split_idx['test'], dtype=torch.long)\n",
        "\n",
        "    # Use the mask to filter indices correctly for each split\n",
        "    train_mask = mask[train_idx]\n",
        "    valid_mask = mask[valid_idx]\n",
        "    test_mask = mask[test_idx]\n",
        "\n",
        "    # Filter the true and predicted labels\n",
        "    y_true_train = data.y[train_idx][train_mask]\n",
        "    y_pred_train = y_pred[train_idx][train_mask]\n",
        "\n",
        "    y_true_valid = data.y[valid_idx][valid_mask]\n",
        "    y_pred_valid = y_pred[valid_idx][valid_mask]\n",
        "\n",
        "    y_true_test = data.y[test_idx][test_mask]\n",
        "    y_pred_test = y_pred[test_idx][test_mask]\n",
        "\n",
        "    # Debugging outputs\n",
        "    print(f\"Train: {y_true_train.numel()}, {y_pred_train.numel()}\")\n",
        "    print(f\"Valid: {y_true_valid.numel()}, {y_pred_valid.numel()}\")\n",
        "    print(f\"Test: {y_true_test.numel()}, {y_pred_test.numel()}\")\n",
        "\n",
        "    # Evaluate using the filtered true and predicted labels\n",
        "    train_acc = evaluator.eval({'y_true': y_true_train, 'y_pred': y_pred_train})['acc'] if y_true_train.numel() > 0 else 0.0\n",
        "    valid_acc = evaluator.eval({'y_true': y_true_valid, 'y_pred': y_pred_valid})['acc'] if y_true_valid.numel() > 0 else 0.0\n",
        "    test_acc = evaluator.eval({'y_true': y_true_test, 'y_pred': y_pred_test})['acc'] if y_true_test.numel() > 0 else 0.0\n",
        "\n",
        "    return train_acc, valid_acc, test_acc\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='OGBN-Arxiv (MLP)')\n",
        "    parser.add_argument('--device', type=int, default=0)\n",
        "    parser.add_argument('--log_steps', type=int, default=1)\n",
        "    parser.add_argument('--use_node_embedding', action='store_true')\n",
        "    parser.add_argument('--num_layers', type=int, default=3)\n",
        "    parser.add_argument('--hidden_channels', type=int, default=256)\n",
        "    parser.add_argument('--dropout', type=float, default=0.5)\n",
        "    parser.add_argument('--lr', type=float, default=0.01)\n",
        "    parser.add_argument('--epochs', type=int, default=500)\n",
        "    parser.add_argument('--runs', type=int, default=10)\n",
        "    args = parser.parse_args()\n",
        "    print(args)\n",
        "\n",
        "    device = f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu'\n",
        "    device = torch.device(device)\n",
        "\n",
        "    node_list = [110223, 146929, 2940, 104544, 62326, 29759, 96890, 47025, 117732, 163206]\n",
        "\n",
        "    dataset = PygNodePropPredDataset(name='ogbn-arxiv', transform=T.ToSparseTensor())\n",
        "\n",
        "    data = dataset[0]\n",
        "    data.adj_t = data.adj_t.to_symmetric()\n",
        "    data = data.to(device)\n",
        "    split_idx = dataset.get_idx_split()\n",
        "    # Filter the split indices based on your `node_list`\n",
        "    train_idx = torch.tensor([n for n in split_idx['train'] if n in node_list], device=device)\n",
        "    valid_idx = torch.tensor([n for n in split_idx['valid'] if n in node_list], device=device)\n",
        "    test_idx = torch.tensor([n for n in split_idx['test'] if n in node_list], device=device)\n",
        "\n",
        "    print(train_idx)\n",
        "    print(valid_idx)\n",
        "    print(test_idx)\n",
        "\n",
        "    if args.use_node_embedding:\n",
        "        embedding = torch.load('embedding.pt', map_location='cpu')\n",
        "        x = torch.cat([x, embedding], dim=-1)\n",
        "    x = x.to(device)\n",
        "\n",
        "    y_true = data.y.to(device)\n",
        "    train_idx = split_idx['train'].to(device)\n",
        "\n",
        "    model = MLP(x.size(-1), args.hidden_channels, dataset.num_classes,\n",
        "                args.num_layers, args.dropout).to(device)\n",
        "\n",
        "    evaluator = Evaluator(name='ogbn-arxiv')\n",
        "    logger = Logger(args.runs, args)\n",
        "\n",
        "    for run in range(args.runs):\n",
        "        model.reset_parameters()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "        for epoch in range(1, 1 + args.epochs):\n",
        "            loss = train(model, x, y_true, train_idx, optimizer)\n",
        "            result = test(model, data, {'train': train_idx, 'valid': valid_idx, 'test': test_idx}, evaluator, node_list)\n",
        "            logger.add_result(run, result)\n",
        "\n",
        "\n",
        "            if epoch % args.log_steps == 0:\n",
        "                train_acc, valid_acc, test_acc = result\n",
        "                print(f'Run: {run + 1:02d}, '\n",
        "                      f'Epoch: {epoch:02d}, '\n",
        "                      f'Loss: {loss:.4f}, '\n",
        "                      f'Train: {100 * train_acc:.2f}%, '\n",
        "                      f'Valid: {100 * valid_acc:.2f}%, '\n",
        "                      f'Test: {100 * test_acc:.2f}%')\n",
        "\n",
        "        logger.print_statistics(run)\n",
        "    logger.print_statistics()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "hnqBaEO6Ydn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}