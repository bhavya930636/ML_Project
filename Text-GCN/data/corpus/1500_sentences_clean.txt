unique properties wide minima deep networks well known \( stochastic \) gradient descent implicit bias towards wide minima deep neural network training , mechanism serves minima however , precise effect trained network yet fully understood paper , characterize wide minima linear neural networks trained quadratic loss first , show linear zero initialization necessarily converge minima prove minima nearly balanced networks whereby gain input intermediate representation change drastically one layer next finally , show consecutive layers wide minima solutions coupled , one left singular vectors weight matrix , one right singular vectors next matrix forms distinct path input output , , show , dedicated signal experiences largest gain end end experiments indicate properties characteristic linear nonlinear models trained practice
approximation capacity channels one bit output quantization motivated recent high bandwidth communication systems , inter symbol interference \( \) channels 1 bit quantized output considered average power constrained continuous input exact capacity difficult characterize , approximation matches exact channel output probability error provided approximation additive noise , channel output \( without noise \) threshold absolute value capacity approximation computed using methods involving standard gibbs distributions achievable schemes approaching approximate capacity provided methods used approximate channel result ideas practical coding schemes channels 1 bit output quantization
study angular based embedding learning text independent speaker verification learning good speaker embedding important many automatic speaker recognition tasks , including verification , identification embeddings learned softmax discriminative enough open set verification tasks angular based embedding learning target achieve optimizing angular distance adding margin penalty apply several different popular angular margin embedding learning strategies work explicitly compare performance speaker recognition dataset observing fact encouraging inter class important applying angular based embedding learning , propose inter class regularization complement angular based loss verify effectiveness methods learning discriminative embedding space task several experiments methods together , manage achieve impressive result 16 5 improvement equal error rate \( \) 18 2 improvement minimum detection cost function comparing baseline softmax systems
recurrent exponential family without time exponential family \( \) , extend restricted \( \) bernoulli random variables exponential families \( et al , \) , generative models trained learning techniques , like
3d structure detections present novel method infer , closed form , 3d spatial collection rigid objects given 2d image detections sequence images particular , starting 2d bounding boxes , novel multi view problem estimation \( \) 3d show efficient solution exists dual space using minimum three views algebraic solution affected presence gross bounding boxes estimation end , also propose robust regularization method robust fitting algorithm able improve performance presence errors detected objects results synthetic tests different real datasets , involving real challenging scenarios , demonstrate applicability potential method
variation social media part speech tagging social media features substantial variation , new challenges syntactic analysis online writing however , variation often aligned author attributes age , gender , , well readily available social network metadata paper , report new evidence link language social networks task part speech tagging find error rates correlated network structure , high accuracy parts network , lower accuracy result , accuracy depends training balanced sample network , rather training texts also describe attempts add robustness variation , building mixture experts model expert associated region social network prior work found similar approaches yield performance improvements sentiment analysis entity linking , unable obtain performance improvements part speech tagging , despite strong evidence link part speech error rates social network structure
feature learning incomplete eeg denoising autoencoder alternative human brain communicate outside world means brain computer interface \( bci \) bci decode \( eeg \) signals brain activities , send command intent external interactive device , effectiveness bci depends performance decoding eeg usually , eeg different kinds artefacts \( e g , \( \) , background activity \) , leads low decoding performance number filtering methods utilized remove effects artefacts , generally fail eeg contains extreme artefacts cases , common approach whole data segment containing extreme artefacts causes bci cannot output decoding results time order solve problem , employ estimate spectral power incomplete eeg \( removing parts artefacts \) , denoising autoencoder \( \) learning proposed method evaluated imagery eeg data results show method successfully decode incomplete eeg good effect
supervised unsupervised transfer learning question answering although transfer learning shown successful tasks like object speech recognition , applicability question answering \( qa \) yet well studied paper , conduct extensive experiments investigate knowledge learned source qa dataset target dataset using two qa models performance models comprehension test \( et al , 2016 \) \( et al , 2013 \) significantly improved via simple transfer learning technique \( et al , 2016 \) particular , one models achieves state art target datasets comprehension test , outperforms previous best model 7 finally , show transfer learning helpful even unsupervised scenarios correct answers target qa dataset examples available
entropy rounding method approximation algorithms let matrix , c linear objective function x fractional vector , lp solution discrete optimization problem task theoretical computer science \( approximation algorithms particular \) obtain integral vector roughly c exceeds c x moderate factor r n give new randomized rounding procedure task , provided bounded delta approximate entropy property means uniformly chosen random signs \( j \) 1 , 1 subset columns , outcome approximately described using sub linear number bits expectation r n achieve result , modify well known techniques field discrepancy theory , especially rely 's entropy method , best knowledge never used context approximation algorithms result made constructive using framework based semidefinite programming r n demonstrate procedure rounding fractional solutions column based linear programs generalizations bin packing example obtain polynomial time opt \( log 2 opt \) approximation bin packing first train delivery problem
visual end effector tracking using 3d model aided particle filter humanoid robot platforms paper addresses recursive estimation robot 's end effector using visual observations cameras problem formulated bayesian framework addressed using sequential monte carlo \( smc \) filtering use 3d rendering engine computer aided design \( \) robot create images robot 's camera images used extract information estimate pose end effector aim , developed particle filter estimating position orientation robot 's end effector using histogram oriented gradient \( \) descriptors capture robust characteristic features shapes cameras rendered images implemented algorithm humanoid robot employed closed loop reaching scenario demonstrate tracking robust clutter , allows errors robot arm closed loop using vision
secure face matching using fully homomorphic encryption face recognition technology demonstrated tremendous progress past years , thanks advances representation learning widespread adoption systems , imperative consider security face representations paper , propose data encryption based framework secure databases face representations , goal preventing information leakage preserving privacy users , maintaining 's utility specifically , explore possibility using fully homomorphic encryption based scheme matching face representations directly encrypted domain along dimensionality reduction scheme trade face matching accuracy computational complexity experiments benchmark face datasets \( , , b , \) indicate secure face matching feasible \( 0 per match pair dimensional features \) minimal loss matching performance
evolution embedding metadata blockchain transactions use blockchains growing every day , utility greatly expanded sending smart contracts decentralized autonomous organizations modern blockchains variety applications designing global identity improving satellite connectivity research look ability blockchains store metadata increasing volume transactions evolving focus utilization show basic approaches improving blockchain privacy also rely embedding metadata paper identifies real life blockchain transactions embedding metadata number major protocols running essentially bitcoin blockchain empirical analysis presents evolution metadata utilization recent years , discussion suggests steps towards preventing use metadata relevant blockchain , analysis considers primarily bitcoin case study paper concludes simultaneously expanding legitimate utilization embedded metadata expanding blockchain functionality , applied research improving security must also attempt protect blockchain
self improving algorithms investigate ways algorithm improve expected performance fine tuning automatically respect unknown input distribution mathcal assume mathcal product type precisely , need process sequence 1 , 2 , ldots inputs \( x 1 , x 2 , ldots , x n \) fixed length n , x drawn independently arbitrary , unknown distribution mathcal goal design algorithm inputs eventually expected running time optimal input distribution mathcal mathcal give self improving algorithms two problems \( \) sorting sequence numbers \( ii \) computing triangulation planar point set algorithms achieve optimal expected limiting complexity algorithms training phase collect information input distribution , followed stationary regime algorithms optimized
transfer learning brain computer interfaces adversarial variational autoencoders introduce adversarial neural networks representation learning novel approach transfer learning brain computer interfaces \( \) proposed approach aims learn subject invariant representations simultaneously training conditional variational autoencoder \( \) adversarial network use shallow convolutional architectures realize , learned encoder transferred extract subject invariant features unseen bci users' data decoding demonstrate proof concept approach based analyses \( eeg \) data imagery bci experiment
capacity memoryless adversary paper , study model communication adversarial noise model , adversary makes online decisions whether transmitted bit based value bit like usual binary symmetric channel information theory fully adversarial channel combinatorial coding theory , adversary , high probability , introduce given fraction error r n shown , capacity \( maximum rate reliable information transfer \) memoryless adversary strictly binary symmetric channel give new upper bound capacity channel upper bound remains open question main component proof examination error correcting properties code skewed distance distribution
log opt approximation covering packing minor models theta r given two graphs g h , define textsf v cover h \( g \) \( resp textsf e cover h \( g \) \) minimum number vertices \( resp edges \) whose removal g produces graph without minor h also textsf v pack h \( g \) \( resp textsf v pack h \( g \) \) maximum number vertex \( resp edge \) disjoint subgraphs g contain minor h denote theta r graph two vertices r parallel edges h theta r , parameters textsf v cover h , textsf e cover h , textsf v pack h , textsf v pack h np hard compute \( sufficiently big values r \) upon combinatorial results graphs large theta r , et al , arxiv , give algorithmic proof textsf v pack theta r \( g \) leq k , textsf v cover theta r \( g \) \( k log k \) , similarly textsf v pack theta r textsf e cover theta r words , class graphs containing theta r minor vertex edge h p property , every positive integer r using algorithmic proofs , introduce unified approach design \( log rm opt \) approximation algorithm textsf v pack theta r , textsf v cover theta r , textsf v pack theta r , textsf e cover theta r runs \( n cdot log \( n \) cdot \) steps also , derive several new h p type results techniques introduce
analysis study time synchronization protocols wireless sensor networks one main problems wireless sensor networks \( wsn \) maintain communication sharing cooperative processing sensors via radio links ensure reliable treatment information many applications based consider local sensor node need common notion time context , majority previous researches focused study protocols , algorithms address issues order resolve synchronization problems previous empirical studies wireless sensor network \( wsn \) proposed several solutions \( algorithms \) focus paper examine evaluate important synchronization algorithms based positions various quantitative qualitative synchronization protocols energy efficient information processing routing
approximating dynamic time edit distance pair point sequences give first subquadratic time approximation schemes dynamic time \( \) edit distance \( ed \) several natural families point sequences mathbb r , fixed ge 1 particular , algorithms compute \( 1 varepsilon \) approximations ed time near linear point sequences drawn k packed k bounded curves , subquadratic backbone sequences roughly speaking , curve kappa packed length intersection ball radius r kappa cdot r , curve kappa bounded sub curve two curve points go far two points compared distance two points backbone sequences , consecutive points approximately equal distances apart , two points lie close together recent results suggest subquadratic algorithm ed arbitrary pair point sequences even 1 algorithms work constructing small set regions cover entries dynamic programming table commonly used distance measures weights entries inside roughly , able use efficient procedures approximately compute paths rectangles
joint space workspace analysis two dof closed chain aim paper compute generalized aspects , e maximal free domains cartesian product joint space workspace , planar parallel mechanism using model interval analysis based method parallel mechanisms admit several solutions direct kinematic models singular configurations divide joint space workspace several connected domains compute domains , model made using space unfortunately , method , singular configurations cannot detected single point joint space interval analysis based method allow us singularities found reduce computing times approach tested simple planar parallel mechanism two degrees freedom
algorithms non linear stochastic resource constrained shortest paths resource constrained shortest path problems usually solved label algorithms , consist smart enumeration non paths recent improvements algorithms rely use bounds path resources partial solutions quality bounds determines performance algorithm main contribution paper introduce standard procedure generate bounds paths resources general setting covers resource constrained shortest path problems , among stochastic versions r n purpose , introduce generalization resource constrained shortest path problem resources taken resource path sum resources problem consists finding path whose resource minimizes non decreasing cost function path resource among paths respect given constraint label algorithms generalized framework use lattice theory provide polynomial procedure find good quality bounds efficiency approach proved extensive numerical study case stochastic resource constrained shortest path problem
learning across scales multiscale method convolution neural networks work establish relation optimal control training deep convolution neural networks \( cnns \) show forward propagation cnns interpreted time dependent nonlinear differential equation learning controlling parameters differential equation network approximates data label relation given training data using continuous interpretation derive two new methods scale cnns respect two different dimensions first class multiscale methods low resolution high resolution data restriction cnn parameters demonstrate enables classifying high resolution images using cnns trained low resolution images vice versa starting learning process second class multiscale methods shallow deep networks leads new training strategies increase cnn using parameters
human action localization sparse spatial supervision introduce approach spatio temporal human action localization using sparse spatial supervision method leverages large amount annotated humans available today human tubes combining state art human detector tracking detection approach given high quality human tubes temporal supervision , select positive negative tubes sparse spatial supervision , e , one spatially annotated frame per instance selected tubes allow us effectively learn spatio temporal action detector based dense trajectories cnns conduct experiments existing action localization benchmarks , j results show approach , despite using sparse spatial supervision , performs par methods using full supervision , e , one bounding box annotation per frame r n validate method , introduce \( daily action localization \) , dataset realistic action localization space time contains high quality temporal spatial annotations 3 instances 10 actions 31 hours videos \( 3 frames \) order magnitude larger existing datasets , diversity appearance long videos
iris recognition death paper presents comprehensive study post mortem human iris recognition carried 1 , 200 near infrared 1 , visible light samples collected individuals conditions used four independent iris recognition methods \( three commercial one academic \) analyze comparison scores check dynamics iris quality decay period hours death study shows post mortem iris recognition may close perfect approximately 5 7 hours death still viable even 21 days death conclusions present past literature iris death , show dynamics post mortem changes iris important biometric identification moderate previously paper contains medical helps understand post mortem eye may impact performance automatic iris recognition also show post mortem iris recognition works equally well images taken near infrared channel visible light sample used however , cross matching presents significantly worse performance paper research database used study made publicly available facilitate research post mortem iris recognition knowledge , paper offers comprehensive evaluation post mortem iris recognition largest database post mortem iris images
improved quantum ldpc decoding strategies quantum channel quantum cryptography via key distribution mechanisms utilize quantum entanglement sender receiver pairs form basis future large scale quantum networks key engineering challenge networks ability correct effects distributed entanglement resources widely believed sophisticated quantum error correction codes , quantum low density parity check \( ldpc \) codes , role however , recently importance channel effect performance deployed quantum ldpc codes work help situation proposing new quantum ldpc decoding strategies significantly reduce performance degradation much 50 new strategies quantum ldpc decoder based previous insights classical ldpc decoders channels , performance known function estimated channel noise show similar carry quantum channel , estimate flip parameter weighted larger values leads significant performance improvement
rate statistics cellular downlink vs adaptive modulation coding letter , focus coded adaptive transmission cellular downlink based stochastic geometry model locations bss , evaluate meta distribution rate , e , distribution rate conditioned point process accurate approximation distribution per user rate proposed clearly shown provide good match simulation results quantify gain per user rate due physical layer codes relative fixed rate adaptive modulation coding
goal driven query answering rules inspired sets , present novel goal driven approach answering queries rules \( \) technique improves performance query answering pruning consequences relevant query challenging setting potentially affect predicates dataset address problem combining existing technique two new algorithm identifying rules relevant query new sets algorithm show empirically technique significantly improve performance query answering , mean difference answering query seconds able process query
generative adversarial self imitation learning paper explores simple regularizer reinforcement learning proposing generative adversarial self imitation learning \( gasil \) , encourages agent past good trajectories via generative adversarial imitation learning framework instead directly maximizing rewards , gasil focuses reproducing past good trajectories , potentially make long term assignment easier rewards sparse delayed gasil easily combined policy gradient objective using gasil learned shaped reward function experimental results show gasil improves performance proximal policy optimization 2d point mass mujoco environments delayed reward stochastic dynamics
complexity modification problems best match graphs best match graphs \( \) vertex colored graphs whose vertices represent genes colors species genes edges identify pairs genes closely related respect underlying evolutionary tree practical applications tree unknown edges quantifying sequence similarity due noise data , empirically determined graphs general condition therefore , practical interest computational biology correct initial estimate consider deletion \( remove k edges \) editing \( add k edges \) problems show decision version deletion editing problem obtain vertex colored graphs np hard using known results called editing , show editing problem 2 colored graphs fixed parameter tractable r n restricted class appears context detection specific type vertex coloring known hierarchical coloring show decision problem modifying vertex colored graph \( either edge deletion editing \) structure , equivalently , colored np complete
sensors overlapping signals concept investigation planar sensors optical transduction traditional methods achieving high localization accuracy tactile sensors usually involve matrix individual sensors distributed area interest approach usually comes price increased complexity , hard adapt non planar propose method sensing terminals embedded volume soft material mechanical material results signal two given terminals multiple terminals pairing possible combinations , obtain rich signal set using wires mine data learn mapping signals extract contact parameters interest approach general enough applied different transduction methods , achieves high accuracy identifying location depth moreover , method simple techniques makes assumption underlying geometry , potentially simplifying future integration robot hands
multi source cross lingual model transfer learning share modern nlp applications great boost utilizing neural networks models deep neural models , however , applicable human languages due lack annotated training data various nlp tasks cross lingual transfer learning \( \) viable method building nlp models low resource target language leveraging labeled data \( source \) languages work , focus multilingual transfer setting training data multiple source languages boost target language performance r n unlike existing methods rely language invariant features , approach utilizes language invariant language specific features instance level model leverages adversarial networks learn language invariant features , mixture experts models dynamically exploit similarity target language individual source language enables model learn effectively share various languages multilingual setup moreover , coupled unsupervised multilingual embeddings , model operate zero resource setting neither target language training data cross lingual resources available model achieves significant performance gains prior art , shown extensive set experiments multiple text classification sequence tagging tasks including large scale industry dataset
role commutativity constraint propagation algorithms constraint propagation algorithms form important part constraint programming systems provide simple , yet general framework allows us explain several constraint propagation algorithms systematic way framework two steps first , introduce generic iteration algorithm partial prove correctness abstract setting algorithm specific partial functions obtain specific constraint propagation algorithms r n particular , using notions commutativity semi commutativity , show ac 3 , 2 , dpc algorithms achieving \( directional \) arc consistency \( directional \) path consistency instances single generic algorithm work reported extends
quantum versus classical communication complexity work addresses two problems context two party communication complexity functions first , concludes line research , viewed demonstrating qualitative advantage quantum communication three common communication two way interactive communication one way communication simultaneous message passing \( smp \) demonstrate functional problem , whose communication complexity \( \( log n \) 2 \) quantum version smp tilde omega \( sqrt n \) classical \( \) version smp r n second , work contributes understanding power commonly studied regime quantum communication smp quantum messages without shared randomness \( latter restriction viewed artificial way making quantum model weak possible \) function efficient solution regime well , means even lacking shared randomness , quantum smp exponentially stronger classical counterpart shared randomness
fully attention based information recurrent neural networks state art natural language processing build rich contextual representations process texts arbitrary length however , recent developments attention mechanisms equipped networks similar capabilities , hence enabling faster computations due increase number operations explore new type architecture domain question answering propose novel approach call fully attention based information \( \) show achieves competitive results stanford question answering dataset \( squad \) fewer parameters faster learning inference methods
efficient local search minimum independent dominating set problem present paper , propose efficient local search minimum independent dominating set problem consider local search uses k swap neighborhood operation given feasible solution , operation obtaining another feasible solution dropping exactly k vertices adding number vertices show , k 2 , \( resp , k 3 given solution minimal respect 2 swap \) , find improved solution neighborhood conclude solution exists \( n delta \) \( resp , \( n delta 3 \) \) time , n denotes number vertices delta denotes maximum degree develop algorithm proposed local search search iteratively algorithm effective updates best known upper bound nine graphs
dual active sampling batch incremental active learning recently , convolutional neural networks \( cnns \) shown unprecedented success field computer vision , especially challenging image classification tasks relying universal approach , e , training deep model massive dataset supervised examples unlabeled data often resource , collecting large set labeled data , hand , expensive , often require considerable human efforts one way effectively select label highly informative instances pool unlabeled data \( e , active learning \) paper proposed new method batch mode active learning , dual active sampling \( \) , based simple assumption , two deep neural networks \( dnns \) structure trained dataset give significantly different output given sample , particular sample additional training state art methods field usually require intensive computational power relying complicated structure , simpler implement , managed get improved results cifar 10 computational time compared core set method
computing optimal faster study following combinatorial problem given set n monotone wires , determines order wires number horizontal layers orders wires two consecutive layers differ neighboring wires given multiset l \( , pairs numbers 1 n \) initial order wires , l pair wires changes order exactly many times specified l aim find l using smallest number layers show problem np hard , give algorithm computes optimal n wires given list l \( \( 2 l n 2 1 \) n 2 2 cdot n cdot n \) time , 1 ratio treat lists every swap occurs \( n ! n \) time implemented algorithm general case compared existing algorithm finally , discuss feasibility lists simple structure
software module clustering based fuzzy adaptive teaching learning based optimization algorithm although showing competitive performances many real world optimization problems , teaching learning based optimization algorithm \( \) poor control exploration exploitation addressing issues , new variant called adaptive fuzzy teaching learning based optimization \( \) developed literature paper describes adoption fuzzy adaptive fuzzy teaching learning based optimization \( \) software module clustering problem comparative studies original teaching learning based optimization \( \) fuzzy variant demonstrate gives superior performance owing adaptive selection search operators based need current search
human computer interface design quantitative measure regret theory regret theory theory describes human decision making risk key obtaining quantitative model regret theory measure preference mind choose among set options unlike physical quantities , measuring psychological preference procedure invariant , e methods change work , alleviate influence choosing procedure compatible way individual makes choice believe resulting model closer nature human decision making preference process decomposed series short surveys reduce cognitive increase response accuracy make questions natural subjects , follow insight humans generate , quantify communicate preference natural language fuzzy set theory hence utilized model responses subjects based ideas , graphical human computer interface \( \) designed information well efficiently collect human responses design also accounts human heuristics biases , e g range effect effect , enhance reliability overall performance survey satisfactory measured model shows prediction accuracy equivalent revisit performance subjects
cyber physical security game theory model humans interacting control systems recent years seen increased interest design deployment smart grid devices control algorithms smart communicating devices represents potential access point research detection however , security measures complete , attackers compromise smart grid devices leading attacker system operator interacting via grid control systems outcome machine human human interactions depend design physical control systems interactions outcomes predicted via simulation , used tool designing attack resilient grids control systems however , accurate predictions require good models physical control systems , also human decision making , present approach develop tools , e , models decisions cyber physical attacking systems system operator defending , demonstrate usefulness design
toward co existing database schemas based bidirectional transformation according strong demands rapid reliable software delivery , co existing database schema versions multiple application versions reality contribute current database management systems support co existing schema versions one database although design co existing schema based view tables previously proposed , flexibility limited due pre defined several restrictions achieve data synchronization among schemas handling independent data schema preliminary report , present new approach co existing schemas based bidirectional transformation explain required properties realize co existing schemas , show co existing schemas implemented systematically applying based bidirectional transformation satisfy satisfied applying bidirectional transformation , satisfy , extra functions need introduced derive extra functions presented
simulation based computation certificates safety dynamical systems paper , present algorithm synthesizing certificates called barrier certificates safety hybrid dynamical systems unlike usual approach using constraint solvers compute certificate system dynamics , synthesize certificate system simulations makes algorithm applicable even cases dynamics either explicitly available , complicated analyzed constraint solvers , example , due presence function symbols r n algorithm allows usage heuristic techniques case formally guarantee correctness result however , cases allow rigorous constraint solving , computed barrier certificate verified , desired hence , cases , algorithm reduces problem finding barrier certificate problem formally verifying given barrier certificate
block wise asynchronous distributed admm algorithm general form consensus optimization many machine learning models , including non smooth , formulated consensus optimization problems , solved alternating direction method multipliers \( admm \) many recent efforts made develop asynchronous distributed admm handle large amounts training data however , existing asynchronous distributed admm methods based full model updates require global model parameters handle concurrency , essentially updates different workers paper , present novel block wise , asynchronous distributed admm algorithm , allows different blocks model parameters updated parallel lock free block wise algorithm may greatly speedup sparse optimization problems , common scenario reality , model updates modify subset decision variables theoretically prove convergence proposed algorithm stationary points non convex general form consensus problems possibly non smooth implement proposed admm algorithm parameter server framework demonstrate convergence near linear speedup performance number workers increases
pi rcnn efficient multi sensor 3d object detector point based attentive fusion module lidar point clouds rgb images extremely essential 3d object detection many state art 3d detection algorithms fusing two types data effectively however , fusion methods based eye view \( \) voxel format accurate paper , propose novel fusion approach named point based attentive fusion \( pacf \) module , multi sensor features directly 3d points except continuous convolution , additionally add point pooling attentive aggregation make fused features expressive moreover , based pacf module , propose 3d multi sensor multi task network called image rcnn \( pi rcnn \) , handles image segmentation 3d object detection tasks pi rcnn employs segmentation sub network extract full resolution semantic feature maps images multi sensor features via powerful pacf module beneficial effectiveness pacf module expressive semantic features segmentation module , pi rcnn improve much 3d object detection demonstrate effectiveness pacf module pi rcnn kitti 3d detection benchmark , method achieve state art metric 3d ap
streaming video http consistent quality conventional http based adaptive streaming \( \) , video source encoded multiple levels constant bitrate representations , client makes representation according measured network bandwidth greatly simplifying adaptation varying network conditions , strategy best optimizing video quality experienced end users quality reduced natural variability video content taken consideration work , study design client rate adaptation algorithm yield consistent video quality assume clients incoming video within finite horizon also take advantage client side video buffer , using room network bandwidth variability , also video bitrate variability challenge , however , lies balance two yield consistent video quality without buffer propose optimization solution uses online algorithm adapt video bitrate step step , applying dynamic programming step incorporate solution practical rate adaptation algorithm designed deployment scale
cross domain system mapping arbitrary phrases taxonomy electronic health record \( \) systems used extensively throughout healthcare domain however , data systems limited due use different coding standards across systems existing methods mapping coding standards based manual human experts mapping , dictionary mapping , symbolic nlp classification cannot accommodate large scale datasets r n work , present , cross domain mapping system capable mapping medical phrases concepts large taxonomy \( ct \) system designed generalize limited set training samples map phrases elements taxonomy covered training data result , system scalable , robust variants coding systems output highly relevant concepts exact concept exists target taxonomy operates three main stages first , lexicon mapped word embeddings second , taxonomy using node embeddings finally , mapping function trained connect two embedding spaces compared multiple algorithms architectures stage training , including word embeddings , cnn bi lstm mapping functions , node embeddings confirmed robustness properties mapping 9 cm diagnosis phrases ct zero shot training comparable accuracy r n system novel contribution task linking phrases taxonomy , data healthcare applied , system use electronic health records generate embedding incorporates medical knowledge improve clinical predictive models
fractional repetition erasure batch codes batch codes family codes represent distributed storage system \( \) n nodes batch data symbols retrieved reading one symbol node fractional repetition codes family codes enable efficient failed nodes work two families codes combined obtain fractional repetition batch \( \) codes provide parallel reads subsets stored symbols addition , new batch codes node failures considered new family batch codes called erasure combinatorial batch codes \( \) properties codes examples constructions based designs affine presented
accurate visual localization automotive applications accurate vehicle localization crucial step towards building effective vehicle vehicle networks automotive applications yet standard grade gps data , provided mobile phones , often noisy exhibits significant localization errors many urban areas approaches accurate localization imagery often rely structure based techniques , thus limited scale expensive compute paper , present scalable visual localization approach real time performance propose hybrid coarse fine approach leverages visual gps location cues solution uses self supervised approach learn compact road image representation representation enables efficient visual retrieval provides coarse localization cues , fused vehicle motion obtain high accuracy location estimates benchmark evaluate performance visual localization approach , introduce new large scale driving dataset based video gps data obtained large scale network connected experiments confirm approach highly effective challenging urban environments , reducing localization error order magnitude
accurate pulmonary nodule detection computed images using deep convolutional neural networks early detection pulmonary cancer promising way enhance patient 's accurate pulmonary nodule detection computed \( ct \) images crucial step pulmonary cancer paper , inspired successful use deep convolutional neural networks \( \) natural image recognition , propose novel pulmonary nodule detection approach based first introduce structure faster region based convolutional neural network \( faster r cnn \) candidate detection slices , three dimensional presented subsequent false positive reduction experimental results nodule analysis 2016 \( \) challenge demonstrate superior detection performance proposed approach nodule detection \( average score 0 , ranking place results \)
preventing posterior collapse sequence vaes pooling variational autoencoders \( vaes \) hold great potential modelling text , could theory separate high level semantic syntactic properties local natural language , however , vaes autoregressive decoders often suffer posterior collapse , phenomenon model learns ignore latent variables , sequence vae language model previous works attempt solve problem complex architectural changes costly optimization schemes paper , argue posterior collapse caused part encoder network capture input verify hypothesis empirically propose straightforward using pooling simple technique effectively posterior collapse , allowing model achieve significantly better data log likelihood standard sequence vaes compared previous preventing posterior collapse , able achieve comparable performances significantly faster
empirical study community detection algorithms social road networks community detection social networks problem considerable interest , since , discovering communities reveals hidden information networks exist many algorithms detect inherent community structures recently investigated social networks however , non trivial decide best approach presence diverse nature graphs , terms density sparsity , inadequate analysis results therefore , study , analyze compare various algorithms detect communities two networks , namely social road networks , varying structural properties algorithms consideration evaluated unique metrics internal external connectivity communities includes internal density , average degree , cut ratio , conductance , normalized cut , average jaccard index evaluation results revealed key insights selected algorithms underlying community structures
propagation complete encodings smooth dnnf theories investigate normal form \( \) encodings function represented smooth normal form \( dnnf \) several encodings decision diagrams considered \( et al 2016 \) authors differentiate encodings implement consistency domain consistency encodings implement unit completeness propagation completeness \( cases implements means unit propagation \) difference former case care properties encoding respect auxiliary variables latter case treat variables \( input ones auxiliary ones \) way latter case useful dnnf part problem containing also constraints sat solver used test currently known encodings smooth dnnf theories implement domain consistency building result \( et al 2016 \) encoding decision diagrams implements propagation completeness , present new encoding smooth dnnf implements propagation completeness gap left open literature encodings
recovery repair schemes shift xor regenerating codes recovery repair schemes proposed shift \( shift xor \) product matrix \( pm \) regenerating codes , outperform existing pm codes terms communication computation costs particular , minimum bandwidth regenerating \( \) codes , recovery repair schemes optimal transmission bandwidth , zero decoding auxiliary data space lower time complexity minimum storage regenerating \( msr \) codes , recovery repair schemes smaller transmission bandwidth , smaller decoding auxiliary data space lower time complexity moreover , schemes involve xor operations recovery repair practical system implementation , procedure first proposed solving system shift xor equations , plays similar fundamental role gaussian elimination solving systems linear equations , independent interest recovery repair shift xor msr codes decomposed sequence systems shift xor equations , hence solved sequence calls procedure solving system shift xor equations decomposition recovery repair depends pm construction , specific shift xor operations , recovery repair schemes extended msr codes using pm construction
ensemble based approach click rate prediction listings global people across world connect make , buy unique goods product listings via advertising campaigns similar traditional search ads click rate \( \) prediction integral part online search advertising systems utilized input auctions determine final ranking listings particular user query paper , provide holistic view 's prediction system propose ensemble learning approach based historical behavioral signals listings well content based features new listings obtain representations texts images utilizing state art deep learning techniques employ multimodal learning combine different signals compare system non trivial baselines large scale real world dataset , demonstrating effectiveness model strong correlations offline experiments online performance paper also first technical overview kind product e commerce context
incorporating global visual features attention based neural machine translation introduce multi modal , attention based neural machine translation \( nmt \) models incorporate visual features different parts encoder decoder global image features extracted using pre trained convolutional neural network incorporate \( \) words source sentence , \( ii \) encoder hidden state , \( iii \) additional data decoder hidden state experiments , evaluate different strategies incorporate global image features compare ones perform best also study impact adding synthetic multi modal , multilingual data find additional data positive impact multi modal models report new state art results best models also significantly improve comparable phrase based statistical mt \( \) model trained data set according metrics evaluated best knowledge , first time purely neural model significantly improves model metrics evaluated data set
high diversity attribute guided face generation gans work focused gan based solution attribute guided face synthesis previous works exploited gans generation photo realistic face images attention question diversity resulting images proposed solution turn introducing novel latent space unit complex numbers able provide diversity score 3 times higher size training dataset important result shown relatively small dataset \( samples vs \) preserving photo realistic properties generated faces significantly higher resolution \( comparison previous works \)
hybrid forest concept aware data stream mining algorithm nowadays growing number online controlling systems organization also high demand monitoring uses data streams log control , data stream mining becomes vital trees \( also called fast decision trees k \) big data approach dealing data stream classification regression problems showed good performance handling facing challenges making possibility time prediction although methods outperform methods e g artificial neural networks \( \) support vector regression \( \) , suffer high latency adapting new concepts statistical distribution incoming data changes article , introduced new algorithm detect handle concept phenomenon properly algorithms also benefits fast ability helps systems able predict faster algorithms data stream arrival also shown approach approaches classification regression tasks
self supervised representation learning signals supervised learning paradigm limited cost sometimes data collection labeling multiple domains self supervised learning , paradigm exploits structure unlabeled data create learning problems solved standard supervised approaches , shown great promise pretraining feature learning approach fields like computer vision time series processing work , present self supervision strategies used learn informative representations multivariate time series one successful approach relies predicting whether time sampled temporal context demonstrated relevant task \( sleep scoring \) two datasets , approach outperforms purely supervised approach low data regimes , capturing important information without access labels
heuristic probabilistic k median problem develop heuristic probabilistic euclidean k median problem based construction et al algorithm computes summary data uses adapted version k means \( , \) compute good solution summary summary maintained data stream , used data stream setting large data sets experimentally evaluate quality summary computed solution compare running time state art data stream clustering algorithms
tractable minor free generalization planar zero field ising models present new family zero field ising models n binary variables obtained consecutive planar \( 1 \) sized components subsets three vertices tree polynomial time algorithm dynamic programming type solving exact inference \( computing partition function \) exact sampling \( generating samples \) consists sequential application efficient \( planar \) brute force \( \( 1 \) sized \) inference sampling components black box illustrate utility new family tractable graphical models , first build polynomial algorithm inference sampling zero field ising models k 3 , 3 minor free topologies k 5 minor free topologies extensions planar zero field ising models neither treewidth bounded second , demonstrate empirically improvement approximation quality np hard problem inference square grid ising model node dependent non zero magnetic field
intrinsic dimension application association rules curse dimensionality association rules firstly , well known exponential increase computational complexity increasing item set size secondly , emph related curse distribution \( \) data high dimension former problem often projection , e , feature selection , whereas best known strategy latter avoidance work first attempt provide computationally feasible method measuring extent dimension curse present data set respect particular class machine learning procedures recent development enables application various methods geometric analysis investigated applied machine learning procedures presence high dimension
ithemal accurate fast basic block throughput estimation using deep neural networks predicting number clock cycles processor takes execute block assembly instructions steady state \( throughput \) important compiler designers performance engineers building analytical model especially complicated modern 64 complex instruction set computer \( \) machines sophisticated processor tedious , error prone , must performed scratch processor generation paper present ithemal , first tool learns predict throughput set instructions ithemal uses hierarchical lstm based approach predict throughput based instructions basic block show ithemal accurate state art hand written tools currently used compiler static machine code particular , model less half error state art analytical models \( 's mca intel 's \) ithemal also able predict throughput values fast aforementioned tools , easily across variety processor minimal effort
learning video representations without single labeled video video recognition models significantly past years , evolving shallow classifiers trained hand crafted features deep spatiotemporal networks however , labeled video data required train models able keep ever increasing depth networks work , propose alternative approach learning video representations require semantically labeled videos instead leverages years effort collecting labeling large clean still image datasets using state art models pre trained image datasets train video models distillation framework demonstrate method learns truly spatiotemporal features , despite trained using supervision still image networks moreover , learns good representations across different input modalities , using completely raw video data sources different 2d teacher models method obtains strong transfer performance , outperforming standard techniques bootstrapping video architectures image based models 16 believe approach opens new approaches learning spatiotemporal representations unlabeled video data
scalable deep neural network architecture multi building multi floor indoor localization based wi fi fingerprinting one key technologies future large scale location aware services covering complex multi scalable indoor localization technique paper , report current status investigation use deep neural networks \( dnns \) scalable building floor classification floor level position estimation based wi fi fingerprinting exploiting hierarchical nature building floor estimation floor level coordinates estimation location , propose new dnn architecture consisting stacked autoencoder reduction feature space dimension feed forward classifier multi label classification building floor location , multi building multi floor indoor localization system based wi fi fingerprinting built evaluate performance building floor estimation floor level coordinates estimation given location using dataset covering three four five university \( \) , experimental results demonstrate feasibility proposed dnn based indoor localization system , provide near state art performance using single dnn proposed scalable dnn architecture multi building multi floor indoor localization based wi fi fingerprinting achieve near state art performance single dnn enables implementation lower complexity energy consumption mobile devices
complexity results fast methods optimal rearrangement grasps paper studies underlying combinatorial structure class object rearrangement problems , appear frequently applications problems involve multiple , similar geometry objects placed flat , horizontal surface , robot approach perform place operations paper considers case start goal object poses overlap , overlapping poses , primary objective minimize number place actions minimize distance end effector non overlapping case , objective solely minimize travel distance end effector problems involve complexities general rearrangement , remain computationally hard cases shown reductions well understood , hard combinatorial challenges rearrangement problems reductions also shown hold reverse direction , enables convenient application rearrangement well studied algorithms algorithms efficient practice despite hardness results paper builds reduction results propose algorithmic pipeline dealing rearrangement problems experimental evaluation , including hardware based trials , shows proposed pipeline computes high quality paths optimization objectives furthermore , exhibits highly desirable scalability number objects increases overlapping non overlapping setup
mixed strategies crowdsourcing popular crowdsourcing techniques mostly focus evaluating labeling quality adjusting weights label aggregation recently , another models regard annotations incomplete tensors recover labels tensor completion however , mixed strategies two methodologies never investigated , rather independent approaches work , propose textit \( c \) , framework integrating arbitrary conventional crowdsourcing tensor completion techniques particular , propose novel iterative label aggregation algorithm outperforms state art methods extensive experiments
approximate bayesian image interpretation using generative probabilistic graphics programs idea computer vision bayesian inverse problem computer graphics long history appealing , proved difficult directly implement instead , vision tasks via complex bottom processing pipelines show possible write short , simple probabilistic graphics programs define flexible generative models automatically interpret real world images generative probabilistic graphics programs consist stochastic scene generator , based graphics software , stochastic likelihood model linking 's output data , latent variables adjust fidelity tolerance likelihood model representations algorithms computer graphics , designed produce high quality images , instead used deterministic backbone highly approximate stochastic generative models formulation combines probabilistic programming , computer graphics , approximate bayesian computation , depends general purpose , automatic inference techniques describe two applications reading sequences degraded characters , inferring 3d road models vehicle mounted camera images probabilistic graphics programs present relies 20 lines probabilistic code , supports accurate , approximately bayesian ambiguous real world images
policy policy policy optimization policy reinforcement learning \( rl \) algorithms high sample complexity policy algorithms difficult merging two holds promise develop efficient algorithms generalize across diverse environments however challenging practice find suitable hyper parameters trade paper simple algorithm named policy updates policy updates uses effective sample size behavior policy target policy control far introduce additional hyper parameters extensive experiments mujoco benchmark show simple technique effective reducing sample complexity state art algorithms code experiments paper https url
sparse lattice networks point cloud processing present network architecture processing point clouds directly operates collection points represented sparse set samples high dimensional lattice applying convolutions lattice scales poorly , terms memory computational cost , size lattice increases instead , network uses sparse bilateral convolutional layers building blocks layers maintain efficiency using indexing structures apply convolutions parts lattice , allow flexible specifications lattice structure enabling hierarchical spatially aware feature learning , well joint 2d 3d reasoning point based image based representations easily incorporated network layers resulting model trained end end manner present results 3d segmentation tasks approach outperforms existing state art techniques
experimental resilience assessment open source driving agent autonomous vehicles \( av \) depend sensors like radar camera perception environment , path planning , control increasing interactions complex environment , growing concerns regarding safety reliability avs paper presents systems theoretic process analysis \( \) based fault injection framework assess resilience open source driving agent , called , different environmental conditions faults sensor data increase coverage scenarios testing , use strategic software fault injection approach faults derived scenarios identified high level analysis system experimental results show proposed strategic fault injection approach increases coverage compared random fault injection , thus , help effective simulation safety critical faults testing avs addition , paper provides insights performance safety mechanisms ability timely detection recovery faulty inputs
optimizing precision open world website fingerprinting traffic analysis attacks identify web page client browsing , using packet metadata known website fingerprinting proven effective closed world experiments privacy technologies like tor however , due base rate , attacks failed large open world settings clients visit sensitive pages low base rate find poor precision designed maximize recall r n work , argue precision important recall open world website fingerprinting reason , develop three classes em precision , based confidence , distance , ensemble learning , applied classifier increase precision test known website fingerprinting attacks show significant improvements precision difficult scenario , attacker monitor distinguish 100 sensitive pages low mean base rate 0 , best optimized classifier achieve precision 0 78 highest precision known attack optimization 0 use precise classifiers tackle realistic objectives website fingerprinting , including selection , identification , website fingerprinting defenses
statistical filtering defending adversarial examples deep learning algorithms known vulnerable adversarial perturbations various tasks image classification problem addressed employing several defense methods detection particular types attacks however , training manipulating networks according particular defense schemes increases computational complexity learning algorithms work , propose simple yet effective method improve robustness convolutional neural networks \( cnns \) adversarial attacks using data dependent adaptive convolution kernels end , propose new type order employ statistical properties input data features computation statistical adaptive maps , filter convolution weights cnns learned statistical maps compute dynamic kernels thereby , weights kernels optimized learning image classification models robust adversarial attacks without additional target detection algorithms empirically demonstrate proposed method enables cnns different types attacks , e g attacks generated gaussian noise , fast gradient sign methods \( et al , 2014 \) black box attack \( , 2016 \)
subcarrier pairing channel gain joint resource allocation relay assisted secure untrusted users joint resource allocation involving optimization subcarrier allocation , subcarrier pairing \( scp \) , power allocation cooperative secure orthogonal frequency division multiple access \( \) communication system untrusted users considered forward \( af \) , decode forward \( \) modes operations considered individual power budget constraints source relay finding optimal subcarrier allocation af system , prove joint power allocation generalized convex problem , solve optimally compared conventional channel gain matching view , optimal scp novel concept channel gain prove optimal scp pairs variance among effective channel gains minimized system , show depending power budgets source relay , scp either role improves energy efficiency , main role improves spectral efficiency system af system confirm scp plays crucial role , improves spectral efficiency system channel gain property scp , various roles scp improving spectral energy efficiency cooperative communication system validated help simulation results
interval edge colorings complete graphs edge coloring graph g colors 1 , 2 , ldots , interval coloring colors used , colors edges vertex g distinct form interval graph g interval colorable interval coloring positive integer interval colorable graph g , w \( g \) denotes value g interval coloring known complete graph interval colorable number vertices even however , exact value w \( k 2n \) known n leq 4 second author showed n q , p odd q nonnegative , w \( k 2n \) geq 2 p q later , n mathbb n , w \( k 2n \) 2 left log 2 n right left n 2 right , left n 2 right number 1 's binary representation n r n paper introduce new technique construct interval colorings complete graphs based 1 , used conjecture , improve lower upper bounds w \( k 2n \) determine exact values n leq 12
little guarantees almost envy freeness fair division goods well studied problem goal problem goods n agents fair manner , every agent valuation subset goods assume general valuations r n envy freeness extensively studied notion fairness however , envy free allocations always exist goods notion fairness consider envy freeness good \( \) agent another agent removal single good agent 's known allocation always exists even n 3 r n show always partition set goods n 1 subsets \( x 1 , ldots , x n , p \) n , x agent set p \( \) r n 1 \) envy freeness good , r n 2 \) agent values p higher , r n 3 \) fewer n goods go , e , p n \( typically n \) r n proof constructive agents additive valuations p large \( e , p close n \) , allocation also good maximin share \( \) guarantee moreover , minor variant algorithm also shows existence allocation 4 7 maximin share \( \) notion fairness stronger improves upon current best bound 1 2 known approximate allocation
performance analysis cognitive radio systems imperfect channel sensing estimation cognitive radio systems , employing sensing based spectrum access strategies , secondary users required perform channel sensing order detect activities primary users realistic scenarios , channel sensing occurs possible errors due miss detections false another challenge , time varying fading conditions channel secondary transmitter secondary receiver learned via channel estimation paper , performance causal channel estimation methods correlated cognitive radio channels imperfect channel sensing results analyzed , achievable rates channel sensing uncertainty investigated initially , cognitive radio channel model channel sensing error channel estimation described , using pilot symbols , minimum mean square error \( mmse \) linear mmse \( l mmse \) estimation methods employed secondary receiver learn channel fading coefficients expressions channel estimates mean squared errors \( \) determined , dependencies channel sensing results , pilot symbol period energy investigated since sensing uncertainty leads uncertainty variance additive , channel estimation strategies performance interestingly shown depend sensing reliability shown l mmse estimation method , general suboptimal , performs close mmse estimation furthermore , assuming channel estimation errors interference introduced primary users zero mean gaussian distributed , achievable rate expressions linear modulation schemes gaussian signaling determined subsequently , training period , data pilot symbol energy allocations jointly optimized maximize achievable rates signaling schemes
ensemble classifiers applications review ensemble classifier group individual classifiers trained data set supervised classification problem paper present review commonly used ensemble classifiers literature ensemble classifiers also developed targeting specific applications also present application driven ensemble classifiers paper
spatiotemporal aware augmented reality image guided therapy suboptimal interaction patient data challenges 3d based ill posed 2d images essential concerns image guided augmented reality \( ar \) introduced operating last decade however , image guided interventions , often considered visualization device improving traditional workflows consequence , technology minimum requires new procedures , user interfaces , interactions main contribution paper reveal workflows taking full advantage head mounted entirely co imaging system times proposed ar landscape enabled co localizing users imaging devices via operating room environment exploiting involved move spatial information different bodies awareness system geometric physical characteristics x ray imaging allows different human machine interfaces demonstrate ar paradigm generic , benefit wide variety procedures system achieved error 4 76 91 mm k management procedure , errors 1 16 circ 1 46 circ angles , respectively , total hope holistic approach towards improving interface 's capabilities also team 's experience effective intervention reduced provide novel approaches procedures training purposes
global constraint volume ii time series constraints first report presents restricted set finite used structural time series constraints described means multi function composition scheme second provides corresponding structural time series constraints constraint explicitly described terms automata registers
applying blockchain securely share clinical data secure scalable data sharing essential collaborative clinical decision making conventional clinical data efforts often , however , creates efficient information exchange effective treatment decision made patients paper provides four contributions study applying blockchain technology clinical data sharing context technical requirements defined shared office national coordinator health information technology \( \) first , analyze requirements implications blockchain based systems second , present , blockchain based architecture designed meet requirements fast healthcare resources \( \) standard shared clinical data third , demonstrate based decentralized app using digital health participants case study collaborative decision making remote cancer care fourth , highlight key learned case study
impact position errors crowd simulation abstract large crowd events , always potential possibility stampede occur may cause even death approaches controlling crowd flows predicting congestion spots would site manage crowd prevent accidents one popular approaches real time crowd simulation based position data personal global system \( gps \) devices however , accuracy spatial data different gps devices , also affected environment event takes place paper , would like assess effect position errors stampede prediction propose automatic real time detection \( \) method predict large events implement three different stampede assessment methods framework incorporate position errors analysis suggests probability simulated stampede changes significantly increase magnitude position errors , cannot entirely help classic techniques , kalman filter thus , position novel stampede assessment methods developed , focusing detection position noise elimination effect
conditional random fields recurrent neural networks pixel level labelling tasks , semantic segmentation , play central role image understanding recent approaches capabilities deep learning techniques image recognition tackle pixel level labelling tasks one central issue methodology limited capacity deep learning techniques visual objects solve problem , introduce new form convolutional neural network combines strengths convolutional neural networks \( cnns \) conditional random fields \( crfs \) based probabilistic graphical modelling end , formulate conditional random fields gaussian pairwise potentials mean field approximate inference recurrent neural networks network , called crf rnn , plugged part cnn obtain deep network desirable properties cnns crfs importantly , system fully integrates crf modelling cnns , making possible train whole deep network end end usual back propagation algorithm , avoiding offline post processing methods object apply proposed method problem semantic image segmentation , obtaining top results challenging pascal voc 2012 segmentation benchmark
survey communication protocols internet things related challenges fog cloud computing integration fast number iot \( internet things \) devices accelerating research new solutions make cloud services scalable context , novel concept fog computing well combined fog cloud computing paradigm becoming essential cloud , services closer end system article surveys e application layer communication protocols iot communication requirements , potential implementation fog cloud based iot systems end , article first briefly presents potential protocol candidates , including request protocols , article surveys protocols based main characteristics , well main performance issues , including latency , energy consumption , network throughput findings used place protocols segment system \( iot , fog , cloud \) , thus opens discussion choice , , system integration survey expected useful system protocol designers choosing communication protocols integrated iot fog cloud system architecture
performance monitoring end end speech recognition measuring performance automatic speech recognition \( asr \) system without ground truth could beneficial many scenarios , especially data unseen domains , performance highly inconsistent conventional asr systems , several performance monitoring \( pm \) techniques well developed monitor performance looking tri phone pre softmax activations neural network acoustic modeling however , strategies monitoring recently developed end end asr systems yet explored , focus paper adapt previous pm measures \( entropy , measure auto encoder \) apply proposed rnn predictor end end setting measures utilize decoder output layer attention probability vectors , predictive power measured simple linear models findings suggest decoder level features feasible informative attention level probabilities pm measures , measure decoder achieves best overall predictive performance average prediction error 8 8 entropy measures rnn based prediction also show competitive , especially unseen conditions
easiest hardest fitness functions hardness fitness functions important research topic field evolutionary computation theory , paper help understanding ability evolutionary algorithms \( \) practice , paper may provide design benchmarks aim paper answer following research questions given fitness function class , functions easiest respect \? hardest \? functions constructed \? paper provides theoretical answers questions easiest hardest fitness functions constructed \( 1 1 \) maximize class fitness functions demonstrated unimodal functions easiest deceptive functions hardest terms time based fitness landscape paper also reveals fitness function class , easiest function one algorithm may become hardest another algorithm , vice versa
level based analysis univariate marginal distribution algorithm estimation distribution algorithms \( \) stochastic heuristics search optimal solutions learning sampling probabilistic models despite popularity real world applications , little rigorous understanding performance even univariate marginal distribution algorithm \( \) simple population based assuming independence decision variables optimisation time linear problem recently incomplete theoretical understanding mainly due lack appropriate analytical tools r n show recently developed level based theorem non populations combined concentration results yield upper bounds expected optimisation time approach results bound mathcal \( n lambda log lambda n 2 \) two problems , , population sizes lambda mu omega \( log n \) , mu lambda parameters algorithm also prove population sizes mu mathcal \( sqrt n \) cap omega \( log n \) expected time mathcal \( lambda n \) , larger population sizes mu omega \( sqrt n log n \) , expected time mathcal \( lambda sqrt n \) generality arguments suggest promising approach derive bounds expected optimisation time
beamspace aware adaptive channel estimation single carrier time varying massive mimo channels paper , problem sequential beam construction adaptive channel estimation based reduced rank \( \) kalman filtering frequency selective massive multiple input multiple output \( mimo \) systems employing single carrier \( sc \) time division duplex \( \) mode considered two stage beamforming , new algorithm statistical pre beamformer design proposed spatially correlated time varying mimo channels assumption channel stationary markov random process proposed algorithm yields nearly optimal pre beamformer whose beam pattern designed sequentially low complexity taking user grouping account , exploiting properties kalman filtering associated prediction error covariance matrices resulting design , based second order statistical properties channel , generates beamspace kalman estimator realized accurately possible observed adaptive channel estimation technique together proposed sequential beamspace construction shows remarkable robustness pilot interference comes significant reduction pilot overhead dimension pre beamformer hardware complexity power consumption
understanding video streaming algorithms wild video streaming algorithms hot research area , interesting new approaches proposed every months , little known behavior streaming algorithms deployed across large online streaming platforms account substantial fraction internet traffic thus study adaptive bitrate streaming algorithms use 10 video platforms diverse target collect traces video player 's response controlled variations network bandwidth , examine algorithmic behavior risk algorithm terms target buffer long takes reach stable state reactive match bandwidth versus operating efficiently use available network bandwidth etc find deployed algorithms exhibit wide spectrum behaviors across , indicating lack consensus one size solution also find evidence deployed algorithms tuned towards stable behavior rather fast adaptation bandwidth variations , tuned towards visual perception metric rather bitrate based metric , many surprisingly large amount available bandwidth
imperfect gaps gap study role perfect completeness proof systems \( \) give new way transform imperfect completeness perfect completeness initial gap constant particular , show text c , r , q text 1 , 1 omega \( 1 \) r \( 1 \) , q \( r \) , c omega \( 1 \) implies one imperfect completeness perfect linear sized \( n \) \( log n \) additive loss query complexity q show result constructing robust circuit using threshold results gap procedure \( completeness imperfect \) , questions studied parallel repetition r n also investigate time complexity approximating instances versus imperfect completeness show gap conjecture without perfect completeness equivalent gap perfect completeness , e show gap , gap around 1 , algorithm , , gap perfect completeness algorithms also relate time complexities two problems fine grained way , show 2 \( n \) leq 1 \( n \( log log n \) \( 1 \) \) , 1 \( n \) , 2 \( n \) denote randomized time complexity approximating max perfect imperfect completeness , respectively
non orthogonal multiple access noma downlink multiuser mimo systems user clustering beamforming power allocation investigate application non orthogonal multiple access \( noma \) successive interference cancellation \( \) downlink multiuser multiple input multiple output \( mimo \) cellular systems , total number receive antennas user equipment \( \) cell number transmit antennas base station \( bs \) first dynamically group receive antennas number clusters equal number bs transmit antennas single beamforming vector shared receive antennas cluster propose linear beamforming technique receive antennas significantly inter cluster interference hand , receive antennas cluster scheduled power domain noma basis receiver inter cluster intra cluster power allocation , provide dynamic power allocation solutions objective maximizing overall cell capacity extensive performance evaluation carried proposed mimo noma system results compared conventional orthogonal multiple access \( \) based mimo systems existing mimo noma solutions numerical results quantify capacity gain proposed mimo noma model mimo existing mimo noma solutions
energy coverage efficiency trade 5g small cell networks small cells densely deployed fifth generation \( 5g \) cellular networks , base stations \( bss \) switch strategy effective approach saving energy consumption considering changes traffic load general , loss coverage efficiency inevitable cost cellular networks adopting bss switch strategies based bss switch strategy , optimized energy density efficiency hard core point process \( \) small cell networks proposed trade energy coverage efficiency simulation results imply minimum active bs distance used bss switch strategy achieve tradeoff energy coverage efficiency 5g small cell networks
regularized adversarial examples model interpretability machine learning algorithms continue improve , increasing need explaining model produces certain prediction certain input recent years , several methods model interpretability developed , aiming provide explanation subset regions model input main reason model prediction parallel , significant research community effort occurring recent years developing adversarial example generation methods models , true label input , would classified human paper , bridge gap adversarial example generation model interpretability , introduce modification adversarial example generation process encourages better interpretability analyze proposed method public medical imaging dataset , quantitatively qualitatively , show significantly outperforms leading known alternative method suggested method simple implement , easily plugged common adversarial example generation frameworks additionally , propose explanation quality metric adversarial explanation , measures well explanation describes model decisions
distributed monitoring asynchronous systems distributed systems notoriously difficult understand analyze order correction w r given properties often exhibit huge number different behaviors , soon active entities \( , agents , processes , etc \) asynchronous manner already systems non trivial task , let alone formal verification r n purpose paper discuss problem distributed monitoring simple model finite state distributed automata based shared actions , called asynchronous automata monitoring question related runtime verification assume check property l unknown complex system , classical static analysis possible therefore instead model checking monitor used , property underlying system runtime r n interested monitoring distributed systems modeled asynchronous automata natural require monitors kind underlying system , consider distributed monitoring distributed monitor global view system , therefore propose notion locally trace language main result shows distributed alphabet actions connected l set infinite traces l complement l c locally safety languages , l locally also show infinite traces , locally safety languages precisely deterministic languages
convolutional long short term memory networks recognizing first person interactions paper , present novel deep learning based approach addressing problem interaction recognition first person perspective proposed approach uses pair convolutional neural networks , whose parameters shared , extracting frame level features successive frames video frame level features aggregated using convolutional long short term memory hidden state convolutional long short term memory , input video frames processed , used classification respective categories two convolutional neural network perform feature encoding short time interval whereas convolutional long short term memory encodes changes longer temporal duration network spatio temporal structure input preserved final processing stage experimental results show method outperforms state art recent first person interactions datasets involve complex motion particular , methods use depth image information along rgb images , previous methods use rgb images 20 recognition accuracy
meta matrix factorization private predictions matrix factorization \( mf \) techniques shown effective predictions \( \) personalized recommender systems existing mf methods use item embeddings model users , ignoring possibility different users may different views item may different models introduce novel mf framework , named meta matrix factorization \( \) , generates private item embeddings models given vector representing user , first obtain collaborative vector collecting useful information users collaborative memory \( cm \) module , employ meta recommender \( \) module generate private item embeddings model based collaborative vector address challenge generating large number high dimensional item embeddings , devise rise dimensional generation \( rg \) strategy first generates low dimensional item embedding matrix rise dimensional matrix , obtain high dimensional embeddings finally , use generated model produce private given user experiments two benchmark datasets show outperforms state art mf methods generates similar item embeddings models different users flexibly exploit collaborative filtering \( cf \) , demonstrating benefits
ranking library materials purpose paper discusses ranking factors suitable library materials shows ranking general complex process ranking library materials requires variety techniques design methodology approach relevant literature reviewed provide systematic overview suitable ranking factors discussion based overview ranking factors used web search engines findings wide variety ranking factors applicable library materials , library systems use designing ranking component library , individual weighting applicable factors necessary research limitations applications article discusses different factors , particular ranking formula given however , article presents argument formula must always individual certain use case practical implications factors presented considered designing ranking component search system project value paper original first systematically discuss ranking library materials based main factors used web search engines
existence simple fair division short proof note study share good n players simple way give short proof existence fair
large scale fast accurate shot boundary detection spatio temporal convolutional neural networks shot boundary detection \( sbd \) important pre processing step video manipulation , segment frames classified either sharp , transition current sbd techniques analyze hand crafted features attempt optimize detection accuracy processing speed however , heavy computations optical flow achieve aim , present sbd technique based spatio temporal convolutional neural networks \( cnn \) since current datasets large enough train accurate sbd cnn , present new dataset containing 3 5 million frames sharp transitions transitions generated using image models dataset contain additional 70 , 000 frames important hard negative transitions perform largest evaluation date one sbd algorithm , real synthetic data , containing 4 85 million frames comparison state art , outperform detection , generate competitive performance sharp detections produce significant improvement addition , 11 times faster state art
learning selective labels presence expert consistency explore problem learning selective labels context algorithm assisted decision making selective labels selection bias problem arises historical decision making us true outcome certain instances examples common many applications , ranging predicting using pre release data patients paper discuss selective labels often cannot effectively standard methods adjusting sample selection bias , even propose data augmentation approach used either leverage expert consistency mitigate partial results selective labels , empirically validate whether learning framework may lead unreliable models prone discrimination
free fine grained scheduling reliable energy efficient data collection lorawan lorawan promises provide wide area network access low cost devices operate 10 years single 1000 battery makes lorawan particularly suited data collection applications \( e g monitoring applications \) , device lifetime key performance metric however , supporting large number devices , lorawan suffers scalability issue due high collision probability aloha based mac layer performance using transmissions due cycle restriction gateway , propose free , fine grained scheduling scheme reliable energy efficient data collection lorawan free takes advantage applications hard delay requirements data delivery supporting data transmission means data transmission scheduled time slots instead transmitted straight away free factors , transmission , frequency channels , time slots , schedules slots frames lorawan end devices result , free overcomes scalability problem lorawan eliminating grouping evaluate performance free versus different lorawan configurations numerical results show free scales well achieves almost 100 data delivery device lifetime estimated 10 years independent traffic type network size comparing poor scalability , low data delivery device lifetime fewer 2 years data traffic standard lorawan configurations
graphx data parallel graph parallel analytics social networks language modeling , growing scale importance graph data driven development numerous new graph parallel systems \( e g , , \) restricting computation expressed introducing new techniques partition graph , systems efficiently execute iterative graph algorithms orders magnitude faster general data parallel systems however , restrictions enable performance gains also make difficult express many important stages typical graph analytics pipeline constructing graph , modifying structure , expressing computation multiple graphs consequence , existing graph analytics pipelines compose graph parallel data parallel systems using external storage systems , leading extensive data movement complicated programming model r n address challenges introduce graphx , distributed graph computation framework graph parallel data parallel computation graphx provides small , core set graph parallel operators expressive enough implement abstractions , yet simple enough relational algebra graphx uses collection query optimization techniques automatic rewrites efficiently implement graph parallel operators evaluate graphx real world graphs workloads demonstrate graphx achieves comparable performance specialized graph computation systems , outperforming end end graph pipelines moreover , graphx achieves balance expressiveness , performance , use
survey deep geometry learning representation perspective researchers achieved great success dealing 2d images using deep learning recent years , 3d computer vision geometry deep learning gain attention many advanced techniques 3d shapes proposed different applications unlike 2d images , uniformly represented regular grids pixels , 3d shapes various representations , depth multi view images , voxel based representation , point based representation , mesh based representation , implicit surface representation , etc however , performance different applications largely depends representation used , unique representation works well applications therefore , survey , review recent development deep learning 3d geometry representation perspective , advantages disadvantages different representations different applications also present existing datasets representations discuss future research directions
joint sensing matrix dictionary optimization tensor compressive sensing tensor compressive sensing \( \) multidimensional framework compressive sensing \( cs \) , terms reducing amount storage , hardware implementations , preserving multidimensional structures signals comparison conventional cs system system , instead using random sensing matrix predefined dictionary , average case performance improved employing optimized multidimensional sensing matrix learned dictionary paper , propose approach jointly optimizes sensing matrix dictionary system sensing matrix design , extended separable approach closed form solution novel iterative method proposed dictionary fixed addition , multidimensional dictionary learning method takes advantages multidimensional structure derived , influence sensing matrices taken account learning process joint optimization achieved via optimization sensing matrix dictionary numerical experiments using synthetic data real images demonstrate superiority proposed approaches
multiview image curves 3d 3d scenes multiple views made impressive recent years , isolated feature points , intensity patterns , structures general setting without controlled acquisition , texture , curves surfaces following specific models limiting scene complexity methods produce point clouds , meshes , voxel representations , producing clouds 3d curve fragments ideally , many applications require structured representations curves , surfaces spatial relationships paper presents step direction approach combines 2d image curves collection 3d curves , topological connectivity represented 3d graph results 3d , complementary surface representations sense 3d evaluate results truth synthetic real datasets
n 2 algorithm computing optimal continuous voltage schedules dynamic voltage scaling techniques allow processor set speed dynamically order reduce energy consumption continuous model , processor run speed , discrete model , processor run finite number speeds given input current best algorithm computing optimal schedules continuous model runs \( n 2 log n \) time scheduling n jobs paper , improve running time \( n 2 \) calculation schedules using refined data structure discrete model , improve computation optimal schedule current best \( log n \) \( n log max , n \) number allowed speeds
complexity optimal mechanism design 's work provides computationally efficient revenue optimal auction selling one item multiple bidders generalizing work selling multiple items central question economics algorithmic game theory , complexity poorly understood answer question showing revenue optimal auction multi item settings cannot found implemented computationally efficiently , unless contains p p true even single additive bidder whose values items independently distributed two rational numbers rational probabilities result general show hard compute encoding optimal auction format \( direct , non \) implemented expected polynomial time particular , well believed complexity theoretic assumptions , revenue optimization simple multi item settings approximated r n note hardness result applies randomized mechanisms simple setting , introducing combinatorial structure problem allowing correlation among item values , introducing combinatorial valuations , requiring mechanism deterministic \( whose structure readily combinatorial \) proof enabled flow interpretation solutions exponential size linear program revenue maximization additional constraint
aggregating binary local descriptors image retrieval content based image retrieval based local features computationally expensive complexity extraction matching local feature one hand , cost extracting , representing , comparing local visual descriptors dramatically reduced recently proposed binary local features hand , aggregation techniques provide meaningful summarization extracted feature image single , allowing us speed scale image search works recently mixed together two research directions , defining aggregation methods binary local features , order leverage advantage approaches paper , report extensive comparison among state art aggregation methods applied binary features , mathematically formalize application fisher kernels bernoulli mixture models finally , investigate combination aggregated binary features emerging convolutional neural network \( cnn \) features results show aggregation methods binary features effective represent alternative direct matching moreover , combination cnn fisher vector \( \) built upon binary features allowed us obtain relative improvement cnn results line recently obtained using combination cnn built upon advantage using built upon binary features extraction process binary features two order magnitude faster
neural network identification people hidden view single pixel single detector light multiple surfaces used retrieve information hidden environments however , full three dimensional retrieval object hidden view achieved systems requires intensive computational processing retrieved data use non , single single pixel detector combination artificial neural network allows us locate position also simultaneously provide actual identity hidden person , chosen database people \( n 3 \) artificial neural networks applied specific computational imaging problems therefore enable novel imaging capabilities simplified hardware processing times
security pixel based image encryption privacy preserving deep neural networks paper aims evaluate safety pixel based image encryption method , proposed apply images visual information deep neural networks \( dnn \) , terms robustness attacks \( \) addition , propose novel dnn based aims reconstruct visual information encrypted images effectiveness proposed attack evaluated two encryption key conditions encryption key , different encryption keys results show proposed attack recover visual information encrypted images images encrypted encryption key otherwise , pixel based image encryption method robustness
evolution strategies converges finite differences since evolution strategies \( es \) tool reinforcement learning et al 2017 , interest determining exact relationship evolution strategies gradient gradient similar class algorithms , finite differences \( fd \) \( et al 2017 , et al 2018 \) several subject performed , investigating formal differences \( et al 2018 \) es fd , well differences standard benchmark problem machine learning , mnist classification problem \( et al 2017 \) paper proves gradients different , converge dimension vector optimization increases
generalization minimum storage regenerating codes paper , propose generalized version minimum storage regenerating \( rsk msr \) codes based product matrix framework \( n , k , \) geq 2 leq n 1 , directly construct \( n , k , \) msr code without constructing larger msr code larger msr code result , size finite field proposed code defined smaller equal size finite field rsk msr code defined addition , ell , secure codes based generalized rsk msr codes obtained applying construction method ell , secure codes proposed , furthermore , message matrix \( n , k , \) generalized rsk msr code derived rsk msr code using construction method ell k , 0 secure code
supervised autoencoder learning beyond euclidean loss autoencoders unsupervised deep learning models used learning representations literature , autoencoders shown perform well variety tasks spread across multiple domains , thereby establishing widespread applicability typically , autoencoder trained generate model minimizes reconstruction error input reconstructed output , computed terms euclidean distance useful applications related unsupervised reconstruction , may optimal classification paper , propose novel supervised autoencoder utilizes multi objective loss function learn representations simultaneously encode \( \) similarity input reconstructed vectors terms direction , \( ii \) distribution pixel values reconstruction respect input sample , also incorporating \( iii \) feature learning pipeline proposed autoencoder model incorporates similarity distance based loss function , along supervision via mutual information based loss detailed analysis component proposed model applicability feature learning different classification tasks efficacy supervised autoencoder demonstrated via extensive experimental evaluations different image datasets proposed model outperforms existing algorithms mnist , cifar 10 , databases also yields state art results , , , databases attribute prediction face recognition , respectively
bandits recommendation systems often face exploration exploitation tradeoffs system learn new options recommending user systems thus modeled multi bandit settings however , users self interested cannot made follow recommendations ask whether exploration nevertheless performed way interests e , system formally , introduce model recommendation system faces exploration exploitation tradeoff constraint never action knows yields lower reward expectation agent would achieve alone main contribution positive result asymptotically optimal , incentive compatible , individually rational recommendation algorithm
processes metric graphs sampling theorem paper studies processes defined time domains structured oriented metric graphs \( oriented 1 manifolds \) setting used , example , forecasting models involving branching scenarios processes , notion spectrum takes account topology manifold introduced paper suggests sufficient conditions uniqueness recovery observations single branch also imply analog sampling theorem branching processes , e , recovery set samples , well set samples single branch
evolving type artificial neural networks investigate turing 's notion type artificial neural network study refinement turing 's original idea , motivated work , bull , types process binary data sequences binary vectors hence associate function type , type em represents function two modes data processing sequential describe evolutionary algorithm , involving graph theoretic types , types representing given function algorithm uses operators implemented algorithm applied three benchmark tasks found algorithm performed much better random search two three tasks , algorithm performed better version
learning bayesian network parameters prior knowledge context specific qualitative influences present method learning parameters bayesian network prior knowledge signs influences variables method standard signs , provides context specific signs well show various signs translate order constraints network parameters regression used compute order constrained estimates available data experimental results show taking prior knowledge signs influences account leads improved fit true distribution , especially small sample data available moreover , computed estimates guaranteed consistent specified signs , thereby resulting network likely accepted experts domain application
power control multi cell networks non orthogonal multiple access paper , investigate problems sum power minimization sum rate maximization multi cell networks non orthogonal multiple access considering sum power minimization , obtain closed form solutions optimal power allocation strategy successfully transform original problem linear one much smaller size , optimally solved using standard interference function solve sum rate maximization problem , first prove power allocation problem single cell convex problem analyzing conditions , optimal power allocation users single cell derived closed form based optimal solution cell , distributed algorithm accordingly proposed acquire efficient solutions numerical results verify theoretical findings showing superiority solutions compared orthogonal frequency division multiple access broadcast channel
gradient based camera exposure control mobile platforms introduce novel method automatically adjust camera exposure image processing computer vision applications mobile robot platforms image processing algorithms rely heavily low level image features based mainly local gradient information , consider gradient quantity determine proper exposure level , allowing camera capture important image features manner robust conditions extend concept multi camera system present new control algorithm achieve consistency adjacent cameras proper exposure level camera implement prototype system shelf machine vision cameras demonstrate effectiveness proposed algorithms practical applications , including pedestrian detection , visual , view imaging , imaging , stereo matching
connected vehicle application development platform cvdep edge centric cyber physical systems connected vehicle \( cv \) application developers need development platform build , test debug cv applications , safety , mobility , environmental applications , edge centric cyber physical systems study objective develop evaluate scalable secure cv application development platform \( cvdep \) enables cv application developers build , test debug cv applications real time cvdep ensures functional requirements cv applications meet latency requirements imposed corresponding cv applications conducted case study evaluate efficacy cvdep using two cv applications \( one safety one mobility application \) validated field evaluation university connected autonomous vehicle testbed \( \) analysis outcome proves efficacy cvdep , satisfies functional requirements \( e g , latency , throughput \) cv application maintaining scalability , security platform applications
bonsai practical compact dynamic trie consider problem implementing space efficient dynamic trie , emphasis good practical performance trie n nodes alphabet size sigma , information theoretic lower bound n log sigma \( n \) bits bonsai data structure compact trie proposed et al \( , \( 3 \) , , p \) disadvantages include user specify upper bound trie size advance \( cannot changed easily \) , space usage log sigma \( log log \) \( asymptotically non optimal smaller sigma n \) lack support supports update operations \( 1 epsilon \) expected time \( based assumptions behaviour hash functions \) , epsilon \( n \) excellent speed performance practice propose alternative , bonsai , addresses problems , obtaining trie uses \( 1 beta \) n \( log sigma \( 1 \) \) bits expectation , supports update operations \( 1 beta \) expected time \( 1 beta 2 \) expected time , user specified parameter beta 0 \( based assumptions behaviour hash functions \) give implementation bonsai uses considerably less memory slightly faster original bonsai
cirquent calculus cirquent calculus new proof theoretic semantic framework , whose main feature based circuit style structures \( called \) , traditional approaches deal tree like objects formulas , among advantages greater efficiency , flexibility expressiveness article presents detailed deep inference cirquent logic , naturally inherently resource shows classical logic , semantically , seen special , conservative fragment general , sense , basic logic logic resources form cirquent calculus reader find various arguments switching new framework , arguments showing expressive power linear logic formula based approaches developing resource logics , exponential improvements traditional approaches representational proof complexities offered cirquent calculus \( including existence polynomial size cut , substitution extension free cirquent calculus proofs notoriously hard principle \) , among main purposes article provide style starting point , author hope , might become new line research proof theory proof theory based circuits instead formulas
generative adversarial networks extreme learned image compression propose framework extreme learned image compression based generative adversarial networks \( gans \) , obtaining visually images significantly lower previous methods made possible gan formulation learned compression combined generator decoder operates full resolution image trained combination multi scale discriminator additionally , method fully synthesize regions decoded image trees semantic label map extracted original image , therefore requiring storage preserved region semantic label map user study low , approach significantly outperforms state art methods , saving 67 compared next best method
random sampling applied mst problem node congested clique model congested clique model , proposed et al , , introduced order provide simple abstraction overlay networks congested clique model distributed \( parallel \) computing , n players \( nodes \) unique set 1 , , n , perform computations synchronous rounds round consists phase local computation communication phase communicating , pair nodes allowed exchange single message size mathcal \( log n \) bits r n since , single round , player communicate even theta \( n \) players , model seems powerful bandwidth restriction emerging underlying network paper study restricted version congested clique model , node congested clique model , proposed et al additional restriction single communication phase , player allowed send receive mathcal \( log n \) messages r n paper , provide communication primitives improve round complexity mst \( minimum spanning tree \) algorithm et al mathcal \( log 3 n \) rounds moreover , propose different approach problem requires mathcal \( log 3 n log log n \) rounds , smaller dependence weights edges r n besides faster mst algorithm , consider key contributions r n efficient implementation basic protocols , r n analysis special case sampling approach , \( related results \) , r n application sparse recovery techniques going slightly beyond standard usage linear graph sketching ,
complexity manipulating elections candidates settings agents different preferences , preference aggregation central issue voting general method preference aggregation , results shown general voting protocols one could try avoid manipulation using voting protocols determining beneficial manipulation hard especially among computational agents , reasonable measure hardness computational complexity earlier work done area , assumed number voters candidates unbounded derive hardness results practical settings number candidates small number voters large show complete information votes , individual manipulation easy , manipulation easy unweighted voters however , constructive manipulation weighted voters intractable voting protocols study , except manipulation tends easier protocols \( schedules protocol \) used make manipulation hard finally , show weak assumptions , weighted manipulation complete information votes hard voting protocol , individual unweighted manipulation hard uncertainty votes
techniques de de present application artificial intelligence techniques field information security problem remote operating system \( os \) detection , also called os fingerprinting , crucial step testing process , since attacker \( security professional \) needs know os target host order choose exploits use os detection accomplished network packets actively sending test packets target host , study specific variations host responses information operating system r n first fingerprinting implementations based analysis differences ip stack implementations next generation focused analysis application layer data information even though information analyzed , variation best fit algorithm still used interpret new information new approach involves analysis composition information collected os identification process identify key elements relations implement approach , developed tools using neural networks techniques field statistics tools successfully integrated commercial software \( core impact \)
fixed parameter approximability boolean minimum version constraint satisfaction problem \( mincsp \) asks assignment number constraints minimum possible , equivalently , asks minimum size set constraints whose deletion makes instance finite set gamma constraints , denote mincsp \( gamma \) restriction problem constraint gamma polynomial time polynomial time approximability mincsp \( gamma \) fully characterized et al j study fixed parameter \( \) approximability problem given instance integer k , one find solution size g \( k \) time f \( k \) n \( 1 \) solution size k exists especially focus case constant factor approximability show following finite constraint language gamma , either exhibit constant factor approximation mincsp \( gamma \) prove mincsp \( gamma \) constant factor approximation unless fpt w 1 particular , show approximating called nearest codeword within constant factor w 1 hard recently , et al showed w 1 hardness approximation implies even set w 1 hard randomized reductions combining results , therefore parameterized complexity even set , famous open question field
correspondences classical intuitionistic uniform provability based analysis inference rules used , provide characterization situations classical provability intuitionistic provability examine relationship notions uniform provability , restriction intuitionistic provability special form goal determine , first , former relations imply latter using result , identify versions called abstract logic programming languages classical intuitionistic logic study reduction classical , , intuitionistic provability uniform provability via addition assumption set formula proved focus understanding situations reduction achieved however , discussions indicate structure proof procedure based reduction , also considered explicitly
efficient discovery variable length time series motifs large length range million scale time series detecting repeated variable length patterns , also called variable length motifs , received great amount attention recent years current state art algorithm utilizes fixed length motif discovery algorithm variable length motifs result , may take hours days execute enumeration range large work , introduce approximate algorithm called hierarchical based motif enumeration \( \) detect variable length motifs large enumeration range million scale time series show experiments scalability proposed algorithm significantly better state art algorithm moreover , motif length range detected considerably larger previous sequence matching based approximate variable length motif discovery approach demonstrate efficiently detect meaningful variable length motifs long , real world time series
power scaling uplink massive mimo systems arbitrary rank channel means paper investigates uplink achievable rates massive multiple input multiple output \( mimo \) antenna systems fading channels , using maximal ratio combining \( \) zero forcing \( zf \) receivers , assuming perfect imperfect channel state information \( csi \) contrast previous relevant works , fast fading mimo channel matrix assumed arbitrary rank deterministic component well rayleigh distributed random component derive tractable expressions achievable uplink rate large antenna limit , along approximating results hold finite number antennas based analytical results , obtain scaling law users' transmit power satisfy , maintaining desirable quality service particular , found regardless k factor , case perfect csi , approximations converge constant value exact results , number base station antennas , , grows large , transmit power user scaled proportionally csi estimated uncertainty , result holds true k factor non zero otherwise , channel experiences rayleigh fading , cut transmit power user proportionally 1 root addition , show increasing k factor , uplink rates converge fixed values zf receivers
planning goal conditioned policies planning methods solve temporally extended sequential decision making problems simple behaviors however , planning requires suitable abstractions states transitions , typically need designed hand contrast , model free reinforcement learning \( rl \) acquire behaviors low level inputs directly , often temporally extended tasks utilize reinforcement learning automatically form abstractions needed planning , thus obtaining best approaches \? show goal conditioned policies learned rl incorporated planning , focus states reach , rather states reached however , complex state observations images , inputs represent valid states therefore also propose using latent variable model represent set valid states , policies provide abstraction actions , latent variable model provides abstraction states compare method planning based model free methods find method significantly outperforms prior work evaluated image based robot navigation manipulation tasks require non greedy , multi behavior
learn explain efficiently via neural logic inductive learning capability making interpretable self decisions essential developing responsible machine learning systems work , study learning explain problem scope inductive logic programming \( \) propose neural logic inductive learning \( \) , efficient differentiable framework learns first order logic rules explain patterns data experiments , compared state art methods , find search rules times longer remaining times faster also show scale large image datasets , e visual , entities
learning sequence encoders temporal knowledge graph completion research link prediction knowledge graphs mainly focused static multi relational data work consider temporal knowledge graphs relations entities may hold time interval specific point time line previous work static knowledge graphs , propose address problem learning latent entity relation type representations incorporate temporal information , utilize recurrent neural networks learn time aware representations relation types used conjunction existing latent factorization methods proposed approach shown robust common challenges real world sparsity heterogeneity temporal expressions experiments show benefits approach four temporal data sets available 3 license 1
report hpc correctness 25 26 2017 dc maintaining hpc requires ability support simulations large scales fidelity study , detail one significant productivity challenges achieving goal , namely increasing bugs , especially face growing hardware software heterogeneity system scale identify key areas timely new research must address challenges , create new correctness tools must ideally play significant role even toward close proposal two day workshop problems identified report broadly discussed , specific plans new research identified
pushing limits lte survey research enhancing standard cellular networks currently tremendous growth data traffic cope demand , close cooperation academic researchers industry standardization experts necessary , exists practice paper , try bridge gap researchers engineers providing review current standard related research efforts wireless communication systems furthermore , give overview attempt exchange information results researchers engineers , via common simulation platform long term evolution \( lte \) corresponding discussion often , especially signal processing , reproducing results tedious task , assumptions parameters clearly specified , consideration state art research standardization process also , practical constraints , impairments imposed technological restrictions well known physical phenomena , e g , signaling overhead , synchronization issues , channel fading , often researchers , simplicity mathematical tractability hence , evaluating relevance research results practical conditions often difficult problems , developed standard simulation platform lte enables research well defined environment demonstrate innovative research framework real world standard possible , sometimes even examples research work , investigate potential several important research areas typical practical conditions , highlight well differences theory practice
synthesizing structured images gans paper aims synthesizing structured images retinal images images , follows given ground truth , generate multiple realistic looking ground truth could binary segmentation map containing structured morphology , synthesized output image size ground truth similar visual appearance presented training set approach inspired recent generative adversarial nets \( gans \) well image style transfer particular , dedicated problem context following properties rather large scale dataset , works well presence 10 training examples , common medical image analysis capable synthesizing diverse images ground truth last importantly , synthetic images produced approach demonstrated useful boosting image analysis performance empirical examination various benchmarks images demonstrate advantages proposed approach
unified approach one shot neural architecture search expressiveness search space key concern neural architecture search \( \) previous approaches mainly limited searching single path networks incorporating multi path search space current one shot remains paper , investigate behavior multi path 's setting show trivial generalization single path multi path incurs severe feature , training stability model ranking ability degradation , employ term batch \( \) changing statistics different sets paths extensive experiments common benchmark , , show boost ranking performance cost 's record clear margin , reaching 0 moreover , take advantage feature similarities paths largely reduce number needed call method searching imagenet , obtain several lightweight models outperform fewer , parameters fewer searching resources code available https url
lost space improving inference ipv4 address space utilization one challenge understanding evolution internet infrastructure lack systematic mechanisms monitoring extent ip addresses actually used paper try advance science inferring ipv4 address space utilization analyzing results obtained different types measurements previously studied approach based passive measurements reveal used address space unseen active approaches paper , study passive approaches detail , extending methodology four different types points , identifying traffic components significantly contribute discovering used ipv4 network blocks combine results obtained passive measurements together data active measurement studies , well measurements additional datasets available researchers analysis large collection heterogeneous datasets , substantially improve state art terms \( \) understanding challenges opportunities using passive active techniques study address utilization \( ii \) knowledge utilization ipv4 space
improved smoothed analysis k means method k means method widely used clustering algorithm one features speed practice worst case running time , however , exponential , gap practical theoretical performance \( 2006 \) aimed gap , proved bound poly \( n k , sigma 1 \) smoothed running time k means method , n number data points sigma standard deviation gaussian perturbation bound , though better worst case bound , still much larger running time observed practice r n improve smoothed analysis k means method showing two upper bounds expected running time k means first , prove expected running time bounded polynomial n sqrt k sigma 1 second , prove upper bound k cdot poly \( n , sigma 1 \) , dimension data space polynomial independent k , obtain polynomial bound expected running time k , \( sqrt log n log log n \) r n finally , show k means runs smoothed polynomial time one dimensional instances
multi reference neural tts adversarial cycle consistency current multi reference style transfer models text speech \( tts \) perform sub optimally datasets , one dataset contains single style class one style dimensions models generally fail produce style transfer dimension dataset paper , propose adversarial cycle consistency training scheme paired unpaired ensure use information style dimensions training , incorporate unpaired randomly selected reference audio samples encourage synthesized speech preserve appropriate using adversarial cycle consistency use method transfer emotion dataset containing four emotions dataset single emotion results 78 improvement style transfer \( based emotion classification \) minimal reduction fidelity subjective evaluations method consistently closer reference style baseline synthesized speech samples available https url
voice assistant mine information control phone previous research sensor based attacks android platform focused mainly controlling sensitive device components , camera , gps approaches get data sensors directly need corresponding sensor r n paper presents novel approach \( gvs attack \) attacks zero android application \( \) speaker idea gvs attack utilizes android system built voice assistant module google voice search android intent mechanism , google voice search foreground , plays audio files \( like call number \) background google voice search recognize voice command execute corresponding operations designs , gvs attack sms , access privacy information , transmit sensitive data achieve remote control without r n also found vulnerability status checking google search app , utilized gvs attack arbitrary numbers even phone securely locked prototype implemented demonstrate feasibility gvs attack real world theory , nearly android devices equipped google services framework affected gvs attack study may application developers researchers zero n't mean safety speaker new attack surface
heads recognizing constant randomness every language k head two way finite automaton \( \( k \) \) recognizing known build constant space algorithm \( k \) language constant randomness , error probability k 2 1 2 reduced repetition defined characteristic heads causes high error property previous verification algorithm , error improved k textrm w 2 1 textrm w 2 , k textrm w le k number heads using new algorithm , subset languages \( k \) k textrm w le 1 verified arbitrarily reducible error using constant space randomness
remote sensing image scene classification benchmark state art remote sensing image scene classification plays important role wide range applications hence remarkable attention past years , significant efforts made develop various data sets present variety approaches scene classification remote sensing images however , systematic review literature concerning data sets methods scene classification still lacking addition , almost existing data sets number limitations , including small scale scene classes image numbers , lack image variations diversity , accuracy limitations severely limit development new approaches especially deep learning based methods paper first provides comprehensive review recent progress , propose large scale data set , termed , publicly available benchmark remote sensing image scene classification \( \) , created university \( \) data set contains 31 500 images , covering scene classes images class proposed 1 \) large scale scene classes total image number 2 \) holds big variations translation , spatial resolution , viewpoint , object pose , , background , occlusion 3 \) high within class diversity class similarity creation data set enable community develop evaluate various data driven algorithms finally , several representative methods evaluated using proposed data set , results reported useful baseline future research
usage cloud computing simulators future systems computational research cloud computing internet based computing , whereby shared resources , software information , provided computers devices demand , like electricity grid currently , \( infrastructure service \) , \( platform service \) \( software service \) used business model cloud computing nowadays , adoption deployment cloud computing increasing various domains , forcing researchers conduct research area cloud computing globally setting research environment critical researchers developing countries evaluate research outputs currently , modeling , simulation technology access resources various university data centers become useful powerful tool cloud computing research several cloud simulators specifically developed various carry cloud computing research , including , , cloud future systems \( university machines , , delta , \) supports leading edge data science research broad range computing enabled education well integration ideas cloud hpc systems paper , features , , learning curve existing cloud computing simulators future systems reviewed analyzed
road surface 3d reconstruction based dense disparity map estimation various 3d reconstruction methods enabled engineers detect road surface achieve millimeter accuracy required road condition assessment , disparity map resolution needs used however , existing stereo matching algorithms specially suitable reconstruction road surface hence paper , propose novel dense disparity estimation algorithm high computational efficiency robustness achieved first perspective view target frame reference view , increases accuracy block matching road surface also improves processing speed estimated iteratively using previously published algorithm , search range propagated three estimated neighboring since search range obtained previous iteration , errors may occur propagated search range sufficient therefore , correlation maxima verification performed issue , resolution achieved interpolation enhancement furthermore , novel disparity global refinement approach developed markov random fields fast bilateral stereo introduced improve accuracy estimated disparity map , updated iteratively minimizing energy function related correlation polynomials algorithm implemented c language near real time performance experimental results illustrate absolute error reconstruction 0 1 3 mm
learning framework robot learning currently reaching high , thanks latest advancement deep learning paper , present open source framework collecting large scale , time synthetic data highly disparate sensory modalities , audio , video , , learning robot manipulation tasks demonstrate learning non linear mappings humanoid robot generates novel motion sequences desired audio data using cross modal correspondences evaluate system quality cross modal retrieval , generating suitable motion sequences match desired unseen audio video sequences
mathematics paper presents aspects mathematics interest cryptography community
simple lightweight human pose estimation recent research human pose estimation achieved significant improvement however , existing methods tend higher scores using complex architecture computationally expensive models benchmark datasets , ignoring deployment costs practice paper , investigate problem simple lightweight human pose estimation first lightweight bottleneck block two non novel concepts convolution attention mechanism , based lightweight block , present lightweight pose network \( lpn \) following architecture design principles model size \( \) small network lpn 50 9 \( \) , computational complexity \( \) 11 give full play potential lpn get accurate predicted results , also propose iterative training strategy model agnostic post processing function beta soft empirically demonstrate effectiveness efficiency methods benchmark dataset coco detection dataset besides , show speed superiority lightweight network inference time non gpu platform specifically , lpn 50 achieve 7 ap score coco test set , 2 parameters 1 0 , inference speed fps intel cpu machine
triple aware detailed tpl friendly detailed require systematic approach detect tpl however , complexity conflict graph \( \) directly detecting tpl work proposes token graph embedded conflict graph \( \) facilitate tpl conflict detection maintaining high coloring flexibility develop tpl aware detailed \( \) applying tpl generation compared greedy coloring approach , experimental results indicate generates shorter cost 2 41 runtime
dmath scalable linear algebra library heterogeneous gpu architectures new scalable parallel library , dmath , presented paper demonstrates leading scaling using , , hybrid parallelism deep learning dmath provides easy use distributed base primitives variety domain specific algorithms include matrix multiplication , convolutions , others allowing rapid development highly scalable applications , including deep neural networks \( dnn \) , whereas previously one restricted libraries provided effective primitives single gpu , like dnn primitives framework development hpc software difficult , labor intensive work , requiring unique skill set dmath allows wide range developers utilize parallel distributed hardware easily one contribution approach data stored gpu hardware , avoiding costly host device advanced memory management techniques utilized , including caching transferred data memory reuse pooling key contribution dmath delivers performance , , productivity specific domain support enables algorithm application quickly solve problems without managing significant complexity associated multi level parallelism dmath use gpu direct remote direct memory access \( \) , developed collaboration groups shown decrease latency increase bandwidth compared previous techniques efficient inter gpu communication crucial achieving greater net performance supporting effective use cost effective , gpu dense architecture adopted dmath caching approach addresses one key drawbacks gpus , keep data sets avoid overheads cpu gpu memory interface possible keywords gpu , , , deep learning , deep neural network , matrix matrix multiplication , , scalability
low rank approximation decomposition large matrices using error correcting codes low rank approximation important tool used many applications signal processing machine learning recently , randomized sketching algorithms proposed effectively construct low rank approximations obtain approximate singular value decompositions large matrices similar ideas used solve least squares regression problems paper , show matrices error correcting codes used find low rank approximations matrix decompositions , extend framework linear least squares regression problems benefits using code matrices following first , easy generate reduce randomness significantly second , code matrices , mild restrictions , satisfy subspace embedding property , better preserving geometry large subspace vectors third , parallel distributed applications , code matrices significant advantages structured random matrices gaussian random matrices fourth , unlike fourier transform matrices , require sampling \( k log k \) columns rank k approximation , log factor necessary certain types code matrices particular , \( 1 epsilon \) optimal norm error achieved rank k approximation \( k epsilon \) samples fifth , fast multiplication possible structured code matrices , fast approximations achieved general dense input matrices , least squares regression problem min b 2 mathbb r n times , \( 1 epsilon \) relative error approximation achieved \( epsilon \) samples , high probability , certain code matrices used
cross correlation p sequence sequences frac p n 1 p k 1 frac p n 1 2 paper , odd prime p p 3 4 , odd n , \( p n 1 \) \( p k 1 \) \( p n 1 \) 2 k n , value distribution exponential sum \( , b \) calculated b run mathbb f p n sequence family mathcal g sequence period n p n 1 also constructed family size mathcal g p n correlation magnitude roughly upper bounded \( p k 1 \) sqrt n 2 weight distribution relevant cyclic code mathcal c mathbb f p length n dimension rm mathbb f p mathcal c 2n also derived result includes case cite special case
automatic segmentation spots using active model challenging task literature , many algorithms used , e g recognition , recognition pattern recognition , use technology large extent area research , still lot work done one important target automate segmentation process , paper propose segmentation algorithm extracting spots , species automatic segmentation achieved combination preprocessing , active morphology parameters stage segmentation algorithm found using optimization procedure , guided ground truth results show automatic segmentation spots possible 78 correct segmentation average reached
waterfall bandits learning ads online popular approach selling online advertising waterfall , makes sequential price offers ad networks , chooses winner order order prices maximize revenue traditional solution learn demand model subsequently solve optimization problem given demand model linear regret design online learning algorithm solving problem , learning optimization , prove algorithm sublinear regret evaluate algorithm synthetic real world data , show quickly learns high quality pricing strategies first principled study learning waterfall design online sequential
graphical language proof strategies complex automated proof strategies often difficult extract , , modify , debug traditional languages , often based stack based goal propagation , make easy write proofs flow goals minor changes input , proof structure changes , address introducing graphical language called writing proof strategies strategies constructed visually together collections evaluated goal nodes diagram via graph rewriting nodes many output wires , use filtering procedure based goal types \( predicates describing features goal \) decide best send newly generated sub goals addition making flow goal information explicit , graphical language role many using visual like branching , merging , feedback argue language enables development robust proof strategies provide several examples , along prototype implementation
facial landmark detection convolutional neural networks present novel convolutional neural network \( cnn \) design facial landmark coordinate regression examine intermediate features standard cnn trained landmark detection show features extracted later , specialized layers capture landmark locations provides natural means applying differential treatment network , processing based facial alignment resulting cnn model \( \) robustness cnns landmark detection , appearance sensitive manner without training multi part multi scale models results standard face landmark detection face verification benchmarks show previously published performances wide
patch refinement localized 3d object detection introduce patch refinement two stage model accurate 3d object detection localization point cloud data patch refinement composed two independently trained based networks , region proposal network \( \) local refinement network \( \) decompose detection task preliminary 's eye view \( \) detection step local 3d detection step based proposed locations , extract small point cloud subsets \( patches \) , processed , less limited memory constraints due small area patch therefore , apply encoding higher voxel resolution locally independence enables use additional augmentation techniques allows efficient , regression focused training uses small fraction scene evaluated kitti 3d object detection benchmark , 28 , 2019 , outperformed previous entries three difficulties class car , using 50 available training data lidar information
information bottleneck problems models connections applications information theoretic views paper focuses variants bottleneck problem taking information theoretic perspective discusses practical methods solve , well connection coding learning aspects connections setting remote source coding logarithmic loss distortion measure , information combining , common reconstruction , wyner problem , efficiency investment information , well , generalization , variational inference , representation learning , autoencoders , others discuss extension distributed information bottleneck problem emphasis gaussian model highlight basic connections uplink cloud radio access networks \( \) oblivious processing model , optimal trade offs relevance \( e , information \) complexity \( e , rates \) discrete vector gaussian frameworks determined , interesting problems mentioned characterization optimal inputs \( features \) distributions power limitations maximizing relevance gaussian information bottleneck , complexity constraints
routine modeling time series metric learning , automatic recognition human activities performed supervised learning algorithms limited sets specific activities work proposes recognize recurrent activity patterns , called routines , instead precisely defined activities modeling routines defined metric learning problem , architecture , called , based sequence sequence models proposed learn distance time series approach relies inertial data thus non preserves privacy experimental results show clustering algorithm provided learned distance able recover daily routines
peer prediction heterogeneous tasks peer prediction method contributions information users settings way verify quality responses multi task peer prediction , reports users across multiple tasks used score contributions paper extends correlated agreement \( ca \) multi task peer prediction mechanism allow reports users heterogeneous tasks , associated different distributions responses motivation comes user generated content places city , tasks vary places , questions places , vary prove generalized ca mechanism informed weak conditions , meaning strictly beneficial user effort acquire information , reporting best strategy effort , well equilibrium demonstrate mechanism good incentive properties tested simulation distributions derived user reports google local
scores create academic academic social network site \( rg \) indicator , rg score , members high profile nature site means rg score may used , tasks researchers evaluated response , study investigates whether reasonable employ rg score evidence scholarly reputation , three different author samples investigated sample includes authors high values sample comprises winners , , physics economics \( 2015 \) longitudinal sample includes data 4 authors different rg scores results suggest high rg scores built primarily activity related asking answering questions site particular , seems impossible get high rg score solely publications within rg possible distinguish \( passive \) interact little site active platform users , get high rg scores others inside site \( questions , answers , social networks influential researchers \) thus , rg scores academic reputation indicators
online speedup learning optimal planning domain independent planning one areas field artificial intelligence description planning task consists initial world state , goal , set actions modifying world state objective find sequence actions , , plan , transforms initial world state goal state optimal planning , interested finding plan , one plans prominent approach optimal planning days heuristic state space search , guided admissible heuristic functions numerous admissible heuristics developed , strengths , well known single best heuristic optimal planning general thus , heuristic choose given planning task difficult question difficulty combining several heuristics , requires computing numerous heuristic estimates state , tradeoff time time combined advantages different heuristics might high present novel method reduces cost combining admissible heuristics optimal planning , maintaining benefits using search space model , formulate decision rule choosing best heuristic compute state present active online learning approach learning classifier decision rule target concept , employ learned classifier decide heuristic compute state evaluate technique empirically , show substantially outperforms standard method combining several heuristics via maximum
first order logic bounded rank every q mathbb n let textrm fo q denote class sentences first order logic fo rank q graph property defined textrm fo q , time \( n q \) thus , minimizing q favorable algorithmic consequences many graph properties amount existence certain set vertices size k usually expressed sentence rank least k use color coding method demonstrate \( hyper \) graph problems defined textrm fo q q independent k property graph problem equivalent question whether corresponding parameterized problem class textrm ac 0 r n crucial results fo sentences access built addition multiplication known fo corresponds circuit complexity class uniform textrm ac 0 explore connection rank fo sentences depth textrm ac 0 circuits , prove textrm fo q textrm fo q 1 structures built addition multiplication
visual tool sequence sequence models neural sequence sequence models proven accurate robust many sequence prediction tasks , become standard approach automatic translation text models work five stage process involves encoding source sequence vector space decoding new target sequence process standard , like many deep learning methods remains quite difficult understand debug work , present visual analysis tool allows interaction trained sequence sequence model stage translation process aim identify patterns learned detect model errors demonstrate utility tool several real world large scale sequence sequence use cases
automatic transferring chinese contemporary chinese long time development , chinese language great deal native difficulty reading sentences written chinese paper , propose unsupervised algorithm constructs sentence aligned contemporary pairs passage aligned corpus method , build large parallel corpus propose apply sequence sequence model automatically transfer contemporary chinese sentences experiments show alignment transfer method produce good result except even human make without background knowledge
modeling patterns smartphone usage relationship cognitive health smartphone usage many people 's lives make rich source information person 's cognitive state work analyze 12 phone usage data , 31 cognitive 82 without develop structured models users' smartphone interactions reveal differences phone usage patterns people without cognitive particular , focus inferring specific types phone usage sessions predictive cognitive model achieves 0 79 healthy subjects , interpretability enables novel insights aspects phone usage strongly relate cognitive health dataset
hierarchical reinforcement learning maxq value function decomposition paper presents maxq approach hierarchical reinforcement learning based target markov decision process \( mdp \) hierarchy smaller mdps value function target mdp additive combination value functions smaller mdps paper defines maxq hierarchy , proves formal results representational power , five conditions safe use state abstractions paper presents online model free learning algorithm , maxq q , proves converges probability 1 kind locally optimal policy known optimal policy , even presence five kinds state abstraction paper evaluates maxq representation maxq q series experiments three domains shows experimentally maxq q \( state abstractions \) converges optimal policy much faster flat q learning fact maxq learns representation value function important benefit makes possible compute execute improved , non hierarchical policy via procedure similar policy improvement step policy iteration paper demonstrates effectiveness non hierarchical execution experimentally finally , paper concludes comparison related work discussion design tradeoffs hierarchical reinforcement learning
average stack cost pushdown automata study average stack cost pushdown automata \( \) associate non negative price stack symbol define cost stack sum costs elements introduce study average stack cost problem \( \) , asks whether exists run given long run average stack costs given threshold problem generalizes mean objective used express quantitative properties pushdown systems particular , compute average response time using problem show problem solved polynomial time
evaluating fairness metrics presence dataset bias data driven algorithms play large role decision making across variety increasingly , algorithms used make decisions significant people 's social economic well , e g , , proliferation systems growing concern potential impact particular , machine learning systems trained biased data potential learn biases central challenge practitioners thus determine whether models bias present case study frame issue bias detection causal inference problem data two main causes bias , sampling bias label bias , investigate abilities six different fairness metrics detect bias type based , propose set best practice select fairness metric likely detect bias present additionally , aim identify conditions certain fairness metrics may fail detect bias instead give practitioners false belief biased model making fair decisions
kara system visual editing interpretations answer set programs answer set programming \( asp \) , solutions problem encoded dedicated models , called answer sets , logical theory answer sets computed program represents theory means asp solver user sets ground first order type representation often user interpret , tools like developed allow answer sets tool kara , introduced paper , follows approaches , using asp language defining interpretations unlike existing tools position primitives according static coordinates , kara allows high level specifications , supporting graph structures , grids , relative graphical elements moreover , functionality previous tools , kara provides interpretations editing reasoning techniques kara part , integrated development environment \( \) asp
learning based approach caching small cell networks network base stations \( bss \) , small base stations \( \) , users distributed according independent poisson point processes considered nodes assumed possess high storage capacity form distributed caching network popular files stored local , user download desired files one offloading loss captured via cost function depends random caching strategy proposed popularity profile content unknown estimated using instantaneous demands users within specified time interval estimate cost function obtained optimal random caching strategy training time achieve epsilon 0 difference achieved optimal costs finite provided user density greater predefined threshold , scales n 2 , n support popularity profile transfer learning based approach improve estimate proposed training time reduced popularity profile modeled using parametric family distributions delay independent n scales linearly dimension distribution parameter
measuring sentences similarity survey study review approaches used measuring sentences similarity measuring similarity natural language sentences crucial task many natural language processing applications text classification , information retrieval , question answering , plagiarism detection survey approaches sentences similarity based adopted methodology three categories word word based , structure based , vector based widely used approaches find sentences similarity approach measures relatedness short texts based specific perspective addition , datasets mostly used benchmarks evaluating techniques field introduced provide complete view issue approaches combine one perspective give better results moreover , structure based similarity measures similarity sentences structures needs investigation
causation recent work experimental shown judgments actual causation often influenced consideration , , number computer scientists also suggested factors help deal problems facing existing accounts actual causation paper flexible formal framework incorporating , , account actual causation resulting account takes actual causation comparative show account would handle number standard cases
joint transceiver design algorithms multiuser miso relay systems energy harvesting paper , investigate multiuser relay system simultaneous wireless information power transfer assuming base station \( bs \) relay station \( rs \) equipped multiple antennas , work studies joint transceiver design problem bs beamforming vectors , rs forward transformation matrix power splitting \( \) ratios single antenna receivers firstly , iterative algorithm based alternating optimization \( \) guaranteed convergence proposed optimize transceiver coefficients secondly , novel design scheme based relaying \( \) proposed significantly reduce computational complexity overhead based designs maintaining similar performance proposed scheme , rs equipped permutation matrices permutation matrix , latent transceiver designed consists bs beamforming vectors , optimally scaled rs permutation matrix receiver ratios given csi , optimal transceiver lowest total power consumption selected transmission propose concave convex procedure based type iterative algorithms non robust robust latent transceiver designs simulation results presented validate effectiveness proposed algorithms
explicit reliable memory regions hpc applications supporting error resilience future class systems critical challenge due scaling trends increasing memory density , scientific simulations expected experience caused transient errors system memory existing hardware based detection recovery techniques inadequate manage presence high memory fault rates r n paper propose partial memory protection scheme based region based memory management define concept regions called provide fault protection program objects provide reliability regions software based parity protection mechanism approach enables critical program objects placed fault coverage provided approach application agnostic , unlike algorithm based fault tolerance techniques
codes matrix space time coded known , transmission quasi static mimo fading channels n transmit antennas , diversity obtained using inner fully diverse space time block code coding gain , derived determinant criterion , comes appropriate outer code inner code cyclic algebra structure number field , perfect space time codes , outer code designed via coding precisely , take quotient algebra two sided ideal leads finite alphabet outer code , cyclic algebra structure finite field finite ring show determinant criterion induces various metrics outer code , hamming distances n 2 , partitioning code using ideal prime 2 leads consider codes either \( f 2 \) \( f 2 \) , non commutative matrix higher dimension , suitable perfect codes , give rise complex examples
deep reinforcement learning time scheduling rf powered backscatter cognitive radio networks rf powered backscatter cognitive radio network , multiple secondary users communicate secondary gateway harvesting energy actively data depending primary channel state coordinate transmission multiple secondary transmitters , secondary gateway needs schedule time , energy harvesting time , transmission time among however , dynamics primary channel uncertainty energy state secondary transmitters , challenging gateway find time scheduling mechanism maximizes total throughput paper , propose use deep reinforcement learning algorithm derive optimal time scheduling policy gateway specifically , deal problem large state action spaces , adopt double deep q network \( \) enables gateway learn optimal policy simulation results clearly show proposed deep reinforcement learning algorithm outperforms non learning schemes terms network throughput
vector quantization machine vision paper shows reduce computational cost variety common machine vision tasks operating directly compressed domain , particularly context hardware acceleration pyramid vector quantization \( \) compression technique choice properties exploited simplify support vector machines \( svm \) , convolutional neural networks \( cnns \) , histogram oriented gradients \( \) features , interest points matching algorithms
fine grained code changes working time , developers code changes version control system , often changes \( e g , \) single , thus creating called sharing commits problematic makes review , , integration commits harder historical analyses project less reliable researchers existing commits , e , finding part task paper , contribute line work two ways \( 1 \) publicly available dataset code changes , created help two developers accurately split code changes self contained tasks period four months \( 2 \) novel approach , , help developers share commits \( atomic commits \) using fine grained code change information based tested publicly available dataset , evaluated deploying 7 developers , used 2 median success rate 91 average one 75 , automatically creating clusters fine grained code changes
scalability message count trickle based broadcasting schemes use wireless sensor networks increases , need efficient reliable broadcasting algorithms grows ideally , broadcasting algorithm ability quickly data , keeping number transmissions low paper , analyze popular trickle algorithm , proposed suitable communication protocol code propagation wireless sensor networks show broadcasting process network using trickle modeled markov chain chain falls class markov chains , closely related residual lifetime distributions shown class markov chains admits stationary distribution special form results used analyze trickle algorithm message count results prove made literature concerning effect period besides providing mathematical analysis algorithm , propose generalized version trickle , additional parameter defining length period
minimize age information age information \( aoi \) newly proposed performance metric information differs traditional delay metric , destination centric measures time since last received information update generated source aoi analyzed several queueing models , problem optimizing aoi arrival service rates studied literature consider problem minimizing aoi space update generation service time distributions particular , ask whether , e periodic generation update packets deterministic service , optimizes aoi considering several queueing systems , show certain settings , deterministic service fact result worst case aoi , heavy distributed service yield minimum aoi leads interesting conclusion , queueing systems , service time distribution minimizes expected packet delay , variance packet delay , fact , result worst case aoi fundamental difference aoi metrics packet delay
back square one probabilistic trajectory forecasting without introduce spatio temporal convolutional neural network model trajectory forecasting visual sources applied auto way provides explicit probability distribution given initial trajectory segment discuss relation \( complicated \) existing work report experiments two standard datasets trajectory forecasting stanford , achieving results par better previous methods
revenue maximizing envy free pricing matching markets budgets study envy free pricing mechanisms matching markets items n budget constrained buyers buyer interested subset items , single value every item preference set moreover , buyer budget constraints maximum payment , aims obtain many items possible preference set goal compute envy free pricing allocation maximizes revenue , e , total payment buyers pricing problem hard approximate better omega \( rm min n , 1 2 epsilon \) epsilon 0 , unless p np hardness result due presence matching constraints given simpler multi unit case approximated constant factor 2 goal paper hardness result restricting specific settings valuations budgets two particularly significant scenarios buyer budget greater single value valuation , buyer budget lower single value valuation surprisingly , scenarios able achieve 1 4 approximation optimal envy free revenue algorithms utilize novel version price auction results may suggest , although difficult approximate optimal revenue general , price auctions could achieve relatively good revenue practical settings
data driven co clustering model internet usage large mobile design simulation future mobile networks center around human interests behavior propose design paradigm mobile networks driven realistic models users' line behavior , based mining wireless records introduce systematic method large scale multi dimensional web activity thousands mobile users 79 locations find surprisingly users consistently modeled using ten clusters disjoint profiles access patterns multiple locations show differential user behavior first study obtain detailed results mobile internet usage
local distributed sampling counting classic distributed graph problems , instance graph space feasible solutions \( e g proper \( delta 1 \) list colorings graph \) , task distributed algorithm construct feasible solution using local information r n study distributed sampling counting problems , instance joint distribution feasible solutions task distributed algorithm sample joint distribution , locally measure volume probability space via marginal probabilities latter task also known inference , local counterpart counting r n self reducible classes instances , following established local model polylogarithmic factors r n joint distributions , approximate inference approximate sampling computationally equivalent r n joint distributions defined local constraints , exact sampling reducible either one tasks r n , sequentially constructing feasible solution trivial locally , tasks easy joint distribution exhibits strong spatial mixing r n combining state arts strong spatial mixing , obtain efficient sampling algorithms local model various important sampling problems , including \( sqrt delta log \) round algorithm exact sampling matchings graphs maximum degree delta , \( log \) round algorithm sampling according model \( weighted independent sets \) uniqueness regime , along omega \( \) lower bound arxiv sampling according model non uniqueness regime , gives first computational phase transition distributed sampling
impact biases big data underlying paradigm big data driven machine learning reflects deriving better conclusions simply analyzing data , without necessity looking theory models simply data always helpful \? , collected 2 predict outcome year 's us presidential election outcome big data prediction proved entirely , whereas needed people make accurate prediction generally , biases occur machine learning whenever distributions training set test set different work , provide review different biases \( big \) data sets machine learning provide definitions discussions commonly biases machine learning class imbalance shift also show biases work text researchers practitioners become aware topic thus derive reliable models learning problems
potential flow generator l 2 optimal transport generative models propose potential flow generator l 2 optimal transport , easily integrated wide range generative models including different versions gans flow based models show correctness robustness potential flow generator several 2d problems , illustrate concept proximity due l 2 optimal transport subsequently , demonstrate effectiveness potential flow generator image translation tasks unpaired training data mnist dataset dataset
evaluating sequence sequence models text recognition encoder decoder models become effective approach sequence learning tasks like machine translation , image captioning speech recognition , yet show competitive results text recognition end , propose attention based sequence sequence model combines convolutional neural network generic feature recurrent neural network encode visual information , well temporal context characters input image , uses separate recurrent neural network decode actual character sequence make experimental comparisons various attention mechanisms positional encodings , order find appropriate alignment input output sequence model trained end end integration hybrid loss allows encoder retain interpretable output , desired achieve competitive results read data sets compared state art without use language model , significantly improve recent sequence sequence approaches
fixed point quantization deep convolutional networks recent years increasingly complex architectures deep convolution networks \( dcns \) proposed boost performance image recognition tasks however , gains performance come cost substantial increase computation model storage resources fixed point implementation dcns potential alleviate complexities facilitate potential deployment embedded hardware paper , propose quantizer design fixed point implementation dcns formulate solve optimization problem identify optimal fixed point bit width allocation across layers experiments show comparison equal bit width settings , fixed point dcns optimized bit width allocation offer 20 reduction model size without loss accuracy cifar 10 benchmark also demonstrate fine tuning enhance accuracy fixed point dcns beyond original floating point model , report new state art fixed point performance 6 78 error rate cifar 10 benchmark
rounding applications constraint satisfaction problems semidefinite programming powerful tool design analysis approximation algorithms combinatorial optimization problems particular , random rounding method , extensively studied two decades , resulting various extensions original technique algorithms wide range applications despite fact approach yields tight approximation guarantees problems , e g , max cut , many others , e g , max sat max , tight approximation ratio still unknown one main reasons fact techniques rounding semi definite known r n work , present new general simple method rounding semi definite programs , based motion approach inspired recent results algorithmic discrepancy theory develop present tools analyzing new rounding algorithms , utilizing mathematical theory motion , complex analysis , partial differential equations focusing constraint satisfaction problems , apply method several classical problems , including max cut , max , max , derive new algorithms competitive best known results show approach presenting simple natural variants , numerically demonstrate exhibit nearly optimal approximation guarantees problems
english foreign languages transferring pre trained language models pre trained models demonstrated effectiveness many downstream natural language processing \( nlp \) tasks availability multilingual pre trained models enables zero shot transfer nlp tasks high resource languages low resource ones however , recent research improving pre trained models focuses heavily english possible train latest neural architectures languages scratch , due required amount compute work , tackle problem transferring existing pre trained model english languages limited computational budget single gpu , approach obtain foreign bert base model within day foreign bert large within two days furthermore , evaluating models six languages , demonstrate models better multilingual bert two zero shot tasks natural language inference dependency parsing
cnn rnn framework crop yield prediction crop yield prediction extremely challenging due dependence multiple factors crop , environmental factors , management practices , interactions paper presents deep learning framework using convolutional neural networks \( cnn \) recurrent neural networks \( rnn \) crop yield prediction based environmental data management practices proposed cnn rnn model , along popular methods random forest \( rf \) , deep fully connected neural networks \( \) , lasso , used forecast yield across entire \( including 13 states \) united states years 2016 , 2017 , 2018 using historical data new model achieved root mean square error \( \) 9 8 respective average yields , substantially outperforming methods tested cnn rnn three salient features make potentially useful method crop yield prediction studies \( 1 \) cnn rnn model designed capture time dependencies environmental factors genetic improvement time without information \( 2 \) model demonstrated capability generalize yield prediction environments without significant drop prediction accuracy \( 3 \) coupled backpropagation method , model could reveal extent conditions , accuracy predictions , soil conditions , management practices able explain variation crop yields
millimeter wave communications oam sm scheme future mobile networks angular \( oam \) technique provides new degree freedom information transmissions millimeter wave communications considering spatial distribution characteristics oam , new oam spatial modulation \( oam sm \) millimeter wave communication system first proposed future mobile networks furthermore , capacity , average bit error probability energy efficiency oam sm millimeter wave communication systems analytically derived performance analysis compared conventional multi input multi output \( mimo \) millimeter wave communication systems , maximum capacity energy efficiency oam sm millimeter wave communication systems improved 3 , respectively moreover , numerical results indicate proposed oam sm millimeter wave communication systems robust path loss conventional mimo millimeter wave communication systems , makes suitable long range transmissions therefore , oam sm millimeter wave communication systems provide great growth space future mobile networks
graph optimization approach range based localization article , propose general graph optimization based framework localization , accommodate different types measurements varying measurement time intervals special emphasis range based localization range trajectory smoothness constraints constructed position graph , robot trajectory sliding window estimated graph based optimization algorithm moreover , convergence analysis algorithm provided , effects number iterations window size optimization localization accuracy analyzed extensive experiments variety scenarios verify effectiveness proposed algorithm demonstrate much higher localization accuracy existing range based localization methods , especially direction
dispersion analysis infinite constellations ergodic fading channels thesis considers infinite constellations fading channels , without power constraint perfect channel state information available receiver infinite constellations framework , proposed poltyrev , analyzing coded modulation codes poltyrev 's capacity , highest achievable normalized log density \( \) codewords per unit volume , possibly large block length , guarantees vanishing error probability given finite block length fixed error probability , gap highest achievable poltyrev 's capacity dispersion analysis asymptotically gap r n thesis dispersion analysis infinite constellations scalar fading channels later , extend analysis case multiple input multiple output fading channels channels , show gap highest achievable poltyrev 's capacity , asymptotically square root channel dispersion block length , inverse q function allowed error probability r n moreover , exact terms poltyrev 's capacity channel dispersion , derived thesis relations amplitude power constrained fading channels also discussed , especially terms capacity , channel dispersion error exponents relations typical cases unconstrained model interpreted limit constrained model , signal noise ratio tends infinity
modelling urban networks using variational autoencoders long standing question urban regional ability describe urban patterns quantitatively transport infrastructure , particularly street networks , provides source information urban patterns generated movements interactions increasing availability street network datasets advancements deep learning methods , presented unprecedented opportunity push frontiers urban modelling towards data driven accurate models urban forms study , present initial work applying deep generative models urban street network data create spatially explicit urban models based work variational autoencoders \( vaes \) deep generative models recently gained popularity due ability generate realistic images initial results show vaes capable capturing key high level urban network metrics using low dimensional vectors generating new urban forms complexity matching captured street network data
adversarial robustness 0 0 adversarial robustness \( art \) python library supporting developers researchers defending machine learning models \( deep neural networks , gradient decision trees , support vector machines , random forests , logistic regression , gaussian processes , decision trees , learn pipelines , etc \) adversarial threats helps making ai systems secure machine learning models vulnerable adversarial examples , inputs \( images , texts , data , etc \) modified produce desired response machine learning model art provides tools build deploy test adversarial attacks defending machine learning models involves verifying model robustness model approaches pre processing inputs , augmenting training data adversarial samples , leveraging runtime detection methods inputs might modified adversary attacks implemented art allow creating adversarial attacks machine learning models required test defenses state art threat models supported machine learning libraries include \( v2 \) , , , , learn , , , , source code art released mit license https github com adversarial robustness release includes code examples , documentation \( http url \)
cryptography multi located parties note describes cryptographic issues related multi located parties general , multi located parties make difficult eavesdropper attack , make easier address problems joint encryption error correction coding easier implement three stage quantum cryptography protocol
multi vehicle flocking control deep deterministic policy gradient method flocking control studied extensively along wide application multi vehicle systems paper multi vehicles system \( \) flocking control collision avoidance communication preserving considered based deep reinforcement learning framework specifically deep deterministic policy gradient \( \) centralized training distributed execution process implemented obtain flocking control policy first , avoid dynamically changed observation state , three layers tensor based representation observation used state remains constant although observation dimension changing reward function designed guide way points tracking , collision avoidance communication preserving reward function augmented introducing local reward function neighbors finally , centralized training process trains shared policy based common training set among agents proposed method tested simulated scenarios different setup
dynamic fair division problem general valuations paper , focus dynamically allocate resource fairly among n players arrive time players may general heterogeneous valuations resource known exact envy free proportional allocations may exist dynamic setting , 2011 thus , study extent guarantee fairness dynamic setting first design two algorithms \( log n \) proportional \( n \) envy free setting general valuations , constructing adversary instances dynamic algorithms must least omega \( 1 \) proportional omega \( n log n \) envy free , show bounds tight logarithmic factor moreover , introduce setting valuations uniform resource different demands , generalize setting et al , 2015 prove \( log n \) upper bound tight lower bound case
sense embedding learning word sense induction conventional word sense induction \( \) methods usually represent instance discrete linguistic features features , train model polysemous word individually work , propose learn sense embeddings task training stage , method induces several sense \( embedding \) polysemous word testing stage , method represents instance contextual vector , induces sense finding nearest sense embedding space advantages method \( 1 \) distributed sense vectors taken knowledge representations trained , usually better performance traditional count based models , \( 2 \) general model whole vocabulary jointly trained induce sense learning framework evaluated semeval 2010 dataset , method outperforms participants recent state art methods verify two advantages comparing carefully designed baselines
two phase authentication based communication iot home networks advancement technology , devices , considered non traditional terms internet capabilities , embedded communicate devices known iot devices technology enabled devices ability communicate internet network device create home iot network iot devices resource constrained lack high level security protocols thus , security becomes major issue network systems one way secure networks reliable authentication protocols data transfer mechanism devices controllable users , internet therefore , also method make communication internet iot devices users paper proposes two phase authentication protocol authentication purposes based secure channel creation communication devices network furthermore , paper discusses elliptic curve cryptography viable alternative efficient key exchange mechanism low powered iot devices network
reliable wide area backscatter via channel polarization long standing vision backscatter communications provide long range connectivity high speed transmissions internet things \( iot \) recent years seen major designing toward goal yet , either operate short range , experience extremely low throughput paper takes one step toward , presenting exploits channel polarization long range backscatter links transform backscatter channels nearly virtual channels channel polarization , bits extremely low error probability specifically , propose new polar code scheme automatically different channel quality , design low cost encoder accommodate polar codes resource constrained backscatter tags build prototype tag test various indoor environments experiments show prototype achieves 10 times throughput gain , extends range limit 1 8 times compared state art long range backscatter solution also simulate ic design nm lp cmos process compared traditional encoders , encoder reduces storage overhead three orders magnitude , power consumption
enabling high dimensional hierarchical uncertainty quantification tensor train decomposition hierarchical uncertainty quantification reduce computational cost stochastic circuit simulation employing spectral methods different levels paper presents efficient framework simulate challenging stochastic circuits systems include high dimensional due high parameter dimensionality , challenging extract surrogate models low level design hierarchy handle high level simulation paper , develop efficient analysis variance based stochastic circuit systems simulator efficiently extract surrogate models low level order avoid curse dimensionality , employ tensor train decomposition high level construct basis functions points , verify algorithm stochastic four random parameters challenging example efficiently simulated simulator cost regular personal computer
tight lower bounds longest common extension problem longest common extension problem problem preprocessing given string length n data structure uses \( n \) bits top input answers \( n \) time queries \( , j \) computing length longest string occurs positions j input prove trade \( n \) \( n \) omega \( n log n \) holds non uniform cell probe model provided input string read , letter separate memory cell , \( n \) omega \( n \) , size input alphabet least 2 8 \( n \) n known trade tight
power allocation multi user cellular networks deep q learning approach model driven power allocation \( \) algorithms wireless cellular networks multiple access channel \( \) investigated decades nowadays , data driven model free machine learning based approaches rapidly developed field , among deep reinforcement learning \( drl \) proved great promising potential different supervised learning , drl takes advantages exploration exploitation maximize objective function certain constraints paper , propose two step training framework first , line learning simulated environment , deep q network \( dqn \) trained deep q learning \( \) algorithm , well designed consistent issue second , dqn fine tuned real data line training procedure simulation results show proposed dqn achieves highest sum rate , comparing ones present training different user densities , dqn outperforms benchmark algorithms thus good generalization ability verified
virtual full duplex wireless broadcasting via compressed sensing novel solution proposed frequent task wireless networks , let nodes broadcast information receive information respective one hop neighboring nodes contribution two fold first , neighbor selects one message bearing codeword unique transmission , shown decoding messages based superposition codewords channel problem compressed sensing case message consists small number bits , iterative algorithm based belief propagation developed efficient decoding second , satisfy half duplex constraint , codeword consists randomly distributed slots slots node slots , neighbors slots one frame interval , node message neighbors simultaneously decodes messages based signals received slots thus solution fully exploits nature wireless medium addresses half duplex constraint fundamental level network consisting poisson distributed nodes , numerical results demonstrate proposed scheme often achieves several times rate slotted aloha csma packet error rate
railway track specific traffic signal selection using deep learning railway industry moving actively towards automation , accurate location track assets like traffic signals , , , , etc extreme importance new positive train control \( \) coming effect , many railway safety rules tied directly location assets like signals speed enforced based location train respect hence essential accurate database types locations assets paper real world use case detecting railway signals camera mounted moving tracking locations camera environment factors moving train provide consistent steady image around 30 frames per second using advanced image analysis deep learning techniques , signals detected camera images database locations created railway signals differ lot road signals terms shapes rules placement respect track due space constraint traffic densities urban areas signals placed side track multiple lines run parallel hence need associate signal detected track train runs present method associate signals specific track belong using video feed front facing camera mounted lead pipeline track detection , region interest selection , signal detection implemented gives overall accuracy 94 7 route covering signals
role management practices productivity gap management practices linked productivity performance however , research findings mixed paper provides multi review current evidence relationship offers suggestions exploration provide extensive review literature terms research findings studies trying measure understand impact individual management practices clusters management r n practices productivity different levels analysis focus review operations r n management \( \) human resource management \( \) practices well joint applications r n practices conclusion , taken whole , research findings r n studies found positive relationship adoption management practices r n productivity , negative association believe lack universal r n consensus effect adoption complementary management practices might driven either r n measurement issues level analysis consequently , need research r n particular , multi level approach lowest possible level aggregation level r n analysis order assess impact management practices upon productivity firms
primitives non blocking data structures define new set primitive operations greatly simplify implementation non blocking data structures asynchronous shared memory systems new operations operate set data records , contains multiple fields operations generalizations well known load link \( \) store conditional \( sc \) operations called operation takes one data record operation process p data record specified set changed since p last performed successful , updates one specific field data record set future changes specified subset data records provide provably correct implementation new primitives single word compare swap simple example , show implement non blocking multiset data structure straightforward way using
optimality treating interference noise compound interference networks k user gaussian interference channel , shown et al user desired signal strength less sum strengths strongest interference user strongest interference user \( values db scale \) , power control treating interference noise \( tin \) optimal perspective generalized degrees freedom \( gdof \) achieves entire channel capacity region within constant gap work , generalize optimality tin compound networks show k user compound gaussian interference channel , every possible state receiver , channel always satisfies tin optimality condition identified et al , gdof region compound channel intersection gdof regions possible network , achievable power control tin furthermore , demonstrate general k user compound interference channel , regardless number states receiver , always construct counterpart k user regular interference channel tin region original compound channel regular interference channel one state receiver , may different original states solving gdof based power control problem compound channel equivalent solving problem regular counterpart exploring power control problem develop centralized power control scheme k user compound interference channels , achieve pareto optimal gdof tuples finally , based scheme , devise iterative power control algorithm requires k updates obtain globally optimal power allocation feasible gdof tuple
fundamental limits profiling velocity compensation frequency frequency \( \) effective achieving high range resolution \( \) modern paper , determine various fundamental limits regarding ambiguity , stability accuracy stationary target profiling velocity compensation accuracy moving targets investigation reveals using information contained phase signal , achieve profiles without ambiguity criterion range shift caused target velocity results paper aid design development processing algorithms profiling velocity compensation
network slicing based 5g future mobile networks mobility resource management challenges fifth generation \( 5g \) networks expected able satisfy users' different quality service \( qos \) requirements network slicing promising technology 5g networks provide services tailored users' specific qos demands driven increased massive wireless data traffic different application scenarios , efficient resource allocation schemes exploited improve flexibility network resource allocation capacity 5g networks based network slicing due diversity 5g application scenarios , new mobility management schemes greatly needed guarantee handover network slicing based 5g systems article , introduce logical architecture network slicing based 5g systems , present scheme managing mobility different access networks , well joint power allocation scheme spectrum sharing two tier systems based network slicing , co tier interference cross tier interference taken account simulation results demonstrate proposed resource allocation scheme flexibly allocate network resources different slices 5g systems finally , several open issues challenges network slicing based 5g networks discussed , including network reconstruction , network slicing management cooperation 5g technologies
knowledge based sequential decision making uncertainty deep reinforcement learning \( drl \) algorithms achieved great success sequential decision making problems , yet lack data efficiency explainability especially , explainability subtasks critical hierarchical decision making since enhances transparency black box style drl methods helps rl practitioners understand high level behavior system better improve data efficiency explainability drl , knowledge introduced work novel algorithm proposed integrating drl symbolic planning experimental analysis publicly available benchmarks explainability subtasks shows method outperform state art approach terms data efficiency
two trees one reads optimized oblivious accesses large scale blockchains bitcoin network offered new way securely performing financial transactions network nevertheless , ability comes cost storing large \( distributed \) , become personal devices kind although simplified payment verification \( spv \) clients address storage issue , bitcoin spv client rely bitcoin nodes obtain transaction history current approaches offer privacy guarantees spv clients r n work presents 3 , trusted hardware bitcoin full client supports efficient oblivious search update bitcoin spv clients without sacrificing privacy clients design , leverage trusted execution capabilities trusted execution environment \( \) ability access patterns oblivious random access memory \( \) protect spv potentially malicious server key novelty 3 lies optimizations introduced conventional , tailored expected spv client usages particular , making natural assumption access patterns spv clients , able propose two tree construction overcomes concurrency limitation associated traditional implemented tested system using current bitcoin transaction output database experiment shows system feasible deployed practice providing strong privacy security guarantees bitcoin spv clients
solving inverse computational imaging problems using deep pixel level prior generative models based deep neural networks quite powerful modelling natural image statistics particular , deep auto models provide state art performance , terms log likelihood scores , modelling tractable densities image manifold work , employ learned deep auto model data prior solving different inverse problems computational imaging demonstrate approach reconstruct images better pixel level , compared existing deep auto encoder based approaches also show randomly dropping update pixels every iteration helps better image reconstruction test approach three computational imaging single pixel camera , real simulated measurements obtain better state art methods problems , terms perceptual quality quantitative metrics
survey latent tree models applications data analysis , latent variables play central role help provide powerful insights wide variety phenomena , ranging biological human latent tree model , particular type probabilistic graphical models , attention simple structure tree allows simple efficient inference , latent variables capture complex relationships past decade , latent tree model subject significant theoretical developments review , propose comprehensive study model first key ideas underlying model second explain efficiently learned data third illustrate use within three types applications latent structure discovery , multidimensional clustering , probabilistic inference finally , conclude give promising directions future researches field
depth motion network learning monocular stereo paper formulate structure motion learning problem train convolutional network end end compute depth camera motion successive , unconstrained image pairs architecture composed multiple stacked encoder decoder networks , core part iterative network able improve predictions network estimates depth motion , additionally surface , optical flow images confidence matching crucial component approach training loss based spatial relative differences compared traditional two frame structure motion methods , results accurate robust contrast popular depth single image networks , learns concept matching , thus , better generalizes structures seen training
communication efficiency self stabilizing protocols self general paradigm provide forward recovery capabilities distributed systems networks intuitively , protocol self stabilizing able recover without external intervention catastrophic transient failure paper , focus lower communication complexity self stabilizing protocols emph need checking every neighbor details , contribution paper \( \) provide new complexity measures communication efficiency self stabilizing protocols , especially phase faults , \( ii \) negative side , show non trivial problems coloring , maximal matching , maximal independent set , impossible get \( deterministic probabilistic \) self stabilizing solutions every communicates less every neighbor phase , \( iii \) positive side , present protocols coloring , maximal matching , maximal independent set fraction participants communicates exactly one neighbor phase
sequential multiple tasks networks naturally learn learn explore behavior standard convolutional neural net setting introduces classification tasks sequentially requires net master new tasks preserving previously learned tasks setting corresponds human face acquire domain expertise , example , individual reads textbook chapter chapter simulations involving sequences ten related tasks , find reason nets scale well advance single skill becoming domain experts observed two key phenomena first , forward accelerated learning task n 1 learned n previous tasks grows n second , backward interference forgetting n previous tasks learning task n 1 n forward goal research , backward interference goal research catastrophic forgetting find goals simply exposure domain
field energy efficient random forest machine learning \( ml \) algorithms , like convolutional neural networks \( cnn \) , support vector machines \( svm \) , etc become widespread achieve high statistical performance however accuracy decreases significantly energy constrained mobile embedded systems space , computations need tight energy budget work , present field \( fog \) implementation random forests \( rf \) achieves accuracy comparable cnns tight energy budgets evaluation fog shows comparable accuracy 1 , , 2 , lower energy per classification compared conventional rf , svm rbf , , cnn , respectively fog 6 less energy efficient svm lr , achieves 18 higher accuracy average across considered datasets
los based beamforming power scaling law massive mimo systems paper massive mimo systems flat fading channels order reduce overhead obtain full channel state information avoid pilot contamination problem , treating component interference , investigate transmit receive beamforming \( \) transmission scheme based line sight \( los \) component rank 1 model , first consider single user system n transmit receive antennas , focus problem power scaling law transmit power scaled proportionally 1 shown grows large , interference , ergodic achievable rate higher corresponding scheme based fast fading minimum mean square error \( mmse \) channel estimation consider uplink downlink single cell scenarios base station \( bs \) antennas k users n antennas transmit power user scaled proportionally 1 , shown finite users grows without bound , user obtains finally rate performance single user case even n grows without bound , however , still remains inter user los interference regarding infinite users , exists power scaling law k b power go infinity fixed finite ratio given b \( 0 , 1 \) , inter user los interference also fast fading effect , fast fading effect b 1 extension multi cells frequency selective channels also discussed moreover , numerical results indicate antenna correlation serious influence rate performance , bs antennas may allowed placed large
examining uk drill music sentiment trajectory analysis paper presents techniques natural language processing used examine sentiment trajectories related drill music united \( uk \) work important key public making drill music recent thus , paper dynamic use sentiment related drill music findings suggest two distinct sentiment use patterns statistical analyses revealed positive views negative ones work provides first empirical insights language use drill music , , therefore , used future studies help understand drill
load synchronization induced control market based coordination strategies recently proposed controlling aggregate demand large number loads schemes offer operational benefits enforcing distribution capacity limits providing users flexibility energy based price however , paper demonstrates also prone load synchronization power energy framework adopted applied population controlled loads \( \) modified switching logic takes account market coordination signals , natural based switching conditions studies market based coordination scheme suggest several factors may contribute load , including sharp changes market prices broadcast loads , lack diversity user specified curves , low limits encountered , form user curves case studies illustrate challenges associated market based coordination strategies provide insights modifications address issues
robustness guarantees deep neural networks videos widespread adoption deep learning models places demands robustness paper , consider robustness deep neural networks videos , spatial features individual frames extracted convolutional neural network temporal dynamics adjacent frames captured recurrent neural network measure robustness , study maximum safe radius problem , computes minimum distance optical flow set obtained given input adversarial example norm ball demonstrate , assumption , problem approximated using finite optimisation via optical flow space , approximation provable guarantees show finite optimisation problem solved two player turn based game cooperative setting , first player selects optical flows second player determines dimensions chosen flow employ approach solve game , sense approximating value game improving upper lower bounds exploit gradient based search algorithm compute upper bounds , admissible algorithm update lower bounds finally , evaluate framework ucf101 video dataset
detecting adversarial perturbations spatial behavior activation spaces neural network based classifiers still prone manipulation adversarial perturbations state art attacks overcome defense detection mechanisms suggested far , adversaries upper hand adversarial examples designed normal input constructed , incorrect classification basic design goal leads characteristic spatial behavior within context activation spaces , term coined authors refer formed activation values network 's layers within output first layers network , adversarial example likely normal instances source class , final layers examples towards adversary 's target class steps enable us leverage inherent shift one class another order form novel adversarial example detector construct spaces activation values deep neural network layers , induce set k nearest neighbor classifiers \( k nn \) , one per activation space neural network layer , using non adversarial examples leverage classifiers produce sequence class labels input sample estimate priori probability class label change one activation space another detection phase compute sequence classification labels input using trained classifiers estimate likelihood classification sequences show adversarial sequences far less likely normal ones evaluated detection method state art c w attack method , using two image classification datasets \( mnist , cifar 10 \) reaching auc 0 95 cifar 10 dataset
outage minimization fading wireless link energy harvesting transmitter receiver paper studies online power control policies outage minimization fading wireless link energy transmitter receiver outage occurs either transmitter receiver enough energy , channel outage , transmitter channel distribution information infinite battery without , prove threshold based power control policies optimal thus propose disjoint joint threshold based policies without battery state sharing transmitter receiver , respectively also analyze impact practical receiver detection processing outage performance considered , policy linear power levels adopted adapt power thresholds per finite battery capacity , three finite state markov chain formulated calculate optimal parameters corresponding performance proposed policies energy arrival correlation transmitter receiver addressed finite infinite battery cases numerical results show impact battery capacity , energy arrival correlation detection cost outage performance proposed policies , well tradeoff outage probability average transmission times
multidimensional transformation based learning paper presents novel method allows machine learning algorithm following transformation based learning paradigm cite tagging applied multiple classification tasks training jointly simultaneously fields motivation constructing system stems observation many tasks natural language processing naturally composed multiple subtasks need resolved simultaneously also tasks usually learned possibly benefit learned joint framework , signals extra tasks usually constitute inductive bias r n proposed algorithm evaluated two experiments one , system used jointly predict part speech text english corpus second used learn joint prediction word segment boundaries part speech tagging chinese results show simultaneous learning multiple tasks achieve improvement task upon training tasks sequentially part speech tagging result 96 state art individual systems particular train test split
learning grasp 3d objects using deep residual u nets detection one challenging tasks robotics must predict grasp configuration object interest real time enable robot interact environment paper , present new deep learning approach detect object given 3d object method trains convolutional neural network \( cnn \) learn set grasping features rgb images named approach emph u net since architecture network designed based u net structure residual network blocks robust efficient compute use set experiments performed assess performance proposed approach regarding grasp success rate simulated robotic scenarios experiments validate promising performance proposed architecture subset dataset simulated robot scenarios
new lower bounds permutation codes using linear block codes paper prove new lower bounds maximal size permutation codes connecting theory permutation codes theory linear block codes specifically , using columns parity check matrix n , k , q linear block code , able prove existence permutation code symmetric group degree n , minimum distance least large cardinality technique , obtain new lower bounds permutation codes enhance ones literature provide asymptotic improvements certain regimes length distance permutation code
life new city noise sensor network noise one quality life issues urban united states continued exposure high levels noise proven effects health , including effects sleep , long term effects , disease , loss investigate ultimately aid mitigation urban noise , network sensor nodes deployed across new city two years , collecting sound pressure level \( \) audio data network 75 years , high resolution measurements years audio data addition , high frequency data collected provides sensors health data analyzed 18 period across 31 sensors used develop prototype model pre failure detection ability identify sensors state 1 time entire network infrastructure , including operation sensors , followed analysis data yield development fault detection approach future system integration plans
deep ensemble framework fake news detection classification fake news , rumor , incorrect information , misinformation detection nowadays crucial issues might serious consequences social rate information increasing rapidly due availability enormous web information sources including social media , news , online etc r n paper , develop various deep learning models detecting fake news classifying pre defined fine grained categories r n first , develop models based convolutional neural network \( cnn \) bi directional long short term memory \( bi lstm \) networks representations obtained two models fed multi layer perceptron model \( \) final classification experiments benchmark dataset show promising results overall accuracy 44 87 , outperforms current state art
orthogonality constrained multi head attention keyword spotting multi head attention mechanism capable learning various representations sequential data paying attention different subsequences , e g , word spoken word subsequences , information single head attention whole sequence one context vector however , naive use multi head attention guarantee attention heads may positional representational redundancy paper , propose regularization technique multi head attention mechanism end end neural keyword spotting system augmenting regularization terms positional contextual non orthogonality attention heads encourages output different representations separate subsequences , turn enables leveraging structured information without explicit sequence models hidden markov models addition , intra head contextual non orthogonality regularization encourages attention head similar representations across keyword examples , helps classification reducing feature variability experimental results demonstrate proposed regularization technique significantly improves keyword spotting performance keyword
optimal multi dimensional mechanism design reducing revenue welfare maximization provide reduction revenue maximization welfare maximization multi dimensional bayesian auctions arbitrary \( possibly combinatorial \) feasibility constraints independent bidders arbitrary \( possibly combinatorial \) demand constraints , appropriately extending 's result setting also show every feasible bayesian auction implemented distribution virtual vcg allocation rules virtual vcg allocation rule following simple form every bidder 's type transformed virtual type f \( \) , via bidder specific function , allocation maximizing virtual welfare chosen using characterization , show find run revenue optimal auction given black box access implementation vcg allocation rule generalize result arbitrarily correlated bidders , introducing notion second order vcg allocation rule r n obtain reduction revenue welfare optimization via two algorithmic results reduced forms settings arbitrary feasibility demand constraints first , provide separation determining feasibility reduced form second , provide geometric algorithm decompose feasible reduced form distribution virtual vcg allocation rules addition , show execute algorithms given black box access implementation vcg allocation rule r n results computationally efficient multi dimensional settings bidders additive case , mechanisms run time polynomial total number bidder types , type profiles generic correlated distributions , natural description complexity problem runtime improved poly \( items , bidders \) item symmetric settings making use recent techniques
cognition enabled robot perception manipulation tasks question designing intelligent autonomous systems integrate various complementary tasks specifically , robotic vision must provide task relevant information environment objects various planning related modules implementations traditional perception cognition action paradigm tasks quasi independent modules function black boxes view perception benefit tight collaboration cognition present , knowledge enabled cognitive perception systems mobile robots performing human scale manipulation tasks , perception interpretation realistic scenes formulated unstructured information management \( \) problem application principle supports implementation perception systems answer task relevant queries objects scene , boost object recognition performance combining strengths multiple perception algorithms , support knowledge enabled reasoning objects enable automatic knowledge driven generation processing pipelines demonstrate potential proposed framework feasibility studies systems real world scene perception built top framework
membership problem finite algebras cube terms membership problem problem deciding given element algebra given set generators one best established computational problems algebra consider variant problem , motivated recent progress constraint satisfaction problem , often referred membership problem \( smp \) smp given set tuples direct product algebras fixed finite set mathcal k finite algebras , whether given tuple direct product generated given set r n main result membership problem smp \( mathcal k \) p mathcal k finite set finite algebras cube term , provided mathcal k contained small variety also prove finite set finite algebras mathcal k variety cube term , one problems smp \( mathcal k \) , smp \( mathbb mathcal k \) , finding compact representations mathcal k , polynomial time reducible others , first two lie np
answer set programming answer set programming \( asp \) powerful modeling combinatorial problems however , writing asp models trivial propose novel method , called answer set programming \( \) , aiming supporting user issue user asp program uncertain parts open question addition , user provides number positive negative examples desired program behaviour model another asp program , solved traditional methods result , user obtains functional asp program modelling problem evaluate approach 21 well known combinatorial problems inspired 's 21 np complete problems demonstrate use case database application based asp
multi scale weight sharing network image recognition paper , explore idea weight sharing multiple scales convolutional networks inspired traditional computer vision approaches , share weights convolution kernels different scales layers network although multi scale feature aggregation sharing inside convolutional networks common practice , previous works address issue convolutional weight sharing evaluate weight sharing scheme two heterogeneous image recognition datasets imagenet \( object recognition \) standard \( scene classification \) approximately 25 fewer parameters , shared weight resnet model provides similar performance compared baseline shared weight models validated via transfer learning experiments four additional image recognition datasets stanford 40 actions \( object centric \) mit \( scene centric \) experimental results demonstrate significant redundancy vanilla implementations deeper networks , also indicate shift towards increasing receptive field per parameter may improve future convolutional network architectures
security management aware 5g v2x security primary concern networks aiming utilization cellular \( c \) services connecting vehicles \( v2x \) present , c v2x observing paradigm shift long term evolution \( lte \) universal radio access network \( e \) fifth generation \( 5g \) based functional architecture however , security management still concerns resolved 5g v2x number key updates non availability sub functions edge cause overheads performance variants cyber attacks paper , security management studied principle tradeoff evaluated number key updates required maintain connection vehicle 5g terminals keeping security functions numerical study presented determine claims understand proposed tradeoff
filters superior template protection iris recognition address fundamental performance issues template protection \( \) iris verification base work popular bloom filter templates protection address key challenges like sub optimal performance low specifically , focus cases bloom filter templates results non ideal performance due presence large within iris images iris recognition number factors presence eye within captured image , occlusion due , low quality iris images due motion factors result obtaining non reliable iris codes thereby provide non ideal biometric performance factors directly impact protected templates derived iris images classical bloom filters employed end , propose extend earlier ideas filters obtaining better reliable templates iris filter based iris codes based leveraging intra inter class distribution exploiting low rank iris codes derive stable bits across iris images particular subject also analyzing bits across various subjects low rank non noisy iris codes enables template protection superior way used constrained setting , also relaxed iris imaging extend work analyze applicability iris images employing large scale public iris image database \( v2 \) , captured unconstrained setting set experiments , demonstrate applicability proposed approach strengths yet another contribution work stems assessing security proposed approach factors studied indicate nature relaxed iris imaging scenarios
network analysis links economic journals exploratory analysis developed paper relies hypothesis power definition policy journal consequently board two journals , journals could common elements policies proximity policies two scientific journals number common database journals used structure network generated explored applying instruments network analysis evidence found compact network containing different components interpreted result perspectives appropriate methods investigation problems construction theories within domain economics
fully dense globally consistent 3d map reconstruction approach enhance relevance capsule robot \( \) field , wireless capsule emerging novel , diagnostic technology inspection diagnosis wide range diseases since development technology , medical device companies many research groups made substantial progress passive capsule robotic active capsule functionality current active flexible however , robotic capsule still challenges particular , use devices generate precise three dimensional \( 3d \) mapping entire inner remains problem global 3d maps inner would help detect location size areas accurately intuitively , thus reliable knowledge , paper presents first complete pipeline complete 3d visual map reconstruction proposed pipeline modular includes preprocessing module , image registration module , final shape based 3d reconstruction module 3d map primarily generated combination image shape techniques , updated frame frame iterative fashion via capsule motion inside comprehensive quantitative analysis proposed 3d reconstruction method performed using simulator , three different cameras , 3d optical
small representations big kidney exchange graphs kidney exchanges markets patients swap last decade , kidney exchanges small regional large national soon , international growth results lives , empirical hardness mathcal np complete problem optimally matching patients state art matching engines use integer programming techniques clear kidney exchanges , methods must tailored specific models objective functions , may fail scale larger exchanges paper , observe kidney exchange compatibility graph encoded constant number patient attributes , problem solvable polynomial time give necessary sufficient conditions representation arbitrary compatibility graph , using real compatibility graphs kidney exchange , show many attributes needed encode real compatibility graphs experiments show , indeed , small numbers attributes
social centrality using network hierarchy community structure several centrality measures formulated quantify notion social networks current measures either local global connectivity nodes found inadequate social networks ignoring hierarchy community structure , inherent human social networks , primary cause positional hierarchy actor community intuitively crucial importance theory social actor 's importance derived position network hierarchy well potential resources intra community \( \) inter community \( bridging \) inspired idea , propose novel centrality measure sc \( social centrality \) social networks measure accounts \) individual 's propensity , ii \) connections within outside community two factors aggregated produce social centrality score comparative analysis sc measure classical recent centrality measures using large public networks shows consistently produces realistic ranking nodes inference based available ground truth tested networks extensive analysis sc measure mapping known well studied networks effectiveness diverse social networks scalability evaluation sc measure efficacy real world large networks
analog neural network computing engine using cmos compatible ctt analog neural network computing engine based cmos compatible \( ctt \) proposed paper ctt devices used analog multipliers compared digital multipliers , ctt based analog shows significant area power reduction proposed computing engine composed scalable ctt array energy efficient analog digital interfaces implementing sequential analog fabric \( \) , engine mixed signal interfaces simplified hardware overhead remains constant regardless size array proof concept ctt computing engine implemented using cmos technology 0 simulated performance achieves 76 8 \( 8 bit \) 500 clock frequency 14 8 example , utilize computing engine address classic pattern recognition problem classifying mnist database obtained performance comparable state art fully connected neural networks using 8 bit fixed point resolution
real time fusion network rgb semantic segmentation incorporating obstacle detection road driving images semantic segmentation made progress due success deep convolutional neural networks considering demand autonomous driving , real time semantic segmentation become research years however , real time rgb fusion semantic segmentation studies carried despite readily accessible depth information nowadays paper , propose real time fusion semantic segmentation network termed efficiently exploits complementary features depth information enhance performance attention augmented way , running necessity autonomous vehicles applications multi dataset training incorporate small obstacle detection , classes required face real world comprehensive set experiments demonstrates effectiveness framework textit cityscapes , method outperforms previous state art semantic , excellent accuracy inference speed full times resolution , outperforming existing rgb networks
analysis differential phase shift quantum key distribution review implementation two protocols \( \) keeping mind implementations easily satisfy requirement use single argue current models take account issues uncertainty principle related time location transmission characteristics single indicates security proofs current implementations even recent successful made hard obtain
term set expansion based nlp intel ai present , corpus based system expanding seed set terms complete set terms belong semantic class implements iterative end end workflow enables users easily select seed set terms , expand , view expanded set , validate , expand validated set store , thus simplifying extraction domain specific fine grained semantic classes used successfully real life use cases including integration automated system issues resolution system video available https url \( images privacy reasons \)
free diagrams triangulations show , mild conditions underlying metric , appropriately defined diagrams embedded triangulations furthermore , always convex vertices , properties parallel ordinary triangulations results apply diagrams set vertices , long diagram free
line construction position propose simple linear time line algorithm constructing position heap string ehrenfeucht et al , 2011 definition position heap differs slightly one proposed ehrenfeucht et al , 2011 considers ordered left right construction based classic suffix pointers 's algorithm suffix trees , 1995 using suffix pointers , position heap extended augmented position heap allows linear time string matching algorithm ehrenfeucht et al , 2011
secure retrospective interference alignment paper , k user interference channel secrecy constraints considered delayed channel state information transmitters \( csit \) propose novel secure retrospective interference alignment scheme transmitters carefully information symbols artificial noises ensure confidentiality achieving positive secure degrees freedom \( \) challenging due delayed nature csit , distributed nature transmitters scheme works two phases phase one , transmitter sends information symbols mixed artificial noises , transmission multiple rounds next phase , transmitter uses delayed csit previous phase sends function net interference artificial noises \( generated previous phase \) , simultaneously useful receivers phases designed ensure desired messages satisfying secrecy constraints present achievable scheme three models , namely \( 1 \) k user interference channel confidential messages \( ic cm \) , show 1 2 \( k 6 \) achievable \( 2 \) k user interference channel external eavesdropper \( ic ee \) \( 3 \) k user ic confidential messages external eavesdropper \( ic cm ee \) show k user ic ee , 1 2 \( k 3 \) achievable , k user ic cm ee , 1 2 \( k 6 \) achievable best knowledge , first result k user interference channel secrecy constrained models delayed csit achieves scales k , square root number users
bounded budget network creation game introduce network creation game player \( vertex \) fixed budget establish links players model , link unit price , agent tries minimize cost , either total distance players underlying \( undirected \) graph created network two versions game studied max version , cost vertex maximum distance vertex vertices , , sum version , cost vertex sum distances vertex vertices prove versions pure nash equilibria exist , problem finding best response vertex np hard take social cost created network diameter , next study maximum possible diameter equilibrium graph n vertices various cases sum players budgets n 1 , equilibrium graphs always trees , prove maximum diameter \( n \) \( log n \) max sum versions , respectively vertex unit budget \( e , establish link one vertex \) , diameter equilibrium graph either version \( 1 \) give examples equilibrium graphs max version , vertices positive budgets yet diameter \( \) interesting \( \) result shows increasing budgets may increase diameter equilibrium graphs hence network structure prove every equilibrium graph sum version diameter \( \) finally , show budget player least k , every equilibrium graph sum version k connected diameter smaller 4
networks risk understanding structure interactions firms critical identify risk concentration possible propagation financial paper consider due , investigating large dataset firms , characterize topological properties payment network focus relation net work risk firms show existence risk , e tendency firms similar risk connected among effect observed considering pairs firms consider communities identified network applying machine learning techniques , leverage knowledge show network properties node used predict missing results suggest risk assessment take account also network interactions among firms
system theoretic approach bandwidth estimation shown bandwidth estimation packet networks viewed terms min plus linear system theory available bandwidth link complete path expressed terms em service curve , function appears network calculus express service available traffic flow service curve estimated based measurements sequence probing packets passive measurements sample path shown existing bandwidth estimation methods derived min plus algebra network calculus , thus providing mathematical justification methods principal difficulties estimating available bandwidth measurement network related potential non underlying network networks viewed systems operate either linear non linear regime , probing schemes extract information point network linear non linear regime experiments testbed university evaluate robustness system theoretic interpretation networks practice multi node experiments evaluate well convolution operation min plus algebra provides estimates available bandwidth path estimates individual links
parameterized algorithms generalizations directed feedback vertex set directed feedback vertex set \( \) problem takes input directed graph g seeks smallest vertex set cycles g one 's 21 mathsf np complete problems parameterized complexity status long standing open problem et al 2008 , j 2008 showed fixed parameter tractability via 4 ! n mathcal \( 1 \) time algorithm , k r n show fixed parameter tractability two generalizations r n find smallest vertex set every strong component g size give algorithm solving problem time 4 k \( k \) ! cdot n mathcal \( 1 \) generalizes algorithm 2017 undirected version problem r n find smallest vertex set every non trivial strong component g 1 regular give algorithm solving problem time 2 mathcal \( k 3 \) cdot n mathcal \( 1 \) r n also solve corresponding arc versions problems fixed parameter algorithms
degrees freedom secrecy wireless relay networks translate problem designing secure communications protocol several users communicating relay wireless network understanding certain products calculate dimension provide various results concerning equations relay users number antennas , approach places fundamental limits amount data network
tri tri finding triangles small subgraphs distributed setting let g \( v , e \) n vertex graph vertex graph , constant subgraph g \? consider problem model n processes connected processes , message contains \( log n \) bits simple deterministic algorithm requires \( n \( \( 2 \) \) log n \) communication rounds presented special case triangle , present probabilistic algorithm requires expected \( \( n \( 1 3 \) \( \( 2 3 \) 1 \) \) \) rounds communication , number triangles graph , \( min n \( 1 3 \) log \( 2 3 \) n \( \( 2 3 \) 1 \) , n \( 1 3 \) \) high probability r n also present deterministic algorithms specially suited sparse graphs graph maximum degree delta , test arbitrary subgraphs diameter \( \( delta \( 1 \) n \) \) rounds triangles , devise algorithm round complexity \( 2 n log \( 2 n 2 \) n \) , denotes g
innovative approaches efficiently complex data web research data produced important technologies design , management use information systems decision support development internet , availability various types data increased thus , users require applications help obtaining knowledge web one possible solution facilitate task extract information web , transform load web , provides uniform access methods automatic processing data chapter , present three innovative researches recently introduced extend capabilities decision support systems , namely \( 1 \) use logical physical model complex data warehouses , \( 2 \) data mining allow analysis tasks complex data \( 3 \) schema evolution complex data warehouses personalized analyses contributions cover main phases data design process data integration modeling user driven analysis
degrees freedom k user time correlated broadcast channel delayed csit degrees freedom \( dof \) k user miso broadcast channel \( bc \) studied transmitter \( \) access delayed channel estimate addition imperfect estimate current channel current estimate could example obtained prediction applied past estimates , case feedback delay within coherence time building previous recent works setting two users , estimation error current channel characterized scaling p exponent alpha , alpha 1 \( resp alpha 0 \) corresponds estimate essentially perfect \( resp useless \) terms dof work , contribute characterization dof region setting deriving dof region providing achievable dof region achievable dof obtained developing new alignment scheme , called k alpha scheme , builds upon principle alignment scheme zero forcing achieve larger dof delayed csit received correlated instantaneous channel state
multimodal based interface autonomous systems present \( multimodal intelligent interaction autonomous systems \) , multimodal interface support situation awareness autonomous vehicles based interaction user able vehicle 's plan , objectives , previous activities progress system mixed actively sends messages key events , fault demonstrate using 's command control interface simulator
survey community search big graphs rapid development information technologies , various big graphs prevalent many real applications \( e g , social media knowledge bases \) important component graphs network community essentially , community group vertices densely connected community retrieval used many real applications , event organization , recommendation , consequently , efficiently find high quality communities big graphs important research topic era big data recently large group research works , called community search , proposed aim provide efficient solutions searching high quality communities large networks real time nevertheless , works focus different types graphs formulate communities different , thus desirable comprehensive review works r n survey , conduct review existing community search works moreover , analyze compare quality communities models , performance different solutions furthermore , point new research directions survey help researchers better understanding existing community search solutions , also provides practitioners better judgment choosing proper solutions
safe reinforcement learning via probabilistic paper targets efficient construction safety decision making scenarios incorporate uncertainty markov decision processes \( mdps \) prominent models capture planning problems reinforcement learning \( rl \) machine learning technique determine near optimal policies mdps may unknown prior exploring model however , exploration , rl prone induce behavior allowed safety critical contexts introduce concept probabilistic enables decision making safety constraints high probability separation concerns , employ formal verification efficiently compute probabilities critical decisions within safety relevant fragment mdp use results realize applied rl algorithm optimizes actual performance objective discuss tradeoffs sufficient progress exploration environment ensuring safety experiments , demonstrate game case study involving service robots learning efficiency increases learning needs orders magnitude fewer
construction new delay tolerant space time codes perfect space time codes \( \) optimal codes original construction multiple input multiple output \( mimo \) systems based cyclic division algebras \( \) , full rate , full diversity codes , non vanishing \( \) hence achieve diversity multiplexing tradeoff \( \) addition , codes led optimal distributed space time codes applied cooperative networks assumption perfect synchronization relays however , diversity delays introduced thus delay tolerant paper , using cyclic division algebras perfect codes , construct new codes maintain properties perfect codes synchronous case moreover , codes preserve full diversity asynchronous transmission
tensor problems np hard prove \( tensor \) many efficiently computable problems numerical linear algebra np hard list includes determining feasibility system equations , deciding whether 3 tensor given eigenvalue , singular value , spectral norm approximating eigenvalue , , singular vector , spectral norm determining rank best rank 1 approximation 3 tensor furthermore , show restricting problems symmetric tensors alleviate np hardness also explain deciding nonnegative symmetric 4 tensor np hard computing combinatorial 4 tensor np , p , hard argue results provide another view boundary computational tractability linear convex problems intractability nonlinear ones
lexicographic method threshold cover problem lexicographic method technique introduced journal graph theory , 20 \( 3 \) , 1995 way simplify problems recognizing obtaining representations graphs , proper arc graphs proper interval graphs method gives rise simple recognition algorithms leads much simpler proofs characterization theorems classes threshold graphs class graphs many equivalent definitions applications integer programming set packing problems graph said threshold cover size k edges covered using k threshold graphs given graph g , constructed auxiliary graph number equal minimum size threshold cover g although showed conjecture false general case , theory computing , , pages , 1995 proved g threshold cover size 2 bipartite show lexicographic method used obtain completely new much simpler proof result method also gives rise simple new based algorithm recognizing graphs threshold cover size 2 although algorithm fastest known , algorithm matches time complexity fastest known algorithm problem algorithm also easily adapted give recognition algorithm bipartite graphs covered two chain subgraphs
adversarial active exploration inverse dynamics model learning present adversarial active exploration inverse dynamics model learning , simple yet effective learning scheme exploration environment without human intervention framework consists deep reinforcement learning \( drl \) agent inverse dynamics model former training samples latter , objective maximize error latter latter trained samples collected former , generates rewards former fails predict actual action taken former competitive setting , drl agent learns generate samples inverse dynamics model fails predict correctly , inverse dynamics model learns adapt challenging samples propose reward structure ensures drl agent collect hard samples hard ones prevent inverse model predicting effectively evaluate effectiveness method several robotic arm hand manipulation tasks multiple baseline models experimental results show method comparable directly trained expert demonstrations , superior baselines even without human priors
method nash equilibria structured games structured game representations recently attracted interest models multi agent artificial intelligence scenarios , rational behavior commonly characterized nash equilibria paper presents efficient , exact algorithms computing nash equilibria structured game representations , including graphical games multi agent influence diagrams \( \) algorithms derived method normal form extensive form games due follow trajectory space perturbed games equilibria , exploiting game structure fast computation function theoretically guaranteed find least one equilibrium game , may find approach provides first efficient algorithm computing exact equilibria graphical games arbitrary topology , first algorithm exploit fine grained structural properties experimental results presented demonstrating effectiveness algorithms comparing running time graphical game algorithm similar , often better , running time previous approximate algorithms algorithm effectively solve games much larger solvable previous methods
language multi agent games learning communicate sequences symbols learning communicate interaction , rather relying explicit supervision , often considered developing general ai study setting two agents playing game , scratch , develop communication protocol necessary succeed game unlike previous work , require messages exchange , train test time , form language \( e sequences discrete symbols \) compare reinforcement learning approach one using differentiable relaxation \( straight softmax estimator \) observe latter much faster converge results effective protocols interestingly , also observe protocol induce optimizing communication success exhibits degree variability \( e information different ways \) , properties characteristic natural languages goal ensure communication accomplished natural language , also perform experiments prior information natural language model study properties resulting protocol
non signaling approximations stochastic team problems paper , consider non signaling approximation finite stochastic teams first introduce hierarchy team decision rules classified increasing order randomized policies , quantum correlated policies , non signaling policies , establish approximation team optimal policies sequential teams via non signaling policies prove distance non signaling policies decentralized policies small extension sufficiently large using result , establish linear programming \( lp \) approximation sequential teams finally , state open problem regarding computation optimal value quantum correlated policies
streaming adaptation deep forecasting models using adaptive recurrent units present , adaptive recurrent unit streaming adaptation deep globally trained time series forecasting models combines advantages learning complex data transformations across multiple time series deep global models , per series localization offered closed form linear models unlike existing methods adaptation either memory intensive non training , require fixed sized state adapt streaming data via easy rnn like update operation core principle driving simple maintain sufficient statistics conditional gaussian distributions use compute local parameters closed form contribution embedding local linear models globally trained deep models allowing end end training one hand , easy rnn like updates across several datasets show effective recently proposed local adaptation methods global network compute local parameters
two stage training chinese recognition paper , present two stage language identification \( \) system based shallow followed simple 2 layer recurrent neural network \( rnn \) architecture , used \( \) chinese recognition challenge first place among teams system trains acoustic model \( \) firstly connectionist temporal classification \( \) recognize given sequence annotation train another rnn classify category utilizing intermediate features inputs compared three stage system explore , results show two stage system achieve high accuracy chinese recognition short utterance long utterance conditions less training time
product quality models assessment quality models provide either abstract quality characteristics concrete quality measurements integration two aspects quality assessment approaches , hence , also specific remain abstract reasons include complexity quality various quality profiles different domains make difficult build quality models project , developed comprehensive approach aimed gap project combined constructive research , involved broad range quality experts academia industry , work reviews , empirical studies within project peer reviewed two project members different area developed two three iterations evaluation contribute comprehensive quality modelling assessment approach \( 1 \) meta quality model defines structure quality models includes concept product factor , gap concrete measurements abstract quality aspects , allows create modules specific domains \( 2 \) largely technology independent base quality model reduces effort complexity building quality models specific domains c systems , refined concrete product factors 500 measures \( 3 \) concrete comprehensive quality assessment approach makes use concepts meta model \( 4 \) empirical evaluation results using real world software systems showed \( \) assessment results using base model largely match expectations experts corresponding systems \( b \) approach models well understood practitioners considered consistent well suited getting overall view quality software product validity base quality model could shown , however \( 5 \) extensive , open source tool support state \( 6 \) model embedded software systems proof concept domain specific quality models provide broad basis development application quality models industrial practice well basis extension , validation comparison approaches research
efficient algorithm 1 dimensional persistent path homology paper focuses developing efficient algorithm analyzing directed network \( graph \) topological viewpoint prevalent technique topological analysis involves computation homology groups concepts well suited spaces directed result , one needs concept homology input space path homology developed directed graphs , , effectively adapted purpose recently also give algorithm compute path homology main contribution paper algorithm computes path homology efficiently 1 dimensional \( h 1 \) case developing algorithm , discover various structures efficient computations aid computing 1 dimensional path implement algorithm present preliminary experimental results
pricing based distributed energy efficient beamforming miso interference channels paper , consider problem maximizing weighted sum energy efficiency \( ee \) multi input single output \( miso \) interference channels \( \) well general models heterogeneous networks \( \) , networks , etc address problem , develop efficient distributed beamforming algorithm based pricing mechanism specifically , carefully introduce price metric distributed beamforming design allows efficient closed form solutions per user beam vector optimization problem convergence distributed pricing based beamforming design theoretically proven furthermore , present implementation strategy proposed distributed algorithm limited information exchange numerical results show algorithm converges much faster existing algorithms , yielding comparable , sometimes even better performance terms ee finally , taking power consumption account , interesting show proposed algorithm limited information exchange achieves better ee full information exchange based algorithm special cases
learning transferable domain priors safe exploration reinforcement learning prior access domain knowledge could significantly improve performance reinforcement learning agent particular , could help agents avoid potentially catastrophic exploratory actions , would otherwise experienced learning work , identify consistently actions set previously learned tasks , use pseudo rewards associated learn prior policy addition enabling exploratory behaviors subsequent tasks domain , show priors transferable similar environments , learned policy parallel learning tasks domain compare approach established , state art algorithms discrete well continuous environments , demonstrate exhibits exploratory behavior learning perform arbitrary tasks domain also present theoretical analysis support results , briefly discuss implications alternative formulations approach , could also useful certain scenarios
human intention recognition flexible warehouses based markov decision processes rapid growth e commerce increases need larger warehouses automation , thus using robots human workers becomes priority order operate efficiently , robot system recognize human theory mind \( \) intuitive state , e , desires , cause behavior paper present based algorithm human intention recognition flexible warehouses placed worker simulated 2d environment three potential goals observe agent 's actions validate respect goal locations using markov decision process framework observations processed proposed hidden markov model framework estimated agent 's desires demonstrate proposed framework predicts human worker 's desires intuitive manner end discuss simulation results
memory efficient sketch method estimating high similarities streaming sets estimating set similarity detecting highly similar sets fundamental problems areas databases , machine learning , information retrieval minhash well known technique approximating jaccard similarity sets successfully used many applications similarity search large scale learning two compressed versions , b bit minhash odd sketch , significantly reduce memory usage original minhash method , especially estimating high similarities \( e , similarities around 1 \) although minhash applied static sets well streaming sets , elements given streaming fashion cardinality unknown even infinite , unfortunately , b bit minhash odd sketch fail deal streaming data solve problem , design memory efficient sketch method , , accurately estimate jaccard similarities streaming sets compared minhash , method uses smaller sized registers \( consists less 7 bits \) build compact sketch set also provide simple yet accurate estimator inferring jaccard similarity sketches addition , derive formulas bounding estimation error determine smallest necessary memory usage \( e , number registers used sketch \) desired accuracy conduct experiments variety datasets , experimental results show method 5 times memory efficient minhash accuracy computational cost estimating high similarities
simple method commonsense reasoning commonsense reasoning long standing challenge deep learning example , difficult use neural networks tackle schema dataset cite paper , present simple method commonsense reasoning neural networks , using unsupervised learning key method use language models , trained massive amount data , score multiple choice questions posed commonsense reasoning tests schema challenges , models outperform previous state art methods large margin , without using expensive annotated knowledge bases hand features train array large rnn language models operate word character level 1 billion , , squad , , customized corpus task show diversity training data plays important role test performance analysis also shows system successfully important features context decide correct answer , indicating good grasp commonsense knowledge
probabilistic deterministic finite automata recurrent networks revisited reservoir computers \( \) recurrent neural networks \( rnns \) mimic finite state automaton theory , workers demonstrated hold practice test capability generalized linear models , , long short term memory \( lstm \) rnn architectures predict stochastic processes generated large suite probabilistic deterministic finite state automata \( \) provide excellent performance benchmark systematically , randomness correlation structure generated processes exactly known , optimal memory limited predictors easily computed , lstms outperform , outperform generalized linear models surprisingly , methods fall short maximal predictive accuracy much 50 training , optimized , tend fall short maximal predictive accuracy 5 , even though previously available methods achieve maximal predictive accuracy orders magnitude less data thus , despite representational rnns , using surprising predictive gap simple one concludes important role methods infer causal states predictive state representations
journal impact factor journal impact factor \( \) heavily decades opinion piece still employed research evaluation purposes carefully considering context academic environment
locality structure aware graph node embedding work propose , methodology learn locality structure aware graph node embeddings unsupervised way particular , show performance existing random walk based approaches depends strongly structural properties graph , e g , size graph , whether graph flat network community profile \( \) , whether graph like , whether classes interest k core like , etc larger graphs flat strongly like , existing methods lead random expand rapidly , many nodes , thereby leading lower quality vector representations less useful downstream tasks rather relying global random neighbors within fixed hop distances , exploits strongly local approximate personalized pagerank stationary distributions precisely local information node embeddings leads , particular , meaningful useful vector representations nodes poorly structured graphs show leads significant improvement downstream multi label classification larger graphs flat , comparable smaller graphs , comparable existing methods link prediction tasks
power allocation precoding large scale mu mimo systems per antenna constraint large scale mimo systems considered one possible candidates next generation wireless communication technique , due potential provide significant higher throughput conventional wireless systems systems , zero forcing \( zf \) beamforming \( \) precoding considered two possible practical spatial multiplexing techniques , average achievable sum rates derived sum power constraint however , practice , power base station constrained antenna case , optimal power allocation difficult problem paper , suboptimal power allocation methods zf based based precoding large scale mimo systems per antenna constraint investigated , could provide useful references practice
bayesian encourages dropout dropout one key techniques prevent learning overfitting explained dropout works kind modified l2 regularization , shed light dropout bayesian bayesian interpretation enables us optimize dropout rate , beneficial learning weight parameters prediction learning experiment result also encourages optimization dropout
demand side management smart grids using repeated game framework demand side management \( dsm \) key solution reducing peak time power consumption smart grids provide consumers shift consumption peak times , utility consumers differential pricing using power different times day consumers take account differential prices deciding much power daily importantly , consumers lower billing costs shifting power usage peak times , also discomfort costs due power consumption patterns existing works propose stationary strategies consumers minimize short term billing discomfort costs contrast , model interaction emerging among self interested , consumers repeated energy scheduling game prove stationary strategies suboptimal terms long term total billing discomfort costs subsequently , propose novel framework determining optimal dsm strategies , consumers choose different daily power consumption patterns depending preferences , routines , needs direct consequence dsm policy , different subsets consumers allowed use power peak times low price subset consumers selected daily joint discomfort billing costs minimized determined based power consumption preferences well past history consumers shifted usage previously importantly , show proposed strategies incentive compatible simulations confirm , given peak average ratio , proposed strategy reduce total cost \( billing discomfort costs \) 50 compared existing dsm strategies
globally optimal selection ground stations satellite systems site diversity availability satellite communication systems extremely limited impairments , \( radio \) cloud coverage \( optical \) solution problem site diversity technique , network distributed ground stations \( \) ensure , high probability , least one available connection satellite time period however , redundant induces unnecessary additional costs network operator context , study optimization problem minimizes number required , subject availability constraints first , problem transformed binary integer linear programming \( \) problem , proven np hard subsequently , design branch bound \( b b \) algorithm , global optimization guarantee , based linear programming \( lp \) relaxation greedy method well finally , numerical results show proposed algorithm significantly outperforms state art methods , low complexity average case
tiramisu code optimization framework high performance systems paper introduces tiramisu , optimization framework designed generate efficient code high performance systems , gpus , , distributed machines , combination tiramisu relies flexible representation based polyhedral model introduces novel four level allows full separation algorithms , schedules , data communication separation targeting multiple hardware architectures algorithm evaluate tiramisu writing set linear algebra dnn kernels integrating pass compiler show tiramisu extends many new capabilities , tiramisu generate efficient code , gpus , distributed heterogeneous systems performance code generated tiramisu matches exceeds hand optimized reference implementations example , matches highly optimized intel library many kernels shows reaching 4x original
codes meet cooperative transmission cellular networks following fast growth cellular networks , users drawn attention dynamic user data traffic static data plans address important largely issue , paper , design new data plan sharing system named , based scenario smartphone users data traffic help others download data realize system , first propose mechanism incorporates codes robust transmission errors encourages concurrent transmissions also implemented easily low implementation complexity design incentive mechanism using game choose assistant users \( \) , participants gain return , used ask future help need download finally real environment experiments conducted results show users manage data plan efficiently , also achieve higher speed download rate
composition problems braids membership identity freeness paper investigate complexity problems related composition known problems class braids three , b 3 , polynomial time solutions prove natural question composition , membership problem , np complete braids three membership problem np b 3 , becomes harder class braids particular show fundamental problems braids least five , problems b 4 remains open finally show freeness problem braids b 3 also np r n paper introduces challenging algorithmic problems topological braids new connections groups , words , complexity theory provides solutions problems application several techniques automata theory , matrix algorithms
incremental dense detection tensor streams consider stream events lock step behavior multi aspect data \( e , tensors \) evolving time \? detect real time , accuracy guarantee \? past studies shown dense tend indicate even behavior many tensor data , including social media , wikipedia , thus , several algorithms proposed detecting dense rapidly accurately however , existing algorithms assume tensors static , many real world tensors , including mentioned , evolve time r n propose , incremental algorithm updates dense tensor stream \( e , sequence changes tensor \) , , incremental algorithm spotting dense algorithms \( 1 \) fast updates algorithms million times faster fastest batch algorithms , \( 2 \) provably accurate algorithms guarantee lower bound density maintain , \( 3 \) effective successfully spots anomalies real world tensors , especially existing algorithms
multi perspective analysis carrier grade deployment face ipv4 address increasingly turn network address translation \( \) accommodate address needs customers recently , beyond employing directly individual customers instead deploying carrier grade \( \) apply address translation many independent disparate spanning physical locations , phenomenon far received little way empirical assessment work present broad systematic study deployment behavior develop methodology detect existence behind extracting non ip addresses peer lists obtain complement approach improvements service , enabling us determine range indicators presence well detailed insights key properties combining two data sources illustrate scope deployment today 's internet , report characteristics commonly deployed effect end users
human centered artificial intelligence machine learning humans increasingly coming contact artificial intelligence machine learning systems human centered artificial intelligence perspective ai ml algorithms must designed awareness part larger system consisting humans argument human centered artificial intelligence two aspects \( 1 \) ai systems understand humans perspective , \( 2 \) ai systems help humans understand argue issues social fairness , , interpretability , transparency
quizz targeted crowdsourcing billion potential users describe quizz , crowdsourcing system simultaneously knowledge users new knowledge quizz operates asking users complete short specific topics user answers questions , quizz estimates user 's acquire new knowledge , quizz also incorporates questions known answer answers given users provide useful signals selecting correct answers questions quizz actively tries identify users internet running advertising campaigns , effectively leveraging targeting capabilities existing , publicly available , ad placement services quizz contributions users using information theory sends feedback user feedback allows ad targeting mechanism optimize ad placement experiments , involve ten users , confirm knowledge specialized topics , advertising network automatically identify users desired expertise interest given topic present controlled experiments examine effect various incentive mechanisms , need short term rewards goals , users contribute finally , cost quality analysis indicates cost approach workers crowdsourcing platforms , offering additional advantage giving access potential users , able reach users specialized expertise typically available existing labor
self learning cloud controllers fuzzy q learning knowledge evolution cloud controllers aim application demands automatically scaling compute resources runtime meet performance guarantees minimize resource costs existing cloud controllers often scaling strategies set adaptation rules however , cloud , applications running top cloud infrastructure less black boxes , making difficult design time define optimal pre adaptation rules thus , burden taking adaptation decisions often cloud application yet , cases , application developers turn limited knowledge cloud infrastructure paper , propose learning adaptation rules runtime end , introduce fql4ke , self learning fuzzy cloud controller particular , fql4ke learns fuzzy rules runtime benefit designing cloud controllers , rely solely precise design time knowledge , may difficult acquire fql4ke users specify cloud controllers simply adjusting weights representing system goals instead complex adaptation rules applicability fql4ke experimentally part cloud application framework experimental results indicate fql4ke outperforms previously developed fuzzy controller without learning mechanisms native auto scaling
convex analysis approach computational entropy paper studies notion computational entropy using techniques convex optimization , investigate following problems \( \) computational entropy \? precisely , computational entropy , real difference security defined using three important classes circuits deterministic boolean , deterministic real valued , \( powerful \) randomized ones \? \( b \) large difference computational entropy unbounded versus efficient adversary \? \( c \) obtain useful , simpler computational entropy \?
self byzantine clock synchronisation almost easy consensus give fault tolerant algorithms establishing distributed systems n nodes clock algorithms operate strong fault model require self stabilisation , e , initial state system may arbitrary , f n 3 ongoing byzantine faults , e , nodes protocol arbitrary manner furthermore , assume local nodes may progress different speeds \( clock \) communication bounded delay model , study synchronisation problem , task guarantee eventually correct nodes generate well separated local events \( e , logical clock \) manner r n compared prior work , achieve exponential improvements stabilisation time number bits , give first sublinear time algorithm problem r n deterministic setting , state art solutions time theta \( f \) node broadcast theta \( f log f \) bits per time unit exponentially reduce number bits per time unit theta \( log f \) retaining stabilisation time r n setting , state art solutions time theta \( f \) node broadcast \( 1 \) bits per time unit exponentially reduce stabilisation time log \( 1 \) f node log \( 1 \) f bits per time unit r n results obtained means recursive approach reducing task self synchronisation bounded delay model non self binary consensus synchronous model general , approach introduces logarithmic overheads terms stabilisation time bits underlying consensus routine
provable learning noisy networks many machine learning applications use latent variable models explain structure data , whereby visible variables \( coordinates given \) explained probabilistic function hidden variables finding parameters maximum likelihood np hard even simple settings recent years , provably efficient algorithms nevertheless developed models linear structures topic models , mixture models , hidden markov models , etc algorithms use matrix tensor decomposition , make reasonable assumptions parameters underlying model r n matrix tensor decomposition seems little use latent variable model current paper shows make progress tensor decomposition applied learning single layer em noisy network , textbook example bayes net , used example classic software disease \( \) patient may observing exhibits r n technical novelty , useful settings future , analysis tensor decomposition presence systematic error \( e , noise error correlated signal , n't decrease number samples goes infinity \) requires steps tensor decomposition methods ground r n simplicity analysis stated assuming network parameters chosen probability distribution method seems generally applicable
open access uk research assessment exercise predictors research performance need validated showing high correlation external criterion trying predict uk research assessment exercise \( \) , together growing movement toward making full texts research articles freely available web offer unique opportunity test validate old new predictors , multiple regression analysis publications , journal impact factors , , co , citation \( age , growth , latency peak , decay rate \) , scores , h index , prior , student counts , co authorship scores , , textual proximity , download co , etc tested validated jointly , , panel parallel panel based metric 2008 weights predictor maximize joint correlation open access provide powerful new means , evaluating , predicting analyzing growing open access database , well powerful making grow faster
retinal segmentation images generative adversarial networks retinal segmentation indispensable step automatic detection retinal diseases images though many approaches proposed , existing methods tend miss fine vessels allow false terminal let alone segmentation , segmentation also problematic quantitative studies need measure precise width vessels paper , present method generates precise map retinal vessels using generative adversarial training methods achieve coefficient 0 drive dataset 0 dataset state art performance datasets
enumeration maximal delta gamma cliques temporal network temporal network mathematical way precisely representing time varying relationship among group agents paper , introduce notion \( delta , gamma \) cliques temporal network , every pair vertices present clique communicates gamma times delta period within given time duration present algorithm maximal cliques present network also implement proposed algorithm three human contact network data sets based obtained results , analyze data set multiple values delta gamma , helps finding contact groups different
minimal spiking neuron solving multi label classification tasks multi spike \( mst \) powerful single spiking neuron model solve complex supervised classification tasks powerful , also complex , computationally expensive evaluate , suitable neuromorphic hardware aim understand whether possible simplify mst model , retaining ability learn process information end , introduce family neuron models \( gnm \) special case spike response model much simpler simulate mst find wide range parameters gnm learn least well mst identify temporal potential single important ingredient gnm enables classify multiple spatio temporal patterns also interpret gnm system , thus bridging computation neural networks molecular information processing conclude paper proposing alternative training approaches gnm including error trace learning error backpropagation
efficient counting optimal resilience consider complete communication network n nodes , nodes receive common clock study synchronous c counting problem given starting state f faulty nodes arbitrary behaviour , task eventually correct nodes labeling increasing values modulo c agreement thus , considering algorithms self despite byzantine failures work , give new algorithms synchronous counting problem \( 1 \) deterministic , \( 2 \) optimal resilience , \( 3 \) linear stabilisation time f \( asymptotically optimal \) , \( 4 \) use small number states , consequently , \( 5 \) communicate small number bits per round prior algorithms either , use large number states need high communication bandwidth , suboptimal resilience particular , achieve exponential improvement state complexity message size deterministic algorithms moreover , present two complementary approaches reducing number bits stabilisation
power allocation adaptive index modulation cooperative networks paper , propose power allocation strategy adaptive orthogonal frequency division multiplexing \( \) index modulation \( \) cooperative networks allocation strategy based \( \) conditions , aims maximizing average network capacity according instantaneous channel state information \( csi \) transmit power source relay constrained separately , thus formulate optimization problem allocating power active compared conventional uniform power allocation strategy , proposed dynamic strategy lead higher average network capacity , especially low signal noise ratio \( snr \) region analysis also verified numerical results produced monte carlo simulations applying proposed power allocation strategy , efficiency adaptive enhanced practice , way implementation future , especially cell edge communications
cross sensor pore detection high resolution fingerprint images using unsupervised domain adaptation high resolution fingerprint sensors , research community focused level 3 fingerprint features especially , providing next generation automated fingerprint recognition system \( \) following recent success deep learning approaches various computer vision tasks , researchers explored learning based approaches pore detection high resolution fingerprint images learning based approaches provide better performance hand crafted feature based approaches however , domain existing learning based pore detection methods past paper , present first study domain existing learning based pore detection methods purpose , generated ground truth dataset referred using 1000 fingerprint sensor evaluated performance existing learning based pore detection approaches , also proposed approach detecting cross sensor scenario referred using unsupervised domain adaptation technique specifically , combination convolutional neural network \( cnn \) based pore detection approach unsupervised domain adaptation approach included training process domain adaptation achieved embedding gradient layer domain classifier network results existing proposed learning based pore detection approaches evaluated provides true detection rate 88 f score 94 importantly , proposed approach achieves state art performance cross sensor dataset
design cmos memristor circuits lstm architecture long short term memory \( lstm \) architecture well known approach building recurrent neural networks \( rnn \) useful sequential processing data application natural language processing near sensor hardware implementation lstm due large parallelism complexity propose 0 18 cmos , memristor lstm hardware architecture near sensor processing proposed system validated forecasting problem based model
deep neural network architecture real time semantic segmentation ability perform pixel wise semantic segmentation real time importance practical mobile applications recent deep neural networks aimed task disadvantage requiring large number floating point operations long run times paper , propose novel deep neural network architecture named \( efficient neural network \) , created specifically tasks requiring low latency operation faster , requires less , less parameters , provides similar better accuracy existing models n tested , cityscapes datasets report comparisons existing state art methods , trade offs accuracy processing time network present performance measurements proposed architecture embedded systems suggest possible software improvements could make even faster
ontology based adaptive e textbook platform student machine co learning use electronic \( e book \) heavily studied years due flexibility , , yet current e book , often version original book , encourage adoption consequently , leads e book incorporate current technologies augment capabilities , information search organization tools shown favorable paper preliminary work add intelligence tools terms information retrieval construction knowledge graph e book material little overhead first introduced information retrieval typed similarity query performed via random walk case study demonstrate applicability e book platform , promising application advancement area electronic
scaling limits wide neural networks weight sharing gaussian process behavior gradient independence neural kernel derivation several recent trends machine learning theory practice , design state art gaussian process convergence analysis deep neural nets \( dnns \) stochastic gradient descent \( sgd \) , found study wide random neural networks central approaches certain scaling limits networks results introducing notion emph tensor program express neural network computations , characterize scaling limit tensors large randomized framework follows \( 1 \) convergence random neural networks gaussian processes architectures recurrent neural networks , convolutional neural networks , residual networks , attention , combination , without batch normalization \( 2 \) conditions emph gradient independence assumption weights backpropagation assumed independent weights forward pass leads correct computation gradient dynamics , \( 3 \) convergence neural kernel , recently proposed kernel used predict training dynamics neural networks gradient descent , initialization architectures \( 1 \) without batch normalization mathematically , framework general enough classical random matrix results laws , well recent results neural network singular values hope work opens way toward design even stronger gaussian processes , initialization schemes avoid gradient explosion vanishing , deeper understanding sgd dynamics modern architectures
transaction reduction proofs exponential explosion parallel remains fundamental challenge model checking concurrent programs partial order reduction \( por \) transaction reduction \( \) decrease number concurrent system unlike por , transactions also reduce number intermediate states modern por techniques , hand , offer dynamic ways identifying commutative behavior , crucial task obtaining good reductions r n show transaction reduction use dynamic commutativity found set por also compare reductions obtained por , demonstrating several examples techniques complement r n implementation dynamic transactions model , compare effectiveness original static two por approaches several inputs , including realistic case studies , demonstrate new dynamic por practice
design analysis time invariant sc ldpc codes small constraint length paper , deal time invariant low density parity check convolutional \( \) codes , subclass spatially coupled low density parity check \( sc ldpc \) codes classic design approaches usually start quasi cyclic \( \) low density parity check \( ldpc \) block codes exploit suitable procedures obtain codes show direct design code former matrix , equivalently , symbolic parity check matrix , leads codes smaller former constraint lengths respect best solutions available literature provide theoretical lower bounds former constraint length relevant families codes , constraints minimum length local cycles graphs also propose new code design techniques approach achieve theoretical limits
solving wave equations unstructured around us form sound , , , study important basic tool across engineering science disciplines every wave solver computational study trade two computational speed accuracy galerkin \( dg \) methods fall high accuracy end spectrum , computational structure ideally suited gpus also achieve high computational speeds words , use dg methods gpus significantly cost obtaining accurate solutions article aims give reader easy use technology , based sample implementation demonstrates highly accurate , gpu capable , real time finite element solver lines code
online power managing strategy hard real time guarantees consider problem online dynamic power management provides hard real time guarantees problem , given jobs associated arrival time , , execution time , objective decide schedule jobs well sequence state transitions processors minimize total energy consumption r n paper , examine problem complexity provide online strategies achieve energy efficiency first , show competitive factor online algorithm problem least 2 present online algorithm gives 4 competitive schedule execution times jobs unit , show competitive factor improves 3 end , algorithm generalized allow trade number processors use energy efficiency resulting schedule
iris verification convolutional neural network propose novel convolutional neural network verify match two images human iris network trained end end validated three publicly available datasets yielding state art results four baseline methods network performs better state art method dataset network , use novel layer whose output interpreted normalized response complex plane show layer improves performance model previously unseen data
robotic navigation using entropy based exploration robotic navigation concerns task robot able find safe feasible path two points complex environment approach problem robotic navigation using reinforcement learning use deep q networks train agents solve task robotic navigation compare entropy based exploration \( \) widely used epsilon greedy exploration strategy training agents using simulation trained agents tested different versions environment test generalization ability learned policies also implement learned policies real robot complex real environment without fine tuning compare effectiveness mentioned exploration strategies real world setting video showing experiments platform available url https url
learning diagnostic policies examples systematic search diagnostic policy test perform next , based results previous tests , make diagnosis cost sensitive diagnostic policies perform tradeoffs \( \) cost tests \( b \) cost optimal diagnostic policy minimizes expected total cost formalize diagnosis process markov decision process \( mdp \) investigate two types algorithms solving mdp systematic search based algorithm greedy search \( particularly value information method \) investigate issue learning mdp probabilities examples , relevant search good policies learn assume bayesian network diagnosis process developed control overfitting speed search research first integrates overfitting systematic search paper two contributions discusses factors make systematic search feasible diagnosis , shows experimentally , benchmark data sets , systematic search methods produce better diagnostic policies greedy methods
two step disentanglement method address problem disentanglement factors generate given data correlated labeling solution simpler previous solutions employs adversarial training first , part data correlated labels extracted training classifier , part extracted enables reconstruction original data contain label information utility new method demonstrated visual datasets well financial data code available https github com two step disentanglement method
multi task pretraining multi role dialogue representation learning multi role dialogue understanding comprises wide range diverse tasks question answering , act classification , dialogue summarization etc dialogue corpora available , labeled data , specific learning tasks , highly expensive work , investigate dialogue context representation learning various types unsupervised pretraining tasks training objectives given naturally according nature utterance structure multi role conversation meanwhile , order locate essential information dialogue summarization extraction , pretraining process enables external knowledge integration proposed fine tuned pretraining mechanism evaluated via three different dialogue datasets along number downstream dialogue mining tasks result shows proposed pretraining mechanism significantly contributes downstream tasks without discrimination different encoders
predicting semantic relations using global graph properties semantic graphs , , resources natural language two layers local level , individual relations \( semantic building blocks \) enhance understanding words used express meanings globally , analysis graph theoretic properties entire net light structure human language whole paper , combine global local properties semantic graphs framework max margin markov graph models \( \) , novel extension exponential random graph model \( \) scales large multi relational graphs demonstrate global modeling improves performance local task predicting semantic relations , yielding new state art results dataset , challenging version link prediction easy cases removed addition , model identifies motifs characteristic well formed lexical semantic
extremely virtual reality environment robotics simulations synthetic data generation data driven algorithms traditional techniques almost every aspect robotic vision problems algorithms need vast amounts quality data able work properly training process amount data real world time consuming error prone task problems limit scale quality synthetic data generation become increasingly popular since faster generate automatic however , current datasets environments lack , interactions , details real world environment built engine 4 aims reduce reality gap leveraging indoor scenes explored robot agents also interact objects visually realistic manner simulated world scenes robots rendered engine virtual reality captures human operator move robot use controllers robotic hands scene information per frame basis offline generate raw data ground truth annotations virtual reality environment enables robotic vision researchers generate realistic visually data full ground truth wide variety problems class instance semantic segmentation , object detection , depth estimation , visual grasping , navigation
diversity multiplexing tradeoff selective fading multiple access mimo channels establish optimal diversity multiplexing \( dm \) tradeoff coherent selective fading multiple access multiple input multiple output \( mimo \) channels provide corresponding code design criteria , conceptual level , find interesting relation dm tradeoff framework notion dominant error event regions first introduced case , ieee , relation allows accurately characterize error mechanisms mimo fading multiple access channels particular , find , given rate tuple , maximum achievable diversity order determined error event dominates total error probability exponentially snr finally , show distributed space time code construction proposed recently , , 2008 , satisfies code design criteria derived paper
emotions make one five understanding online product reviews sentiment analysis people buy products online , primarily base decisions recommendations others given online reviews current work analyzed online reviews sentiment analysis used extracted sentiments features predict product several machine learning algorithms predictions disentangled various ai \( \) understand whether model showed bias prediction study 1 algorithms \( , support vector machines , random forests , gradient boosting machines , \) identified random forests best algorithms predicting product study 2 , analysis global feature importance identified sentiment negative predictive features two visualization methods , local feature partial dependency , revealed several incorrect prediction mechanisms instance level performing benchmarking classification , study 3 identified high information rate 64 4 high class imbalance underlying reason identified problems conclusion , good performance machine learning algorithms must taken dataset , encountered work , could biased towards certain predictions work demonstrates methods reveal prediction bias
designing zero effort human observation attacks important component authentication system widespread use computing devices daily life need zero effort schemes however , eliminating user effort may lead hidden security authentication schemes case point , investigate prominent zero effort scheme , called , provides interesting useful solution difficult problem demonstrated original paper identify subtle incorrect assumption adversary model leads fundamental design exploit break scheme class attacks much easier human perform realistic adversary model , compared attacks studied paper example , one main attacks , human attacker mimic 's typing activity terminal , significantly successful compared attack requires activities well movements , understanding design cases input , show draw well understood design principles improve 's security
dynamic approach switching heuristics complete tree search highly effective method problems , years , branching heuristics introduced refine technique varying problems recently , algorithms taken process step , trying predict best heuristic instance hand however , motivation behind algorithm selection taken still , used dynamically choose appropriate algorithm encountered paper identify feature space captures evolution problem branching tree similarity among instances models show exploit features decide best time switch branching heuristic show system trained efficiently experiments highly heterogeneous collection instances show significant gains pure algorithm selection approach given instance uses single heuristic throughout search
low rank bandits latent mixtures study task maximizing rewards recommending items \( actions \) users sequentially interacting recommender system users modeled latent mixtures c many representative user classes , class mean reward profile across actions user features \( mixture distribution classes \) item features \( mean reward vector per class \) unknown priori user identity contextual information available learner interacting induces low rank structure matrix expected rewards r , b recommending item user b problem reduces well known linear bandit either user item side features known setting user , stochastically sampled profile , small number sessions , develop bandit algorithm two sided uncertainty combines robust tensor power method et al \( \) linear bandit algorithm et al \( 2011 \) provide first rigorous regret analysis combination , showing regret user interactions \( c \) , b number users ingredient towards result novel robustness property , independent interest
together learning understanding natural language paper , explore various approaches learning two types components language focus author involved moments based dataset develop models based deep neural networks task , including bi directional long short term memory networks , without attention also experiment number novel embedding methods , embedding neural machine translation \( \) embedding language models \( \) compare results acquired several traditional machine learning methods best models achieve 87 97 accuracy 13 accuracy , significantly higher baselines
deep long audio inpainting long \( 200 ms \) audio inpainting , recover long missing part audio segment , could widely applied audio editing tasks transmission loss recovery challenging problem due high dimensional , complex non correlated audio features deep learning models made tremendous progress image video inpainting , audio inpainting much attention work , take step , exploring possibility adapting deep learning frameworks various domains audio synthesis image inpainting audio inpainting also , first systematically analyze factors audio inpainting performance , explore factors ranging mask size , receptive field audio representation could affect performance also set benchmark long audio inpainting code available github upon accepted
mining android app usages generating actionable based execution scenarios based models extracted android app execution traces , events , source code extremely useful challenging tasks generation scenarios test cases however , extracting effective models expensive process moreover , existing approaches automatically deriving based models able generate scenarios include events observed execution \( event \) traces paper , address major challenges novel hybrid approach , coined approach based record mine generate validate framework , relies app usages yield execution \( event \) traces , mining event traces generating execution scenarios using statistical language modeling , static dynamic analyses , validating resulting scenarios using interactive execution app real device framework aims mining models capable generating feasible fully \( e , actionable \) scenarios either natural user behavior usages \( e g , corner cases \) given app evaluated case study involving several medium large open source android results demonstrate able mine based models used generate actionable execution scenarios natural sequences events google 7
vector field neural networks work establishing mathematical formalization different interpretations neural networks , providing first contribution starting point , new interpretation explored , using idea implicit vector fields moving data particles flow new architecture , vector fields neural networks \( \) , proposed based interpretation , vector field becoming explicit specific implementation using 's method solve ordinary differential equations \( \) gaussian vector fields tested first experiments present visual results important features new architecture providing another contribution interpretable regularization model parameters , new architecture evaluated different hyperparameters inputs , objective evaluating influence model performance , computational time , complexity model compared known basic models naive bayes , feed forward neural networks , support vector machines \( svm \) , showing comparable , better , results different datasets finally , conclusion provides many new questions ideas improvement model used increase model performance
communication complexity inevitable intersection known methods communication complexity unstructured search based hardness set problem techniques may certain important aspects original problem intuitively , search much simpler task set hard even np , successful search inherently results short , makes easy np possibility hardness search problems may definitions r n construct natural variation intersection search problem , input comes product distribution , nevertheless , every pair input subsets share least one element call problem inevitable intersection , analysis seems require new , subtle approach particular , relying hardness set r n prove lower bound communication complexity inevitable intersection , identify properties large rectangles make impossible partition input matrix small number nearly rectangles \( analysis non local addresses existence large low discrepancy , possibility partition whole matrix rectangles \) believe technique provides new insight combinatorial structure search like communication problems
mechanisms integrated feature normalization remaining useful life estimation using lstms applied hard disks emerging smart communities , improving overall system availability becoming major concern order improve reliability components system propose inference model predict remaining useful life \( \) components paper work components data servers hard disks , subject degradation deep long short term memory \( lstm \) network used backbone fast , data driven decision framework dynamically captures pattern incoming data article , discuss architecture neural network describe mechanisms choose various hyper parameters , describe challenges faced extracting effective training sets highly class imbalanced big data establish methods online predictions extensive data pre processing , feature extraction validation online simulation sets unknown remaining useful lives hard disks algorithm performs especially well predicting near critical device approaching failure proposed approach able predict whether disk going fail next ten days average precision 0 also show architecture trained particular model used predict devices different models transfer learning
learning constraints regularized empirical risk minimization constrained labels \( contrast fixed labels \) general abstraction learning common loss regularization functions , optimization problem assumes form mixed integer program \( \) whose objective function non convex form , problem standard optimization techniques construct solutions whose objective functions convex specifically , characterize convex extension objective function , given computing values convex extension np hard however , applying characterization every function additive decomposition objective function , obtain class convex extensions computed efficiently decompositions , common loss regularization functions , derive closed form
feature reuse overfitting densenet specialized dropout recently convolutional neural networks \( cnns \) achieve great accuracy visual recognition tasks densenet becomes one popular cnn models due effectiveness feature reuse however , like cnn models , also face overfitting problem existing dropout method applied effective due introduced nonlinear connections particular , property feature reuse densenet , dropout effect spatial correlation inside feature maps address problems , design specialized dropout method three aspects , dropout location , dropout granularity , dropout probability insights could potentially applied general approach boosting accuracy cnn models similar nonlinear connections experimental results show specialized dropout method yield better accuracy compared vanilla densenet state art cnn models , accuracy boost increases model depth
robust object tracking search optimized multi particle filter particle filter \( pf \) used extensively estimation target non linear non gaussian state however , performance suffers due inherent problem sample order address , propose novel method based upon search optimization overcome low performing particles detected proposed detection mechanism transductive reliability achieve faster convergence proposed pf tracking framework addition , present adaptive fuzzy fusion model integrate multi extracted evaluated particle automatic boosting particles using proposed fusion model enhances performance method also achieve optimal state estimation performance proposed evaluated 12 benchmark video sequences compared state art solutions qualitative quantitative results reveals proposed outperforms existing solutions also efficiently handle various tracking challenges average outcome , achieve 7 98 f measure 0
bridging air gap attacking air conditioning system modern physically separate sensitive computational infrastructure public accessible networks order prevent cyber attacks however , attackers still manage networks , either means supply chain therefore , attacker 's main challenge determine way command control isolated accessible network \( e g , internet \) r n paper , propose new adversarial model shows air network receive communications channel , show attackers may use air conditioning system \( connected internet \) send commands within air network since communication protocols rather domain , propose novel line encoding protocol suitable type channel moreover , provide experimental results demonstrate channel 's feasibility , calculate channel 's bandwidth lastly , offer analysis propose various ways channel detected r n believe study details previously unseen vector attack security experts aware
distributed mpc guaranteeing global locally designed tubes paper studies fundamental relation exists assumptions usually employed distributed model predictive control implementations , corresponding notions invariance implicit controllers relation made explicit form theorem presents sufficient conditions global shown constraint local robust controllers sufficient global closed loop system stable , controllers related complex forms control based distributed model predictive control implementations
multi parametric solution path algorithm instance weighted support vector machines instance weighted variant support vector machine \( svm \) attracted considerable attention recently since useful various machine learning tasks non stationary data analysis , data modeling , transfer learning , learning rank , transduction important challenge scenarios overcome computational bottleneck instance weights often change dynamically adaptively , thus weighted svm solutions must computed paper , develop algorithm efficiently exactly update weighted svm solutions arbitrary change instance weights , contribution extension conventional solution path algorithm single regularization parameter multiple instance weight parameters however , extension gives rise significant problem \( solution path turns \) identified high dimensional space facilitate , introduce parametric representation instance weights also provide geometric interpretation weight space using notion critical region current affine solution remains optimal find intersections solution path boundaries extensive experiments various practical applications , demonstrate usefulness proposed algorithm
whole body pose taxonomy manipulation tasks exploiting interaction environment promising powerful way enhance stability humanoid robots robustness executing manipulation tasks recently works show advances direction considering humanoid multi , able fully develop abilities autonomous way , need first understand classify variety possible poses humanoid robot achieve balance end , propose adaptation successful idea widely used field robot grasping field humanoid balance multi whole body pose taxonomy classifying set whole body robot configurations use environment enhance stability criteria classification used develop grasping , focusing simplifying large number possible poses human body adopt propose taxonomy 46 poses , containing three main categories , considering number type supports well possible transitions poses taxonomy induces classification motion primitives based pose used support , set rules store generate new motions present preliminary results apply known segmentation techniques motion data whole body motion database using motion capture data multi , identify support poses providing segmentation distinguish manipulation parts action
streaming algorithms news scientific literature recommendation submodular maximization knapsack constraint submodular maximization problems belong family combinatorial optimization problems wide applications paper , focus problem maximizing monotone submodular function subject knapsack constraint , propose streaming algorithm achieves left \( frac 1 1 2d epsilon right \) approximation optimal value , needs one single pass dataset without storing data memory experiments , extensively evaluate effectiveness proposed algorithm via two applications news recommendation scientific literature recommendation observed proposed streaming algorithm achieves execution speedup memory saving several orders magnitude , compared existing approaches
spatial filtering eeg based regression problems brain computer interface bci \( eeg \) signals frequently used brain computer interfaces \( \) , easily noises , preprocessing must done fed machine learning algorithm classification regression spatial filters widely used increase signal noise ratio eeg bci classification problems , applications bci regression problems limited paper proposes two common spatial pattern \( csp \) filters eeg based regression problems bci , extended csp filter classification , making use fuzzy sets experimental results eeg based response speed estimation large scale study , collected sessions attention task data 17 subjects 5 period , demonstrate two proposed spatial filters significantly increase eeg signal quality used lasso k nearest neighbors regression user response speed estimation , spatial filters reduce root mean square estimation error 10 77 , time increase correlation true response speed 86
learning safe unlabeled multi robot planning motion constraints paper , present learning approach goal assignment trajectory planning unlabeled robots operating 2d , obstacle specifically , tackle unlabeled multi robot motion planning problem motion constraints multi agent reinforcement learning problem sparse global reward contrast previous works , formulate entirely new hand crafted optimization cost trajectory generation algorithm different robot dynamic model , framework general approach applicable arbitrary robot models , using velocity obstacle , devise smooth projection guarantees collision free trajectories robots respect neighbors obstacles efficacy algorithm demonstrated simulations
differences expected two ranking compared benchmarks research evaluations comparison two terms indicators frequently faces problem assessing differences meaningful letter proposes benchmarks used supporting interpretation differences
language recognition power affine automata work study non linear generalization based affine transformations probabilistic quantum automata proposed recently \( computer science theory applications , , , 1 15 , 2016 n arxiv n n \) referred affine automata first , present efficient simulations probabilistic quantum automata means affine automata class stochastic languages initiate study affine automata particular , show infinite family unary regular languages recognized 2 state affine automata , whereas number inner states quantum probabilistic automata cannot bounded finally , present characterization \( regular \) unary languages recognized two state affine automata
cellular memristive output reservoir reservoir computing machine learning complex system , , uses complex internal dynamics non linearly project input higher dimensional space single trainable output layer high dimensional space features relevant perform given task , classification initially , often constructed recurrent neural networks , constructed many different elements demonstrated elementary cellular automata \( ca \) one system recently demonstrated powerful efficient basis used construct reservoir investigate feasibility performance reservoir computing circuit fully integrated , programmable read layer , designed , , tested full custom reservoir computing circuit design , cellular memristive output reservoir \( \) , implemented nm cmos technology integrated front end line \( \) random access memory \( \) used construct trainable output layer detail design system present test results verifying operation capability carry non linear classifications
hybrid cpu gpu framework network motifs massively parallel architectures gpu becoming increasingly important due recent proliferation data paper , propose key class hybrid parallel algorithms leverages multiple cpus gpus simultaneously computing k vertex induced subgraph statistics \( called \) addition hybrid multi core cpu gpu framework , also investigate single gpu methods \( using multiple cores \) multi gpu methods leverage available gpus simultaneously computing induced subgraph statistics methods leverage gpu devices , whereas hybrid multi core cpu gpu framework leverages available multi core cpus multiple gpus computing large networks compared recent approaches , methods orders magnitude faster , also cost effective superior performance per per particular , methods times faster recent state art method best knowledge , first work leverage multiple cpus gpus simultaneously computing induced subgraph statistics
inverse determinant sums connections fading channel information theory algebra work considers inverse determinant sums , arise union bound error probability , tool designing analyzing algebraic space time block codes general framework study sums established , connection asymptotic growth inverse determinant sums diversity multiplexing gain tradeoff investigated proven growth inverse determinant sum division algebra based space time code completely determined growth unit group reduces inverse determinant sum analysis studying certain asymptotic lie groups using recent methods ergodic theory , complete classification inverse determinant sums well known algebraic space time codes provided approach reveals interesting tight relation diversity multiplexing gain tradeoff point counting lie groups
background modeling inference early implementations , background modeling process building model background video stationary camera , identifying pixels well model pixels well described background model assumed moving objects many systems today maintain models foreground well background , models explain pixels video paper , argue logical evolution simply use rule classify pixels particular , essential background likelihood , foreground likelihood , prior pixel simple application rule gives posterior probability label remaining question quality component models background likelihood , foreground likelihood , prior describe model built using past observations given pixel location , also including observations spatial neighborhood around location enables us model influence neighboring pixels improvement earlier models allow influence although similar joint domain range model , show model overcomes certain model use spatially dependent prior background foreground background foreground labels previous frame , spatial smoothing account movement objects , used build prior current frame
feature mappings point clouds recent decades , use 3d point clouds widespread computer industry development techniques analyzing point clouds increasingly important particular , mapping point clouds challenging problem paper , develop discrete u mappings , guarantee uniform , point cloud surfaces based discrete , propose novel method called computing u mappings feature point clouds using proposed method , u metric introduced evaluating point clouds consequently , algorithm enables accurate recognition classification point clouds experimental results demonstrate effectiveness proposed method
secret key generation many one networks integrated game theoretic information theoretic approach paper considers secret key generation several agents base station observe independent identically distributed correlated random variables agent generate longest possible individual key base station means public communication keys must jointly secret external entities many one secret key generation setting , shown agents take advantage collective protocol increase sum rate generated keys however , agent interested maximizing secret key rate , agents may collective protocol furthermore , collective protocol employed , fairly allocate individual key rates arises valid issue paper studies cooperation self interest game theoretic treatment work cooperation best interest agents exists individual secret key rate allocations agents follow protocol additionally , explicit coding scheme achieves allocations proposed
intelligent surfaces free space optical communications paper , investigate use intelligent surfaces \( \) \( e , smart \) line sight requirement free space optical \( fso \) systems characterize impact physical parameters irs , size , position , orientation , quality end end fso channel addition , develop statistical channel model geometric losses accounts random movements irs , transmitter , receiver due building model used performance analysis irs based fso systems analytical results shows depending angle beam direction irs plane , building irs either smaller larger impact quality end end fso channel building transmitter receiver furthermore , simulation results validate accuracy developed channel model offer insight system design
meta reinforcement learning autonomous inference subtask dependencies propose address novel shot rl problem , task characterized subtask graph describes set subtasks dependencies unknown agent agent needs quickly adapt task adaptation phase maximize return test phase instead directly learning meta policy , develop meta learner subtask graph inference \( \) , latent parameter task interacting environment maximizes return given latent parameter facilitate learning , adopt intrinsic reward inspired upper confidence bound \( \) encourages efficient exploration experiment results two grid world domains ii environments show proposed method able accurately infer latent task parameter , adapt efficiently existing meta rl hierarchical rl methods
intensity assisted automatic accurate extrinsic calibration 3d lidar camera using chessboard paper presents novel method fully automatic convenient extrinsic calibration 3d lidar camera chessboard proposed method based 3d corner estimation chessboard sparse point cloud generated one frame lidar estimate corners , formulate full scale model chessboard fit 3d points chessboard model optimizing cost function constraints correlation intensity color chessboard patterns method introduced problem optimization corners model considered 3d corners chessboard corners chessboard 3d point cloud estimated , extrinsic calibration two sensors converted 3d 2d matching problem corresponding 3d 2d points used calculate absolute pose two sensors unified perspective n point \( \) , calculated parameters initial values refined using method performance proposed corner detection method 3d point cloud evaluated using simulations results experiments , conducted lidar camera proposed projection error metric , qualitatively quantitatively demonstrate accuracy stability final extrinsic calibration parameters
deep steering learning end end driving model spatial temporal visual cues recent years , autonomous driving algorithms using low cost vehicle mounted cameras attracted increasing academia industry multiple , including object detection , 3 reconstruction etc , work focus vision based model directly maps raw input images steering angles using deep networks represents research topic computer vision technical contributions work three fold first , model learned evaluated real human driving videos time vehicle sensors differs many prior models trained synthetic data games second , state art models , , mostly predict wheel angles independently video frame , common understanding driving process instead , proposed model combination spatial temporal cues , jointly investigating instantaneous monocular camera observations vehicle 's historical states practice accomplished carefully designed recurrent units \( e g , lstm lstm \) proper network layers third , facilitate interpretability learned model , utilize visual back propagation scheme discovering image regions final steering prediction experimental study based 6 hours human driving data provided comprehensive quantitative evaluations demonstrate effectiveness robustness model , even scenarios like changes turning comparison state art models clearly reveals superior performance predicting due wheel angle self driving car
managed blockchain based consensus enforced rules transparency blockchain based usually , distributed , consensus based systems single entity control managed implemented using private blockchains different complete control arbitrary activity without transparency \( since control mining \) work explore hybrid approach managed cryptocurrency maintained distributed consensus based methods perform ongoing management functions consensus methods enforce rules cryptocurrency provide transparency management actions enables introduction management features common managing entity cannot perform arbitrary actions transparency enforced thus need users trust also enable manage cryptocurrency demonstrate implement approach modest modifications implicit bitcoin specification , however , approach applied blockchain based cryptocurrency using variety consensus methods
chemora solving framework modern hpc architectures modern hpc architectures consist heterogeneous multi core , many node systems deep memory modern applications employ ever advanced methods study multi physics problems developing applications explore cutting edge physics cutting edge hpc systems become complex task requires significant hpc knowledge experience unfortunately , combined knowledge currently reach groups application developers r n chemora framework solving systems partial differential equations \( \) targets modern hpc architectures chemora based , prominent usage computational community chemora , expressed either high level like language defined separately equations , include finite differences , galerkin finite elements \( \) , adaptive mesh refinement \( amr \) , multi block systems r n use chemora toolkit implement equations cpus , study systems black , , core collapse
question answering transfer learning large fine grained supervision data show task question answering \( qa \) significantly benefit transfer learning models trained different large , fine grained qa dataset achieve state art two well studied qa datasets , semeval 2016 \( task \) , basic transfer learning technique squad , model outperforms previous best model 8 demonstrate supervision provides better guidance learning lexical syntactic information supervision , quantitative results visual analysis also show similar transfer learning procedure achieves state art task
teacher student learning paradigm tri training efficient method unlabeled data exploitation given labeled data expensive obtain real world scenarios , many semi supervised algorithms explored task exploitation unlabeled data traditional tri training algorithm tri training shown promise tasks labeled data limited work , introduce new paradigm tri training , real world teacher student learning process show adaptive teacher student thresholds used proposed method provide control learning process higher label quality perform evaluation semeval sentiment analysis task provide comprehensive comparisons experimental settings containing labeled versus unlabeled data rates experimental results show method outperforms strong semi supervised baselines , requiring less number labeled training samples
learn adapt stochastic dual gradients network resource allocation network resource allocation shows popularity era data information explosion existing stochastic optimization approaches fall short desirable cost delay tradeoff recognizing central role multipliers network resource allocation , novel learn adapt stochastic dual gradient \( la \) method developed paper learn empirical optimal historical data , adapt resource allocation strategy , requires one sample \( gradient \) evaluation stochastic dual gradient \( \) method la interpreted learning approach eye future , , modified heavy ball approach optimization viewpoint established theoretically empirically la improves cost delay tradeoff state art allocation schemes
simpler specifications easier proofs distributed algorithms using history variables paper studies specifications proofs distributed algorithms message history variables used , using basic paxos multi paxos distributed consensus precise case studies show using maintaining state variables yields simpler specifications easier understand also allows easier proofs developed fewer invariants proof furthermore , proofs checked efficiently r n show specifications proofs proof system \( \) reduced 25 27 , respectively , basic paxos , 46 \( 100 lines 50 lines \) \( 1000 lines 500 lines \) , respectively , multi paxos overall need 54 fewer manually written invariants proofs 46 fewer proof basic paxos takes 26 less time et al 's check , proofs multi paxos checked within 1 5 whereas prior proofs multi paxos fail checked new version
scalable neural methods reasoning symbolic knowledge base describe novel way representing symbolic knowledge base \( kb \) called sparse matrix kb representation enables neural modules fully differentiable , original semantics kb , expressive enough model multi hop , scalable enough use large sparse matrix kb distributed across multiple gpus , scale entities , orders magnitude faster naive sparse matrix implementations kb enables simple end end architectures obtain competitive performance several benchmarks representing two families tasks kb completion , learning semantic
impact integrity attacks real time pricing smart grids vulnerability false data injection attacks real time electricity pricing power grid market recently explored previous work focused impact caused attackers compromise pricing signals send false prices subset consumers paper extend previous work considering powerful general adversary model , new analysis method based sensitivity functions , proposing several mitigate negative impact attacks include adding low pass filter pricing signals , selecting time interval price updates , selecting parameters controller , designing robust control algorithms , detecting anomalies behavior system
k gap interval graphs initiate study new parameterization graph problems multiple interval representation graph , vertex associated least one interval real line , edge two vertices interval associated one vertex intersection interval associated vertex graph n vertices k gap interval graph multiple interval representation n k intervals total order scale algorithmic properties interval graphs \( k 0 \) , graph problems k , find fpt algorithms several problems , including feedback vertex set , dominating set , independent set , clique , clique cover , multiple interval coloring problem turns w 1 hard design algorithm recognition problem
processor based active queue management providing qos multimedia application objective paper implement active network based active queue management technique providing quality service \( qos \) using network processor \( np \) based enhance multimedia applications performance evaluated using intel np simulator results demonstrate , active network based active queue management better performance algorithm case congestion well suited achieve high speed packet classification support multimedia applications minimum delay queue loss using simulation , show proposed system provide flows improved network utilization bandwidth shared among flows according levels priority first analyze feasibility optimality load distribution schemes present separate solutions non delay sensitive streams delay sensitive streams rigorous simulations experiments carried evaluate performance
new algorithm solving ring lpn reducible polynomial lpn \( learning parity noise \) problem recently proved great importance special useful case ring lpn problem , typically provides improved efficiency constructed cryptographic primitive present new algorithm solving ring lpn problem case polynomial used reducible greatly outperforms previous algorithms solving problem using algorithm , break authentication protocol proposed instance using reducible polynomial , 2 70 bit operations
enhancing reliability 5g communication services guaranteed delay although network functions software defined networking offer many dynamic features , flexibility , scalability , easy services cost time service function , introduces new challenges terms reliability , availability , latency services particularly , network service functions \( e g , , service , dynamic virtual , routing \) high possibility network failures due software issues hardware letter , propose novel solution called enhance reliability service chains 5g service level
improving assessment peer identification aligned massive open online \( \) use peer assessment grade open questions scale , allowing students provide feedback relative teacher based grading , peer assessment delivers lower quality feedback fewer learner interactions present identified peer review \( \) framework , provides non blind peer assessment driving high quality feedback show , compared traditional peer assessment methods , leads significantly longer useful feedback well discussion
cycle consistency training end end speech recognition paper presents method train end end automatic speech recognition \( asr \) models using unpaired data although end end approach need expert knowledge dictionaries build asr systems , still requires large amount paired data , e , speech utterances cycle consistency losses recently proposed way mitigate problem limited paired data approaches compose reverse operation given transformation , e g , text speech \( tts \) asr , build loss requires unsupervised data , speech example applying cycle consistency asr models trivial since fundamental information , speaker , lost intermediate text bottleneck solve problem , work presents loss based speech encoder state sequence instead raw speech signal achieved training text encoder model defining loss based encoder reconstruction error experimental results corpus show proposed cycle consistency training reduced word error rate 14 7 initial model trained 100 paired data , using additional hours audio data without also investigate use text data mainly language modeling improve performance unpaired data training scenario
playing slam augmented deep reinforcement learning number recent approaches policy learning 2d game domains successful going directly raw input images actions however employed complex 3d environments , typically suffer challenges related partial observability , combinatorial exploration spaces , path planning , scenarios inspired prior work human cognition indicates humans employ variety semantic concepts abstractions \( object categories , localisation , etc \) reason world , build agent model incorporates abstractions policy learning framework augment raw image input deep q learning network \( dqn \) , adding details objects structural elements encountered , along agent 's localisation different components automatically extracted composed topological representation using fly object detection 3d scene reconstruction evaluate efficacy approach , 3d first person combat game exhibits number challenges discussed , show augmented framework consistently learns better , effective policies
clustering cluster queries propose framework semi supervised active clustering framework \( \) , learner allowed interact domain expert , asking whether two given instances belong cluster study query computational complexity clustering framework consider setting expert center based clustering notion margin show trade computational complexity query complexity prove case k means clustering \( e , expert solution k means \) , access relatively queries allows efficient solutions otherwise np hard problems r n particular , provide probabilistic polynomial time \( \) algorithm clustering setting asks big \( k 2 log k k log n \) cluster queries runs time complexity big \( log n \) \( k number clusters n number instances \) algorithm high probability data satisfying margin conditions , without queries , show problem np hard also prove lower bound number queries needed computationally efficient clustering algorithm setting
neighbor cell list optimization femtocell femtocell handover dense networks dense goal network deployment among three types femtocell , femtocell , femtocell femtocell , latter two main concern dense network deployment handover cases , minimum well appropriate neighbor cell list key element successful handover paper , propose algorithm make minimum appropriate number neighbor femtocell list femtocell femtocell handover algorithm considers received signal level \( \) open close access cases detected neighbor simulation results show proposed scheme able attain minimum optimal number neighbor femtocell list possible femtocell femtocell handover
gene trees xenology relation two genes sense separated least one horizontal gene transfer event gene transfer asymmetric sense transferred copy one remains within hence xenology precisely non symmetric relation x transferred least since least common x show xenology relations characterized small set induced subgraphs three vertices furthermore , xenology relation derived unique least resolved edge labeled tree tree edge labeling computed polynomial time fact xenology relation graph property , finally far reaching consequences approximation problems associated xenology relations
near optimal exploration exploitation non communicating markov decision processes designing state space mdp , common include states transient reachable policy \( e g , car , product space speed position contains configurations physically reachable \) leads defining weakly communicating multi chain mdps paper , introduce , first algorithm able perform efficient exploration exploitation finite markov decision process \( mdp \) without requiring form prior knowledge particular , mdp texttt c communicating states , actions gamma texttt c leq texttt c possible communicating next states , derive \( texttt c sqrt gamma texttt c texttt c \) regret bound , texttt c diameter \( e , longest shortest path \) communicating part mdp contrast optimistic algorithms \( e g , , optimistic \) suffer linear regret weakly communicating mdps , well posterior sampling algorithms \( e g , \) , require prior knowledge bias span optimal policy bias exploration achieve sub linear regret also prove weakly communicating mdps , algorithm ever achieve logarithmic growth regret without first linear regret number steps exponential parameters mdp finally , report numerical simulations supporting theoretical findings showing overcomes limitations state art
mpc inspired neural network policies sequential decision making paper investigate use mpc inspired neural network policies sequential decision making introduce extension algorithm training policies show improved training performance generalization capabilities take advantage extension show scalable efficient training complex planning policy architectures continuous state action spaces provide extensive comparison neural network policies considering feed forward policies , recurrent policies , recurrent policies planning structure inspired path integral control framework results suggest mpc type recurrent policies better robustness modeling error
case lost mnist although popular mnist dataset et al , derived database , 1995 , precise processing steps derivation lost time propose reconstruction accurate enough serve replacement mnist dataset , changes accuracy trace mnist source rich metadata , partition , etc also reconstruct complete mnist test set 60 , 000 samples instead usual 10 , 000 since balance 50 , 000 never distributed , enable us investigate impact five years mnist experiments reported testing performances results confirm trends observed et al 2018 , 2019 although rates slightly , classifier ordering model selection remain broadly reliable attribute phenomenon pairing benefits comparing classifiers
exploiting explicit paths multi hop reading comprehension propose novel , path based reasoning approach multi hop reading comprehension task system needs combine multiple passages answer question although inspired multi hop reasoning knowledge graphs , proposed approach operates directly unstructured text generates potential paths passages scores without direct path supervision proposed model , named , attempts extract implicit relations text entity pair representations , compose encode path capture additional context , also passage representations along path compute passage based representation unlike previous approaches , model able explain reasoning via explicit paths passages show approach outperforms prior models multi hop dataset , also generalized apply dataset , matching state art performance
robust iterative hard thresholding compressed sensing compressed sensing \( cs \) sparse signal reconstruction \( \) signal processing technique exploits fact acquired data sparse representation basis one popular technique reconstruct approximate unknown sparse signal iterative hard thresholding \( \) however performs poorly non gaussian noise conditions face outliers \( gross errors \) paper , propose robust method based ideas estimation estimates sparse signal scale error distribution simultaneously method negligible performance loss compared gaussian noise , superior performance heavy non gaussian noise conditions
probability network slicing random physical link failure fifth generation communication technology \( 5g \) mobile networks associated integration cross domain networks network slicing enabling technology 5g provides dynamic , demand , reliable logical network slices \( e , network services \) common physical network infrastructure since network slice subject failures , namely node link failures , physical infrastructure , interest evaluate reliability network slice assigning customers paper , propose evaluation metric , textit probability , quantify reliability network slice random physical link failure \( \) prove existence textit base protecting spanning tree set probability network slice propose necessary sufficient conditions identify base protecting spanning tree set develop corresponding mathematical formulations , used generate reliable network slices 5g environment addition proving approaches simulation results , also discuss problems approaches related tree problems present computational complexity approximability
eeg people determination aim paper design construct \( eeg \) based brain controlled provide communication bridge system external technical device people determination individuals partial complete eeg technique reads activity brain capturing brain signals non using special eeg signals acquired go pre processing , feature extraction classification technique allows human alone converted control commands used moving right , left , forward , backward brain signals acquired using discrete wavelet transform used feature extraction support vector machine \( svm \) used classification
source target inference models spatial instruction understanding models execute natural language instructions robotic tasks assembly navigation several useful applications , , remote scenarios study semantics spatially referred configuration arrangement instructions , based challenging 2016 labeled block dataset task involves finding source block moving target position \( mentioned via reference block \) , blocks colors referred via spatial location features present novel models subtasks source block classification target position regression , based joint loss language spatial world representation learning , well cnn based dual attention models compute alignment world blocks instruction phrases target position prediction , compare two inference approaches sampling via policy gradient versus expectation inference via supervised regression models achieve new state art task , improvement source block accuracy 22 target position distance
based action recognition using lstm cnn recent methods based 3d data achieved outstanding performance due , robustness , view independent representation development deep learning , convolutional neural networks \( cnn \) long short term memory \( lstm \) based learning methods achieved promising performance action recognition however , cnn based methods , inevitable loss temporal information sequence encoded images order capture much spatial temporal information possible , lstm cnn adopted conduct effective recognition later score fusion addition , experimental results show score fusion cnn lstm performs better lstm lstm feature method achieved state art results rgb datasets 3d human action analysis proposed method achieved 87 40 terms accuracy ranked 1 st place large scale 3d human activity analysis challenge depth videos
light metric long known dimensional euclidean point sets admit \( 1 epsilon \) w e epsilon \( \) , total edge weight w e times weight minimum tree set whether similar result holds metric spaces low dimension important open problem , numerous attempts resolution paper , resolve question , show spaces admit \( 1 epsilon \) w \( epsilon \) \( \) r n important right , result also implies much faster polynomial time approximation scheme metric spaces , improving upon bound presented 12
leveraging user profile behaviour design practical spreadsheet controls finance function recognizing use within finance likely near future , paper discusses major barrier preventing organizations adopting spreadsheet management programs even without effort improve spreadsheet controls , finance functions still take simple yet effective steps start managing risk errors key selecting controls complement existing user practice
word segmentation micro texts external lexicon heterogeneous data paper describes system designed 2016 shared task word segmentation micro texts
exact expression information distance information distance defined two strings also finite multiset strings cardinality greater two give elementary proof expressing information distance terms plain complexity exact since cardinality multiset lower bound multiset upper bound constant additive term
towards dialogue based navigation multivariate adaptation driven intention politeness social robots service robots need show appropriate social behaviour order deployed social environments healthcare , education , , etc main capabilities robots navigation conversational skills person , person might want robot navigate faster vice versa linguistic features indicate politeness provide social cues person patient behaviour novelty presented paper dynamically incorporate politeness robotic dialogue systems navigation understanding politeness users speech used robot behaviour responses therefore , developed dialogue system navigate indoor environment , produces different robot responses based users intention degree politeness deploy test system robot changes user politeness
arc diagrams flip distances hamiltonian triangulations show every triangulation \( maximal planar graph \) n ge 6 vertices hamiltonian triangulation using sequence less n 2 combinatorial edge flips previously best upper bound uses 4 connectivity means establish general 5 flips necessary reach 4 connected triangulation result improves upper bound diameter flip graph combinatorial triangulations n vertices 5 2n 6 also show every triangulation n vertices simultaneous flip less 2n 3 edges 4 connected triangulation bound number edges tight , additive constant another application show every planar graph n vertices admits arc diagram less n 2 , , less n 2 \( potentially 6 \) edges resulting graph admits 2 page book embedding
enhancing trust tesla system solution trust important factor improving quality online education comprehensive model trust based authentication developed tested within score eu project tesla use biometric verification technologies identity authorship claims individual students online education scenarios significant component tesla technical \( \) , tesla , large scale pilot tests tesla system results students involved pilot tests analyzed work also describe tesla authentication detection instruments role enhancing trust
visual permutation learning present principled approach structure visual data solving novel deep learning task coined visual permutation learning goal task find permutation structure data shuffled versions case natural images , task original image patches shuffled unknown permutation matrix unfortunately , permutation matrices discrete , thereby difficulties gradient based methods end , continuous approximation matrices using stochastic matrices generate standard cnn predictions using iterations iterations network layer , propose , end end cnn model task utility demonstrated two challenging computer vision problems , namely , \( \) relative attributes learning \( ii \) self supervised representation learning results show state art performance public benchmarks \( \) classification segmentation tasks pascal voc dataset \( ii \)
stochastic approximation canonical correlation analysis propose novel first order stochastic approximation algorithms canonical correlation analysis \( cca \) algorithms presented instances matrix stochastic gradient \( \) matrix gradient \( \) , achieve epsilon population objective poly \( frac 1 epsilon \) iterations also consider practical variants proposed algorithms compare methods cca theoretically empirically
energy coupling error reduction non iterative co simulations simulators coupled co simulation , residual total energy full coupled system system dynamics , quality results , lead instability using power realize simulator coupling , energy based co simulation method \( \) et al 2016 exploits concepts define non iterative global error estimation adaptive step size control relying coupling variable data alone following similar , nearly energy preserving coupling element \( \) et al 2013 uses simulator inputs approximately ensure energy , discuss modification direct feed present one coupled simulators demonstrate accuracy efficiency non iterative co simulations substantially enhanced combining 's adaptive step size controller car model linear nonlinear damping characteristics serves co simulation benchmark , observe reductions coupling errors 98 utilizing concepts discussed
general notion useful information paper introduce general framework defining depth sequence respect class show general framework captures depth notions introduced complexity theory far review notions , show particular cases general depth framework , review classical results different depth notions
complexity estimating paper studies complexity estimating distribution p observed samples , respect baseline distribution q known emph priori extending results et al \( \) estimating entropy , present improved estimation techniques together upper lower bounds sample complexity r n show , estimating entropy sublinear \( alphabet size \) number samples , sample complexity heavily dependent emph events occurring q , unbounded general \( estimation technique used \) divergence order 1 , provide upper lower bounds number samples dependent probabilities p q conclude worst case sample complexity polynomial alphabet size probabilities q non negligible r n gives theoretical insights heuristics used applied papers handle numerical instability , occurs small probabilities q result small probabilities care numerical issues , also sample complexity
self supervised learning cross modal audio video clustering visual audio modalities highly correlated yet contain different information strong correlation makes possible predict semantics one good accuracy intrinsic differences make cross modal prediction potentially task self supervised learning video audio representations compared within modality learning based intuition , propose cross modal deep clustering \( xdc \) , novel self supervised method leverages unsupervised clustering one modality \( e g audio \) signal modality \( e g video \) cross modal supervision helps xdc utilize semantic correlation differences two modalities experiments show xdc significantly outperforms single modality clustering multi modal variants xdc achieves state art accuracy among self supervised methods several video audio benchmarks including , ucf101 , , importantly , video model pretrained xdc significantly outperforms model pretrained full supervision imagenet action recognition ucf101 best knowledge , xdc first method demonstrate self supervision outperforms large scale full supervision representation learning action recognition
eliminating timing side channel using program repair propose method , based program analysis transformation , eliminating timing side channels software code implements security critical applications method takes input original program together list secret variables \( e g , cryptographic keys , security , \) transformed program output transformed program guaranteed equivalent original program free instruction cache timing side channels specifically , ensure number cpu cycles taken execute path independent secret data , cache behavior memory accesses , terms , independent secret data implemented method validated effectiveness large set applications , cryptographic libraries , lines c c code total experiments show method scalable real applications effective eliminating timing side channels
case linear output activations gradient boosting work , show output activation functions , softmax , learning number standard classification tasks moreover , present results showing utility softmax stem normalization , fact , normalization makes things worse rather , advantage error gradients exponential gradient boosting shown speed convergence improve generalization end , demonstrate faster convergence better performance diverse classification tasks image classification using cifar 10 imagenet , semantic segmentation using pascal voc 2012 latter case , using state art neural network architecture , model faster method \( roughly two days training less \) standard softmax activation , slightly better performance
instruction sequences expressing multiplication algorithms function bit strings , restriction bit strings given length computed finite instruction sequence contains instructions set get content boolean registers , forward instructions , termination instruction describe instruction sequences kind compute function bit strings models multiplication natural numbers less 2n respect binary representation bit strings length n , fixed arbitrary n 0 , according long multiplication algorithm multiplication algorithm one results obtained instruction sequence expressing former algorithm longer one expressing latter algorithm length bit strings involved greater 28 also go use instruction sequence backward instructions expressing long multiplication algorithm leads instruction sequence shorter two length bit strings involved greater 2
scalar arithmetic multiple data precision deep neural networks quantization weights activations deep neural networks \( dnns \) powerful technique network compression , significant attention success however , much inference time benefit quantization accessible customized hardware fpga implementation quantized arithmetic building prior work , show construct fast implementations arbitrary bit precise signed integer operations using software technique vector architecture custom bit width lanes fixed width scalar arithmetic strongest level quantization , approach yields maximum speedup 6 platform , 10 arm platform versus quantization native 8 bit
chain rule optimal transport distance define novel class distances statistical multivariate distributions solving optimal problem marginal densities respect ground distance defined conditional densities using chain rule factorization probabilities , show perform optimal transport ground space information geometric manifold conditional probabilities prove new distance metric whenever chosen ground distance metric distance generalizes wasserstein distances point sets recently introduced metric distance statistical mixtures first application chain rule optimal transport \( \) distance , show ground distance statistical mixtures upper bounded optimal transport distance , whenever ground distance joint convex report experiments quantify distance total variation distance square root generalization shannon divergence mixtures
achieving ultra reliable communication via enabled diversity schemes internet things progress build smart , wireless networks critical many use cases paper , present multi transmission scheme achieve ultra reliability critical machine type wireless communication networks take advantage diversity , fundamental dealing fading channel impairments , achieving ultra reliable region operation order five 9 's defined standardization bodies evaluate interference limited network composed multiple remote radio heads allowed , keeping thus reducing interference , performing strategies maximal ratio transmission , order serve user equipment ultra reliability provide extensive numerical analysis discuss gains cooperation centralized radio access network
optical flow estimation using spatial pyramid network learn compute optical flow combining classical spatial pyramid formulation deep learning estimates large motions coarse fine approach one image pair pyramid level current flow estimate computing update flow instead standard minimization objective function pyramid level , train one deep network per level compute flow update unlike recent flownet approach , networks need deal large motions pyramid several advantages first , spatial pyramid network \( \) much simpler 96 smaller flownet terms model parameters makes efficient appropriate embedded applications second , since flow pyramid level small \( 1 pixel \) , convolutional approach applied pairs images appropriate third , unlike flownet , learned convolution filters appear similar classical spatio temporal filters , giving insight method improve results accurate flownet standard benchmarks , suggesting new direction combining classical flow methods deep learning
interests mitigation search engine bias search engines become key media scientific , economic , social activities enabling people access information web despite size complexity side , search engines bias traffic users according page ranking strategies , create cycle established already popular sites bias could lead information show , intuition , empirical data support conclusion popular sites receive far less traffic predicted discuss model accurately predicts traffic data patterns taking consideration interests users searching behavior addition way search engines rank pages heterogeneity user interests observed mitigation search engines popularity bias
ordered decomposition binary decision diagram context knowledge compilation \( \) , study effect augmenting ordered binary decision diagrams \( \) two kinds decomposition nodes , e , vertices vertices denote decomposition propositional knowledge bases , respectively resulting knowledge compilation language called ordered , decomposition binary decision diagram \( oaodd \) roughly speaking , several previous languages seen special types oaodd , including , binary decision diagram \( \) , \( l \) , multi level decomposition diagrams \( \) one hand , propose families algorithms fragments oaodd others hand , present rich set polynomial time algorithms perform logical operations according algorithms , well theoretical analysis , characterize space efficiency tractability oaodd fragments respect evaluating criteria map finally , present compilation algorithm formulas negative normal form oaodd
surrogate models enhancing efficiency neuroevolution reinforcement learning last years , reinforcement learning received lot attention one method solve reinforcement learning tasks neuroevolution , neural networks optimized evolutionary algorithms disadvantage neuroevolution require numerous function evaluations , fully utilizing available information fitness evaluation especially problematic fitness evaluations become expensive reduce cost fitness evaluations , surrogate models employed partially replace fitness function difficulty surrogate modeling neuroevolution complex search space compare different networks end , recent studies showed kernel based approach , particular distance measures , works well kernels compare different networks via behavior \( \) rather topology encoding \( \) work , discuss use surrogate model based neuroevolution \( ne \) using distance reinforcement learning detail , investigate \) potential ne respect evaluation efficiency b \) select input sets distance measure reinforcement learning problem results indicate able considerably increase evaluation efficiency using dynamic input sets
two stream convolutional networks dynamic saliency prediction recent years , visual saliency estimation images attracted much attention computer vision community however , predicting saliency videos received little attention inspired recent success deep convolutional neural networks based static saliency , work , study two different two stream networks dynamic saliency prediction prove generalization capability models , also introduce novel , empirically grounded data tion technique task test models dataset report superior results existing moreover , perform transfer learning experiments , recently proposed static saliency dataset , models optical flows estimated static images experiments show taking motion account way helpful static saliency estimation
machine learning ten things known earlier effective data analysis despite widespread usage machine learning throughout organizations , key principles commonly particular 1 \) least four main families supervised learning logical modeling methods , linear combination methods , case based reasoning methods , iterative summarization methods 2 \) many application domains , almost machine learning methods perform similarly \( \) deep learning methods , leading technique computer vision problems , maintain edge methods problems \( reasons \) 3 \) neural networks hard train often try train 4 \) n't use interpretable model , make bad 5 \) explanations ca n't trust 6 \) much always find accurate yet interpretable model , even deep neural networks 7 \) special properties decision making robustness must built , n't 8 \) causal inference different prediction \( correlation causation \) 9 \) method deep neural architectures , always 10 \) artificial intelligence
learning navigation visual localization trajectory prediction driving , people make decisions based current traffic well desired route map known often able navigate without directions current self driving models improve performances using additional gps information aim push forward self driving research perform route planning even absence gps system learns predict real time vehicle 's current location future trajectory , function time , known map , given raw video stream intended destination gps signal available training time , training data annotation fully automatic different published models , predict vehicle 's trajectory seconds , complete steering , speed acceleration information derived entire time span trajectories capture information multiple levels , instant steering commands depend present traffic obstacles , longer term navigation decisions , towards specific destination collect dataset regular car smartphone records video gps streams gps data used derive ground truth supervision labels create analytical representation map tests , system outperforms published methods visual localization steering gives accurate navigation two known locations
inference learning latent conditional random fields weakly supervised semantic image segmentation conditional random fields \( crfs \) commonly employed post processing tool image segmentation tasks unary potentials crf often learnt independently classifier , thereby inference crf training classifier scheme works effectively , pixel level labelling available images however , absence pixel level labels , classifier faced task selectively assigning image level labels pixels image prior work often localization cues , saliency maps , priors , bounding boxes etc , address challenging problem contrast , model labels pixels latent variables crf pixels image level labels observed variables latent crf cost inference latent crf entire dataset , training inference network approximate posterior distribution latent variables given observed variables inference network trained end end fashion , requires localization cues training moreover , unlike approaches weakly supervised segmentation , proposed model n't require post processing proposed model achieves performance comparable approaches employ saliency masks task weakly supervised semantic image segmentation challenging voc 2012 dataset
quantization effects convergence properties rigid formation control systems quantized distance measurements paper , discuss quantization effects rigid formation control systems target described inter agent distances practical sensing measurement constraints , consider paper distance measurements quantized forms show gradient based formation control , case uniform quantization , distance errors converge locally bounded set whose size depends quantization error , case logarithmic quantization , distance errors converge locally zero special quantizer involving function considered agents measure coarse distances terms binary information case , formation converges locally target formation within finite time lastly , discuss effect asymmetric uniform quantization rigid formation control
common randomness key generation limited interaction basic two terminal common randomness \( \) key generation models considered , communication terminals may limited , particular may enough achieve maximum key rate introduce general notions concave function , characterize first order key communication tradeoff terms evaluation concave functional defined set distributions , simpler multi letter characterization two extreme cases given special attention first , regime small communication rates , bits per interaction bit \( \) key bits per interaction bit \( \) expressed new strong data processing constant , defined minimum parameter certain information theoretic functional concave given source distribution also provide computationally friendly strong converse bound similar \( necessarily strong \) one terms maximal correlation coefficient set distributions proof uses properties r divergence criterion bound given applications binary symmetric sources second , new characterization minimum interaction rate needed achieving maximum key rate \( \) given , resolve conjecture cite regarding binary sources also propose new conjecture binary symmetric sources
uniform noise injection non uniform quantization neural networks present novel method neural network quantization non uniform k quantizer , distribution quantized parameters approach provides novel alternative existing uniform quantization techniques neural networks suggest compare results function bit operations \( \) performed , assuming look table availability non uniform case setup , show advantages strategy low computational budget regime proposed solution harder implement hardware , believe sets basis new alternatives neural networks quantization
high quality correspondence segmentation estimation dual lens smart phone estimating correspondence two images extracting foreground object two challenges computer vision dual lens smart phones , , coming market , two images slightly different views provide us new information two topics propose joint method tackle simultaneously via joint fully connected conditional random field \( crf \) framework regional correspondence used handle regions matching make crf system computationally efficient method evaluated 2 , 000 new image pairs , produces promising results challenging images
based implementation known arc consistency classical \( fd \) systems , domains variables completely known constraint propagation process however , systems interacting external environment , whole domains variables constraint propagation may cause computation time , even acquired data time use r n cases , interactive constraint satisfaction problem \( \) model proposed extension csp model , make possible start constraint propagation even domains fully known , performing acquisition domain elements necessary , without need propagation every acquisition r n paper , show solver two language , defined previous work , express , implemented constraint handling rules \( \) language , language particularly suitable high level implementation constraint solvers
big data analytics large scale wireless networks challenges opportunities wide proliferation various wireless communication systems wireless devices led arrival big data era large scale wireless networks big data large scale wireless networks key features wide variety , high volume , real time velocity , huge value leading unique research challenges different existing computing systems article , present survey state art big data analytics \( \) approaches large scale wireless networks particular , life cycle four consecutive stages data acquisition , data preprocessing , data storage , data analytics present detailed survey technical solutions challenges large scale wireless networks according stage life cycle moreover , discuss open research issues outline future directions promising area
disparate equilibria algorithmic decision making individuals long term impact algorithmic decision making shaped dynamics deployed decision rule response focusing settings individual desires positive classification including many important applications , study dynamic learning setting individuals positive outcome based group 's expected gain decision rule updated maximize benefit characterizing equilibria dynamics , show natural challenges desirable long term outcomes arise due heterogeneity across groups lack consider two interventions , decision rule group cost investment show achieves optimal outcomes case effects may depend initial conditions otherwise contrast , cost investment shown create better equilibria group even absence
p vs np geometric complexity theory hypothesis geometric complexity theory \( \) approach p vs np related problems high level overview research plan results obtained far presented series three advanced study , , 9 11 , 2009 article contains material covered , gives mathematical overview background algebraic geometry , representation theory quantum groups assumed
concentration inequalities empirical distribution study concentration inequalities \( \) divergence empirical distribution true distribution applying recursion technique , improve method types bound uniformly regimes sample size n alphabet size k , improvement becomes significant k large discuss applications results obtaining concentration inequalities l 1 deviations empirical distribution true distribution , difference concentration around expectation zero
studying social networks scale macroscopic twitter social graph twitter one largest social networks using exclusively directed links among accounts makes twitter social graph much closer social graph supporting real life communications , instance , facebook therefore , understanding structure twitter social graph interesting computer scientists , also researchers fields , however , little known information propagation twitter constrained inner structure paper , present depth study macroscopic structure twitter social graph tweets , specific user activity associated component macroscopic structure , evolution macroscopic structure time past 6 years study , twitter retrieve accounts social relationships \( follow links \) among accounts 2012 million accounts billion links , present methodology macroscopic structure twitter social graph macroscopic structure consists 8 components defined connectivity characteristics component group users specific usage twitter instance , identified components together , finally , present method approximate macroscopic structure twitter social graph past , validate method using old datasets , discuss evolution macroscopic structure twitter social graph past 6 years
infinite families near mds codes holding designs n , k , n k 1 linear code called mds code n , k , n k linear code said almost maximum distance separable \( almost mds short \) code said near maximum distance separable \( near mds short \) code dual code almost maximum distance separable first near mds code 11 , 6 , 5 code discovered code holds 4 designs , extended code holds system \( 5 , 6 , 12 \) largest strength known past 70 years , near mds codes holding designs discovered many infinite families near mds codes finite fields constructed however , question whether infinite family near mds codes holding infinite family designs geq 2 remains open 70 years paper long standing problem presenting infinite family near mds codes gf \( 3 \) holding infinite family 3 designs infinite family near mds codes gf \( 2 \) holding infinite family 2 designs two families also studied , shown dimension optimal distance optimal
compound multiple access channels partial cooperation two user discrete memoryless compound multiple access channel \( mac \) common message decoders considered capacity region characterized special cases physically degraded channels cooperation , achievable rate regions provided general case results extended corresponding gaussian model gaussian setup , provided achievable rates shown lie within constant number bits boundary capacity region several special cases alternative model , encoders connected links rather common message , studied well , capacity region model also determined cases physically degraded channels cooperation numerical results also provided obtain insights potential gains decoders encoders
provably efficient rl rich observations via latent state decoding study exploration problem mdps rich observations generated small number latent states certain assumptions , demonstrate estimate mapping observations latent states sequence regression clustering steps previously decoded latent states provide labels later regression problems use construct good exploration policies provide finite sample guarantees quality learned state decoding function exploration policies , complement theory empirical evaluation class hard exploration problems method exponentially improves q learning naive exploration , even q learning access latent states
constrained resources service industry via video analytics service contribute significantly many developed developing business activities expand rapidly , many service companies maintain 's satisfaction due service response caused resource resource solutions effective way reducing effect operations however , proactive approach expensive terms capacity labor costs many companies fall productivity fail find sufficient strong arguments justify cost new technology yet cannot new technologies match question whether innovative solution utilize available resources drastically reduce effect resources may cause yet achieving high level service quality low cost work demonstrates practical analysis tracking system designed deployed international \( \) video analytics helps achieve management 's goal satisfying 's needs via real time detection problems may service consumption process using existing video technology rather adopting new technologies paper presents integration commercial video surveillance system deep learning algorithms video analytics show system provide accurate decision faced total partial occlusion high accuracy significantly improves daily operation work technologies resource management within service measure real time
impact preprocessing deep representations iris recognition unconstrained environments use iris biometric widely used high level uniqueness nowadays , one major research challenges relies recognition iris images obtained visible spectrum unconstrained environments scenario , acquired iris affected capture distance , rotation , , motion , low contrast , creating noises iris recognition systems besides iris region , usually preprocessing techniques normalization segmentation noisy iris images employed minimize problems techniques run errors context , propose use deep representations , specifically , architectures based vgg resnet 50 networks , dealing images using \( \) iris segmentation normalization use transfer learning face domain also propose specific data augmentation technique iris images results show approach using non normalized circle iris images new state art protocol ii competition , subset database , one challenging databases unconstrained environments , reporting average equal error rate \( \) 13 98 represents absolute reduction 5
ibbe sgx cryptographic group access control using trusted execution environments many cloud storage systems allow users protect data making use encryption , support collaborative editing data major challenge enabling collaboration need enforce cryptographic access control policies secure efficient manner paper , introduce ibbe sgx , new cryptographic access control extension efficient terms computation storage even processing large dynamic workloads membership operations , time offering zero knowledge guarantees ibbe sgx builds upon identity based broadcasting encryption \( ibbe \) address ibbe 's cloud deployments exploiting intel software extensions \( sgx \) derive computational complexity moreover , propose group partitioning mechanism computational cost membership update bound fixed constant partition size rather size whole group implemented evaluated new access control extension results highlight ibbe sgx performs membership changes 1 2 orders magnitude faster traditional approach hybrid encryption \( \) , producing group metadata 6 orders magnitude smaller , time offering zero knowledge guarantees
performance zero forcing processing multi way massive mimo relay networks consider multi way massive multiple input multiple output relay network zero forcing processing relay taking account time division duplex protocol channel estimation , derive analytical approximation spectral efficiency approximation tight simple enables us analyze system performance , well , compare spectral efficiency zero forcing maximum ratio processing results show using large number relay antennas zero forcing technique , simultaneously serve many active users time frequency resource , high spectral efficiency
new convex relaxation tensor completion study problem learning tensor set linear measurements prominent methodology problem based generalization trace norm regularization , used extensively learning low rank matrices , tensor setting paper , highlight limitations approach propose alternative convex relaxation euclidean ball describe technique solve associated regularization problem , builds upon alternating direction method multipliers experiments one synthetic dataset two real datasets indicate proposed method improves significantly tensor trace norm regularization terms estimation error , remaining computationally tractable
explaining increase predicted risk clinical much work aims explain model 's prediction static input consider explanations temporal setting dynamical model produces sequence risk estimates given input time step estimated risk increases , goal explanation attribute increase relevant inputs past formal setup techniques general , carry depth case study clinical setting goal patient 's risk decide whether adjust treatment given potentially long sequence new events since last patient , explanation helps quickly develop methods lift static techniques dynamical setting , identify address challenges specific dynamics experimentally assess utility different explanations clinical expert evaluation
deep architecture integrated 2d 3d human sensing propose deep architecture emph fully automatic 2d 3d human sensing \( \) , including emph recognition reconstruction , emph monocular images system computes ground segmentation , semantically identifies human body parts pixel level , estimates 2d 3d pose person model supports joint training components means multi task losses early processing stages feed advanced ones increasingly complex , accuracy robustness design allows us tie complete training protocol , taking advantage multiple datasets would otherwise cover model components complex 2d image data body part labeling without associated 3d ground truth , complex 3d data limited 2d background variability detailed experiments based several challenging 2d 3d datasets \( , , \) , evaluate sub structures model , effect various types training data loss , demonstrate state art results achieved processing levels also show wild monocular rgb architecture perceptually competitive state art \( commercial \) system based rgb data
semi quantitative equivalence fast reactions semantic used process algebra capture notion similar behaviour , paper proposes semi quantitative equivalence stochastic process algebra developed biological modelling consider away fast reactions suggested quasi steady state assumption define fast slow bisimilarity based idea also show appropriate condition cooperation operator condition requires synchronisation fast actions , fast slow bisimilarity weak bisimilarity also show operator extends reactions available species models necessary consider matching slow transitions illustrate equivalence two models competitive
multi instance learning data context multi instance learning , analyze single instance \( \) learning objective show data family classifiers sufficiently rich , method useful learning algorithm particular , show larger data imbalance , quality typically perceived negative , fact implies better resilience algorithm statistical dependencies objects addition , results shed new light known issues method setting linear classifiers , show issues significantly less likely occur setting neural networks demonstrate results synthetic dataset , coco dataset problem patch classification weak image level labels derived captions
modeling single votes single one important well known domain restrictions preferences computational study single peaked largely restricted elections tie free votes , recent work studies computational complexity attacks single peaked elections votes restricted models single peaked preferences top orders study computational complexity manipulation votes standard model single peaked preferences single preferences show models avoid complexity behavior models also state surprising result relation axis complexity manipulation single peaked preferences
hidden parameter markov decision processes regression approach discovering latent task control applications often feature tasks similar , identical , dynamics introduce hidden parameter markov decision process \( mdp \) , framework family related dynamical systems low dimensional set latent factors , introduce regression approach learning structure data control setting , show learned mdp rapidly identifies dynamics new task instance , allowing agent flexibly adapt task variations
parallel hierarchical affinity propagation mapreduce accelerated evolution explosion internet social media generating quantities data \( scales \) amongst desires extract actionable intelligence vast big data need scalable , performance analytics algorithms directly address need , propose novel mapreduce implementation based clustering algorithm known affinity propagation strategy extends multilevel hierarchical affinity propagation algorithm enables aggregation unstructured data minimal free parameters , principle requiring similarity measure data points detail linear run time complexity approach , overcoming limiting quadratic complexity original algorithm experimental validation clustering methodology variety synthetic real data sets \( e g images point data \) demonstrates state art mapreduce clustering techniques
face transfer generative adversarial network face transfer facial performances character target video source actor traditional methods typically based face modeling propose end end face transfer method based generative adversarial network specifically , leverage generate face image target character corresponding head pose facial expression source order improve quality generated videos , adopt explore effect different receptive field sizes generated images
strategic communication prospect theoretic agents gaussian test channel paper , model game simple gaussian test channel human transmitter \( leader \) communicates source message human receiver \( \) model human decision making using prospect theory models proposed continuous decision spaces assuming value function squared distortion transmitter receiver , analyze effects weight functions transmitter receiver optimal communication strategies , namely encoding transmitter decoding receiver , sense show optimal strategies behavioral agents sense identical designed unbiased agents time , also show prospect theoretic transmitter receiver larger expected distortion , thus making behavioral agents less unbiased agents consequently , presence cognitive biases increases need transmission power order achieve given distortion transmitter receiver
proving query rewrites sql semantics every database system contains query performs query rewrites unfortunately , developing query remains highly challenging task part challenges comes rich features query languages , makes reasoning rewrite rules difficult paper , propose machine semantics sql , de language relational database , validating rewrite rules unlike previously proposed semantics either non cover small amount sql language features , semantics covers major features sql , including , correlated , aggregation , indexes semantics , called , based k relations homotopy type theory , denote relations mathematical functions tuples types implemented coq , takes fewer lines code proved wide range sql rewrite rules , including database research literature \( e g , set rewrites \) real world query \( e g , elimination \) several rewrite rules never previously proven correct addition , query equivalence generally , implemented automated decision procedure using queries well studied fragment sql encompasses many real world queries
deep ordinal classification based cumulative link models paper proposes deep convolutional neural network model ordinal regression considering family probabilistic ordinal link functions output layer link functions used cumulative link models , traditional statistical linear models based pattern 1 dimensional space set ordered thresholds space different classes problem case , projections estimated non linear deep neural network improve results , combine ordinal models loss function takes account distance categories , based weighted kappa index three different link functions studied experimental study , results statistical analysis experiments run two different ordinal classification problems , statistical tests confirm models improve results model outperform proposals considered literature
efficient riemannian training recurrent neural networks learning symbolic data sequences recurrent neural networks powerful models sequential data , able represent complex dependencies sequence simpler models hidden markov models cannot handle yet notoriously hard train r n introduce effective training procedure using gradient metric inspired riemannian geometry produces algorithm independent design choices encoding parameters unit activities metric gradient designed algorithmic cost close backpropagation time connected networks r n also introduce emph persistent contextual neural networks \( \) variant recurrent neural networks feature architecture inspired finite automata modified time evolution better model long distance effects r n demonstrated effectively capture variety complex algorithmic constraints hard synthetic problems basic block context free grammars \( important feature natural languages , difficult learn \) , intersections multiple independent markov type relations , long distance relationships xor problem problem , perform better complex state art algorithms thanks metric update , fewer gradient steps training samples needed instance , generating model sequences form n learned 10 samples two , even n ranging thousands
experience replay experience replay online reinforcement learning agents reuse experiences past prior work , experience transitions uniformly sampled replay memory however , approach simply transitions frequency experienced , regardless significance paper develop framework experience , replay important transitions frequently , therefore learn efficiently use experience replay deep q networks \( dqn \) , reinforcement learning algorithm achieved human level performance across many games dqn experience replay achieves new state art , outperforming dqn uniform replay 41 games
grammar based neural text sql generation sequence sequence paradigm employed neural text sql models typically performs token level decoding consider generating sql grammar grammar based decoding shown significant improvements semantic parsing tasks , sql general programming languages complexities present logical make writing hierarchical grammars difficult introduce techniques handle complexities , showing construct schema dependent grammar minimal generation analyze techniques , two challenging text sql datasets , demonstrating yield 14 18 relative reductions error
jointly learning label sentences learning construct text representations end end systems difficult , natural languages highly compositional task specific annotated datasets often limited size methods directly language composition allow us guide models based existing knowledge , towards robust interpretable representations paper , investigate objectives different used learn better language representations propose architecture jointly learning label sentences predictions level combined together using attention mechanism , token level labels also acting explicit supervision sentence level representations experiments show learning perform tasks jointly multiple levels , model achieves substantial improvements sentence classification sequence labeling
competition drive optimize coverage consider game theoretic setting individuals resources varying quality example group patches different scenarios , individuals biased towards selecting higher quality patches , , time , aiming avoid costly goal investigate impact collision costs parallel coverage resources whole group consider sites , site x value f \( x \) f \( x \) reward associated site x , assume single individual x exclusively , receives exact reward typically , assume 1 individuals visit x receives f \( x \) particular , competition costs high , individual might receive amount strictly less f \( x \) , could even negative , modeling cooperation site , also consider cases one gets f \( x \) k identical players rewards independently act parallel , one shot scenario , single site visit , without sites explored others group performance evaluated expected coverage , defined sum f \( x \) sites explored least one player since assume players cannot coordinate choosing site focus symmetric strategies main message paper optimal symmetric coverage expected collision costs relatively high , following judgment solomon type rule holds single player explores site x gains full reward f \( x \) , several players explore , neither one receives reward policy , turns exists unique symmetric nash equilibrium strategy , , fact , evolutionary stable moreover , strategy yields best possible coverage among symmetric strategies coverage measure social welfare , policy thus enjoys \( symmetric \) price anarchy precisely 1 , whereas , fact , congestion policy price strictly greater 1 model falls within scope mechanism design , precisely area exploration finds relevance evolutionary , studies bayesian parallel search algorithms
face alignment using 3d ensemble regression trees abstract face alignment algorithms locate set landmark points images faces taken situations state art approaches typically fail lose accuracy presence occlusions , strong , large pose variations ambiguous configurations paper present , robust efficient face alignment algorithm based coarse fine ensembles regression trees robustly fitting 3d face model probability maps produced convolutional neural network initialization address self occlusions large face , implicitly imposes prior face shape solution , addressing occlusions ambiguous face configurations coarse fine structure combinatorial explosion parts experiments performed , improves state art , , data sets finally , perform cross dataset experiments reveal existence significant data set bias benchmarks
discourse augmented network reinforcement learning natural language inference natural language inference \( \) , also known recognizing textual \( \) , one important problems natural language processing requires infer logical relationship two given sentences current approaches mostly focus interaction architectures sentences , paper , propose transfer knowledge important discourse augment quality model observe people usually use discourse represent logical relationship two sentences words potentially deep connections meanings sentences , thus utilized help improve representations moreover , use reinforcement learning optimize new objective function reward defined property datasets make full use labels information experiments show method achieves state art performance several large scale datasets
3d multi cell trajectory design efficient iot data collection cell \( dc \) emerging technique offer flexible cost effective wireless connections collect internet things \( iot \) data areas networks trajectory dc significantly impacts data collection performance however , designing trajectory challenging issue due complicated 3d mobility dc , unique dc ground \( \) channel features , limited dc bs \( \) link quality , etc paper , propose 3d dc trajectory design dc assisted iot data collection multiple fly iot devices relay iot data base stations \( bss \) trajectory design formulated mixed integer non linear programming \( \) problem minimize average user dc \( \) , considering state art practical channel model problem multiple quasi convex integer linear programming \( \) sub problems , optimizes user association , user scheduling , horizontal trajectories dc , respectively , 3d multi dc trajectory design algorithm developed solve problem , sub problems optimized iteratively block coordinate descent \( \) method compared static dc deployment , proposed trajectory design lower average 10 15 db , reduce standard deviation , indicates improvements link quality user fairness
annotations intersection functional programming languages , classic form annotation single type constraint term intersection types add single term may checked several times different types , different contexts , requiring annotation several types moreover , useful \( systems , necessary \) indicate context type used r n paper explores technical design space annotations systems intersection types earlier work \( 2004 \) introduced contextual typing annotations , apart elementary mechanisms right hand annotation \( standard form \) , left hand annotation \( context right hand annotation used \) , allows multiple annotations , index variables novel element left hand annotation , terms \( right hand annotations \) judgment must follow current context
multi perspective fusion network commonsense reading comprehension commonsense reading comprehension \( \) significantly challenging task , aiming choosing right answer question passage , may require commonsense knowledge inference existing approaches interaction information choice , passage , question simple combination manner emph union perspective , comparison information deeper level instead , propose multi perspective fusion network \( \) , extending single fusion method multiple perspectives introducing emph difference emph similarity fusion along emph union comprehensive accurate information captured three types fusion design several groups experiments dataset cite evaluate effectiveness three types fusion respectively experimental results , conclude difference fusion comparable union fusion , similarity fusion needs union fusion experimental result also shows model achieves state art accuracy test set
user guide grid based approximation partial differential equations present , new scientific software library numerical approximation partial differential equations \( \) using grid based approximations open source software project exclusively written programming language main motivation behind development library provide easy use framework development complex solvers dynamically typed style without sacrificing performance typed languages work driven user guide library covers popular linear nonlinear systems scalar vector fields , single multi field problems , finite element , structured unstructured meshes
boost strategy generative error based video anomaly detection algorithms generation error \( ge \) based algorithms show excellent performances task video anomaly detection however , step anomaly detection , two problems \( 1 \) events usually occur local areas reduces events use frame level ge anomaly score \( 2 \) every discrimination advantages disadvantages , difficult aggregate multiple effectively address problems , propose strategy two modules firstly , replace frame level ge maximum block level frame anomaly score secondly , assuming anomaly threshold reliable anomaly detected , propose reliable anomaly \( r anomaly \) based multiple aggregation method method , set strict anomaly detection threshold \( \) auxiliary discrimination detect r anomalies use detected r anomalies enhance anomaly scores main discrimination experiments carried datasets results demonstrate effectiveness proposed strategy achieve state art performance
scaling laws secrecy capacity cooperative wireless networks investigate large wireless networks subject security constraints contrast point point , interference limited communications considered prior works , propose active cooperative relaying based schemes consider network n l legitimate nodes , n e , path loss exponent alpha geq 2 long n e 2 \( log \( n e \) \) gamma \( n l \) , positive gamma , show one obtain unbounded secure aggregate rate means zero cost secure communication , given fixed total power constraint entire network achieve result \( \) source using wyner randomized encoder serial \( multi stage \) block markov scheme , relays \( ii \) relays acting virtual multi antenna apply beamforming simpler parallel \( two stage \) relaying scheme achieve unbounded secure aggregate rate n e frac alpha 2 1 \( log \( n e \) \) gamma delta \( frac alpha 2 1 \) \( n l \) holds , positive gamma , delta
incomplete based dimensionality reduction high dimensional big data appears many research fields image recognition , biology collaborative filtering often , exploration data classic algorithms encountered difficulties due phenomenon therefore , dimensionality reduction methods applied data prior analysis many methods based principal components analysis , driven , namely map data low dimension subspace preserves significant statistical properties high dimensional data consequence , methods directly address geometry data , mutual distances multidimensional data point thus , operations classification , anomaly detection machine learning tasks may affected r n work provides dictionary based framework driven data analysis includes dimensionality reduction , sample extension anomaly detection high dimensional data low dimensional subspace embedding preserves original high dimensional geometry data user defined distortion rate addition , identifies subset landmark data points constitute dictionary analyzed dataset dictionary enables natural extension low dimensional embedding sample data points , gives rise distortion based criterion anomaly detection suggested method demonstrated synthetic real world datasets achieves good results classification , anomaly detection sample tasks
optimizing user selection schemes vector broadcast channels paper , focus ergodic downlink sum rate performance system consisting set heterogeneous users study three user selection schemes group near orthogonal users simultaneous transmission first scheme random selection policy achieves fairness , exploit multi user diversity second scheme greedy selection policy fully exploits multi user diversity , achieve fairness , third scheme achieves fairness partially exploiting multi user diversity also consider two beamforming methods data transmission , namely , maximum ratio transmission zero forcing beamforming scheduling schemes studied paper , key parameter controls degrees orthogonality channel directions co scheduled users focus optimally setting parameter scheduling scheme ergodic downlink sum rate end , derive analytical expressions ergodic downlink sum rate considering scheduling scheme numerical results also presented provide insights
parallel passive web browsing behavior effects website metrics getting deeper insights online browsing behavior web users major research topic since advent provides useful information optimize website design , web browser design , search engines , online argue new technologies new services continue significant effects way people web example , music radio station last require users front computer social media networking sites like facebook micro sites like twitter attracted new types users previously less go online changes people web feature new characteristics well understood far paper , provide novel unique insights presenting first results , long term effort create comprehensive representative dataset capturing online user behavior firstly investigate concepts parallel browsing passive browsing , showing browsing web longer dedicated task many users based results , analyze impact calculation user 's time e , time user become important metric quantify popularity websites
boolean functions maximize mutual information ability information processing motivated boolean networks interest recent information theoretic research one measure quantify ability well known mutual information using fourier analysis show functions maximize mutual information input variable outcome function proof result boolean functions uniform distributed well product distributed input variables
approximation density classification problem via morphological adaptation majority \( density classification \) problem cellular automata \( ca \) aims converge string cells final homogeneous state reflects majority states present initial configuration problem challenging ca individual cells possess information local states problem exercise propagation processing information within distributed computational medium explore whether majority problem approximated similarly simple distributed computing multi agent model initial pattern discrete voting choices represented spatial arrangement agent population , held place removed model shape size , moving form minimal distance connecting line final position line shown , simple examples , successfully represent majority decision , also accurately reflects size majority note properties , limitations potential improvements approach full circle encoding morphological adaptation approach simple \( space efficient \) ca model
understanding co evolution large multi relational social networks understanding dynamics evolution large social networks important problem paper , characterize evolution large multi relational social networks proliferation online media twitter , facebook , massively multi player online role playing games created social networking data unprecedented scale 's 2 one example used game multi relational networks reveal dynamics evolution multi relational setting macroscopic study game network macroscopic analysis involves network smaller studying dynamics within sub networks , referred `communities' evolutionary perspective multi relational network analysis , made following contributions specifically , formulated analyzed various metrics capture evolutionary properties networks find co evolution rates trust based `communities' approximately 60 higher trade based `communities' also find trust trade connections within `communities' reduce size increases finally , study dynamics trade trust within `communities' find interesting results relationship trade trust dynamics within `communities'
evolutionary algorithm based adaptive navigation information retrieval interfaces computer interfaces general , especially information retrieval tasks , important able quickly find retrieve information state art approach , used , example , search engines , effective introduces losses meanings due context keywords back translation authors argue increases time reduces accuracy information retrieval compared could system employs modern information retrieval text mining methods presenting results adaptive human computer interface system effectively learns operator needs iterative interaction current work , combination adaptive interface real time collaborative feedback analysis documents relevance weighting proposed viable alternative approach information retrieval systems adaptive navigation provided dynamic links panel controlled evolutionary algorithm documents relevance initially established standard information retrieval techniques refined real time interaction users system introduced concepts multidimensional knowledge map weighted point interest allow finding relevant documents users common interests trivial calculation browsing search approach , ability algorithm adapt navigation users interests , collaborative refinement self features system main factors making architecture effective various fields non structured knowledge represented users
sample complexity general reinforcement learning present new algorithm general reinforcement learning true environment known belong finite class n arbitrary models algorithm shown near optimal \( n log 2 n \) time steps high probability infinite classes also considered show key criterion determining existence uniform sample complexity bounds matching lower bound given finite case
rate splitting multi antenna non orthogonal unicast multicast transmission spectral energy efficiency analysis non orthogonal unicast multicast transmission system , multicast stream intended users power domain unicast streams conventional approach based multi user linear precoding \( mu lp \) user relies successive interference cancellation \( \) first remove decode multicast stream decoding intended unicast stream paper , investigate application power domain non orthogonal multiple access \( noma \) linearly rate splitting \( rs \) non orthogonal unicast multicast transmission two different objectives studied , namely maximizing weighted sum rate \( \) maximizing energy efficiency \( ee \) numerical results show proposed rs assisted transmission strategy energy efficient conventional mu lp wide range user deployments \( diversity channel directions , channel strengths channel state information transmitter \) network loads \( regimes \) moreover , ee performance gains rs come without increase receiver complexity compared mu lp comparison proposed noma assisted transmission strategies , rs achieves better ee performance wide range user deployments network loads much less complex receivers hence , conclude proposed rs assisted strategy superior downlink multi antenna non orthogonal unicast multicast transmission
constant composition codes derived linear codes paper , propose class linear codes obtain weight distribution codes almost optimal moreover , several classes constant composition codes \( \) constructed linear codes
economic perspective major cloud computing providers cloud computing defined resources network essential utility similar electricity , , years , number providers emerged provide basic advanced form services cloud computing however , providers employ specification range services offered makes difficult common user select platform based requirements paper provides comparison different cloud service providers economic perspective performs cost analysis services provided providers different scenarios based analysis , conclusions drawn directions research provided
evaluating large scale study open source projects software engineering , relying experience render expertise time example , based experience , consider javascript language hence lowest guide decisions without prior empirical validation
combining model based model free updates trajectory centric reinforcement learning reinforcement learning \( rl \) algorithms real world robotic applications need data efficient learning process ability handle complex , unknown dynamical systems requirements well model based model free rl approaches , respectively work , aim combine advantages two types methods principled manner focusing time varying linear gaussian policies , enable model based algorithm based linear quadratic \( \) integrated model free framework path integral policy improvement \( \) combine method guided policy search \( gps \) train arbitrary parameterized policies deep neural networks simulation real world experiments demonstrate method solve challenging manipulation tasks comparable better performance model free methods maintaining sample efficiency model based methods video presenting results available https url
simtensor synthetic tensor data generator simtensor multi platform , open source software generating artificial tensor data \( either cp structure \) research tensor factorization algorithms simtensor alone application based provides wide range generating tensor data various configurations comes user friendly graphical user interface , enables user generate tensors complicated settings easy way also generated data universal formats , via wide range programming languages \( c , c , , r , , , , python , many \) innovative part simtensor generate temporal tensors periodic , effects streaming structure apply constraints non different kinds sparsity data simtensor also provides simulate different kinds change points various types anomalies source code binary versions simtensor available download http url
srg snippet relatedness based temporal action proposal generator recent temporal action proposal generation approaches suggested integrating segment snippet score based methodologies producing proposals high recall accurate boundaries paper , different hybrid strategy , focus potential snippet score based approach specifically , propose new snippet score based method , named snippet relatedness based generator \( srg \) , novel concept snippet relatedness snippet relatedness represents related specific action instance effectively learn snippet relatedness , present pyramid non local operations locally globally capturing long range dependencies among employing components , srg first produces 2d relatedness score map enables generation various temporal intervals reliably covering action instances high overlap , srg evaluates action confidence scores temporal intervals boundaries obtain temporal action proposals 14 1 3 datasets , srg outperforms state art methods temporal action proposal generation furthermore , compared competing proposal generators , srg leads significant improvements temporal action detection
reinforcement learning online information seeking search , recommendation , online advertising three important information providing mechanisms web information seeking techniques , satisfying users' information needs suggesting users personalized objects \( information services \) appropriate time place , play crucial role information problem recent great advances deep reinforcement learning \( drl \) , increasing interests developing drl based information seeking techniques drl based techniques two key advantages \( 1 \) able continuously update information seeking strategies according users' real time feedback , \( 2 \) maximize expected cumulative long term reward users reward different definitions according information seeking applications click rate , revenue , user satisfaction paper , give overview deep reinforcement learning search , recommendation , online advertising methodologies applications , review representative algorithms , discuss appealing research directions
methods quantized compressed sensing paper , compare performance various greedy quantized compressed sensing algorithms reconstruct sparse signals quantized compressed measurements also introduce two new greedy approaches reconstruction quantized compressed sampling matching \( \) adaptive quantized iterative hard thresholding \( \) compare performance greedy quantized compressed sensing algorithms given bit depth , sparsity , noise level
finding maximal sets laminar 3 separators planar graphs linear time consider 3 connected planar graph g using laminar separators size three show find maximal set laminar 3 separators graph linear time also discuss find maximal laminar set 3 separators special families example discuss non trivial , split g two components size least two vertex v , also show find maximal set 3 separators disjoint v laminar satisfy every vertex x two unique component g x containing v cases , show construct corresponding tree decomposition three new algorithms form important component recent methods finding disjoint paths graphs
distance landmarks revisited road graphs computing shortest distances one problems graphs , remains challenging task today distance landmarks recently studied shortest distance queries auxiliary data structure , referred landmark covers paper studies apply distance landmarks fast exact shortest distance query answering large road graphs however , direct application distance landmarks impractical due high space time cost problem , investigate novel techniques combined distance landmarks first notion hybrid landmark covers , landmark covers second , propose notion agents , represents small subgraph holds good properties fast distance query answering also show agents computed linear time third , introduce graph partitions deal remaining subgraph cannot captured agents fourth , develop unified framework integrates r proposed techniques existing optimization techniques , fast shortest distance query answering finally , experimentally verify techniques significantly improve shortest distance queries , using real life road graphs
getting robots dense pedestrian aim enable mobile robot navigate environments dense , e g , shopping , , train stations , terminals challenging environments , existing approaches suffer two common problems robot may get cannot make progress toward goal , may get lost due severe occlusions inside crowd propose navigation framework handles robot navigation lost problems simultaneously first , enhance robot 's mobility robot crowd using reinforcement learning based local navigation policy developed previous work cite , naturally takes account coordination robot human secondly , robot takes advantage excellent local mobility recover localization failure particular , dynamically chooses approach set recovery positions rich features best knowledge , method first approach simultaneously problem navigation lost problem dense evaluate method simulated real world environments demonstrate outperforms state art approaches videos available https url
bridging gap pre training fine tuning end end speech translation end end speech translation , hot topic recent years , aims translate segment audio specific language end end model conventional approaches employ multi task learning pre training methods task , suffer huge gap pre training fine tuning address issues , propose connectionist encoding network \( \) gap fine tuning , keeping roles consistent , pre training attention module furthermore , propose two simple effective methods guarantee speech encoder outputs mt encoder inputs consistent terms semantic representation sequence length experimental results show model outperforms baselines 2 2 bleu large benchmark dataset
next information technology research goals 's vision computing largely realized 's , distance passing turing test three associated problems provided long range research goals many us example , scalability problem motivated several decades defines set fundamental research problems , , turing extend 's computational goal include highly secure , highly available , self programming , self managing , self systems extend 's vision include system automatically , indexes , , evaluates , information \( well human might \) another group problems extends turing 's vision intelligent machines include vision , speech , , senses problem simply stated orthogonal others , though share common core technologies
improved fpt algorithms weighted independent set bull free graphs recently , , 2014 given fpt algorithm weighted independent set bull free graphs parameterized weight solution , running time 2 \( k 5 \) cdot n 9 article improve running time 2 \( k 2 \) cdot n 7 , also improve previous turing kernel problem \( k 5 \) \( k 2 \) furthermore , subclass bull free graphs without length 1 p geq 3 , speed running time 2 \( k cdot k frac 1 p 1 \) cdot n 7 p grows , running time asymptotically tight terms k , since prove integer p geq 3 , weighted independent set cannot solved time 2 \( k \) cdot n \( 1 \) class bull , c 4 , ldots , c 1 free graphs unless fails
multi level wavelet convolutional neural networks computer vision , convolutional networks \( cnns \) often adopts pooling receptive field advantage low computational complexity however , pooling cause information loss thus detrimental operations features extraction analysis recently , dilated filter proposed trade receptive field size efficiency effect cause sparse sampling input images patterns address problem , paper , propose novel multi level wavelet cnn \( \) model achieve better trade receptive field size computational efficiency core idea wavelet transform cnn architecture reduce resolution feature maps time , increasing receptive field specifically , image restoration based u net architecture , inverse wavelet transform \( \) deployed reconstruct high resolution \( hr \) feature maps proposed also viewed improvement dilated filter generalization average pooling , applied image restoration tasks , also cnns requiring pooling operation experimental results demonstrate effectiveness proposed tasks image denoising , single image super resolution , image removal object classification
adaptive trajectory planning optimization limits handling paper , tackle problem trajectory planning control vehicle locally varying traction limitations , presence obstacles employ concepts adaptive model predictive control run time adaptation force constraints imposed local traction conditions solve resulting optimization problem real time control synthesis time varying constraints , propose novel numerical scheme based real time iteration sequential quadratic programming \( rti \) , call sampling augmented adaptive rti \( rti \) sampling augmentation conventional rti provides additional feasible candidate trajectories optimization procedure thus , proposed rti algorithm enables real time constraint adaptation reduces sensitivity local minima extensive numerical simulations demonstrate method increases vehicle 's capacity avoid accidents scenarios obstacles locally varying traction , compared equivalent non adaptive control schemes traditional planning tracking approaches
test continuous integration environments abstract two heuristics namely diversity based \( \) history based test \( \) separately proposed literature yet , combination widely studied continuous integration \( ci \) environments objective study regression faults earlier , allowing developers integrate verify changes frequently continuously achieve , investigated six open source projects , included several builds large time period findings indicate previous failure knowledge seems strong predictive power ci environments used effectively tests necessarily need large data , effectiveness improves certain degree larger history interval used effectively early stages , historical data available , also combined improve effectiveness among investigated techniques , found history based diversity using multiset superior terms effectiveness comes relatively higher overhead terms method execution time test ci environments effectively performed negligible investment using previous failure knowledge , effectiveness improved considering among tests
cross layer transmission design tactile internet ensure low end end \( \) delay tactile internet , short frame structures used 5g systems , transmission errors finite channel codes considered guarantee high reliability requirement paper , study cross layer transmission optimization tactile internet , queueing delay transmission delay delay , different packet loss error probabilities considered characterize reliability show required transmit power becomes unbounded allowed maximal queueing delay shorter channel coherence time satisfy quality service requirement finite transmit power , introduce proactive packet dropping mechanism , optimize queue state information channel state information dependent transmission policy since resource policy transmission packet dropping policy related packet error probability , queueing delay probability , packet dropping probability , optimize three probabilities obtain policies related probabilities start single user scenario extend framework multi user scenario simulation results show optimized three probabilities order magnitude therefore , take account factors design systems tactile internet applications
network coding new coding queue management algorithm proposed communication networks employ linear network coding algorithm feature encoding process truly online , block block approach setup assumes packet erasure broadcast channel stochastic full feedback , proposed scheme potentially applicable general lossy networks link link feedback algorithm guarantees physical queue size sender tracks degrees freedom \( also called virtual queue size \) new notion node packet introduced terms idea , algorithm may viewed natural extension schemes coded networks approach , known drop seen algorithm , compared baseline approach called drop decoded shown expected queue size approach \( 1 \) \( 1 \) omega \( 1 \) \( 1 \) 2 baseline approach , load factor
crowd counting deep structured scale integration network automatic estimation number people unconstrained crowded scenes challenging task one major difficulty stems huge scale variation people paper , propose novel deep structured scale integration network \( \) crowd counting , addresses scale variation people using structured feature representation learning structured loss function optimization unlike conventional methods directly multiple features weighted average concatenation , first introduce structured feature enhancement module based conditional random fields \( crfs \) refine multiscale features message passing mechanism module , scale specific feature considered continuous random variable complementary information refine features scales second , utilize dilated multiscale structural similarity loss enforce learn local correlation people 's scales within regions various size , thus yielding high quality density maps extensive experiments four challenging benchmarks well demonstrate effectiveness method specifically , achieves improvements 9 5 error reduction dataset 24 9 dataset state art methods
central bank wikipedia analyze influence interactions 60 largest world banks world countries using reduced google matrix algorithm english wikipedia network 5 articles top rank positions taken banks , industrial commercial bank first place , show network influence banks central bank determine network structure interactions banks countries pagerank sensitivity countries selected banks also present gpu oriented code significantly numerical computations reduced google matrix
person identification past present future person identification \( id \) become increasingly popular community due application research significance aims spotting person interest cameras early days , hand crafted algorithms small scale evaluation predominantly reported recent years large scale datasets deep learning systems make use large data considering different tasks , classify current id methods two classes , e , image based video based tasks , hand crafted deep learning systems reviewed moreover , two new id tasks much closer real world applications described discussed , e , end end id fast id large paper 1 \) introduces history person id relationship image classification instance retrieval 2 \) surveys broad selection hand crafted systems large scale methods image video based id 3 \) describes critical future directions end end id fast retrieval large 4 \) finally important yet developed issues
sampling colorings almost uniformly sparse random graphs problem sampling proper q colorings uniform distribution extensively studied existing require q ge alpha delta beta alpha beta , delta maximum degree graph problem becomes challenging underlying graph unbounded degree since even decision q becomes nontrivial situation h r e random graph mathcal g \( n , n \) typical class graphs received lot recent attention case , performance sampler usually measured relation q average degree interested fully polynomial time almost uniform sampler \( \) state art sampler proper q coloring mathcal g \( n , n \) requires q ge 5 r n paper , design proper q colorings mathcal g \( n , n \) requiring q ge 3d \( 1 \) , improves best bound problem far sampler based spatial mixing property q coloring random graphs core sampler deterministic algorithm estimate marginal probability blocks , computed novel block version recursion q coloring unbounded degree graphs
learning surrogate models document image quality metrics automated document image processing computation document image quality metrics often depends upon availability ground truth image corresponding document limits applicability quality metrics applications hyperparameter optimization image processing algorithms operate fly unseen documents work proposes use surrogate models learn behavior given document quality metric existing datasets ground truth images available trained surrogate model later used predict metric value previously unseen document images without requiring access ground truth images surrogate model empirically evaluated document image competition \( \) document image competition \( h \) datasets
asymmetric kernel gaussian processes learning target variance work incorporates multi modality data distribution gaussian process regression model approach problem discriminative perspective learning , jointly training data , target space variance neighborhood certain sample metric learning start using data centers rather training samples subsequently , center selects kernel metric enables center adjust kernel space correspondence topology targets multi modal approach additionally add allowing center learn precision matrix demonstrate empirically reliability model
networks maximum entropy apply principle maximum entropy select unique joint probability distribution set joint probability distributions specified network detail , start showing unique joint distribution bayesian tree maximum entropy model conditional distributions result , however , hold general bayesian networks thus present new kind maximum entropy models , computed sequentially show general bayesian networks , sequential maximum entropy model unique joint distribution moreover , apply new principle sequential maximum entropy interval bayesian networks generally networks especially show application equivalent number small local entropy
evaluation basic modules isolated error correction texts error correction important problem natural language processing , good performance downstream tasks well important feature user facing applications texts language , exist works specific error correction solutions , often developed dealing specialized corpora , evaluations many different approaches big resources errors address problem testing basic promising methods , corpus annotated extracted wikipedia modules may combined appropriate solutions error detection context awareness following results , combining edit distance distance semantic vectors may suggested interpretable systems , lstm , particularly enhanced embeddings , seems offer best raw performance
limited multi label projection layer propose limited multi label \( \) projection layer new primitive operation end end learning systems layer provides probabilistic way modeling multi label predictions limited exactly k labels derive efficient forward backward layer show layer used optimize top k recall multi label tasks incomplete label information evaluate layers top k cifar 100 classification scene graph generation show layers add negligible amount computational overhead , strictly improve model 's representational capacity , improve accuracy also revisit top k entropy method competitive baseline top k classification
resource allocation multiple access channels consider problem rate allocation gaussian multiple access channel , goal maximizing utility function transmission rates contrast literature focuses linear utility functions , study general concave utility functions present gradient projection algorithm problem since constraint set problem described exponentially many constraints , methods use exact projections computationally intractable therefore , develop new method uses approximate projections use structure capacity region show approximate projection implemented recursive algorithm time polynomial number users propose another algorithm implementing approximate projections using rate splitting show improved bounds convergence time
estimating tactile data adaptive grasping novel objects present adaptive grasping method finds stable grasps novel objects main contributions paper computation probability success grasps already applied grasp method performs grasp tactile data grasps current grasp simulated data used evaluate grasps thereby guide us toward better grasps demonstrate applicability method constructing system plan , apply adapt grasps novel objects experiments conducted objects object set success rate method 88 experiments show application grasp method improves grasp stability significantly
adversarial semi supervised audio source separation applied voice extraction state art music source separation employs neural networks trained supervised fashion multi track databases estimate sources given mixture datasets available , often extensive data augmentation used combat overfitting mixing random tracks , however , even reduce separation performance instruments real music strongly correlated key concept approach source estimates optimal indistinguishable real source signals based idea , drive towards outputs realistic discriminator networks trained apart real samples way , also use unpaired source mixture without drawbacks creating music mixtures framework widely applicable assume specific network architecture number sources knowledge , first adoption adversarial training music source separation prototype experiment voice separation , separation performance increases approach compared purely supervised training
characteristics international versus non international scientific publication media team author based data coverage international publication citation databases web science towards local media social response increased usage databases evaluation systems mostly international journals available earlier basis development current standard indicators indicators may longer measure exactly concepts applied newly introduced extended media categories , possibly different characteristics international journals paper investigates differences media without international dimension publication data team author level findings relate international publication categories research quality , important validation usage evaluation models aim quality
optimal linear time algorithm quasi monotonic monotonicity simple yet significant qualitative characteristic consider problem segmenting sequence k segments want segments monotonic possible alternate signs propose quality metric problem using l norm , present optimal linear time algorithm based novel moreover , given time \( n log n \) consisting labelling , compute optimal segmentation constant time compare experimentally performance two piecewise linear segmentation heuristics \( top bottom \) show algorithm faster accurate applications include pattern recognition qualitative modelling
learning physical long term predictor evolution highly developed abilities many natural quickly accurately predict mechanical phenomena humans successfully developed laws physics abstract model mechanical phenomena context artificial intelligence , recent line work focused estimating physical parameters based sensory data use physical simulators make long term predictions contrast , investigate effectiveness single neural network end end long term prediction mechanical phenomena based extensive evaluation , demonstrate networks outperform alternate approaches even access ground truth physical simulators , especially physical parameters known priori , network outputs distribution outcomes capture inherent uncertainty data approach demonstrates first time possibility making actionable long term predictions sensor data without requiring explicitly model underlying physical laws
hierarchical quasi clustering methods asymmetric networks paper introduces hierarchical quasi clustering methods , generalization hierarchical clustering asymmetric networks output structure preserves input data show output structure equivalent finite quasi space study respect two desirable properties prove modified version single admissible quasi clustering method moreover , show stability proposed method establish invariance properties algorithms developed value quasi clustering analysis illustrated study internal migration within united states
extended operators based variation operational semantics using offer introduced previous work , extend algebras used model operators extension uses algebra causal interaction trees , \( p \) , existing transformations automatically provide extensions algebra extend \( p \) , since equivalence induced new operational semantics weaker induced interaction semantics extension leads canonical normal forms structures simplification algorithm synthesis boolean coordination constraints
compensated integrated gradients reliably interpret eeg classification integrated gradients widely employed evaluate contribution input features classification models satisfies prediction method , however , requires appropriate baseline reliable determination contributions propose compensated integrated gradients method require baseline fact , method calculated integrated gradients arbitrary baseline using sampling prove method reliable processes input features classifier independent , identical like shared weights convolutional neural networks using three datasets , experimentally demonstrate proposed method reliable original integrated gradients , computational complexity much lower sampling
fast subgraph matching gpus paper , propose gpu efficient subgraph algorithm using graph framework , \( subgraph matching \) , compute graph matching gpus contrast previous approaches cpu based depth first , based possible matches explored simultaneously first strategy advantage using based leverage massively parallel processing capabilities gpu disadvantage generation intermediate results propose several optimization techniques cope problem implementation follows filtering verification strategy previous work gpus requires one two step , use one step verification decide candidates current frontier nodes implementation speedup 4x previous gpu state art implementation
privacy preserving collaborative machine learning data using machine learning \( ml \) methods widely used studies however , data often held different \( e g , , healthcare companies \) consider data sensitive information , even though address issue , recent works proposed solutions using secure multi party computation \( mpc \) , train decentralized data way participants could learn beyond final trained model r n design implement several mpc friendly ml primitives , including class weight parallelizable approximation activation function addition , develop solution extension encrypted , enabling us quickly experiment machine learning techniques cryptographic protocols leveraging advantages 's optimizations implementation state art methods , winning first place track secure analysis competition
structured sparsity generalization present data dependent generalization bound large class regularized algorithms implement structured sparsity constraints bound applied standard squared norm regularization , lasso , group lasso , versions group lasso overlapping groups , multiple kernel learning regularization schemes cases competitive results obtained novel feature bound applied infinite dimensional setting lasso separable space multiple kernel learning number kernels
topological characteristics applications demonstrate applications topological characteristics considered three dimensional bodies modeling
face representation deep learning linear encoding parameter space recently , convolutional neural networks \( cnns \) achieved tremendous performances face recognition , one popular perspective regarding success cnns could learn discriminative face representations face images complex image feature encoding however , still unclear intrinsic mechanism face representation cnns work , investigate problem face images points shape appearance parameter space , results demonstrate \( \) encoding decoding neuron responses \( representations \) face images cnns could achieved linear model parameter space , agreement recent discovery face neurons , different aforementioned perspective face representation complex image feature encoding \( ii \) linear model face encoding decoding parameter space could achieve close even better performances face recognition verification state art cnns , might provide new design strategies face recognition systems \( iii \) neuron responses face images cnns could modelled axis model , model recently proposed face modelling results might shed often nature behind tremendous performances face recognition
identifying correlated heavy hitters two dimensional data stream consider online mining correlated heavy hitters data stream given stream two dimensional data , correlated aggregate query first applying along primary dimension , computes aggregate along secondary dimension prior work identifying heavy hitters streams almost exclusively focused identifying heavy hitters single dimensional stream , yield little insight properties heavy hitters along dimensions typical applications however , interested identifying heavy hitters , also understanding properties items appear frequently along heavy , frequency distribution items appear along heavy hitters consider queries following form stream \( x , \) tuples , h x values heavy hitters , maintain values occur frequently x values h call problem correlated heavy hitters \( \) formulate approximate formulation identification , present algorithm tracking data stream algorithm easy implement uses workspace orders magnitude smaller stream present provable guarantees maximum error , well detailed experimental results demonstrate space accuracy trade
scholarly journal transition restricted open access business models used segments media industry changed internet , surprisingly little changed scholarly peer reviewed journals electronic delivery become norm , still dominating market , selling content article asks question open access \( oa \) output mainly publicly research yet become mainstream business model oa implies revenue logic paying content authors paying form universal free access current situation analyzed using five forces model analysis demonstrates lack competitive pressure industry , leading high profit levels leading yet strong need change way operate oa article \( \) might nevertheless start rapidly becoming common driving forces change currently consist public research , pushing oa starting dedicated paying authors respective countries turn lead situation introduced big deals involving \( \) journals , \( b \) hybrid journals \( c \) future also full oa journals appears relatively risk free strategy leading retain market high profit levels
consistent scale normalization object recognition scale variation remains challenge problem object detection common usually adopt multi scale training testing \( image pyramid \) \( feature pyramid network \) process objects wide scale range however , multi scale methods variation scale even deep convolution neural networks cannot handle well work , propose innovative paradigm called consistent scale normalization \( csn \) resolve problem csn scale space objects consistent range \( csn range \) , training testing phase problem scale variation , reduces difficulty network learning experiments show csn multi scale counterpart significantly object detection , instance segmentation multi task human pose estimation , several architectures coco test , single model based csn achieves 46 5 map resnet backbone , among state art \( \) candidates object detection
shape neutral analysis graph based data structures data structures lead runtime errors arbitrary memory access despite , reasoning data structure properties low level heap manipulating programs remains challenging paper present constraint based program analysis data structure integrity , w r given target data structure properties , heap program approach automatically generate solver properties using type definitions target program generated solver implemented using constraint handling rules \( \) extension built heap , integer solvers key property program analysis target data structure properties shape neutral , e , analysis check properties given data structure graph shape , linked lists versus trees nevertheless , analysis detect errors wide range data structure manipulating programs , including use lists , trees , , graphs , etc present implementation uses modulo constraint handling rules \( \) system experimental results show approach works well real world c programs
modeling stated preference mobility demand comparison machine learning logit models logit models usually applied studying individual travel behavior , e , predict travel mode choice gain behavioral insights preferences recently , studies applied machine learning model travel mode choice reported higher sample predictive accuracy traditional logit models \( e g , logit \) however , little research focuses comparing interpretability machine learning logit models words , draw behavioral insights high performance black box machine learning models remains largely field travel behavior modeling r n paper aims providing comprehensive comparison two approaches examining key similarities differences model development , evaluation , behavioral interpretation logit machine learning models travel mode choice modeling complement theoretical discussions , paper also empirically evaluates two approaches stated preference survey data new type system integrating high frequency fixed route services results show machine learning produce significantly higher predictive accuracy logit models moreover , machine learning logit models largely many aspects behavioral interpretations addition , machine learning automatically capture nonlinear relationship input features choice outcomes paper concludes great potential merging ideas machine learning conventional statistical methods develop refined models travel behavior research suggests new research directions
exploration control learning object manipulation skills novelty search local adaptation programming robot deal open tasks remains challenge , particular robot objects , grasping , pushing object interaction simulated corresponding models robot behavior thus cannot directly behaviors hard learn without search space large reward sparse propose method generate diverse repertoire simple object interaction behaviors simulation goal robot learning development process limited robot achieve repertoire exploited solve different tasks reality thanks proposed adaptation method could used training set data algorithms r n proposed approach relies definition goal space generates repertoire trajectories reach goals , thus allowing robot control goal space repertoire built shelf simulation thanks quality diversity algorithm result set solutions tested simulation may result two different problems \( 1 \) repertoire discrete finite , may contain trajectory deal given situation \( 2 \) trajectories may lead behavior reality differs simulation reality gap propose approach deal issues using local motion parameters observed effects furthermore , present approach update existing solution repertoire tests done real robot approach validated two different experiments robot ball manipulation tasks
matrix compression using method method routinely used sample extension kernel matrices describe method applied find singular value decomposition \( \) general matrices eigenvalue decomposition \( \) square matrices take input matrix mathbb r times n , user defined integer leq min \( , n \) mathbb r times , matrix sampled columns used construct approximate rank left \( 2 left \( n right \) right \) operations square , rank similarly constructed left \( 2 n right \) operations thus , matrix compressed version discuss choice propose algorithm selects good initial sample version proposed algorithm performs well general matrices kernel matrices whose exhibit fast decay
radnet level accuracy using deep learning detection ct scans describe deep learning approach automated brain detection computed \( ct \) scans model procedure followed radiologists 3d ct real world similar radiologists , model 2d cross slices paying close attention potential regions , model utilizes 3d context neighboring slices improve predictions slice subsequently , aggregates slice level predictions provide diagnosis ct level refer proposed approach recurrent attention densenet \( radnet \) employs original densenet architecture along adding components attention slice level predictions recurrent neural network layer incorporating 3d context real world performance radnet independent analysis performed three radiologists 77 brain radnet demonstrates 82 prediction accuracy ct level comparable radiologists , radnet achieves higher recall two three radiologists , remarkable
explaining black box models inductive synthesis nature , composition black box models makes ability generate explanations response challenging importance explaining black box models become increasingly important given prevalence ai ml systems need build frameworks around explanations also increase trust uncertain systems paper present , method generating explanations behaviour black box models \( 1 \) probing model extract model output examples using sensitivity analysis \( 2 \) applying , method inductive logic program synthesis , generate logic programs based critical input output pairs \( 3 \) interpreting target program human explanation demonstrate application method generating explanations artificial neural network trained follow simple traffic rules self driving car simulation conclude discussion scalability approach potential applications explanation critical scenarios
approximate query service autonomous iot cameras today 's analytics powered cameras still limited urban , areas power network resources expand diverse environments , especially grid highly network constrained , cameras , e , independent external power supply compute infrastructure autonomous cameras useful analytics \? response icam , runtime autonomous cameras , capable producing useful analytics results camera resources icam built two novel techniques \( 1 \) first time , icam explores joint tradeoff sampling strategy wide selection nn choices , errors sources one single bounded error \( 2 \) observing disparate video characteristics across different time , icam employs learning based sampling action runtime test icam 1 , 000 hours videos typical embedded hardware , icam continuously generates object counts within 11 true counts counts , icam presents error estimation shown bounded achieves 3 4x smaller bounded error baselines
secret sharing fast fading mimo wiretap channels secret sharing fast fading mimo wiretap channel considered source destination try share secret information fast fading mimo channel presence also makes channel observations different correlated made destination interactive public channel also available use source destination secret sharing process falls channel type model considered minor extension result \( continuous channel \) employed evaluate key capacity fast fading mimo wiretap channel effects spatial dimensionality provided use multiple antennas source , destination , investigated
survey advances epistemic logic program solvers recent research extensions answer set programming included interest language epistemic specifications , adds modal operators k \( known \) \( may true \) provide powerful reasoning enhanced capability , particularly reasoning incomplete information epistemic logic program set rules language research efficient solver enable practical use programs problem solving paper , report current state development epistemic logic program solvers
overcoming language variation sentiment analysis social attention variation language ubiquitous , particularly forms writing social media , variation random , often linked social properties author paper , show exploit social networks make sentiment analysis robust social language variation key idea linguistic tendency linked individuals use language similar ways formalize idea novel attention based neural network architecture , attention divided among several basis models , depending author 's position social network effect smoothing classification function across social network , makes possible induce personalized classifiers even authors labeled data metadata model significantly improves accuracies sentiment analysis twitter review data
generalized congestion games different types dynamics studied repeated game play , one received much attention recently consists based regret algorithms area machine learning known dynamics based generic regret algorithms may converge nash equilibria general , larger set outcomes , namely coarse correlated equilibria moreover , convergence results based generic regret algorithms typically use weaker notion convergence convergence average plays instead actual plays work done showing using specific regret algorithm , well known multiplicative updates algorithm , convergence actual plays equilibria shown better quality outcomes terms price anarchy reached atomic congestion games load balancing games cases natural regret dynamics perform well suitable classes games terms convergence quality outcomes dynamics converge \? r n answer question board model showing employing descent algorithm , well known generic regret algorithm , actual plays converge quickly equilibria congestion games furthermore , bandit model considers realistic prevalent setting partial information , time step player knows cost currently strategy , costs strategies class atomic congestion games , propose family bandit algorithms based descent algorithms previously presented , show player individually adopts bandit algorithm , joint \( mixed \) strategy profile quickly converges implications
distributed reinforcement learning via consider classical td \( 0 \) algorithm implemented network agents wherein agents also incorporate updates received neighboring agents using like mechanism combined scheme shown converge average cost problems
compressed subspace learning based canonical angle preserving property union \( \) popular model describe underlying low dimensional structure data fine details structure described terms canonical angles \( also known principal angles \) , well known characterization relative subspace positions paper , prove random projection called johnson \( jl \) property approximately preserves canonical angles probability result indicates random projection approximately preserves structure inspired result , propose framework compressed subspace learning \( \) , enables extract useful information structure data greatly reduced dimension demonstrate effectiveness various subspace related tasks subspace visualization , active subspace detection , subspace clustering
scalable real time object detection directed sparse sampling define object detection imagery problem estimating large extremely sparse bounding box dependent probability distribution subsequently identify sparse distribution estimation scheme , directed sparse sampling , employ single end end cnn based detection model methodology extends previous state art detection models additional emphasis high evaluation rates reduced manual engineering introduce two , corner based region interest estimator based cnn model resulting model scene adaptive , require manually defined reference bounding boxes produces highly competitive results , pascal voc pascal voc 2012 real time evaluation rates analysis suggests model performs particularly well object localization desirable argue advantage stems significantly larger set available regions interest relative methods source code available https url
compressive sampling sar imaging paper presents compressive sampling \( \) associated fast imaging scheme synthetic radar \( sar \) different analog information \( \) , using independent signals sample sar due different transmitted resulting sensing matrix lower correlation two columns fixed signal , better sar image reconstructed proper setting signals , sensing matrix structures suitable fast computation matrix vector multiplication operations , leads fast image reconstruction performance proposed scheme using real sar image reconstructed sar images one fourth data achieve image quality similar classical sar images samples
top k product design based collaborative tagging data widespread use popularity collaborative content sites \( e g , , amazon , , etc \) created rich resources users order make decisions various products , e commerce products , , etc products desirable tags \( e g , modern , reliable , etc \) higher selected customers creates opportunity product designers design better products likely desirable tags published paper , investigate mine collaborative tagging data decide attribute values new products return top k products likely maximum number desirable tags published given training set existing products features user tags , first build naive bayes classifier tag show problem np complete even simple naive bayes classifiers used tag prediction present suite algorithms solving problem \( \) exact two tier algorithm \( based top k querying techniques \) , performs much better naive brute force algorithm works well moderate problem instances , \( b \) set approximation algorithms larger problem instances novel polynomial time approximation algorithm provable error bound practical hill heuristic conduct detailed experiments synthetic real data web evaluate efficiency quality proposed algorithms , well show product designers benefit leveraging collaborative tagging information
guidance navigation control systems cooperative application devices small robots game enables robots mobile low surfaces small bodies use enables robots , hop , rest surfaces would otherwise possible robots extending technology enable robots world , single robot may slip fall , however , system work using work much like team systematically slope system show paper faces possible single robot alone consider team four robots configuration robot slope using , one one robot , slope one robots , falls , remaining robots holding distributed controls approach enables system possible avoid getting one hard reach location instead , risk distributed close cooperation , robots identify multiple trajectories surface benefits also realized surfaces fast result robot surface space multiple robots surface entire system secure work combines dynamics control simulation evaluate feasibility approach simulation results show promising towards advanced development technology team real robots
sorting recurrent comparison errors present sorting algorithm case recurrent random comparison errors algorithm essentially achieves simultaneously good properties previous algorithms sorting n distinct elements model particular , runs \( n 2 \) time , maximum elements output \( log n \) , total \( n \) guarantees best possible since prove even randomized algorithms cannot achieve \( log n \) maximum high probability , \( n \) total expectation , regardless running time
distributed computation conditional quantized decentralized particle filters conditional posterior rao lower bound \( \) effective sensor resource management criteria large , distributed sensor networks existing algorithms distributed computation \( dpcrlb \) based raw observations leading significant communication overhead estimation mechanism letter distributed computational techniques determining conditional dpcrlb quantized , decentralized sensor networks \( dpcrlb \) analytical expressions dpcrlb derived , particularly useful particle filter based dpcrlb compared accuracy centralized counterpart monte carlo simulations
bathymetry approximation mesh generation simulations due nature domain geometry flow simulations , completely accurate description domain terms computational mesh frequently infeasible bathymetry simplification methods used remove small scale details geometry , particularly areas away region interest end , novel method bathymetry simplification presented existing simplification methods typically remove points geometry satisfies particular geometric criteria bathymetry usually simplified using traditional filtering techniques , remove fourier modes principal component analysis \( \) used fields small scale structures larger scale coherent features robust way , rigorous simple mathematical framework present method based principal component analysis aimed towards simplification bathymetry present algorithm detail show simplified bathymetry region around finally , methods used context unstructured mesh generation aimed resource assessment simulations regions around uk
area protection adversarial path finding scenarios multiple mobile agents graphs theoretical experimental study target allocation strategies defense coordination address problem area protection graph based scenarios multiple agents problem consists two adversarial teams agents move undirected graph shared teams agents placed vertices graph one agent vertex move adjacent vertices conflict free way teams asymmetric goals aim one team attackers given area aim team protect area attackers selected vertices study strategies allocating vertices team block attacking agents show decision version problem area protection hard assumption agents allocate target vertices multiple times develop various line vertex allocation strategies team simplified variant problem single stage vertex allocation evaluated performance multiple benchmarks success strategy heavily dependent type instance , one contributions work identify suitable vertex allocation strategies diverse instance types particular , introduce simulation based method identifies tries capture graph , frequently used attackers experimental evaluation suggests method often allows successful defense even instances attackers significantly
many weights cyclic code upper lower bounds largest number weights cyclic code given length , dimension alphabet given application cyclic codes considered upper bounds given special cyclic codes \( called strongly cyclic \) , whose nonzero codewords period equal length code asymptotics derived function gamma \( k , q \) , defined largest number nonzero weights cyclic code dimension k f q , algorithm compute nonzero weights infinite families codes , either binary q , well q hamming code determined , two difficult results independent interest
knowledge based programs plans complexity plan existence knowledge based programs \( \) high level protocols describing course action agent perform function knowledge use expressing action policies ai planning surprisingly given corresponds equivalent plan vice versa , typically succinct standard plans , imply line computation time make argument formal , prove exists exponential gap knowledge based programs standard plans address complexity plan existence results follow results already known literature planning incomplete knowledge , many unknown far
degrees freedom region mimo interference channel shannon feedback two user multiple input multiple output \( mimo \) fast fading interference channel \( ic \) arbitrary number antennas four terminals studied settings shannon feedback , limited shannon feedback , output feedback , wherein certain channel matrices outputs , channel outputs , respectively , available transmitters finite delay numbers antennas four terminals , shown dof regions shannon feedback limited shannon feedback settings considered identical , equal dof region delayed channel state information \( csit \) , shown always case specific class mimo characterized certain relationship numbers antennas four nodes , dof regions shannon limited shannon feedback settings , identical , strictly dof region delayed csit realize dof gains shannon limited shannon feedback , new retrospective interference alignment scheme developed wherein transmitter cooperation made possible output feedback addition delayed csit employed effect efficient form interference alignment feasible previously known schemes use delayed csit dof region output feedback , transmitter delayed knowledge outputs , also obtained class mimo satisfy one two inequalities involving numbers antennas
closest vector problem distance guarantee present substantially efficient variant , terms running time size preprocessing , algorithm , , solving \( preprocessing version closest vector problem , \) distance guarantee instance , alpha 1 2 , algorithm finds \( unique \) closest lattice point target point whose distance lattice alpha times length shortest nonzero lattice vector , requires preprocessing n \( n \( alpha 2 n \( 1 2 alpha \) 2 \) \) vectors , runs time \( nn \) r n second main contribution , present reductions showing solve , plain preprocessing versions , input target point within bounded distance lattice reductions based ideas due recent sparsification technique due combining reductions algorithm gives approximation factor \( n sqrt log n \) search , improving previous best \( n 1 5 \) due , , combined improved algorithm obtain , surprisingly , \( n \) vectors preprocessing sufficient solve \( slightly worse \) approximation factor \( n \)
higher order clustering networks fundamental property complex networks tendency edges cluster extent clustering typically clustering coefficient , probability length 2 path closed , e , induces triangle network however , higher order cliques beyond triangles crucial understanding complex networks , clustering behavior respect higher order network structures well understood introduce higher order clustering coefficients measure closure probability higher order network cliques provide comprehensive view edges complex networks cluster higher order clustering coefficients natural generalization traditional clustering coefficient derive several properties higher order clustering coefficients analyze common random graph models finally , use higher order clustering coefficients gain new insights structure real world networks several domains
phase transition random intersection graphs analyze component evolution random intersection graphs average degree close 1 average degree increases , size largest component random intersection graph goes phase transition give bounds size largest components transition also prove largest component transition unique
coarse fine prediction single image 3d human pose paper addresses challenge 3d human pose estimation single color image despite general success end end learning paradigm , top performing approaches employ two step solution consisting convolutional network \( convnet \) 2d joint localization subsequent optimization step recover 3d pose paper , identify representation 3d pose critical issue current convnet approaches make two important contributions towards validating value end end learning task first , propose fine 3d space around subject train convnet predict per voxel joint creates natural representation 3d pose greatly improves performance direct regression joint coordinates second , improve upon initial estimates , employ coarse fine prediction scheme step addresses large dimensionality increase enables iterative refinement repeated processing image features proposed approach outperforms state art methods standard benchmarks achieving relative error reduction greater 30 average additionally , investigate using representation related architecture suboptimal compared end end approach , practical interest , since enables training image corresponding 3d available , allows us present compelling results wild images
structured learning tree potentials crf image segmentation propose new approach image segmentation , exploits advantages conditional random fields \( crfs \) decision trees literature , potential functions crfs mostly defined linear combination pre defined parametric models , methods like structured support vector machines \( \) applied learn linear coefficients instead formulate unary pairwise potentials forests ensembles decision trees , learn ensemble parameters trees unified optimization problem within large margin framework fashion , easily achieve nonlinear learning potential functions unary pairwise terms crfs moreover , learn class wise decision trees object appears image due rich structure flexibility decision trees , approach powerful modelling complex data label relationships resulting optimization problem challenging exponentially many variables constraints show challenging optimization efficiently solved combining modified column generation cutting techniques experimental results binary \( , , \) multi class \( 21 , pascal voc 2012 \) segmentation datasets demonstrate power learned nonlinear potentials
web privacy hardware performance events browser history reveals highly sensitive information users , financial status , health conditions , political views private browsing modes networks consequently important tools preserve privacy regular users particular yet , work show malicious application infer websites google mode tor browser exploiting hardware performance events \( \) particular , analyze help advanced machine learning techniques k nearest neighbors , decision trees , support vector machines , contrast previous literature also convolutional neural networks profile 40 different websites , 30 top sites 10 , two machines intel arm processor monitoring instructions , cache accesses , cycles 5 seconds , manage classify selected websites success rate 86 3 results show hardware performance events clearly privacy web users therefore propose mitigation strategies attacks still allow legitimate use
estimating spatial reuse configuration models propose new methodology estimate spatial reuse csma like scheduling instead focusing spatial users , model users random graph using models random graphs , show properties medium access mechanism captured deterministic equations , size graph gets large performance indicators probability connection given node computed equations also perform simulations illustrate results types random graphs even spatial structures , estimates get accurate soon variance interference negligible
end end speaker verification adversarial examples automatic speaker verification systems increasingly used primary means recently , proposed train speaker verification systems using end end deep neural models paper , show systems vulnerable adversarial example attack adversarial examples generated adding noise original speaker examples , way almost indistinguishable original examples human yet , generated , sound speaker used system speaker b present white box attacks end end deep network either trained also present two black box attacks adversarial examples generated system trained , attack system trained adversarial examples generated system trained spectrum feature set , attack system trained results suggest accuracy system false positive rate dramatically increased
interpolation shifted polynomials given black box function evaluate unknown rational polynomial f mathbb q x points modulo prime p , exhibit algorithms compute representation polynomial shifted power basis , determine sparsity mathbb z 0 , shift alpha mathbb q , exponents 0 leq e 1 e 2 e , coefficients c 1 , ldots , c mathbb q 0 f \( x \) c 1 \( x alpha \) e 1 c 2 \( x alpha \) e 2 c \( x alpha \) e r n r n computed sparsity minimal shifted power basis novelty algorithm complexity polynomial \( sparse \) representation size , may logarithmic degree f method combines previous results sparse interpolation computing , provides way handle polynomials extremely high degree , sense , sparse information
near optimal fully dynamic subgraph give first fully dynamic algorithm \( 1 epsilon \) approximate subgraph worst case time text poly \( log n , epsilon 1 \) per update high probability dense subgraph discovery important primitive many real world applications community detection , link spam detection , distance query indexing , computational biology result improves upon previous best approximation factor \( 4 epsilon \) fully dynamic subgraph obtained , algorithm combines uniform sparsification technique used , , along augmenting path like dual technique maintain approximate solution efficiently
deep applying convolutional neural networks vessels detection considered safe tool evaluation disease perform approximately 12 million patients year 1 cases , manually analyzed actually , clinical practice algorithms could improve automate work neural networks show high efficiency tasks image analysis used analysis facilitate developed algorithm based convolutional neural network neural network u net 2 vessels segmentation detection research used data obtained one city 's augmented improve learning efficiency u net usage provided high quality segmentation combination algorithm ensemble classifiers shows good accuracy task evaluation test data subsequently , approach basis creation analytical system could speed diagnosis diseases greatly facilitate work
leveraging human domain knowledge model empirical reward function reinforcement learning problem traditional reinforcement learning \( rl \) problems depend simulation environment models real world physics problem trains rl agent observing environment paper , present novel approach creating environment modeling reward function based empirical rules extracted human domain knowledge system study using empirical rewards function , build environment train agent first create environment effect setting cabin temperature typically done rl problems creating model system detailed study instead , propose empirical approach model reward function based human domain knowledge document rules usually exercise humans setting temperature try model reward function modeling empirical human domain rules reward function rl unique aspect paper continuous action space problem using deep deterministic policy gradient \( \) method , solve maximizing reward function create policy network predicts optimal temperature given external temperature
trade offs exploiting body morphology control simple bodies model based control complex bodies model free distributed control schemes design robot bodies control purposes implicitly performed engineers , however , methodology set tools largely optimization morphology \( shape , material properties robot bodies , etc \) behind development controllers become even prominent advent , soft bodies carry substantial potential regarding exploitation control sometimes referred morphological computation sense offloading computation needed control body , argue dynamical systems rather computational perspective problem , look simple vs complex bodies , attractive notion soft bodies automatically taking control tasks address another key dimension design space whether model based control used extent feasible develop models different
efficient computation slepian functions arbitrary regions sphere paper , develop new method fast memory efficient computation slepian functions sphere slepian functions , arise solution slepian concentration problem sphere , desirable properties applications measurements available within spatially limited region sphere function required analyzed spatially limited region slepian functions currently easily computed large band limits arbitrary spatial region due high computational large memory storage requirements special case polar cap , region enables decomposition slepian concentration problem smaller consequently efficient computation slepian functions large band limits exploiting efficient computation slepian functions polar cap region sphere , develop formulation , supported fast algorithm , approximate computation slepian functions arbitrary spatial region enable analysis modern datasets support large band limits proposed algorithm , carry accuracy analysis approximation , computational complexity analysis , review memory storage requirements illustrate , numerical experiments , proposed method enables faster computation , smaller storage requirements , allowing sufficiently accurate computation slepian functions
sensing capacity sensor networks class linear observation fixed snr models paper address problem finding sensing cap sensor networks class linear observation models fixed snr regime sensing cap defined maximum number signal dimensions reliably identified per sensor tion context sparsity phenomena key feature determines sensing capacity snr environment effect sparsity number measurements required accurate reconstruction sparse phenomena widely compressed sensing nevertheless development motivated algorithmic perspective paper aim derive bounds information theoretic set thus provide algorithm independent conditions reliable reconstruction sparse signals direction first generalize nd provide lower bounds probability error reconstruction subject arbitrary criteria using lower bounds probability error , derive upper bounds sensing capacity show fixed snr regime sensing capacity goes zero sparsity goes zero means sensors required monitor sparse events derive lower bounds sensing capacity \( achievable \) via deriving upper bounds probability error via adaptation max likelihood detection set given distortion criteria l bounds sensing capacity exhibit similar behavior though snr gap upper lower bounds subsequently , show effect correlation sensing across sensors across sensing modalities sensing capacity various degrees models correlation next main contribution show effect sensing diversity sensing capacity , effect co sensing diversity related effective coverage sensor respect field direction show following results \( \) sensing capacity goes sensing diversity per sensor goes \( b \) random sampling \( coverage \) field sensors better l sampling \( coverage \)
structure image caption generation abstract big challenge computer vision make machine automatically describe content image natural language sentence previous works made great progress task , use global local image feature , may lose important subtle global information image paper , propose model 3 gated model global local image features together task image caption generation model mainly three gated structures \( 1 \) gate global image feature , adaptively decide much global image feature sentence generator \( 2 \) gated recurrent neural network \( rnn \) used sentence generator \( 3 \) gated feedback method rnn employed increase capability fitting specially , global local image features combined together paper , makes full use image information global image feature controlled first gate local image feature selected attention mechanism latter two , relationship image text well explored , improves performance language part well multi modal embedding part experimental results show proposed method outperforms state art image caption generation
learning universal graph neural network embeddings aid transfer learning learning powerful data embeddings become center piece machine learning , especially natural language processing computer vision domains embeddings pretrained huge corpus data unsupervised fashion , sometimes aided transfer learning however currently graph learning domain , embeddings learned existing graph neural networks \( \) task dependent thus cannot shared across different datasets paper , present first powerful theoretically guaranteed graph neural network designed learn task independent graph embeddings , referred deep universal graph embedding \( \) model incorporates novel graph neural network \( universal graph encoder \) leverages rich graph kernels \( multi task graph decoder \) unsupervised learning \( task specific \) adaptive supervised learning learning task independent graph embeddings across diverse datasets , also benefits transfer learning extensive experiments studies , show proposed model consistently outperforms existing state art models graph kernels increased accuracy 3 8 graph classification benchmark datasets
nlocalsat boosting local search solution prediction boolean problem famous np complete problem computer science effective way problem stochastic local search \( sls \) however , method , initialization assigned random manner , impacts effectiveness sls solvers address problem , propose nlocalsat nlocalsat combines sls solution prediction model , sls changing initialization assignments neural network evaluated nlocalsat five sls solvers \( , , , , \) problems random track sat competition 2018 experimental results show solvers nlocalsat achieve 27 improvement original sls solvers
maximum problem parameterized structure color hierarchy graph let g \( v , \) vertex colored arc weighted directed acyclic graph \( \) rooted vertex r , let h color hierarchy graph , defined follows v \( h \) color set c g , arc color c color exists h arc g vertex color c vertex color paper , study maximum problem \( mca \) , takes input g additional constraint h also , aims finding g rooted r , maximum weight , color appears mca problem motivated inference unknown mass experiments however , whereas problem studied roughly ten years , crucial property h necessarily exploited recently paper , investigate mca new light , providing algorithmic results problem , specific focus fixed parameterized tractability \( fpt \) issues , relatively different structural parameters h particular , provide \( 3 \) time algorithm solving mca , number vertices least two h , thereby improving \( 3 c \) algorithm b et al 2008 also prove mca w 2 hard relatively treewidth h , show fpt relatively , v c
primal versus dual ising model represent ising model statistical physics factor graphs primal dual domains 's voltage current laws , show primal factor graph , dependency among variables along cycles , whereas dual factor graph , dependency primal \( resp dual \) domain , dependent variables computed via fundamental cycles \( resp fundamental \) domain , propose importance sampling algorithm estimate partition function primal domain , proposal distribution defined spanning tree , computations done tree contrast , dual domain , computations done spanning tree model , proposal distribution defined tree
neural algorithms neuromorphic hardware architectures represent growing family potential post 's law era platforms largely due event driving processing inspired human brain , computer platforms offer significant energy benefits compared traditional processors unfortunately still remains considerable difficulty successfully programming , deploying neuromorphic systems present framework answer need rather attain knowledge program exploit spiking neural dynamics utilize potential benefits neuromorphic computing , designed provide higher level abstraction hardware independent mechanism linking variety scalable spiking neural algorithms variety sources individual kernels linked together provide sophisticated processing intended suitable wide range neuromorphic applications , including machine learning , scientific computing , brain inspired neural algorithms ultimately , hope community adopts open standardization attempts allowing free exchange easy implementations ever growing list spiking neural algorithms
key management mobile sensor networks wireless sensor networks consist sensor nodes limited computational communication capabilities paper deals mobile sensors divided clusters based physical locations efficient ways key distribution among sensors inter intra cluster communications security entire network considered efficient key management taking consideration network 's power capabilities
fully convolutional multi class multiple instance learning multiple instance learning \( \) reduce need costly annotation tasks semantic segmentation required degree supervision propose novel formulation multi class semantic segmentation learning fully convolutional network setting , seek learn semantic segmentation model weak image level labels model trained end end jointly optimize representation pixel image label assignment fully convolutional training inputs size , need object proposal pre processing , offers loss map selecting latent instances multi class loss exploits supervision given images multiple labels evaluate approach preliminary experiments pascal voc segmentation challenge
analyzing interfaces workflows light field editing increasing number available consumer light field cameras , , , imaging , new form progressively becoming common however , still tools light field editing , interfaces create remain largely given extended dimensionality light field data , clear intuitive interfaces optimal workflows , contrast well studied two dimensional \( 2 \) image manipulation software work , provide detailed description subjects performance preferences number simple editing tasks , form basis complex operations perform detailed state sequence analysis hidden markov chain analysis based sequence tools interaction users employ editing light fields insights aid researchers designers creating new light field editing tools interfaces , thus close gap 4 2 image editing
cluster based kriging approximation algorithms complexity reduction kriging gaussian process regression applied many fields non linear regression model well surrogate model field evolutionary computation however , computational space complexity kriging , cubic quadratic number data points respectively , becomes major bottleneck data available nowadays paper , propose general methodology complexity reduction , called cluster kriging , whole data set smaller clusters multiple kriging models built top addition , four kriging approximation algorithms proposed candidate algorithms within new framework algorithms applied much larger data sets maintaining advantages power kriging proposed algorithms explained detail compared empirically broad set existing state art kriging approximation methods well defined testing framework according empirical study , proposed algorithms consistently outperform existing algorithms moreover , practical suggestions provided using proposed algorithms
key net detection handcrafted learned cnn filters introduce novel approach detection task combines handcrafted learned cnn filters within shallow multi scale architecture handcrafted filters provide anchor structures learned filters , localize , score rank features scale space representation used within network extract different levels design loss function detect robust features exist across range scales maximize score http url model trained data created imagenet evaluated benchmark results show approach outperforms state art detectors terms , matching performance complexity
approximability maximum agreement maximum compatible tree problems aim paper give complete approximability two tree consensus problems particular interest computational biology maximum agreement \( mast \) maximum compatible tree \( mct \) problems take input label set collection trees whose leaf sets labeled label set define size tree number well known mast problem consists finding maximum sized tree embedded input tree , label preserving embeddings variant mct less , allows input trees arbitrarily refined results follows show mct np hard approximate within bound n 1 e rooted trees , n denotes size input tree approximation lower bound already known mast j , consensus algorithms trees strings , thesis , university , furthermore , prove mct two rooted trees within bound 2 l g 1 e n , unless problems np solvable quasi polynomial time result previously established mast three rooted trees j , , l , k , complexity comparing evolutionary trees , discrete applied mathematics \( 1 3 \) \( \) \( note mast two trees solvable polynomial time , j , tree theorems computing maximum agreement , information processing \( 2 \) \( \) 77 82 \) let cmast , resp cmct , denote complement version mast , resp mct cmast , resp cmct , consists finding tree feasible solution mast , resp mct , whose leaf label set smallest subset input labels approximation threshold cmast , resp cmct , rooted trees shown approximation threshold cmast , resp cmct , trees already known cmast cmct within ratio three rooted trees v , f , maximum agreement compatible , c , , u \( \) , combinatorial pattern matching , , , , , 2004 , g , j , approximating complement maximum compatible subset k trees , k , , v v \( \) , international workshop approximation algorithms combinatorial optimization , , , , , , latter results showing cmast hard three rooted trees cmct hard two rooted trees
max c min projection fuzzy morphological memories theory applications face recognition max c min projection fuzzy morphological memories \( max c min \) two layer fuzzy morphological neural networks able implement memory designed storage retrieval finite fuzzy sets vectors paper address main features memories , include absolute storage capacity , fast retrieval stored items , memories , excellent tolerance either noise noise particular attention given called , besides performing floating point operations , exhibit largest noise tolerance among max c min computational experiments reveal 's max c , combined noise strategy , yields fast robust classifier strong potential face recognition
performance analysis dual user mimo systems linear receivers flat rayleigh fading performance linear receivers presence co channel interference rayleigh channels fundamental problem wireless communications performance evaluation systems well known receive arrays antennas close enough experience equal average snrs source contrast , almost analytical results available systems sources receive antennas widely separated , receive antennas experience average snrs source single receive antenna receives different average snr source although extremely difficult problem , progress possible two user scenario paper , derive closed form results probability density function \( \) cumulative distribution function \( \) output signal interference plus noise ratio \( \) signal noise ratio \( snr \) minimum mean squared error \( mmse \) zero forcing \( zf \) receivers independent rayleigh channels arbitrary numbers receive antennas results verified monte carlo simulations approximations high snr analysis also derived results enable system analysis evaluation outage probability , bit error rate \( \) capacity
metric sets trajectories practical mathematically consistent metrics space sets trajectories important scientists field computer vision , machine learning , robotics , general artificial intelligence however , existing notions sets trajectories either mathematically inconsistent limited practical use paper , outline limitations current mathematically consistent metrics , based \( et al 2008 \) heuristic notions used practice , whose main ideas common clear mot measures \( 2008 \) widely used computer vision two steps , propose new intuitive metric sets trajectories address limitations first , explain solution leads metric hard compute modify formulation obtain metric easy compute keeping useful properties previous metric notion first demonstrating following three features metric 1 \) quickly computed , 2 \) incorporates identity optimal way , 3 \) metric mathematical sense
encoding data systems hierarchical temporal memory \( \) inspired machine intelligence technology architecture processes white paper describe encode data sparse distributed representations \( \) use systems explain several existing encoders , available open source project called , discuss requirements creating encoders new types data
image aesthetics assessment using multi channel convolutional neural networks image aesthetics assessment one emerging domains research domain deals classification images categories depending basis users article , focus images high quality low quality image deep convolutional neural networks used classify images instead using raw image input , different saliency maps images also used , input proposed multi channel cnn architecture experiments reported widely used database show improvement assessment performance existing approaches
understanding predicting memorability natural scene images memorability measures easily image , may contribute designing covers , materials , recent works shed light visual features make generic images , object images face however , clear understanding reliable estimation natural scene memorability remain paper , provide attempt answer exactly makes natural scene end , first establish large scale natural scene image memorability \( \) database , containing 2 , natural scene images ground truth memorability scores , mine database investigate low , high level handcrafted features affect memorability natural scene particular , find high level feature scene category rather correlated natural scene memorability also find deep feature effective predicting memorability scores therefore , propose deep neural network based natural scene memorability \( \) predictor , takes advantage scene category finally , experimental results validate effectiveness , state art methods
randomized consensus attractive repulsive links study convergence properties randomized consensus algorithm graph attractive repulsive links time instant , node randomly selected interact random neighbor depending link two nodes given subgraph attractive repulsive links , node update follows standard attractive weighted average repulsive weighted average , respectively repulsive update sign standard consensus update way , consensus formation seen model link faults malicious attacks communication network , impact trust social network various probabilistic convergence divergence conditions established threshold condition strength repulsive action given convergence expectation repulsive weight threshold value , algorithm convergence divergence explicit value threshold derived classes attractive repulsive graphs results show single repulsive link sometimes drastically change behavior consensus algorithm also explicitly show robustness consensus algorithm depends size properties graphs
word embeddings regularization neural machine translation systems regularization neural machine translation still significant problem , especially low resource settings problem , propose word embeddings \( \) new regularization technique system jointly trained predict next word translation \( categorical value \) word embedding \( continuous value \) joint training allows proposed system learn properties represented word embeddings , empirically improving generalization unseen sentences experiments three translation datasets showed consistent improvement strong baseline , ranging 0 91 2 54 bleu points , also marked improvement state art system
semi regular dual graphs paper shows np completeness finding hamiltonian cycles induced subgraphs dual graphs semi regular also shows np hardness new , wide class graphs called augmented square grids work follows prior studies complexity finding hamiltonian cycles regular semi regular grid graphs
nonlinear distortion reduction reliable perturbations data novel method correcting effect nonlinear distortion orthogonal frequency division multiplexing signals proposed method depends adaptively selecting distortion subset data , using tools compressed sensing sparse bayesian recovery estimate distortion central method fact \( \) decoded different levels confidence , depending coupled function magnitude phase distortion carrier , addition respective channel strength moreover , required method , significant improvement terms achievable rate achieved relative previous work
rich club phenomenon internet topology show internet topology autonomous system \( \) level rich club phenomenon rich nodes , small number nodes large numbers links , well connected rich club core tier measured using rich club connectivity node node link distribution obtained core tier without heuristic assumption rich club phenomenon simple qualitative way differentiate power law topologies provides criterion new network models show , compared measured rich club graph networks obtained using \( \) scale free network model , fitness model 3 0 model
symbolic regression random search purpose compare symbolic regression genetic programming \( srgp \) symbolic regression random search \( \) , novel method symbolic regression described methods limit problem space n binary trees , terminals n functions , use dense enumeration full binary trees perform uniform random sampling set equations compare single basic configuration symbolic regression genetic programming symbolic regression random search using 1000 randomly generated problems perform hyperparameter search 50 randomly generated symbolic regression problems randomly generated hyperparameter configurations , examining performance srgp results single configuration experiment , srgp outperformed 0 problems , random search best 26 2 problems , tie 24 8 problems cases tied , genetic programming best 6 experiments \( 99 ci , 60 7 , 2 \) cases tied hyperparameter search , srgp best 44 \( 99 ci , 41 , \) cases average random configuration srgp performs worse
contextual hate speech words within social media social media platforms recently seen increase occurrence hate speech discourse led calls improved detection methods rely annotated data , keywords , classification technique approach provides good coverage , fall short dealing new terms produced online communities act original sources words alternate hate speech meanings code words \( created adopted words \) designed automatic detection often benign meanings regular discourse example , , , instances words alternate meaning used hate speech overlap introduces additional challenges relying keywords collection data specific hate speech , downstream classification work , develop community detection approach finding hate speech communities collecting data members also develop word embedding model learns alternate hate speech meaning words demonstrate code words several annotation experiments , designed determine possible recognize word used hate speech without alternate meaning report inter agreement rate k 0 , k 0 data drawn community keyword approach respectively , supporting hate speech detection contextual task depend fixed list keywords goal advance domain providing high quality hate speech dataset addition learned code words fed existing classification approaches , thus improving accuracy automated detection
state based service description paper propose state transition diagrams service description contrast techniques like example allow model non atomic services sequences transitions especially important distributed system concurrent service cannot give mathematical model object behaviour based concurrent sequential messages give precise semantics service descriptions terms mathematical model
deterministic polynomial association schemes problem finding nontrivial factor polynomial f \( x \) finite field f q many known efficient , randomized , algorithms deterministic complexity problem famous open question even assuming generalized hypothesis \( \) work improve state art focusing prime degree polynomials let n degree \( n 1 \) r smooth , find nontrivial factor f \( x \) deterministic poly \( n r , log q \) time assuming sqrt n \( 2 r \) thus , r \( 1 \) algorithm polynomial time , r n infinitely many prime degrees n algorithm applicable better best known assuming r n methods build algebraic combinatorial framework schemes , \( 2009 \) show scheme n points , implicitly algorithm , structure leading us improved time complexity structure theorem proves existence small intersection numbers association scheme many relations , roughly equal numbers
finding community structure based subgraph similarity community identification long standing challenge modern network science , especially large scale networks containing nodes paper , propose new metric quantify structural similarity subgraphs , based algorithm community identification designed extensive empirical results several real networks disparate fields demonstrated present algorithm provide level reliability , measure modularity , takes much shorter time well known fast algorithm proposed , \( \) propose hybrid algorithm simultaneously enhance modularity save computational time compared algorithm
universal machines introduce notion universal machines \( \) class brain inspired general purpose computing machines based systems memory , whereby processing storing information occur physical location analytically prove memory properties universal computing power \( turing complete \) , intrinsic parallelism , functional , information overhead , namely , collective states support exponential data compression directly memory also demonstrate computational power turing machine , namely , solve polynomial \( np \) complete problems polynomial time however , information overhead , needs amount memory cells \( \) grows problem size example , provide polynomial time solution subset sum problem simple hardware implementation even though results prove np p within turing paradigm , practical realization would represent paradigm shift present architectures , us closer brain like neural computation
learning multiple categories deep convolution networks deep convolution networks proved successful big datasets 1000 classes imagenet results show error rate increases size dataset increases experiments presented may explain networks effective solving big recognition problems big task made multiple smaller tasks , results show ability deep convolution networks decompose complex task number smaller tasks learn simultaneously results show performance solving big task single network close average performance solving smaller tasks separate network experiments also show advantage using task specific category labels combination class labels
lstm based goal recognition latent space approaches goal recognition progressively relaxed requirements amount domain knowledge available observations , yielding accurate efficient algorithms capable recognizing goals however , recognize goals raw data , recent approaches require either human domain knowledge , samples behavior account almost actions observed infer possible goals clearly strong requirement real world applications goal recognition , develop approach leverages advances recurrent neural networks perform goal recognition classification task , using encoded plan traces training empirically evaluate approach state art goal recognition image based domains , discuss conditions approach superior previous ones
discrete rotation point cloud recognition despite recent active research processing point clouds deep networks , attention sensitivity networks paper , propose deep learning architecture achieves discrete mathbf \( 2 \) mathbf \( 3 \) rotation point cloud recognition specifically , rotation input point cloud elements rotation group similar feature vectors generated approach easily reduced invariance eliminating permutation operations maximum average method directly applied existing point cloud based networks , resulting significant improvements performance inputs show state art results classification tasks various datasets mathbf \( 2 \) mathbf \( 3 \) addition , analyze necessary conditions applying approach based networks source codes https url
secure variant hill cipher hill cipher classical symmetric encryption algorithm know plaintext attack although vulnerability rendered practice , still serves important role linear algebra paper , variant hill cipher introduced makes hill cipher secure efficiency proposed scheme includes core cryptographic protocol introduced
lightweight robust representation economic scales satellite imagery satellite imagery long attractive data source provides information human areas super resolution satellite images rapidly becoming available , little study focused extract meaningful information human patterns economic scales data present read , new approach obtaining essential spatial representation given high resolution satellite imagery based deep neural networks method combines transfer learning embedded statistics efficiently learn critical spatial characteristics arbitrary size areas represent fixed length vector minimal information loss even small set labels , read distinguish subtle differences urban areas infer degree extensive evaluation demonstrates model outperforms state art predicting economic scales , population density \( r 2 0 \) , shows high potential use developing countries level economic scales known
prediction optimal drug schedules controlling effects targeted drug perturbations cellular activities difficult predict using intuition alone complex behaviors cellular networks approach overcoming problem develop mathematical models predicting drug effects approach co development computational methods extracting insights useful therapy selection optimizing drug scheduling , present evaluate strategy identifying drug schedules minimize amount drug needed achieve important cellular activity process , \( \) targeting currently evaluated diverse clinical trials without benefit control engineering perspective using nonlinear ordinary differential equation \( \) model accounts influences among protein \( , , \) methods guaranteed find locally optimal control strategies , find optimal drug schedules \( open loop controllers \) six classes approach designing multi therapy drug schedules affect different cell signaling networks interest
near optimal mechanism impartial selection examine strategy proof elections select winner amongst set agents , winning impartial selection problem introduced independently et al fisher showed permutation mechanism impartial 1 2 optimal , , selects agent gains , expectation , least half number votes popular agent furthermore , showed mechanism 7 12 optimal agents cannot election show better guarantee possible , provided popular agent receives least large enough , constant , number votes specifically , prove , epsilon 0 , constant n epsilon \( independent number n voters \) , maximum number votes popular agent least n epsilon permutation mechanism \( frac 3 4 epsilon \) optimal result tight r n furthermore , main result , prove near optimal impartial mechanisms exist particular , impartial mechanism \( 1 epsilon \) optimal , epsilon 0 , provided maximum number votes popular agent least constant epsilon
flat2layout flat representation estimating layout general room types paper proposes new approach , flat2layout , estimating general indoor room layout single view rgb image whereas existing methods produce layout topologies captured box shaped room proposed flat representation encodes layout information row vectors training target deep model dynamic programming based employed decode estimated flat output deep model final room layout flat2layout achieves state art performance existing room layout benchmark paper also constructs benchmark validating performance general layout topologies , flat2layout achieves good performance general room types flat2layout applicable scenario layout estimation would impact applications scene modeling , robotics , augmented reality
better training infinite restricted machines infinite restricted machine \( irbm \) extension classic enjoys good property automatically deciding size hidden layer according specific training data sufficient training , irbm achieve competitive performance classic however , convergence learning irbm slow , due fact irbm sensitive ordering hidden units , learned filters change left hidden unit right break dependency neighboring hidden units speed convergence training , novel training strategy proposed key idea proposed training strategy randomly hidden units gradient descent step potentially , mixing infinitely many different hidden units achieved learning method , similar effect preventing model fitting dropout original irbm also modified capable discriminative training evaluate impact method convergence speed learning model generalization ability , several experiments performed mnist datasets experimental results indicate proposed training strategy greatly learning enhance generalization ability
performance optimization mobile edge computing via deep reinforcement learning improve quality computation experience mobile devices , mobile edge computing \( \) emerging promising paradigm providing computing capabilities within radio access networks close proximity nevertheless , design computation offloading policies system remains challenging specifically , whether execute computation task local mobile device task cloud execution adapt environmental dynamics manner paper , consider representative mobile user ultra dense network , one multiple base stations \( bss \) selected computation offloading problem solving optimal computation offloading policy modelled markov decision process , objective minimize long term cost offloading decision made based channel mobile user bss , energy queue state well task queue state break curse high dimensionality state space , propose deep q network based strategic computation offloading algorithm learn optimal policy without priori knowledge dynamic statistics numerical experiments provided paper show proposed algorithm achieves significant improvement average cost compared baseline policies
exact reconstruction euclidean distance geometry problem using low rank matrix completion euclidean distance geometry problem arises wide variety applications , determining molecular computational localization sensor networks distance information incomplete , problem formulated norm minimization problem paper , minimization program matrix completion problem low rank r matrix respect suitable basis well known restricted property satisfied scenario instead , dual basis approach introduced theoretically analyze reconstruction problem matrix satisfies certain coherence conditions parameter , main result shows underlying configuration n points recovered high probability \( log 2 \( n \) \) uniformly random samples computationally , simple fast algorithms designed solve euclidean distance geometry problem numerical tests different three dimensional data protein validate effectiveness efficiency proposed algorithms
kleene algebra observations kleene algebra tests \( kat \) algebraic framework reasoning control flow sequential programs kat reason concurrent programs straightforward , native kat conjunction expected concurrency lead equation paper , propose kleene algebra observations \( \) , variant kat , alternative foundation extending kat concurrent setting free model , establish decision procedure w r theory
verifying cryptographic security implementations c using automated model extraction thesis presents automated method verifying security properties protocol implementations written c language assume successful run protocol follows path c code , fact typical security protocols linear structure perform symbolic execution path extract model expressed process calculus similar one used tool symbolic execution uses novel algorithm allows symbolic variables represent potentially unknown length model incoming protocol messages r n r n extracted models use pointer addressed memory , may still contain low level details concerning message formats next step replace message expressions abstract projection operators properties operators , projection operation inverse operation , typically satisfied respect inputs correct types therefore model ensure type safety constraints satisfied resulting model verified obtain computational security result directly , , obtain computational security result computational soundness theorem r n r n order security properties c programs prove correctness approach describe embedding c programs process calculus , c protocol participants executed part larger system , described process calculus , represents environment attacker develop security preserving simulation relation preserved embedding , show step model transformation simulates previous step , thus proving overall soundness approach currently consider trace properties r n r n method achieves high automation require user input beyond necessary specify properties cryptographic primitives desired security goals evaluated method several protocol implementations , lines code biggest case study 1000 line implementation independently written without verification mind found several fixed authors , able verify fixed code without modifications
sequential information guided sensing study value information sequential compressed sensing characterizing performance sequential information guided sensing practical scenarios information inaccurate particular , assume signal distribution parameterized gaussian gaussian mixtures estimated mean covariance matrices , measure noisy linear projection using one sparse vectors , e , observing one signal time establish set performance bounds bias variance signal estimator via posterior mean , capturing conditional entropy \( also related size uncertainty \) , additional power required due inaccurate information reach desired precision based , study estimate covariance based direct samples covariance sketching numerical examples also demonstrate superior performance greedy sensing algorithms compared random non adaptive counterparts
empirically evaluating adaptable spoken dialogue system recent technological advances made possible build real time , interactive spoken dialogue systems wide variety applications however , users respect limitations systems , performance typically although users differ respect knowledge system limitations , although different dialogue strategies make system limitations users , current systems try improve performance adapting dialogue behavior individual users paper presents empirical evaluation toot , adaptable spoken dialogue system train schedules web conduct experiment 20 users carry 4 tasks adaptable non adaptable versions toot , resulting corpus 80 values wide range evaluation measures extracted corpus results show adaptable toot generally outperforms non adaptable toot , utility adaptation depends toot 's initial dialogue strategies
shifting baseline single modality performance visual navigation qa demonstrate surprising strength unimodal baselines multimodal domains , make concrete recommendations best practices future research existing work often random majority class baselines , argue unimodal approaches better capture dataset biases therefore provide important comparison assessing performance multimodal techniques present unimodal three recent datasets visual navigation qa , absolute gain performance published baselines
survey constrained combinatorial testing combinatorial testing \( ct \) potentially powerful testing technique , whereas failure ability might dramatically reduced fails handle constraints efficient manner ensure applicability ct presence constrained problem domains , large diverse efforts towards techniques applications constrained combinatorial testing paper , provide comprehensive survey representations , influences , techniques constraints ct , covering papers published 2018 survey various constraint handling techniques , also reviews less well studied , yet potentially important , constraint identification techniques since real world programs usually constrained , survey interest researchers practitioners looking use study constrained combinatorial testing techniques
real time dense stereo matching fpga accelerated embedded devices many applications low power real time robotics , stereo cameras sensors choice depth perception typically active counterparts biggest , however , directly sense depth maps instead , must estimated data intensive processes therefore , appropriate algorithm selection plays important role achieving desired performance characteristics motivated applications space mobile robotics , implement evaluate field programmable gate arrays \( fpga \) accelerated adaptation efficient large scale stereo \( \) algorithm despite offering one best tradeoffs efficiency accuracy , shown run 1 5 3 fps high end cpu system preserves properties original algorithm , plane priors , achieve frame rate fps consuming 4 w power unlike previous fpga based designs , take advantage components cpu fpga system strategy necessary complex computationally diverse algorithms low power , real time systems
evaluating learning scenarios categorization case strong baselines learning received great deal attention recently several approaches proposed however , evaluations involve diverse set scenarios making meaningful comparison difficult work provides systematic categorization scenarios evaluates within consistent framework including strong baselines state art methods results provide understanding relative difficulty scenarios simple baselines \( , l2 regularization , naive strategies \) surprisingly achieve similar performance current mainstream methods conclude several suggestions creating harder evaluation scenarios future research directions code available https url
robust federated learning noisy communication federated learning communication efficient training process local training edge devices updated local model central server nevertheless , impractical achieve perfect acquisition local models wireless communication due noise , also serious effects federated learning tackle challenge , propose robust design federated learning alleviate effects noise paper considering noise two aforementioned steps , first formulate training problem parallel optimization node expectation based model worst case model due non convexity problem , regularization loss function approximation method proposed make tractable regarding worst case model , develop feasible training scheme utilizes sampling based successive convex approximation algorithm tackle unavailable maxima minima noise condition non convex issue objective function furthermore , convergence rates new designs analyzed theoretical point view finally , improvement prediction accuracy reduction loss function demonstrated via simulations proposed designs
learning write notes electronic health records significant amount time free form textual notes electronic health records \( \) systems much documentation work seen burden , reducing time patients ai assisted note writing , propose new language modeling task predicting content notes conditioned past data patient 's medical record , including patient demographics , , , past notes train generative models using public , de identified mimic iii dataset compare generated notes dataset multiple measures find much content predicted , many common templates found notes learned discuss models useful supporting note writing features error detection auto complete
word translation without parallel data state art methods learning cross lingual word embeddings bilingual dictionaries parallel corpora recent studies showed need parallel data supervision character level information methods showed encouraging results , par supervised counterparts limited pairs languages sharing common alphabet work , show build bilingual dictionary two languages without using parallel corpora , monolingual word embedding spaces unsupervised way without using character information , model even outperforms existing supervised methods cross lingual tasks language pairs experiments demonstrate method works well also language pairs , like english english chinese finally describe experiments english low resource language pair , exists limited amount parallel data , show potential impact method fully unsupervised machine translation code , embeddings dictionaries publicly available
see see experimental evidence much relevant information may due google web search personalisation influence web search personalisation professional knowledge work area investigate public self assess dependency google web search engine , whether aware potential impact algorithmic biases ability retrieve relevant information , much relevant information may actually due web search personalisation find majority participants experimental study neither aware potential problem strategy mitigate risk missing relevant information performing online significantly , provide empirical evidence 20 relevant information may due web search personalisation work significant implications web research public , provided training potential algorithmic biases may affect judgments decision making , well clear risk missing relevant information
semeval 2016 task 6 detecting stance tweets using character word level cnns paper describes approach detecting stance tweets task \( semeval 2016 task 6 \) utilized recent advances short text categorization using deep learning create word level character level models choice word level character level models particular case informed validation performance final system combination classifiers using word level character level models also employed novel data augmentation techniques expand training dataset , thus making system robust system achieved average precision , recall f1 scores 0 67 , 0 0 respectively
2 3 energy efficient lattice cryptography processor quantum secure internet things modern public key protocols , elliptic curve cryptography \( \) , rendered algorithm 1 large scale quantum computers built therefore , working quantum algorithms , lattice based cryptography emerged prime candidate 1 however , high computational complexity algorithms makes challenging implement lattice based protocols resource constrained iot devices , need secure data present future adversaries address challenge , present lattice cryptography processor parameters , enables two orders magnitude energy gate reduction system area architectural optimizations demonstrates multiple lattice based protocols proposed round 1 post quantum standardization process
findings third workshop neural generation translation document describes findings third workshop neural generation translation , held empirical methods natural language processing \( 2019 \) first , research trends papers presented second , describe results two shared tasks 1 \) efficient neural machine translation \( nmt \) participants creating nmt systems accurate efficient , 2 \) document level generation translation \( \) participants developing systems generate summaries structured data , potentially text another language
mixture maximum entropy markov models present mixture maximum entropy markov model \( \) , class directed graphical models extending allows tractable long range dependencies nodes restricting conditional distribution node mixture distributions given show efficiently compute exact marginal posterior node distributions , regardless range dependencies enables us model non sequential correlations present within text documents , well documents , web pages apply named entity recognition task web page classification task , model shows significant improvement basic , competitive long range sequence models use approximate inference
analysis stochastic service guarantees communication networks basic calculus basic calculus presented stochastic service guarantee analysis communication networks central calculus two definitions , maximum \( virtual \) centric \( b c \) stochastic arrival curve stochastic service curve , respectively generalize arrival curve service curve deterministic network calculus framework b c stochastic arrival curve stochastic service curve , various basic results derived \( min , \) algebra general case analysis , crucial development stochastic network calculus results include \( \) superposition flows , \( ii \) concatenation servers , \( iii \) output characterization , \( \) per flow service aggregation , \( v \) stochastic delay guarantees addition , perform independent case analysis , stochastic strict server defined , uses ideal service process process characterize server concept stochastic strict server allows us improve basic results \( \) \( v \) independent case , also provides convenient way find stochastic service curve serve moreover , approach introduced find b c stochastic arrival curve flow stochastic service curve server
beam management millimeter wave beamspace mu mimo systems millimeter wave \( mmwave \) communication attracted increasing attention promising technology 5g networks one key architectural features mmwave use massive antenna arrays transmitter receiver therefore , employing directional beamforming \( \) , mmwave base stations \( \) mmwave users \( \) capable supporting multi beam simultaneous transmissions however , researches considered single beam , means make full potential mmwave context , order improve performance short range indoor mmwave networks multiple , investigate challenges potential solutions downlink multi user multi beam transmission , described high dimensional \( e , beamspace \) multi user multiple input multiple output \( mu mimo \) technique , including multi user training , simultaneous users' grouping , multi user power allocation furthermore , present theoretical numerical results demonstrate beamspace mu mimo compared single beam transmission largely improve rate performance mmwave systems
model based pricing machine learning data data analytics using machine learning \( ml \) become ubiquitous science , business intelligence , many domains lot work focuses reducing training cost , inference runtime storage cost ml models , little work studies reduce cost data acquisition , potentially leads loss revenue efficiency r n paper , propose model based pricing \( \) framework , instead pricing data , directly prices ml model instances first formally describe desired properties framework , focus avoiding next , show concrete realization framework via noise injection approach , provably satisfies desired formal properties based proposed framework , provide algorithmic solutions prices models different market scenarios \( maximize revenue \) finally , conduct extensive experiments , validate framework provide high revenue , high buyer , also operate low runtime cost
sound answer powerful resolution mechanism logic programs captures least fixed point semantics plain many applications , interested set answers goal , require aggregation answers several works studied efficient techniques , lattice based answer mode directed , various forms aggregation r n much attention efficient implementation different approaches , soundness considered paper shows different implementations indeed fail produce least fixed points programs , provide formal framework existing approaches establish soundness criterion programs approach sound r n article consideration
smash co designing software compression hardware accelerated indexing efficient sparse matrix operations important workloads , machine learning graph analytics applications , heavily involve sparse linear algebra operations operations use sparse matrix compression effective means avoid storing performing unnecessary computation zero elements however , compression techniques like compressed sparse row \( \) widely used today introduce significant instruction overhead expensive pointer operations discover positions non zero elements paper , identify discovery positions \( e , indexing \) non zero elements key bottleneck sparse matrix based workloads , greatly reduces benefits compression propose smash , hardware software cooperative mechanism enables highly efficient indexing storage sparse matrices key idea smash explicitly enable hardware recognize exploit sparsity data end , devise novel software encoding based hierarchy encoding used efficiently sparse matrix , regardless extent structure sparsity time , encoding directly interpreted hardware design lightweight hardware unit , management unit \( \) , scans hierarchy perform highly efficient indexing sparse matrices smash expressive rich communicate , enables use accelerating sparse matrix computation demonstrate benefits smash four use cases include sparse matrix kernels graph analytics applications evaluations show smash provides average performance improvements 38 sparse matrix vector multiplication 44 sparse matrix matrix multiplication , state art implementation , wide variety matrices different characteristics smash incurs modest hardware area overhead 0 order cpu core
explicit learning curves transduction application clustering compression algorithms inductive learning based inferring general rule finite data set using label new data transduction one attempts solve problem using labeled training set label set unlabeled points , given learner prior learning although transduction seems easier task induction , many provably useful algorithms transduction moreover , precise relation induction transduction yet determined main theoretical developments related transduction presented years one 's basic results rather tight error bound transductive classification based exact computation tail tight , bound given implicitly via computational routine first contribution explicit characterization slightly extended bayesian version 's transductive bound characterization obtained using concentration inequalities tail sums random variables obtained sampling without replacement derive error bounds compression schemes \( transductive \) support vector machines transduction algorithms based clustering main observation used deriving new error bounds algorithms unlabeled test points , transductive setting known advance , used order construct useful data dependent prior distributions hypothesis space
communication efficient client aided secure two party protocols application secure multi party computation \( mpc \) allows set parties compute function jointly keeping inputs private compared mpc based circuits , recent research results show mpc based secret sharing \( ss \) works high speed moreover , ss based mpc easily achieve higher throughput ss based mpc , however , need many communication rounds computing concrete protocols like check , less comparison , etc property suited large latency environments like internet \( \) paper , construct semi secure communication efficient two party protocols core technique triple extension , new tool treating multi , also show use efficiently mainly focus reducing number communication rounds , protocols also succeed reducing number communication bits \( cases \) example , propose less comparison protocol \( practical parameters \) three communication rounds moreover , number communication bits also 38 4 fewer result , total online execution time 1 shorter previous work adopting settings although computation costs protocols expensive previous work , confirm via experiments disadvantage small effects whole online performance typical environments
approximations rayleigh block fading channels paper presents approximations state art converse achievability bounds , single antenna , rayleigh block fading channels approximations calculated efficiently shown accurate snr values small 0 db , channel uses , channel 's coherence interval smaller two demonstrated derived approximations recover normal approximation reliability function channel
tiramisu polyhedral compiler expressing fast code paper introduces tiramisu , polyhedral framework designed generate high performance code multiple platforms including , gpus , distributed machines tiramisu introduces scheduling language novel extensions explicitly manage complexities arise targeting systems framework designed areas image processing , , linear algebra deep learning tiramisu two main features relies flexible representation based polyhedral model rich scheduling language allowing fine grained control optimizations tiramisu uses four level intermediate representation allows full separation algorithms , loop transformations , data , communication separation targeting multiple hardware architectures algorithm evaluate tiramisu writing set image processing , deep learning , linear algebra benchmarks compare state art hand tuned libraries show tiramisu matches outperforms existing libraries different hardware architectures , including cpus , gpus , distributed machines
effects loss functions target representations adversarial robustness understanding evaluating robustness neural networks adversarial settings subject growing interest attacks proposed literature usually work models trained minimize cross entropy loss output softmax probabilities work , present interesting experimental results suggest importance considering loss functions target representations , specifically , \( 1 \) training mean squared error \( 2 \) representing targets codewords generated random evaluate robustness neural networks implement proposed modifications using existing attacks , showing increase accuracy attacks 98 7 decrease targeted attack success rates 99 8 model demonstrates robustness compared conventional counterpart even attacks tailored modifications furthermore , find parameters modified model significantly smaller bounds , important measure correlated model 's sensitivity adversarial perturbations
characterizing deep learning model compression embedded inference recent advances deep neural networks \( dnns \) make attractive embedded systems however , take long time dnns make inference resource constrained computing devices model compression techniques address computation issue deep inference embedded devices technique highly attractive , rely specialized hardware , computation offloading often infeasible due privacy concerns high latency however , remains unclear model compression techniques perform across wide range dnns design efficient embedded deep learning solutions , need understand behaviors work quantitative approach characterize model compression techniques representative embedded deep learning architecture , perform extensive experiments considering 11 influential neural network architectures image classification natural language processing domains experimentally show two mainstream compression techniques , data quantization pruning , perform network architectures implications compression techniques model storage size , inference time , energy consumption performance metrics demonstrate opportunities achieve fast deep inference embedded systems , one must carefully choose compression settings results provide insights apply model compression techniques designing efficient embedded deep learning systems
entropy constrained maximizing mutual information quantization paper , investigate quantization output binary input discrete memoryless channel maximizing mutual information input quantized output entropy constrained quantized output polynomial time algorithm introduced find truly global optimal quantizer results hold binary input channels arbitrary number quantized output finally , extend results binary input continuous output channels show sufficient condition single threshold quantizer optimal quantizer theoretical results numerical results provided justify techniques
political polarization spread misinformation important challenge process tracking detecting misinformation understand political gap people called fake news possible factor responsible gap opinion polarization , may general public classify content want fake work , study relationship political polarization content reported twitter users related fake news investigate polarization may create distinct misinformation actually perform study based two datasets collected twitter first dataset contains tweets us general , compute degree polarization user towards party second dataset , collect tweets urls co fake news related keywords , , well reactions towards tweets urls analyze relationship polarization perceived misinformation , whether users information fake results show increase polarization users urls associated fake news keywords , compared information labeled fake news discuss impact findings challenges tracking fake news ongoing misinformation
structure political media coverage revealed patterns given extremely large pool events available , media outlets need focus subset issues aspects outlets often systematic bias selection process , different outlets different versions reality however , absence objective measures empirical evidence , direction extent remains widely r n paper propose framework based patterns quantifying characterizing degree media outlets exhibit systematic bias apply framework massive dataset news articles spanning six years 's , reveal systematic pattern indeed 's behavior moreover , show pattern successfully exploited unsupervised prediction setting , determine new select broadcast encoding bias patterns low rank space provide analysis structure political media coverage reveals latent media bias space surprisingly well political type linguistic analysis differences across latent dimensions , showing different types media outlets different even reporting events example , outlets mapped mainstream conservative side latent space focus presidential characterized
hierarchical cooperative multi agent reinforcement learning skill discovery human players professional team achieve high level coordination dynamically choosing complementary skills executing primitive actions perform skills step toward creating intelligent agents capability fully cooperative multi agent settings , propose two level hierarchical multi agent reinforcement learning \( \) algorithm unsupervised skill discovery agents learn useful distinct skills low level via independent q learning , learn select complementary latent skill variables high level via centralized multi agent training extrinsic team reward set low level skills intrinsic reward solely latent skill variables trajectory low level skill , without need hand crafted rewards skill scalable decentralized execution , agent independently chooses latent skill variables primitive actions based local observations overall method enables use general cooperative algorithms training high level policies single agent rl training low level skills experiments stochastic high dimensional team game show useful skills cooperative team play interpretability learned skills show promise proposed method achieving human ai cooperation team games
towards spectrum graph convolutional networks present ongoing work understanding limitations graph convolutional networks \( \) well work generalizations graph convolutions representing complex node attribute dependencies based analysis help corresponding computation graphs , propose generalization existing aggregation operations \( \) determined structural properties local neighborhood graphs \( b \) restricted weighted show proposed approach strictly expressive requiring modest increase number parameters computations also show proposed generalization identical standard convolutional layers applied regular grid graphs
importance sampling based approximate optimal planning control paper , propose sampling based planning optimal control method nonlinear systems non differentiable constraints motivated developing scalable planning algorithms , consider optimal motion plan feedback controller approximated weighted sum given bases given approximate optimal control formulation , main contribution introduce importance sampling , specifically , model reference adaptive search algorithm , iteratively compute optimal weight parameters , e , weights corresponding optimal policy function approximation given chosen bases key idea perform search iteratively estimating distribution converges 's delta infinitely global optimal weights , using direct policy search , incorporated trajectory based verification ensure , class nonlinear systems , obtained policy optimal robust bounded correctness efficiency methods demonstrated numerical experiments including linear systems nonlinear cost function motion planning dubins car
oriented word error alignment speech recognition error analysis speech translation propose variation commonly used word error rate \( \) metric speech recognition evaluation incorporates alignment , absence time boundary information computing alignment words reference hypothesis , adjacent errors converted word boundaries alignment performed alignment information used correct word alignment labels error region demonstrate oriented word error rate \( power \) yields similar scores added advantages better word alignments ability capture one many alignments corresponding errors speech recognition hypotheses improved alignments allow us better trace impact error types speech recognition downstream tasks speech translation
linear sketching mathbb f 2 initiate systematic study linear sketching mathbb f 2 given boolean function f 0 , 1 n 0 , 1 randomized mathbb f 2 sketch distribution mathcal times n matrices elements mathbb f 2 mathcal computing f \( x \) high probability study connection mathbb f 2 sketching two player one way communication game corresponding xor function results show communication game mathbb f 2 sketching uniform distribution \( dependence error \) implications result include 1 \) composition theorem mathbb f 2 sketching complexity recursive majority function , 2 \) tight relationship mathbb f 2 sketching complexity fourier sparsity , 3 \) lower bounds certain subclass symmetric functions also fully resolve conjecture regarding one way communication complexity linear threshold functions designing mathbb f 2 sketch optimal size r n furthermore , show \( non uniform \) streaming algorithms process random updates mathbb f 2 constructed mathbb f 2 sketches uniform distribution minor loss contrast previous work , \( \) show result linear sketches adversarial setting result n't require stream length exponential n holds streams length tilde \( n \) constructed uniformly random updates finally , state conjecture asks whether optimal one way communication protocols xor functions constructed mathbb f 2 sketches small loss
recent advances mobile grid cloud computing cloud computing systems extensively used solve large complex problems science engineering fields systems include powerful computing resources connected high speed networks due recent advances mobile computing networking technologies , become feasible integrate various mobile devices , robots , aerial vehicles , sensors , smart phones , grid cloud computing systems integration enables design development next generation applications sharing resources mobile environments introduces several challenges due dynamic network paper discusses applications , research challenges involved design development mobile grid cloud computing systems , recent advances field
ensuring rapid mixing low bias asynchronous gibbs sampling gibbs sampling markov chain monte carlo technique commonly used estimating marginal distributions speed gibbs sampling , recently interest executing empirical results suggest many models efficiently sampled , traditional markov chain analysis apply asynchronous case , thus asynchronous gibbs sampling poorly understood paper , derive better understanding two main challenges asynchronous gibbs bias mixing time show experimentally theoretical results match practical outcomes
improved stereo matching constant highway networks confidence learning present improved three step pipeline stereo matching problem introduce multiple stage propose new highway network architecture computing matching cost possible disparity , based multilevel weighted residual , trained hybrid loss supports multilevel comparison image patches novel post processing step introduced , employs second deep convolutional neural network pooling global information multiple network outputs image disparity map , conventional winner takes strategy , confidence prediction confidence score achieved training network new technique call loss lastly , learned confidence employed order better detect outliers refinement step proposed pipeline achieves state art accuracy largest competitive stereo benchmarks , learned confidence shown outperform existing alternatives
using neural generative models release synthetic twitter corpora reduced users present method generating synthetic versions twitter data using neural generative models goal protecting individuals source data identification attacks still data research value specifically , generate corpora maintain user level word distributions augmenting neural language models user specific components compare approach two standard text data protection methods iterative translation evaluate three methods measures risk utility define risk following models identification , define utility based two general word distribution measures two common text analysis research tasks find neural models able significantly lower risk previous methods little cost utility also demonstrate neural models allow data providers actively control risk utility trade model tuning parameters work presents promising results new tool addressing problem privacy free text sharing social media data way privacy responsible
explaining hyperspectral imaging based disease identification 3d cnn saliency maps goal develop accurate model disease identification using hyperspectral data soil disease affects yield hyperspectral images captured different range nm developed 3d convolutional neural network model disease identification model classification accuracy 95 class f1 score 0 87 infer trained model using saliency map sensitive pixel locations enable classification sensitivity individual classification also determined using saliency map visualization identify sensitive nm using saliency map visualization since sensitive near infrared region \( 1000 nm \) spectrum , also commonly used spectrum region determining health , predictions using model
weight simple method overcome catastrophic forgetting enable learning recent years , deep neural networks found success human level cognitive skills , yet suffer several major obstacles one significant limitation learn new tasks without forgetting previously learned tasks , known catastrophic forgetting research , propose simple method overcome catastrophic forgetting enable learning neural networks draw principles physics develop concept weight weight operates modification update rule gradient descent optimization method converges rate comparable stochastic gradient descent algorithm operate multiple task domains performs current methods offering improvements computation memory efficiency
domain specific language geometric relations rigid bodies targeted robotic applications paper presents dsl geometric relations rigid bodies relative position , orientation , pose , linear velocity , angular velocity , dsl formal model recently proposed semantics standardization geometric relations rigid bodies , referred semantics explicitly states coordinate invariant properties operations , , importantly , choices made coordinate representations geometric relations results set concrete suggestions , allowing write fully software interfaces , including automatic semantic correctness geometric operations rigid body coordinate representations r n dsl implemented two different ways external dsl internal dsl besides defining grammar operations , dsl also implements constraints model , object constraint language language used , model , constraint modelled r n paper discusses implemented dsl tools developed top dsl particular , checking semantic constraints providing semantic meaningful errors editing proposed
learning variable ordering heuristics solving constraint satisfaction problems backtracking search algorithms often used solve constraint satisfaction problem \( csp \) efficiency backtracking search depends greatly variable ordering heuristics currently , commonly used heuristics hand crafted based expert knowledge paper , propose deep reinforcement learning based approach automatically discover new variable ordering heuristics better adapted given class csp instances show directly optimizing search cost hard bootstrapping , propose optimize expected cost reaching leaf node search tree capture complex relations among variables constraints , design representation scheme based graph neural network process csp instances different sizes constraint experimental results random csp instances show learned policies outperform classical hand crafted heuristics terms minimizing search tree size , effectively generalize instances larger used training
2017 davis challenge video object segmentation present 2017 davis challenge video object segmentation , public dataset , benchmark , competition specifically designed task video object segmentation following successful , pascal voc , established research fields scene classification semantic segmentation , davis challenge comprises dataset , evaluation methodology , public competition dedicated workshop co located 2017 davis challenge follows recent publication davis \( densely annotated video segmentation \) , development several novel state art video object segmentation techniques paper describe scope benchmark , highlight main characteristics dataset , define evaluation metrics competition , present detailed analysis results participants challenge
bootstrapping models confidence intervals policy evaluation autonomous agent , executing poor policy may costly even agents , desirable determine confidence interval lower bounds performance given policy without executing said policy current methods exact high confidence policy evaluation use importance sampling require substantial amount data achieve tight lower bound existing model based methods address problem discrete state spaces since exact bounds intractable many domains trade strict guarantees safety data efficient approximate bounds context , propose two bootstrapping policy evaluation methods use learned mdp transition models order estimate lower confidence bounds policy performance limited data continuous discrete state spaces since direct use model may introduce bias , derive theoretical upper bound model bias model transition function estimated trajectories bound understanding conditions model based methods high bias finally , empirically evaluate proposed methods analyze settings different bootstrapping policy confidence interval methods succeed fail
partial interference alignment k user mimo interference channels paper , consider partial interference alignment interference detection \( \) design k user quasi static mimo interference channels discrete inputs transmitter antennas l independent data streams desired receiver n receive antennas focus case k 1 transmitters aligned every receiver result , residual interference receiver cannot aligned receiver detects residual interference based map however , window interference profile receiver interference detection \( id \) paper , propose low complexity partial interference alignment scheme dynamically select user set create favorable interference profile id receiver first derive average symbol error rate \( \) taking account non residual interference due discrete using graph theory , devise low complexity user set selection algorithm scheme , minimizes asymptotically tight bound average end end performance moreover , substantially simplify interference detection receiver using semi definite relaxation \( \) techniques shown performance proposed scheme significant gain compared various conventional baseline solutions
learning invariant representations local transformations learning invariant representations important problem machine learning pattern recognition paper , present novel framework transformation invariant feature learning incorporating linear transformations feature learning algorithms example , present transformation invariant restricted machine represents data weights transformations , achieves invariance feature representation via probabilistic max pooling addition , show transformation invariant feature learning framework also extended unsupervised learning methods , autoencoders sparse coding evaluate method several image classification benchmark datasets , mnist variations , cifar 10 , stl 10 , show competitive superior classification performance compared state art furthermore , method achieves state art performance phone classification tasks dataset , demonstrates wide applicability proposed algorithms domains
dimension reduction based joint activity detection channel estimation algorithm massive access free random access promising protocol support massive access beyond fifth generation \( \) cellular internet things \( iot \) traffic specifically , coherence interval , base station \( bs \) performs joint activity detection channel estimation \( \) data transmission due deployment large scale antennas array existence huge number iot devices , usually high computational complexity needs long pilot sequences solve challenges , paper proposes dimension reduction method , projects original device state matrix low dimensional space exploiting sparse low rank structure , develop optimized design framework coupled full column rank constraint reduce size search space however , resulting problem non convex highly intractable , conventional convex relaxation approaches end , propose logarithmic smoothing method non smoothed objective function transform interested matrix positive semidefinite matrix , followed giving riemannian trust region algorithm solve problem complex field simulation results show proposed algorithm efficient large scale problem requires shorter pilot sequences state art algorithms exploit sparsity device state matrix
clinical notes improved document classification models using neural language models clinical notes contain extensive record patient 's health status , status presence conditions however , detail within structured data electronic health systems , extraction patient conditions free clinical text , critical task supports downstream applications decision support secondary use records previous work systems high performing require hand engineering , often rules recent work pretrained language models enabled advances representing text variety tasks therefore explore several architectures modeling typing rely solely bert representations clinical note , removing need manual engineering find architectures competitive outperform existing state art methods two tasks
differential privacy enabled federated learning sensitive health data leveraging real world health data machine learning tasks requires addressing many practical challenges , distributed data , privacy concerns creating centralized database person specific sensitive data , resource constraints transferring integrating data multiple sites , risk single point failure paper , introduce federated learning framework learn global model distributed health data held locally different sites framework offers two levels privacy protection first , move share raw data across sites centralized server model training process second , uses differential privacy mechanism protect model potential privacy attacks perform comprehensive evaluation approach two healthcare applications , using real world electronic health data 1 million patients demonstrate feasibility effectiveness federated learning framework offering level privacy maintaining utility global model
sampling galerkin reconstruction reproducing kernel spaces paper , consider sampling reproducing kernel subspace l p introduce pre reconstruction operator associated sampling scheme propose galerkin reconstruction general space setting show proposed galerkin method provides quasi optimal approximation , corresponding galerkin equations could solved iterative approximation projection algorithm also present detailed analysis numerical simulations galerkin method signals finite rate innovation
rbf wavelet like series transforms high dimensional problems paper developed systematic strategy establishing rbf wavelet analysis , includes continuous discrete rbf wavelet transforms respectively terms singular fundamental solutions general solutions differential operators particular , rbf transforms presented high dimensional data processing also found kernel functions diffusion operator feasible construct stable like rbf transforms presented time space rbf transforms based non singular solution fundamental solution time dependent differential operators present methodology extended analysis known , gaussian pre wavelet kernel
criteria finite difference bases normal difference paper , give decision criteria normal difference polynomial univariate difference polynomial ring f finite difference bases algorithm compute finite difference bases criteria satisfied novelty criteria lies fact complicated properties difference polynomial reduced elementary properties univariate polynomials z x
new efficient k n oblivious transfer protocol paper presents new efficient protocol k n oblivious transfer generalization 's 1 2 oblivious transfer protocol based key exchange proposed protocol , parties involved generate keys use oblivious transfer
image similarity using deep cnn curriculum learning image similarity involves similar looking images given reference image solution called , deep siamese network trained pairs positive negative images using novel online pair mining strategy inspired curriculum learning also created multi scale cnn , final image embedding joint representation top well lower layer embedding 's go show multi scale siamese network better capturing fine grained image similarities traditional cnn 's
feature control intrinsic motivation hierarchical reinforcement learning problem sparse rewards one hardest challenges contemporary reinforcement learning hierarchical reinforcement learning \( \) problem using set temporally extended actions , options , handcrafted specific tasks , though , introduce generic class broad applicability visual domain underlying approach \( common work using auxiliary tasks \) hypothesis ability control aspects environment inherently useful skill incorporate end end hierarchical reinforcement learning system test two variants algorithm number games suite highlight advantage approach one hardest games 's ability handle sparse rewards key agent learns several times faster current state art agent game , reaching similar level performance update 22 11 17 found standard agent simple shaped reward , e extrinsic reward feature control intrinsic reward , comparable performance agent light new experiments performed , advantage approach attributed ability learn useful features intrinsic rewards rather ability explore reuse skills hierarchical components led us new conclusion result
complexity local max cut almost completely consider problem finding local optimum max cut flip neighborhood , exactly one node changes partition \( , \) showed completeness problem graphs unbounded degree side , \( , 1995 \) showed cubic graphs every flip local search takes \( n 2 \) steps , n number nodes due huge gap degree three unbounded degree , , , \( , 2008 \) smallest local max cut problem flip neighborhood graphs maximum degree complete paper , prove computation local optimum graphs maximum degree five complete thus , solve problem posed et al almost completely showing either four five \( unless p \) side , also prove graphs degree \( log n \) every flip local search polynomial smoothed complexity roughly speaking , instance , edge weights \( gaussian \) random noise variance sigma 2 , every flip local search time polynomial n sigma 1 , probability 1 n omega \( 1 \) results together , may conclude although local max cut likely hard graphs bounded degree , solved polynomial time slightly instances high probability
emerging technologies research challenges 5g wireless networks take long term evolution \( lte \) cellular , increasing interest technologies define next generation \( 5g \) standard article identifies several emerging technologies change define future generations standards technologies already making way standards lte , others still development additionally , look research problems new technologies pose
learning relate captions bounding boxes work , propose novel approach predicts relationships various entities image weakly supervised manner relying image captions object bounding box annotations source supervision proposed approach uses top attention mechanism align entities captions objects image , leverage syntactic structure captions align relations use alignments train relation classification network , thereby obtaining grounded captions dense relationships demonstrate effectiveness model visual dataset achieving recall 50 15 recall 100 25 relationships present image also show model successfully predicts relations present corresponding captions
bit malicious deep short url based e detection existence spam urls online social media \( \) become massive e counter long complex urls character limit imposed various \( like twitter \) , concept url gained lot traction url take input long url output short url page \( long url \) return popularity time , url become prime target attackers giving advantage malicious content bitly , leading service among services exploited heavily carry attacks , work home scams , content propagation , etc imposes additional performance pressure bitly url able detect take timely action content study , analyzed dataset , short urls marked bitly 2013 results reveal bitly using claimed spam detection services effectively also show bitly account goes despite recurrent activity bitly page identification links , observed approach weak controlling overall propagation spam also identified short url based features coupled two domain specific features classify bitly url malicious benign achieved accuracy 86 41 feature set identified generalized url services well best knowledge , first large scale study highlight issues implementation bitly 's spam detection policies proposing suitable
cell detection star convex automatic detection segmentation cells microscopy images important many biological applications recent successful learning based approaches include per pixel cell segmentation subsequent pixel grouping , localization bounding boxes subsequent shape refinement situations crowded cells , prone segmentation errors , merging cells valid cell instances due poor approximation bounding boxes overcome issues , propose localize cell via star convex , much better shape representation compared bounding boxes thus need shape refinement end , train convolutional neural network predicts every pixel cell instance position demonstrate approach two synthetic datasets one challenging dataset diverse microscopy images
perfect privacy maximal correlation problem private data studied information theoretic perspective considering pair correlated random variables \( x , \) , denotes observed data x denotes private latent variables , following problem addressed maximum information revealed , information x \? assuming markov kernel maps revealed information u , shown maximum mutual information u , e , \( u \) , obtained solution standard linear program , x u required independent , called textit perfect privacy solution shown greater equal textit non private information x carried maximal information perfect privacy shown solution linear program also utility measured reduction mean square error , mathbb e \( u \) 2 , probability error , u jointly gaussian \( x , \) , shown perfect privacy possible kernel applied whereas perfect privacy achieved mapping x , private latent variables also observed encoder next , measuring utility privacy \( u \) \( x u \) , respectively , slope optimal utility privacy trade curve studied \( x u \) 0 finally , similar independent analysis , alternative characterization maximal correlation two random variables provided
robust occlusion aware pose estimation objects adaptive hands many manipulation tasks , placement within hand manipulation , require object 's pose relative robot hand task difficult hand significantly object especially hard adaptive hands , easy detect 's configuration addition , rgb approaches face issues texture less objects hand object look similar paper presents depth based framework , aims robust pose estimation short response times approach detects adaptive hand 's state via efficient parallel search given highest overlap hand 's model point cloud hand 's point cloud robust global registration performed generate object pose hypotheses , clustered false hypotheses via physical reasoning remaining quality evaluated given agreement observed data extensive evaluation synthetic real data demonstrates accuracy computational efficiency framework applied challenging , highly scenarios different object types study identifies framework 's components help performance work also provides dataset hand object pose estimation code dataset available https github com hand object pose
pos tagging necessary even helpful neural dependency parsing pre deep learning era , part speech tags considered indispensable feature engineering dependency parsing due important role data purely lexical features , quite works focus joint tagging parsing models avoid error propagation contrast , recent studies suggest pos tagging becomes much less important even useless neural parsing , especially using character based word representations yet still full systematic investigation interesting issue , empirically answer , design four typical multi task learning frameworks \( e , share , share tight , stack discrete , stack hidden \) , joint tagging parsing based state art considering much pos tags parse trees , also investigate utilization large scale heterogeneous pos tag data conduct experiments english chinese datasets , results clearly show pos tagging \( homogeneous heterogeneous \) still significantly improve parsing performance using stack hidden joint framework conduct detailed analysis gain insights linguistic aspect
connectionist theory refinement searching space network topologies algorithm learns set examples ideally able exploit available resources \( \) computing power \( b \) domain specific knowledge improve ability generalize connectionist theory refinement systems , use background knowledge select neural network 's topology initial weights , proven effective exploiting domain specific knowledge however , exploit available computing power occurs lack ability refine topology neural networks produce , thereby limiting generalization , especially given domain theories present algorithm uses \( \) domain specific knowledge help create initial population knowledge based neural networks \( b \) genetic operators \( specifically designed knowledge based networks \) search better network topologies experiments three real world domains indicate new algorithm able significantly increase generalization compared standard connectionist theory refinement system , well previous algorithm growing knowledge based networks
distributed storage codes repair transfer interior points storage bandwidth tradeoff regenerating codes class recently developed codes distributed storage , like solomon codes , permit data recovery subset nodes within node network however , regenerating codes possess addition , ability repair failed node connecting arbitrary subset nodes shown case functional repair , tradeoff amount data stored per node bandwidth required repair failed node special case functional repair exact repair replacement node required store data identical failed node exact repair interest greatly system implementation first result paper explicit , exact repair code point storage bandwidth tradeoff corresponding minimum possible repair bandwidth , case code particularly simple graphical description , interestingly ability carry exact repair without need perform arithmetic operations term ability code perform repair transfer data repair transfer second result paper shows interior points storage bandwidth tradeoff cannot achieved exact repair , thus existence separate tradeoff exact repair specifically , identify set scenarios term node pooling , show necessity satisfy scenarios system
analysis low density parity check codes error floor regime paper develop method introduced 1 , 2 , 3 analyze quantitatively performance low density parity check \( ldpc \) codes decoded iteratively called error floor regime discuss statistical properties numerical scheme focusing detailed analysis comparison two regular ldpc codes 's \( , 64 , 20 \) \( , , 16 \) codes regime moderate values signal noise ratio compare results evaluations standard monte carlo frame error rate
bi level cooperative driving strategy allowing lane changes paper studies cooperative driving connected automated vehicles \( \) conflict areas \( e g , non intersections regions \) due safety concerns , existing studies lane change since may cause coordination appropriately performed however , many traffic scenarios \( e g , work \) , vehicles must change lanes solve problem , potential collision two kinds thus establish bi level planning problem right way vehicles critical conflict considered upper level , right way vehicles lane changes resolved lower level solutions upper level problem represented tree space , near optimal solution combining monte carlo tree search \( \) heuristic rules within short planning time proposed strategy suitable shortest delay objective also objectives \( e g , energy saving passenger \) numerical examples show proposed strategy leads good traffic performance real time
coverage analysis millimeter wave networks impact directional antenna arrays millimeter wave \( mm wave \) communications considered promising technology 5g networks exploiting beamforming gains large scale antenna arrays combat increased path loss mm wave one defining features however , previous works mm wave network analysis usually adopted antenna patterns tractability , lead significant deviation performance actual antenna patterns paper , using tools stochastic geometry , carry comprehensive investigation impact directional antenna arrays mm wave networks first present general tractable framework coverage analysis arbitrary distributions interference power arbitrary antenna patterns applied mm wave ad cellular networks , two sophisticated antenna patterns desirable accuracy analytical tractability proposed approximate actual antenna pattern compared previous works , proposed approximate antenna patterns help obtain insights role directional antenna arrays mm wave networks particular , shown coverage probabilities types networks increase non decreasing concave function antenna array size analytical results verified effective reliable simulations , numerical results also show large scale antenna arrays required satisfactory coverage mm wave networks
rich feature accurate object detection semantic segmentation object detection performance , measured canonical pascal voc dataset , last years best performing methods complex ensemble systems typically combine multiple low level image features high level context paper , propose simple scalable detection algorithm improves mean average precision \( map \) 30 relative previous best result voc 2012 achieving map 3 approach combines two key insights \( 1 \) one apply high capacity convolutional neural networks \( cnns \) bottom region proposals order localize segment objects \( 2 \) labeled training data , supervised pre training auxiliary task , followed domain specific fine tuning , yields significant performance boost since combine region proposals cnns , call method r cnn regions cnn features also compare r cnn , recently proposed sliding window detector based similar cnn architecture find r cnn outperforms large margin 200 class detection dataset source code complete system available http url
zero shot task adaptation meta mapping deep learning systems flexibly reuse knowledge \? toward goal , propose new class challenges , class architectures solve challenges meta mappings , involve systematically task behaviors adapt new tasks zero shot key achieving challenges representing task performed way task representation therefore draw functional programming recent work meta learning propose class meta mapping \( \) approaches represent data points tasks shared latent space , learn infer transformations space approaches applied type machine learning task , including supervised learning reinforcement learning demonstrate utility perspective zero shot behavior adapt new tasks
hierarchical clustering hyperspectral images using rank two nonnegative matrix factorization paper , design fast hierarchical clustering algorithm high resolution hyperspectral images \( \) core algorithm , new rank two nonnegative matrix factorization \( \) algorithm used split clusters , motivated convex geometry concepts method single cluster containing pixels , step , performs following 1 \) selects cluster way error next step minimized 2 \) selected cluster two disjoint clusters using rank two way clusters well balanced stable proposed method also used extraction algorithm presence pure pixels effectiveness approach illustrated several synthetic real world shown outperform standard clustering techniques k means , k means , standard
explicit lower bounds outage probability integer forcing channels performance integer forcing communication compound multiple input channel investigated upper bound resulting outage probability function gap capacity derived previously , assuming random precoding matrix drawn ensemble applied prior transmission present work simple explicit lower bound worst case outage probability derived case system two transmit antennas two receive antennas , leveraging properties ensemble derived lower bound also extended random space time precoding , may serve useful benchmark assessing relative various algebraic space time precoding schemes show lower bound may adapted case 1 times n system application , derive closed form bounds symmetric rate capacity rayleigh fading multiple access channel terminals equipped single antenna lastly , demonstrate integer forcing coupled distributed space time coding able approach bounds
addressing data sparsity issue neural amr parsing neural attention models achieved great success different nlp tasks ever , promise amr parsing task due data sparsity issue paper , de sequence sequence model amr parsing present different ways tackle data sparsity problem show methods achieve significant improvement baseline neural tion model results also state art systems use extra linguistic resources
review p2p video streaming main objective article provide overview p2p based video demand live streaming services article introduction media streaming simplified architecture various solutions offering video streaming context widespread usage internet discussed followed short introduction p2p networks applications broad discussion various p2p streaming schemes p2p streaming applications main focus chapter finally , security issues solutions p2p video streaming discussed briefly
ranking function synthesis linear lasso programs scope work constraint based synthesis termination arguments restricted class programs called linear lasso programs termination argument consists ranking function well set supporting invariants r n extend existing methods several ways first , use 's theorem instead lemma allows us consider linear lasso programs additionally contain strict inequalities existing methods restricted non strict inequalities r n second , consider several kinds ranking functions affine linear , piecewise lexicographic ranking functions moreover , present novel kind ranking function called ranking function fixed number phases phase , affine linear ranking function abstraction synthesis specific ranking functions , introduce notion ranking function template enables us handle ranking functions unified way r n method relies non linear algebraic constraint solving known scale poorly large problems mitigation formalize assessment difficulty constraints present argument easier kind general non linear constraints r n prove method complete termination argument form specified given ranking function template fixed number affine linear supporting invariants , method find termination argument r n knowledge , approach propose powerful technique synthesis based discovery termination arguments linear lasso programs encompasses enhances several methods proposed thus far
driver drowsiness estimation eeg signals using online weighted adaptation regularization regression owarr one big challenge transition brain computer interfaces \( \) settings real life applications availability high performance robust learning algorithms effectively handle individual differences , e , algorithms applied new subject zero little subject specific calibration data transfer learning domain adaptation extensively used purpose however , previous works focused classification problems paper considers important regression problem bci , namely , online driver drowsiness estimation eeg signals integrating fuzzy sets domain adaptation , propose novel online weighted adaptation regularization regression \( owarr \) algorithm reduce amount subject specific calibration data , also source domain selection \( \) approach save half computational cost owarr using simulated driving dataset 15 subjects , show owarr owarr achieve significantly smaller estimation errors several approaches also provide comprehensive analyses robustness owarr owarr
defending deep learning architectures adversarial samples dynamics supervised denoising autoencoder adversarial attacks deep learning models demonstrated human , decreasing model performance considerably attempts provide invariance attacks adversarial samples send samples classifier similar paper proposes novel effective strategy allows adversarial samples onto underlying manifold \( unknown \) target class distribution specifically , given manifold adversarial example , algorithm \( \) guided supervised denoising autoencoder network \( \) allows drive adversarial samples towards high density regions data generating distribution , adversarial example transformed back manifold onto data manifold learning model trained perform well robustly experiments various benchmark datasets show novel method exhibits high robustness attacks outperforms state art defense algorithms
inferring medical work reports clinical trials know particular medical treatment actually works \? ideally one would available evidence relevant clinical trials unfortunately , results primarily natural language scientific articles , substantial burden trying make sense paper , present new task corpus making unstructured evidence actionable task inferring reported findings full text article describing randomized controlled \( \) respect given intervention , , outcome interest , e g , inferring article provides evidence supporting use reduce risk , compared r n present new corpus task 10 , 000 coupled full text articles describing results using suite models ranging heuristic \( rule based \) approaches attentive neural architectures demonstrate difficulty task , believe largely , technical input texts facilitate work important , challenging problem make corpus , documentation , website , code baselines evaluation available http url
moga searching beyond evolution foundation neural network applications mobile end latest , neural architecture search claimed network design unfortunately , today mobile methods mainly focus cpu instead gpu , latter , however , much practice faster speed , lower overhead less interference bearing target hardware mind , propose first mobile gpu aware \( moga \) neural architecture search order precisely tailored real world applications , objective devise mobile network lies achieving better performance maximizing utilization bounded resources higher capability time consumption alleviate weighted evolution techniques moreover , encourage increasing number parameters higher representational power fewer gpu days , obtain series models outperform similar latency constraints , e , moga achieves 75 9 top 1 accuracy imagenet , moga b 75 5 costs 0 5 ms mobile gpu moga c best gpu awareness reaching 75 3 cpu faster gpu models test code made available https url
modification index allowing comparisons across different scientific fields aim paper propose simple modification original measure , relative index , value 0 \( bottom \) 1 \( top \) , expressing distance top given field normalization different scientific disciplines compared
mining interesting attributed subgraphs community detection graphs , data clustering , local pattern mining three fields data mining machine learning recent years , attributed subgraph mining emerging new powerful data mining task intersection areas given graph set attributes vertex , attributed subgraph mining aims find subgraphs \( subset \) attribute values values sense research task three fields , principled integration graph attribute data poses two challenges definition pattern language intuitive efficient search strategies , formalization interestingness patterns propose integrated solution challenges proposed pattern language improves upon prior work highly flexible intuitive show effective principled algorithm patterns language proposed approach quantifying interestingness patterns language rooted information theory , able account prior knowledge data prior work typically interestingness based subgraph attributes separately , combining trade instead , proposal trade implicitly principled , parameter free manner extensive empirical results confirm proposed pattern syntax intuitive , interestingness measure well actual subjective interestingness
gated dilated networks nodule classification ct scans different types convolutional neural networks \( cnns \) applied detect computed \( ct \) scans however , size nodule diverse range 3 30 high variation nodule sizes makes classifying difficult challenging task study , propose novel cnn architecture called gated dilated \( gd \) networks classify benign unlike previous studies , gd network uses multiple dilated convolutions instead max capture scale variations moreover , gd network context aware sub network input features features suitable dilated convolution evaluated proposed network 1 , 000 ct scans dataset proposed network outperforms baseline models including conventional cnns , resnet , densenet , auc 0 95 compared baseline models , gd network improves classification accuracies range sized furthermore , observe relationship size nodule attention signal generated context aware sub network , new network architecture
internal models homotopy type theory show various models homotopy type theory essentially global character cannot described internal language model constructed get around problem extending internal language modal operator expressing properties global elements setting show construct \( \) notion sets model , starting assumption interval tiny property interval sets indeed leads completely internal development models homotopy type theory within call type theory
intelligent human robot interaction public spaces eu project , developed social robot designed interact naturally flexibly users public spaces shopping present latest version robot system developed project system encompasses audio visual sensing , social signal processing , conversational interaction , perspective taking , geometric reasoning , motion planning successfully combines components framework using robot operating system \( \) deployed shopping interacting customers paper , describe system components , interplay , resulting robot scenarios provided shopping
contextual hourglass networks segmentation density estimation hourglass networks u net v net popular neural architectures medical image segmentation counting problems typical instances hourglass networks contain connections layers connections improve performance due effects vanishing gradient problem ability model combine feature maps earlier later layers propose method combining feature maps layers also feature maps layers different spatial dimensions instance , method enables integration bottleneck feature map reconstruction layers proposed approach applicable hourglass architecture evaluated contextual hourglass networks image segmentation object counting problems medical domain achieve competitive results outperforming popular hourglass networks 17 points
enhancing segmentation precision semantic edge aware loss nowadays deep neural networks achieve impressive performances semantic segmentation tasks , usually trained optimizing pixel wise losses cross entropy result , predictions networks usually accurately capture object boundaries exhibit inside objects paper , propose novel approach improve structure predicted segmentation masks introduce novel semantic edge detection network , allows match predicted ground truth segmentation masks semantic edge aware strategy \( \) combined backbone deep network end end training framework experimental validation pascal voc 2012 cityscapes datasets , show proposed approach enhances structure predicted segmentation masks enforcing sharp boundaries avoiding inside objects , improving segmentation performance addition , semantic edge aware loss integrated popular segmentation network without requiring additional annotation negligible computational load , compared standard pixel wise cross entropy loss
introduction person identification generative adversarial networks person identification basic subject field computer vision traditional methods several limitations solving problems person like occlusion , pose variation feature variation complex background , deep learning paradigm opens new ways person identification research becomes hot field generative adversarial nets \( gans \) past years attracted attention solving problems paper reviews gan based methods person identification focuses related papers different gan based frameworks discusses advantages disadvantages finally , proposes direction future research , especially prospect person identification methods based gans
cross modal pre training large scale weak supervised image text data paper , introduce new vision language pre trained model image text joint embedding model transformer based model , takes different modalities input models relationship model pre trained four tasks simultaneously language modeling \( \) , object classification \( \) , region feature regression \( \) , image text matching \( \) enhance pre training quality , collected large scale weak supervised image text \( \) dataset web first pre train model dataset , conduct second stage pre training conceptual captions captions experiments show multi stage pre training strategy outperforms single stage pre training also fine evaluate pre trained model image retrieval text retrieval tasks , achieve new state art results datasets
efficient search based inference noisy belief networks inference algorithms arbitrary belief networks impractical large , complex belief networks inference algorithms specialized classes belief networks shown efficient paper , present search based algorithm approximate inference arbitrary , noisy belief networks , generalizing earlier work search based inference two level , noisy belief networks initial experimental results appear promising
effective aesthetics prediction multi level spatially features propose effective deep learning approach aesthetics quality assessment relies new type pre trained features , apply data set , currently largest aesthetics database previous approaches miss information original images , due taking small , scaling training , propose first method efficiently supports full resolution images input , trained variable input sizes allows us significantly improve upon state art , increasing rank order correlation coefficient \( \) ground truth mean opinion scores \( \) existing best reported 0 0 achieve performance , extract multi level spatially \( \) features convolutional blocks pre trained v2 network , train custom shallow convolutional neural network \( cnn \) architecture new features
power efficient sensing communication scheme joint source channel network coding using compressive sensing propose joint source channel network coding scheme , based compressive sensing principles , wireless networks channels \( may include multiple access broadcast \) , sources temporal spatial dependencies goal provide reconstruction sources within allowed distortion level receiver perform joint source channel coding source randomly source values lower dimensional space consider sources satisfy restricted eigenvalue \( \) condition well general sources randomness network allows mapping lower dimensional spaces approach relies using analog random linear network coding receiver uses compressive sensing decoders reconstruct sources key insight fact , compressive sensing analog network coding preserve source characteristics required compressive sensing decoding
scaling multiple source entity resolution using efficient transfer learning consider serious , previously challenge facing almost approaches scaling entity resolution \( er \) multiple data sources cost labeling training data supervised learning similarity scores pair sources exists rich literature describing almost aspects pairwise er , new challenge arising due unprecedented ability acquire store data online sources , features driven er search , uniqueness noisy missing data characteristics source show real world synthetic data state art techniques , reality heterogeneous sources means number labeled training data must scale number sources , maintain constant precision recall address challenge new transfer learning algorithm requires far less training data \( equivalently , achieves superior accuracy data \) trained using fast convex optimization intuition behind approach adaptively share structure learned one scoring problem scoring problems sharing data source common demonstrate theoretically motivated approach incurs runtime cost maintain constant precision recall cost labeling increasing linearly number sources
towards multimodal understanding passenger vehicle interactions autonomous vehicles intent slot recognition utilizing audio visual data understanding passenger spoken interactions car 's vision \( inside outside vehicle \) important building blocks towards developing contextual systems natural interactions autonomous vehicles \( av \) study , continued exploring \( automated vehicle multimodal cabin experience \) , cabin agent responsible handling certain multimodal passenger vehicle interactions give instructions , agent parse commands properly considering available three modalities \( language text , audio , video \) appropriate functionality av system collected multimodal cabin dataset multi turn using scheme via realistic game previous , various rnn based models detect utterance level \( set destination , change route , go faster , go , , , , drop , open , others \) along intent keywords relevant slots \( location , position direction , object , , time guidance , person \) associated action performed av scenarios recent work , propose discuss benefits multimodal understanding cabin utterances incorporating language input \( text speech embeddings \) together non acoustic visual input inside outside vehicle \( e , passenger cabin video stream , referred objects outside vehicle road view camera stream \) experimental results outperformed text baselines , achieved improved performances utterance level intent detection slot
towards data collection tor network collector developed tor project 's metrics team purpose data public tor network applications developed tor project report requirements prototype replacement collector service , evaluates frameworks libraries available reduce code costs collector service
driver less vehicles security vs privacy social perspective moment autonomous cars biggest technology robotics research community great technological advances past years full autonomous car still far reality article existing system discusses possibility computer vision enabled driving superior lidar based system detailed overview privacy might arise autonomous driving discussed detail technical well perspective proved evidence arguments efficient accurate estimation efficient solution constraint satisfaction problem addressed case autonomous cars correlated preserving privacy user difficult trade since important aspects taken account fact one cannot compromise safety issues car makes inevitable run serious privacy concerns might social political effects
ensemble maximum entropy classification linear regression author age prediction evolution internet created unstructured data web , significant part textual task author profiling seeks find demographics people solely linguistic content based features text ability describe authors clearly applications fields security , well instead age classification problem , also frame age regression one , use ensemble chain method incorporates power classification regression learn authors exact age
exploiting domain knowledge via weight sharing application text categorization fundamental advantage neural models nlp ability learn representations scratch however , practice often means ignoring existing external linguistic resources , e g , domain specific unified medical language system \( \) propose general , novel method exploiting resources via weight sharing prior work weight sharing neural networks considered largely means model compression contrast , treat weight sharing flexible mechanism incorporating prior knowledge neural models show approach consistently yields improved performance classification tasks compared baseline strategies exploit weight sharing
lossy graph model delay reduction generalized decodable network coding problem minimizing decoding delay generalized decodable network coding \( g idnc \) perfect lossy feedback scenarios formulated maximum weight clique problem g idnc graph letter , introduce new lossy g idnc graph \( idnc \) model minimize decoding delay lossy feedback scenarios whereas g idnc graph represents packets , idnc graph represents also uncertain packet combinations , arising lossy feedback events , expected decoding delay among certain packets lower expected sending packets separately compare decoding delay performance idnc g idnc graphs extensive simulations numerical results show new idnc graph formulation outperforms g idnc graph formulation lossy feedback situations achieves significant improvement decoding delay especially feedback erasure probability higher packet erasure probability
concurrent games paper , study notion strategies concurrent games intuitively , admissible strategy one player plays well , strategy dominates , e , \( almost \) super set adversarial strategies prove admissible strategies always exist concurrent games , precisely , objectives players omega regular , show perform assume admissible synthesis , e , compute admissible strategies \( almost \) hypothesis players play admissible
key concepts ethics artificial intelligence growing influence decision making autonomous systems artificial intelligence lives force us consider values embedded systems ethics implemented systems \? study , solution seen framework form practical implementation model ethics ai take first steps main concepts used field needs identified keyword based systematic mapping study \( sms \) keywords used ai ethics conducted help identifying , comparing main concepts used current ai ethics discourse papers retrieved sms discovered occurring keywords academic papers suggest focus finding keywords first step providing direction future research ai ethics field
monocular ground plane normal estimation geometric consistency focus estimating 3d orientation ground plane single image formulate problem inter multi task prediction problem jointly optimizing pixel wise surface normal direction , ground plane segmentation , depth estimates specifically , proposed model , , first estimates depth surface normal two separate streams , two ground plane computed leverage geometric correlation depth normal , propose add consistency loss top computed ground plane addition , ground segmentation stream used ground regions selectively back parameter updates ground regions image method achieves top ranked performance ground plane normal estimation horizon line detection real world datasets kitti , improving performance previous art 17 7 relatively
analyzing cloud optical properties using cameras clouds play significant role received 's surface important study various cloud properties , impacts total 's surface one important optical properties cloud cloud optical thickness \( \) defined amount light pass clouds values generally obtained satellite images however , satellite images low temporal spatial suitable study applications energy generation forecasting therefore , ground based cameras getting popular fields paper , analyze cloud optical thickness value , ground based cameras , provide future research directions
inference attributes based mobile phone usage patterns social network topology mobile phone usage provides information , used better understand structure population paper , focus population mobile phone users first present study mobile phone usage according gender age groups able detect significant differences phone usage among different population study performance different machine learning \( ml \) methods predict features \( namely , age gender \) unlabeled users leveraging individual patterns , well structure communication graph show specific implementation diffusion model , graph structure , significantly better performance node based standard ml methods provide details methodology together analysis robustness results changes model parameters furthermore , carefully examining topological relations training nodes \( seed nodes \) rest nodes network , find topological metrics direct influence performance algorithm
robust piecewise constant smoothing revisited robust estimator , namely , piecewise constant smoothing revisited paper starting generalized formulation , propose numerical scheme framework solving via series weighted average filtering \( e g , box filtering , gaussian filtering , bilateral filtering , guided filtering \) equivalence local histogram based filters \( median filter mode filter \) , proposed framework enables fast approximation histogram filters via number box filtering gaussian filtering addition , high quality piecewise constant smoothing achieved via number bilateral filtering guided filtering integrated proposed framework experiments depth map denoising show effectiveness framework
fpga accelerated design deep learning pedestrian detection self driving vehicles rise self driving vehicles comes risk accidents need higher safety , protection pedestrian detection following scenarios , thus car object avoid pedestrian , case road intersections , important car currently , special topology deep neural networks called fused deep neural network \( f dnn \) considered state art pedestrian detection , lowest miss rate , yet slow therefore , acceleration needed speed performance project proposes two contributions address problem , using deep neural network used object detection , called single shot multi box detector \( \) first contribution training tuning hyperparameters improve pedestrian detection second contribution new fpga design accelerating model 10 platform final system used self driving vehicles real time preliminary results improved shows 3 higher miss rate f dnn pedestrian detection benchmark , 4x performance improvement acceleration design expected achieve additional performance improvement significantly minimal difference accuracy
sample efficient ensemble reinforcement learning ensemble learning prevalent method employed machine learning relative success ensemble methods attributed ability tackle wide range instances complex problems require different low level approaches however , ensemble methods relatively less popular reinforcement learning owing high sample complexity computational expense involved present new training evaluation framework model free algorithms use ensembles policies obtained single training instance policies diverse nature learned directed perturbation model parameters regular intervals show learning diverse set policies required good ensemble extreme diversity prove detrimental overall performance evaluate approach challenging discrete continuous control tasks also discuss various strategies framework substantially sample efficient , computationally seen outperform state art \( \) scores mujoco video results found https com channel
providing diversity k nearest neighbor query results given point query q multi dimensional space , k nearest neighbor \( \) queries return k closest answers according given distance metric database respect q scenario , possible majority answers may similar , especially data clusters variety applications , homogeneous result sets may add value user paper , consider problem providing diversity results queries , , produce closest result set answer sufficiently different rest first propose user definition diversity , present algorithm , called , producing diverse result set per definition detailed experimental evaluation real synthetic data , show produce diverse result sets reading small fraction tuples database , imposes additional overhead evaluation traditional queries , thereby providing interface diversity distance
non orthogonal multiple access schemes wireless powered communication networks characterize time power allocations optimize sum throughput wireless powered communication network \( \) non orthogonal multiple access \( noma \) setup , energy rich \( er \) source wireless energy several devices , use simultaneously transmit data access point \( ap \) uplink prior works , paper consider generic scenario , er ap , e , two separate entities study two noma decoding schemes , namely low complexity decoding \( \) successive interference cancellation decoding \( \) scheme , formulate sum throughput optimization problem finite horizon despite complexity optimization problem , attributed non convexity , series geometric programs hand , establish convexity optimization problem propose algorithm find optimal solution numerical results demonstrate importance using successive interference cancellation noma , show energy distributed function system parameters
neural population models present method using neural networks model evolutionary population dynamics , draw recent deep learning advancements trained neural networks interactions conduct experiments demonstrate models evolutionary game theory capable describing behavior neural population systems
hierarchical statistical static timing analysis statistical static timing analysis deals increasing variations processes reduce worst case timing analysis correlation delays circuit components , timing model generation hierarchical timing analysis face challenges static timing analysis paper , novel method generate timing models circuits considering variations proposed resulting timing models accurate input output delays 80 smaller original circuits additionally , accurate hierarchical timing analysis method design level using pre characterized timing models proposed method incorporates correlation modules replacing independent random variables improve timing accuracy experimental results show correlation modules strongly affects delay distribution hierarchical design proposed method good accuracy compared monte carlo simulation , faster three orders magnitude
adaptive graph convolutional neural networks graph convolutional neural networks \( graph cnns \) generalizations classical cnns handle graph data molecular data , point could social networks current filters graph cnns built fixed shared graph structure however , real data , graph structures size connectivity paper proposes generalized flexible graph cnn taking data arbitrary graph structure input way task driven adaptive graph learned graph data training efficiently learn graph , distance metric learning proposed extensive experiments nine graph structured datasets demonstrated superior performance improvement convergence speed predictive accuracy
reconfigurable wireless networks driven advent sophisticated ubiquitous applications , ever growing need information , wireless networks without evolving complex dynamic systems user demands progressively , application requirements continue expand range diversity future wireless networks , therefore , must equipped ability handle numerous , challenging , requirements network reconfiguration , considered prominent network paradigm , play key role leveraging future network performance considerably current user experiences paper presents comprehensive overview reconfigurable wireless networks depth analysis reconfiguration layers protocol stack networks possess ability adapt hardware software components architectures , thus enabling flexible delivery broad services , well robust operation highly dynamic conditions paper offers framework research reconfigurable wireless networks provide reader holistic view concepts , methods , strategies reconfigurable wireless networks focus given reconfigurable systems relatively new emerging research areas cognitive radio networks , cross layer reconfiguration , software defined networks addition , modern networks intelligent capable self organization thus , paper discusses concept network intelligence means enable reconfiguration highly complex dynamic networks key processes network intelligence , reasoning , learning , context awareness , presented illustrate methods take reconfiguration new level finally , paper supported several examples case studies showing tremendous impact reconfiguration wireless networks
efficient parallel solver linear systems present first parallel algorithm solving systems linear equations symmetric , dominant \( \) matrices runs polylogarithmic time nearly linear work algorithm construction sparse approximate inverse chain input matrix sequence sparse matrices whose product approximates inverse whereas fast algorithms solving systems equations matrices exploit low spanning trees , algorithm requires spectral graph
multi scale cnn crf framework environmental image segmentation order researchers identify environmental \( \) effectively , multi scale cnn crf \( \) framework em image segmentation proposed paper two parts framework first novel pixel level segmentation approach , using newly introduced convolutional neural network \( cnn \) , namely mu net , dense conditional random field \( crf \) post processing second vgg 16 based patch level segmentation method novel buffer strategy , improves segmentation quality details experiment , compared state art methods em images , proposed method reduces memory requirement , improves overall evaluation indexes \( , jaccard , recall , accuracy \) 85 24 , 77 42 , 82 27 96 76 87 13 , 79 , 87 12 96 91 respectively , reduces volume overlap error 22 58 20 26 therefore , method shows big potential em segmentation field
rate constrained shaping codes structured sources shaping codes used encode information use channels cost constraints applications include data transmission power constraint , recently , data storage flash memories constraint memory cell latter application , system requirements often rate constraint paper , study rate constrained fixed variable length shaping codes , memoryless costly channels general sources analysis relies theory word valued sources establish relationship code expansion factor minimum average symbol cost determine expansion factor minimizes average cost per source symbol \( total cost \) , corresponding conventional optimal source code cost equivalence established codes minimizing average symbol cost codes minimizing total cost , separation theorem proved , showing optimal shaping achieved concatenation optimal compression optimal shaping uniform source shaping codes often incorporate , either explicitly implicitly , form non signaling use results explore connections shaping codes codes map sequence source symbols output sequence symbols approximately independent distributed according specified target distribution , distribution matching \( dm \) codes optimal dm codes characterized terms new performance measure generalized expansion factor \( \) motivated costly channel perspective used study dm codes minimize divergence normalized divergence
benchmarking cross project prediction approaches costs metrics prediction powerful tool guide use quality resources recent years , many researchers focused problem cross project prediction \( cpdp \) , e , creation prediction models based training data projects however , published papers evaluate cost efficiency predictions , e , save costs used guide quality efforts within paper , provide benchmark 26 cpdp approaches based cost metrics benchmark shows assuming defective average better cpdp cost moreover , show ranking approaches using cost metrics ranking based metrics directly consider costs findings show must effort evaluating actual benefits cpdp , current state art cpdp actually trivial approach cost oriented evaluations
learning metrics compact networks image embedding metric learning networks used compute image embeddings , widely used many applications image retrieval face recognition paper , propose use network distillation efficiently compute image embeddings small networks network distillation successfully applied improve image classification , explored metric learning , propose two new loss functions model communication deep teacher network small student network evaluate system several datasets , including 200 2011 , cars , stanford online products show embeddings computed using small student networks perform significantly better computed using standard networks similar size results compact network \( 0 25 \) , used mobile devices , show proposed method greatly improve recall 1 results 27 5 44 6 furthermore , investigate various aspects distillation embeddings , including attention layers , semi supervised learning cross quality distillation \( code available https url \)
efficient primal dual algorithm fair combinatorial optimization problems consider general class combinatorial optimization problems including among others allocation , multiple knapsack , matching problems standard version problems maximum weight optimization problem sum values optimized however , sum good aggregation function fairness distribution values \( corresponding example different criteria \) important paper , using generalized index \( \) , well known measure , instead sum model fairness , formulate new general problem , call fair combinatorial optimization although non linear aggregating function , 0 , 1 linear program \( ip \) formulated finding optimal solution exploiting proposed however , time commercial solvers \( e g , , \) solving \( ip \) increases quickly size reach hours even relatively small sized ones faster alternative , propose heuristic solving \( ip \) based primal dual approach using decomposition experimentally evaluate methods exact solution \( ip \) several fair optimization problems related matching demonstrate efficiency demonstrate efficiency method evaluating exact solution \( ip \) several fair optimization problems related matching numerical results show method outputs short time efficient solutions giving lower bounds may take several orders magnitude longer obtain moreover , instances know optimal value , solutions quasi optimal optimality gap less 0 3
energy scaling targeted optimal control complex networks recently shown control energy required control dynamical complex network large control inputs methods reduce control energy focused , network , place additional control inputs , contrast , show controlling states subset nodes network , rather state every node , holding number control signals constant , required energy control portion network reduced substantially energy requirements exponentially decay number target nodes , suggesting large networks controlled relatively small number inputs long target set appropriately sized validate conclusions model real networks arrive energy scaling law better design control objectives regardless system size , energy restrictions , state restrictions , input node choices target node choices energy required control dynamical complex network large control inputs authors demonstrate subset network targeted energy requirements decrease exponentially
improved low rank matrix decompositions via randomized transform two randomized algorithms constructing low rank matrix decompositions algorithms employ randomized transform 14 first algorithm recently 9 , provide novel analysis significantly improves approximation bound obtained 9 preliminary version second algorithm 7 , present mild modification algorithm achieves approximation bound significantly improves corresponding running time
attention analyze bilstm case ner bilstm used core module ner sequence labeling setup state art approaches use bilstm additional resources , language modeling , multi task supervision improve ner paper instead takes step back focuses analyzing problems bilstm exactly self attention improvements formally show limitation \( crf \) bilstm modeling cross context patterns word xor limitation , show two types simple cross structures self attention cross bilstm effectively problem test real world ner datasets , 5 0 2017 , clear consistent improvements baseline , 8 7 multi token entity give depth analyses improvements across several aspects ner , especially identification multi token study sound foundation future improvements sequence labeling ner url https url
constructing interpretable features short text classification use background knowledge remains largely many text classification tasks work , explore word means constructing new semantic features , may improve performance robustness learned classifiers propose , parallel algorithm constructing taxonomy based features , demonstrate use six short text classification problems , including gender , age type prediction , drug effectiveness side effect prediction , news topic prediction experimental results indicate interpretable features constructed using notably improve performance classifiers constructed features , combination fast , linear classifiers tested strong baselines , hierarchical attention neural networks , achieved comparable better classification results short documents , also serve extraction corpus specific keywords finally , investigated semantic space potential features observe similarity well known 's law
lanenet real time lane detection networks autonomous driving lane detection detect lanes road provide accurate location shape lane one key techniques enable modern assisted autonomous driving systems however , several unique properties lanes challenge detection methods lack features makes lane detection algorithms tend objects similar local appearance moreover , inconsistent number lanes road well diverse lane line patterns , e g , , single , double , merging , splitting lines performance paper , propose deep neural network based method , named lanenet , break lane detection two stages lane edge proposal lane line localization stage one uses lane edge proposal network pixel wise lane edge classification , lane line localization network stage two detects lane lines based lane edge proposals note goal lanenet built detect lane line , introduces difficulties false detections similar lane road like characters despite difficulties , lane detection shown robust highway urban road scenarios method without relying assumptions lane number lane line patterns high running speed low computational cost lanenet capability deployed vehicle based systems experiments validate lanenet consistently delivers outstanding performances real world traffic scenarios
energy harvesting system enhanced dc dc pump technology rf dc enhanced dc dc voltage technology radio frequency identification \( \) energy harvesting presented letter received rf power level 14 higher , system , using shelf low cost discrete components connected flexible antenna , able produce 2 4 v dc voltage power general purpose electronic devices simple proof concept , device , temperature sensor , considered work experimental results demonstrate capability system perform temperature data distance 5 conventional reader used rf energy source
comparison named entity recognition tools applied texts named entity recognition \( ner \) popular domain natural language processing reason , many tools exist perform task amongst points , differ processing method rely upon , entity types detect , nature text handle , input output formats makes difficult user select appropriate ner tool specific situation article , try answer question context texts , first constitute new corpus wikipedia articles select 4 publicly available , well known free research ner tools comparison stanford ner , net , ner apply corpus , assess performances compare considering overall performances , clear hierarchy stanford best results , followed , however , detailed evaluation performed relatively entity types article categories highlights fact performances influenced factors opens interesting perspective regarding combination individual tools order improve performance
discovery privacy aware clinical data unstructured clinical texts contain rich health related information better utilize knowledge clinical texts , discovering medical query term become important task recent automatic discovery methods leveraging raw text information developed however , preserve patient privacy security , usually quite difficult get access large scale raw clinical texts paper , study new setting named discovery privacy aware clinical data \( e , medical terms extracted clinical texts aggregated co occurrence counts , without raw clinical texts \) solve problem , propose new framework leverages two important types information privacy aware clinical data , e , surface form information , global context information discovery particular , surface form module enables us detect look similar global context module plays complementary role discover semantically similar different surface forms , allow us deal query issue \( e , query found given data \) conduct extensive experiments case studies publicly available privacy aware clinical data , show outperform strong baseline methods large various settings
timely distributed computation consider status update system update packets need processed extract embedded useful information source node sends acquired information computation unit \( \) consists master node n worker nodes master node received computation task worker nodes upon computation , master node aggregates results sends back source node keep emph updated investigate age performance coded \( repetition coded , mds coded , multi message mds \( mm mds \) coded \) schemes presence exponential transmission delays shifted exponential computation times show asymptotically mm mds coded scheme outperforms schemes furthermore , characterize optimal codes average age minimized
computational optimization convolutional neural networks using separated filters architecture paper considers convolutional neural network transformation reduces computation complexity thus neural network processing usage convolutional neural networks \( cnn \) standard approach image recognition despite fact computationally , example recognition mobile platforms embedded systems paper propose cnn structure transformation 2d convolution filters linear combination separable filters allows obtain separated convolutional filters standard training algorithms study computation efficiency structure transformation suggest fast implementation easily cpu gpu demonstrate cnns designed letter recognition proposed structure show 15 speedup without accuracy loss industrial image recognition system conclusion , discuss question possible accuracy decrease application proposed transformation different recognition problems convolutional neural networks , computational optimization , separable filters , complexity reduction
much research shared facebook hidden public view comparison public private online activity around one papers despite position biggest social media platform , facebook never main stage research study , argue lack attention researchers due lack relevant activity platform , challenges collecting facebook data limited activity takes place select group public pages groups present new method collecting , reactions , across platform including private use data articles published 2015 2017 journal one compare data collected aggregated results show 58 7 papers shared platform outside public view , collecting , volume activity approximates patterns previously observed twitter results suggest role impact facebook medium science scholarly communication furthermore , importance transparency around collection aggregation
polynomial time algorithm achieve extended representation consider committee voting setting subset candidates based , target number candidates selected particular focus property called extended representation \( \) although committee satisfying guaranteed exist , computational complexity finding committee open problem explicitly mentioned multiple recent papers complexity finding committee satisfying presenting polynomial time algorithm problem algorithmic approach may useful constructing voting rules multi winner voting
rate distortion theory finite point processes study compression data case useful information contained set rather vector , e , ordering data points number data points unknown analysis based rate distortion theory theory finite point processes introduce fundamental information theoretic concepts quantities point processes present general lower upper bounds rate distortion function enable comparison vector setting , bounds point processes fixed cardinality particular , analyze fixed number gaussian data points show significantly reduce required rates compared best possible compression strategy gaussian vectors example point processes variable cardinality , study best possible compression poisson point processes specific case poisson point process uniform intensity unit square , lower upper bounds separated small gap thus provide good characterization rate distortion function
transformer based automatic post editing context aware encoding approach multi source inputs recent approaches automatic post editing \( \) research shown better results obtained multi source models , jointly encode source \( src \) machine translation output \( mt \) produce post sentence \( \) along trend , present new multi source model based transformer construct effective joint representations , model learns incorporate src context mt representation approach , achieve significant improvement baseline systems , well state art multi source model moreover , demonstrate capability model incorporate src context , show word alignment unknown mt system successfully captured encoding results
event correlation forecasting multivariate streaming sensor data event management sensor networks field involving several steps across processing chain paper , discuss major steps performed real near real time event handling including event detection , correlation , prediction filtering first , discuss existing univariate multivariate change detection schemes online event detection sensor data next , propose online event correlation scheme internal dynamics operation system responsible generation various types events show representation event dependencies within probabilistic temporal knowledge representation framework allows formulation rules also address important issue identifying dependencies among events setting time dependent framework filtering extracted rules time proposed theory applied domain validated extensive real sensor streams large scale sensor networks deployed
improving based visual feature learning whitening recent years , spiking neural networks \( \) alternative deep neural networks \( dnns \) present higher computational efficiency using low power neuromorphic hardware require less labeled data training using local unsupervised learning rules spike timing dependent \( \) snn proven effectiveness image classification simple datasets mnist however , process natural images , pre processing step required difference \( \) filtering typically used together center center coding , results loss information detrimental classification performance paper , propose use whitening pre processing step learning features experiments cifar 10 show whitening allows learn visual features closer ones learned standard neural networks , significantly increased classification performance compared filtering also propose approximation whitening convolution kernels computationally learn suited implemented neuromorphic hardware experiments cifar 10 show performs similarly regular whitening cross dataset experiments cifar 10 stl 10 also show fairly stable across datasets , making possible learn single whitening transformation process different datasets
free growth rates spatially coupled ldpc codes minimum important parameter related decoding performance ldpc codes iterative message passing decoding paper , consider ensembles time varying spatially coupled ldpc \( sc ldpc \) codes arising finite graph covers fixed degree show certain \( j , k \) regular sc ldpc code ensembles fixed cover degree , typical minimum \( associated tail \) sc ldpc code ensembles grows linearly constraint \( block \) length constraint \( block \) length tends infinity prove one bound free growth rate \( respectively , \) using associated tail \( \) sc ldpc code ensemble show empirically bounds sufficiently large period , gives exact free growth rate sc ldpc ensemble considered
hyperparameters optimization deep learning based emotion prediction human robot interaction enable humanoid robots share social space need develop technology easy interaction robots using multiple modes speech , share emotions targeted research towards addressing core issue emotion recognition problem would require less computation resources much number network hyperparameters adaptive computed low social robots real time communication specifically , proposed inception module based convolutional neural network architecture achieved improved accuracy 6 improvement existing network architecture emotion classification tested multiple datasets humanoid robots real time proposed model reducing trainable hyperparameters extent 94 compared vanilla cnn model clearly indicates used real time based application human robot interaction rigorous experiments performed validate methodology sufficiently robust could achieve high level accuracy finally , model implemented humanoid robot , real time robustness model evaluated
graph based anomaly detection description survey detecting anomalies data vital task , numerous high impact applications areas security , finance , health care , law numerous techniques developed past years spotting outliers anomalies unstructured collections multi dimensional points , graph data becoming ubiquitous , techniques structured em graph data focus recently objects graphs long range correlations , suite novel technology developed anomaly detection graph data r n survey aims provide general , comprehensive , structured overview state art methods anomaly detection data represented graphs key contribution , provide comprehensive exploration data mining machine learning algorithms em detection tasks give general framework algorithms various settings unsupervised vs \( semi \) supervised approaches , static vs dynamic graphs , attributed vs plain graphs highlight effectiveness , scalability , generality , robustness aspects methods , importance anomaly em highlight major techniques facilitate root cause , , detected anomalies analysis sense making finally , present several real world applications graph based anomaly detection diverse domains , including financial , auction , computer traffic , social networks conclude survey discussion open theoretical practical challenges field
speaking language matching machine human captions adversarial training strong progress made image captioning last years , machine human captions still quite distinct closer look reveals due generated word distribution , vocabulary size , strong bias generators towards frequent captions furthermore , humans generate multiple , diverse captions , due inherent ambiguity captioning task considered today 's systems r n address challenges , change training objective caption generator reproducing captions generating set captions indistinguishable human generated captions instead learning target , employ adversarial training combination approximate sampler implicitly match generated distribution human one method achieves comparable performance state art terms correctness captions , generate set diverse captions , significantly less biased match word statistics better several aspects
improved combination rule fault diagnosis data multiple sensors effectively fused accurate monitoring many engineering applications last years , one applications multi sensor fusion fault diagnosis theory evidence along combination rule popular method multi sensor fusion successfully applied fault diagnosis information obtained different sensors shows high conflict , classical combination rule may produce counter intuitive result overcome , paper proposes improved combination rule multi sensor data fusion numerical examples forward show effectiveness proposed method comparative analysis also carried existing methods show superiority proposed method multi sensor fault diagnosis
structural analysis high index process simulation paper deals structural analysis problem dynamic process high index models consider two methods index reduction models 's method symbolic differential elimination algorithm discussion comparison methods given via class fundamental process simulation examples particular , efficiency method illustrated function number process design
pricing randomized allocations randomized mechanisms , map set probability distribution outcomes rather single outcome , important ill understood area computational mechanism design investigate role randomized outcomes \( , \) context fundamental multi parameter mechanism design problem selling heterogeneous items unit demand bidders extent improve revenue pricing rather items , modification problem affect computational tractability \? results show answers questions whether consumers purchase one \( buy one model \) purchase set receive independent sample \( buy many model \) buy one model , polynomial time algorithm compute revenue maximizing envy free prices \( thus overcoming inapproximability corresponding item pricing problem \) revenue optimal system revenue optimal item pricing unbounded factor long number item types exceeds 4 buy many model n item types , profit achieved pricing item pricing factor \( log n \) , optimal pricing cannot approximated within factor \( n eps \) eps 0 , unless np time randomized algorithms lower bounds rely mixture geometric algebraic techniques , whereas upper bounds use novel rounding scheme transform mechanism randomized outcomes one deterministic outcomes bounded amount revenue
using trusted data train deep networks labels severe noise growing importance massive datasets advent deep learning makes robustness label noise critical property classifiers sources label noise include automatic labeling large datasets , non expert labeling , label data adversaries latter case , may arbitrarily bad , even bad classifier predicts labels high confidence protect sources noise , leverage fact small set clean labels often easy demonstrate robustness label noise severe strengths achieved using set trusted data clean labels , propose loss correction utilizes trusted examples data efficient manner mitigate effects label noise deep neural network classifiers across vision natural language processing tasks , experiment various label noises several strengths , show method significantly outperforms existing methods
combining tools optimization analysis floating point computations recent interest optimizing analyzing floating point programs lead diverse array new tools numerical programs tools often complementary , focusing distinct aspect numerical programming building reliable floating point applications typically requires addressing several aspects , makes easy composition essential paper describes composition two recent floating point tools , performs accuracy optimization , , performs accuracy verification find combination provides numerous benefits users , able use check whether 's optimizations improved worst case error , well benefits tool authors , including number bugs tools combination also allowed us compare different program rewriting techniques implemented tools first time paper road map combining floating point tools common challenges
connectivity network analysis propose network characterization combinatorial fitness adapting notion inherent networks proposed energy surfaces use well known family example case inherent network graph vertices represent local maxima landscape , edges account transition probabilities corresponding extracted networks representative small landscape instances , performed statistical characterization properties found network properties related search difficulty underlying varying values k
vector summarization applications network graphs provide deterministic data summarization algorithm approximates mean p frac 1 n sum p p p set p n vectors real , weighted mean tilde p emph subset \( 1 eps \) vectors , e , independent n prove squared euclidean distance p tilde p eps variance p use algorithm maintain approximated sum vectors unbounded stream , using memory independent , logarithmic n vectors seen far main application extract represent compact way groups activity summaries users underlying data exchanges example , case mobile networks , use gps traces identify , case social networks , use information exchange identify groups algorithm provably identifies heavy entries proximity \( \) matrix heavy hitters used extract represent compact way groups activity summaries users underlying data exchanges evaluate algorithm several large data sets
systematic deterministic graph minor embedding cartesian products graphs limited connectivity current next generation quantum need efficient graph minor embedding methods methods allow non native problems adapted target 's architecture overhead widely used heuristic techniques quickly proving significant bottleneck solving real world applications alleviate difficulty , propose systematic deterministic embedding method , exploiting structures input graph specific problem quantum focus specific case cartesian product two complete graphs , regular structure occurs many problems divide embedding problem first embedding one factors cartesian product pattern resulting simplified problem consists placement connecting together copies reach valid solution obvious advantage systematic deterministic approach respect speed efficiency , embeddings produced easily scaled larger processors show desirable properties number used chain length distribution conclude , briefly address problem presenting possible extensions method
orthogonal random features present discovery related random fourier features gaussian kernel approximation , replacing random gaussian matrix properly scaled random orthogonal matrix significantly decreases kernel approximation error call technique orthogonal random features \( \) , provide theoretical empirical justification behavior motivated discovery , propose structured orthogonal random features \( \) , uses class structured discrete orthogonal matrices speed computation method reduces time cost mathcal \( 2 \) mathcal \( log \) , data dimensionality , almost compromise kernel approximation quality compared experiments several datasets verify effectiveness existing methods also provide discussions using type discrete orthogonal structure range applications
efficient rank minimization via solving non iterative thresholding algorithm rank minimization \( rm \) investigated task finding solutions exploiting low rank structure parameter matrices recently , solving rm problem leveraging non convex received significant attention demonstrated theoretical experimental work non convex relaxation , e g norm regularization \( \) norm regularization \( \) , provide better approximation original problems convex however , designing efficient algorithm theoretical guarantee remains challenging problem paper , propose simple efficient proximal type method , namely iterative thresholding algorithm \( \) , concrete analysis solve rank minimization problems non convex weighted norm low rank theoretically , proposed method could converge critical point mild assumptions rate order \( 1 \) moreover , experimental results synthetic data real world data sets show proposed algorithm outperforms state arts efficiency accuracy
parameterized approximation algorithms boxicity boxicity graph g \( v , e \) , denoted box \( g \) , minimum integer k g represented intersection graph axis parallel boxes mathbb r k problem computing boxicity even graph classes like bipartite , co bipartite split graphs within \( n 1 epsilon \) factor , epsilon 0 polynomial time unless np give fpt approximation algorithms computing boxicity graphs , parameter used vertex edge edit distance given graph families graphs bounded boxicity seen generalization discussed cite r n extending idea one algorithms , also get left \( frac n sqrt log log n sqrt log n right \) factor approximation algorithm computing boxicity left \( frac n \( log log n \) frac 3 2 sqrt log n right \) factor approximation algorithm computing first \( n \) factor approximation algorithms known boxicity consequence result , \( n \) factor approximation algorithm computing partial order dimension finite \( n \) factor approximation algorithm computing threshold dimension split graphs would follow
dynamic environments , , make effective use environment resources collective intelligence termite instance build complexity far beyond comprehension individual termite , ant dynamically allocate labor various vital tasks defense without central decision making ability recent research suggests life even highly social , , interactions , found observations ant similar natural mechanisms based self organization order coherent sophisticated patterns global behaviour keeping mind characteristics present simple model tackle collective adaptation social based real ant behaviors \( algorithm \) tracking dynamic environments highly multimodal complex functions described well know de test suite , purpose comparison , recent model artificial \( algorithm \) based similar features described analyzed final results indicate collective intelligence able cope quickly adapt situations even cooperative period , community deal two different purposes , outperforming adaptive speed
asymptotic maximal order statistic fading using tools extreme value theory \( \) , proved limiting distribution maximum l independent identically distributed \( \) signal interference ratio \( \) random variables \( \) distribution , user signals independent non identically distributed \( n \) kappa mu fading limiting distribution used analyze outage probability selection combining \( sc \) , moments maximum shown converge moments used deriving results asymptotic rate sc finally , rate convergence actual maximum distribution distribution derived analyzed different kappa mu parameters , results stochastic ordering used analyze variations limiting distribution respect variations source fading parameters close match observed monte carlo simulations limiting distributions outage probability rate
search fastest concurrent union find algorithm union find \( disjoint set union \) one fundamental problems computer science well studied theoretical practical perspectives sequential case recently , interest analyzing problem concurrent scenario , several asymptotically efficient algorithms proposed yet , date , little known practical performance concurrent union find r n work addresses gap evaluate analyze performance several concurrent union find algorithms optimization strategies across wide range platforms \( intel , , arm \) workloads \( social , random , road networks , well complex algorithms \) first observe , due limited computational cost , number induced cache critical determining factor performance existing algorithms introduce new techniques reduce cost storing node implicitly using plain reads way affect correctness algorithms finally , show union find implementations interesting application transactional memory \( \) one fastest algorithm variants discovered sequential one uses coarse grained lock optimization reduce synchronization cost increase scalability
logical relations coherence effect subtyping semantics programming language subtyping typically defined typing rather typing judgments avoid semantic , semantics expected coherent , e , independent typing tion given typing judgment article present heterogeneous , , step indexed logical relations establishing coherence semantics languages subtyping illustrate effectiveness proof method , develop proof coherence type directed , selective translation typed call value lambda calculus control effect subtyping article coq formalization relies novel shallow embedding logic reasoning step indexing
positional cartesian genetic programming cartesian genetic programming \( cgp \) many modifications across variety implementations , recursive connections node weights alternative genetic operators also proposed cgp , fully studied work , present new form genetic programming based floating point representation new form cgp , called positional cgp , node positions allows evaluation many different genetic operators allowing previous cgp improvements like using nine benchmark problems three different classes , evaluate optimal parameters cgp , including novel genetic operators
games costs delays demonstrate usefulness adding delay infinite games quantitative winning conditions delay game , one players may delay obtain lookahead 's show determining winner delay games winning conditions given parity automata costs complete exponential bounded lookahead sufficient general necessary thus , although parity condition costs quantitative extension parity condition , results show adding costs increase complexity delay games parity conditions r n furthermore , study new phenomenon appears quantitative delay games lookahead quality winning strategies vice versa determine extent tradeoff particular , even smallest lookahead allows improve quality optimal strategy worst possible value almost smallest possible one thus , benefit introducing lookahead allow player games would lose without , lookahead also allows improve quality winning strategies games even without lookahead
scheduling trees tasks sparse linear algebra scientific workloads often described directed acyclic task graphs paper , focus factorization sparse matrices , whose task graph structured tree parallel tasks among existing models parallel tasks , concept tasks especially powerful allows task processed time varying number processors following model matrix computations , consider tasks whose speedup p alpha , p fractional share processors task , alpha \( 0 alpha leq 1 \) parameter depend task first relevance model application actual experiments platforms , study optimal allocation proposed minimization using optimal control theory largely simplify proofs pure scheduling arguments building insight gained thanks new proofs , extend study distributed platforms , task cannot distributed among several distributed nodes distributed setting \( homogeneous heterogeneous \) , prove np completeness corresponding scheduling problem , propose approximation algorithms finally assess relevance approach simulations realistic trees show average performance gain allocations respect existing solutions \( thus actual speedup functions \) 16 alpha 0 9 \( value observed real experiments \)
rotation distance fixed parameter tractable rotation distance trees measures number simple operations takes transform one tree another known polynomial time algorithms computing rotation distance case ordered rooted trees , show rotation distance two ordered trees fixed parameter tractable , parameter , k , rotation distance proof relies initial trees trees size bounded
constructing bi similar finite state abstractions using asynchronous l complete approximations paper constructs finite state abstraction possibly continuous time infinite state model two steps first , finite external signal space added , generating called phi dynamical system secondly , strongest asynchronous l complete approximation external dynamics constructed main results , show \( \) abstraction simulates original system , \( ii \) bisimilarity original system abstraction holds , original system l complete state space satisfies additional property
turing kernelization structural mathcal f minor free deletion fixed finite family graphs mathcal f , mathcal f minor free deletion problem takes input graph g integer ell asks whether exists set x v \( g \) size ell g x mathcal f minor free mathcal f k 2 mathcal f k 3 encodes vertex cover feedback vertex set respectively parameterized feedback vertex number g two problems known admit polynomial kernelization polynomial kernelization also exists mathcal f containing planar graph forests paper show mathcal f minor free deletion parameterized feedback vertex number 2 hard mathcal f p 3 rules existence polynomial kernel assuming np poly , also gives evidence problem admit polynomial turing kernel hardness result generalizes mathcal f containing p 3 subgraph free graph , using parameter vertex deletion distance treewidth \( mathcal f \) , \( mathcal f \) denotes minimum treewidth graphs mathcal f case , mathcal f contains p 3 subgraph free graph , present polynomial turing kernelization results extend mathcal f subgraph free deletion
submodule clustering method multi way data sparse low rank representation new submodule clustering method via sparse low rank representation multi way data proposed paper instead multi way data vectors , method natural orders preserve data intrinsic structures , e g , image data matrices implement clustering , multi way data , viewed tensors , represented proposed tensor sparse low rank model obtain submodule representation , called free module , finally used spectral clustering proposed method extends conventional subspace clustering method based sparse low rank representation multi way data submodule clustering combining product operator new method tested several public datasets , including data , video sequences images experiments show new method outperforms state art methods , sparse subspace clustering \( \) , low rank representation \( \) , ordered subspace clustering \( \) , robust latent low rank representation \( \) sparse submodule clustering method \( \)
dealing ambiguity robotic grasping via multiple predictions humans grasping manipulating objects life long experience knowledge 3d shape weight distribution objects however , lack intuition robots makes robotic grasping challenging task often several equally viable options grasping object however , ambiguity modeled conventional systems estimate single , optimal grasp position propose tackle problem simultaneously estimating multiple grasp poses single rgb image target object , problem robotic grasping replacing conventional grasp rectangles grasp belief maps , hold precise location information account uncertainty inherent task augment fully convolutional neural network multiple hypothesis prediction model predicts set grasp hypotheses , critical real time robotic applications grasp detection accuracy 90 unseen objects , outperforming current state art task
privacy preserving double auction mechanism based homomorphic encryption sorting networks effective resource allocation approach , double auctions \( \) extensively studied electronic commerce previous studies focused design strategy proof mechanisms , much research effort done concerning privacy security issues however , security , especially privacy issues become public concern law enforce privacy guarantees recently paper , address privacy issue electronic auctions , design privacy preserving mechanism double auctions employing homomorphic encryption sorting networks achieve provable privacy auctions reveal information except auction results , resulting strict privacy guarantee moreover , achieve practical system performance , compare different sorting algorithms , suggest using faster ones experimental results show different sorting algorithms may great effect performance mechanism , demonstrate protocol real world applications electronic commerce
globally optimized mutual influence aware ranking e commerce search web search , mutual influences documents studied perspective search result methods web search directly applicable e commerce search differences little research done mutual influences items e commerce search propose global optimization framework mutual influence aware ranking e commerce search framework directly optimizes gross volume \( \) ranking , ranking two tasks first task mutual influence aware purchase probability estimation propose global feature extension method incorporate mutual influences features item also use recurrent neural network \( rnn \) capture influences related ranking orders purchase probability estimation second task find best ranking order based purchase probability treat second task sequence generation problem solved using beam search algorithm performed online b test large e commerce search engine results show method 5 increase search engine strong baseline
sparse neural networks advances designing training deep neural networks led principle large deeper network , better perform result , computational resources become key limiting factor achieving better performance one strategy improve network capabilities decreasing computation required replace dense fully connected convolutional layers sparse layers paper experiment training sparse neural network topologies first , test pruning based sparse topologies , use network topology obtained initially training dense network pruning low weight connections second , test nets , class sparse network structures proven connectivity sparsity properties results show compared dense topologies , sparse structures show promise training potential also exhibit highly nonlinear convergence , study
sampling random spanning trees faster matrix multiplication present algorithm , high probability , generates random spanning tree edge weighted undirected graph tilde \( n 5 3 1 3 \) time \( tilde \( cdot \) \( n \) factors \) tree sampled distribution probability tree proportional product edge weights improves upon previous best algorithm due et al runs matrix multiplication time , \( n omega \) special case unweighted graphs , improves upon best previously known running time tilde \( min n omega , sqrt n , 4 3 \) n 7 4 \( et al , , et al \) r n effective resistance metric essential algorithm , work et al , determinant based random walk based techniques used previous algorithms instead , algorithm based gaussian elimination , fact effective resistance preserved graph resulting eliminating subset vertices \( called complement \) part algorithm , show compute epsilon approximate effective set vertex pairs via approximate tilde \( \( n \) epsilon 2 \) time , without using johnson lemma requires tilde \( min \( \) epsilon 2 , n epsilon 4 epsilon 2 \) time combine approximation procedure error correction procedure edges estimate n't sufficiently accurate
binary constraint satisfaction problems defined topological abstract binary constraint satisfaction problem \( csp \) decide whether exists assignment set variables satisfies specified constraints pairs variables binary csp instance presented labelled graph encoding forms constraints imposed consider defined restricting allowed form graph one type restriction certain specified \( patterns \) captures tractable classes csp , capture classes defined language restrictions , well known structural property extend notion pattern introduce notion topological minor binary csp instance finite set patterns occurring topological obtain compact mechanism expressing novel tractable csp , including new class acyclic instances
interactive zero shot learning net consider task visual net , cnn without extra data recognize novel concepts may training set prior work make use linguistic cues zero shot learning , using language representation training set , implicitly learned cnn , generalize new classes end , introduce set visualization techniques better reveal activation patterns relations groups cnn filters next demonstrate knowledge languages used certain cnn neurons part model , call language classifier demonstrate robustness simple applying weakly supervised manner labeling unlabeled concepts visual classes present training data specifically show built top cnn trained imagenet classification localize humans determine pose pascal voc without extra labeled data additional training apply interactive zero shot manner , demonstrating languages expressive enough detect set visual classes ms coco never appear imagenet training set
learning agent heat pump set back strategy using model free reinforcement learning conventional control paradigm heat pump less efficient auxiliary element keep temperature set point constant day constant temperature set point ensures heat pump operates efficient heat pump mode minimizes risk less efficient auxiliary element alternative constant set point strategy , paper proposes learning agent set back strategy set back strategy set point temperature convenient moments , e g home finding optimal set back strategy requires solving sequential decision making process uncertainty , presents two challenges first challenge description characteristics building unavailable challenging obtain second challenge relevant information state , e building , cannot measured learning agent order overcome two challenges , paper proposes auto encoder coupled batch reinforcement learning technique proposed approach validated two building types different characteristics simulation results indicate proposed learning agent reduce energy consumption 4 9 100 days 9 11 80 days compared conventional constant set point strategy
convex bodies linear competitive ratio study problem convex bodies online given sequence convex bodies k mathbb r algorithm must points x k online fashion \( e , x chosen k 1 revealed \) objective minimize total distance successive points sequence recently , et al \( 2019 \) 2 \( \) competitive algorithm problem give algorithm \( min \( , sqrt log \) \) competitive sequence length
basis block structured integer programming consider 4 block n fold integer programming \( ip \) , constraint matrix consists n copies small matrices , b , one copy c specific block structure prove , ell infty norm basis elements 4 block n fold ip upper bounded fpt \( n c \) c number matrix c fpt multiplicative factor dependent parameters small matrices , b , c , \( e , number columns , largest absolute value among entries \) improves upon existing upper bound fpt \( n 2 c \) provide matching lower bounded omega \( n c \) , even holds arbitrary non zero integral element kernel space consider special case 4 block n fold c zero matrix \( called 3 block n fold ip \) show , surprisingly , 3 block n fold ip admits basis whose ell infty norm bounded fpt \( 1 \) , despite fact ell infty norm basis elements still omega \( n \) finally , provide upper bounds ell infty norm basis elements 3 block n fold ip based upper bounds , establish algorithms 3 block n fold ip provide improved algorithms 4 block n fold ip
tdma like access scheme splitting request transmission vehicular networks paper , consider safety message transmission dense vehicular network increasing vehicular network density , collision rate increases multiple vehicles transmit safety messages simultaneously address issue , propose request transmission split time division multiple access \( tdma \) scheme , referred tdma scheme , divide frame three phases , e , access phase , broadcast feedback phase , free transmission phase vehicle selects repetition rate according given probability distribution transmission request packet improve reliability request addition , unit coordinator uses successive interference cancellation technique resolve request tdma also reduces request time containing vehicle identity request packet theoretical analysis numerical results verify tdma scheme provide higher throughput coded slotted aloha scheme
covering point patterns encoder point pattern finite number points interval 0 , described using bits based bits , select subset 0 , contains points pattern shown , point pattern produced homogeneous poisson process intensity lambda , restricted select subset average measure , , tends infinity , minimum number bits per second needed encoder lambda log also shown , tends infinity , point pattern 0 , containing lambda points successfully described using lambda log bits per second sense finally , wyner version problem considered points pattern known
aloha auxiliary loss optimization hypothesis augmentation malware detection popular application machine learning information security \( ml \) , ml classifier trained predict whether given malware parameters classifier typically optimized outputs model set input samples closely match true malicious benign \( 1 0 \) target labels however , often number sources contextual metadata malware sample , beyond aggregate malicious benign label , including multiple labeling sources malware type information \( e g , , , etc \) , feed classifier auxiliary prediction targets work , fit deep neural networks multiple additional targets derived metadata threat intelligence feed \( \) malware , including multi source malicious benign loss , count loss multi source detections , semantic malware attribute tag loss find incorporating multiple auxiliary loss terms yields marked improvement performance main detection task also demonstrate gains likely stem informed neural network representation due regularization multi target learning auxiliary loss architecture yields significant reduction detection error rate \( false \) 42 6 false positive rate \( \) 10 3 compared similar model one target , decrease 8 10 5
aggregating algorithm competing paper deals line regression settings signals belonging lattice algorithms work semi online setting inputs known advance outcomes unknown given step step apply aggregating algorithm construct prediction method whose cumulative loss input vectors comparable cumulative loss linear functional lattice product get algorithm takes signals arbitrary domain cumulative loss comparable cumulative loss predictor function spaces describe several applications setting
practical bilateral privacy preserving federated learning federated learning , emerging distributed training model neural networks without collecting raw data , attracted widespread attention however , almost existing researches federated learning consider protecting privacy clients , preventing model final model parameters untrusted clients external attackers paper , present first bilateral privacy preserving federated learning scheme , raw training data clients , also model training phase well final model parameters specifically , present efficient privacy preserving technique mask global model , allows clients train noisy global model , also ensures server obtain exact updated model detailed security analysis shows clients access neither model final global model meanwhile , server cannot obtain raw training data clients additional information used exact updated model finally , extensive experiments demonstrate proposed scheme comparable model accuracy traditional federated learning without much extra communication overhead
reinforcement learning traffic control adaptive horizon paper proposes reinforcement learning approach traffic control adaptive horizon build controller traffic network , q learning based strategy controls light passing time network intersections applied controller includes two components regular q learning controller controls traffic light signal , adaptive controller continuously optimizes action space q learning algorithm order improve efficiency q learning algorithm regular q learning controller uses control cost function reward function determine action choose adaptive controller control cost updates action space controller determining subset actions likely obtain optimal results action space subset uncertainties traffic turning rate introduced test robustness controller stochastic environment compared model predictive control \( mpc \) , results show proposed q learning based controller outperforms mpc method reaching stable solution shorter period achieves lower control costs proposed q learning based controller also robust 30 traffic demand uncertainty 15 turning rate uncertainty
locally decodable codes subsets finite fields prime factors mersenne numbers k query locally decodable code \( \) encodes n bit message x n bit codeword c \( x \) , one recover bit x message querying k bits codeword c \( x \) , even constant fraction codeword bits major goal related research establish optimal trade length query complexity codes r n recently introduced novel technique constructing locally decodable codes improved upper bounds code length technique based mersenne paper extend work argue progress via methods tied progress old number theory question regarding size largest prime factors mersenne numbers r n specifically , show every mersenne number 2 1 prime factor p gamma yields family k \( gamma \) query locally decodable codes length \( n 1 \) , fixed k epsilon 0 one use technique obtain family k query length \( n epsilon \) infinitely many mersenne numbers prime factors known currently
dataset benchmark document introduces background usage dataset benchmark documentation first background , widely given digital method modern trend protection restoration follow trend , release first public dataset restoration rest documentation details data generation enable data driven fashion , dataset provided large number training testing example sufficient deep learning approach detailed usage dataset well benchmark described
joint network coding 3 receiver gaussian broadcast channels receiver message side information problem characterizing capacity region gaussian broadcast channels receiver message side information appears difficult remains open n 3 receivers paper proposes joint network coding method 3 receiver cases using method , establish unified inner bound capacity region 3 receiver gaussian broadcast channels general message side information configuration achievability proof inner bound uses idea joint interference , interference using dirty paper coding encoder successive decoding decoders show inner bound larger achieved state art coding schemes outer bound also established shown tight 46 64 possible cases
decentralized stochastic gradient tracking empirical risk minimization recent works shown decentralized sgd centralized counterparts large scale machine learning , theoretical gap still fully understood paper , propose decentralized stochastic gradient tracking \( \) algorithm peer peer networks empirical risk minimization problems , explicitly evaluate convergence rate terms key parameters problem , e g , algebraic connectivity communication network , batch size , gradient variance importantly , first theoretical result emph exactly recover rate centralized sgd , optimal dependence algebraic connectivity networks using stochastic gradients moreover , explicitly quantify network affects speedup rate improvement existing works interestingly , also point first time linear sublinear speedup possible empirically validate neural networks logistic regression problems , show advantage state art algorithms
classification cell phones iris images soft great potential various applications ranging , security online however , faces many challenges since limited control data acquisition conditions chapter presents super resolution convolutional neural networks \( \) approach increases resolution low quality iris images images subject 's faces work shows increasing image resolution \( \) improve classification rate using random forest classifier best classification rate 90 15 right 87 15 left eye achieved images pixels results compare well state art show improving image resolution classification rate increases additionally , novel database captured subjects x created \( available upon request \)
approximability three valued max csp maximum constraint satisfaction problem \( max csp \) , one given finite collection \( possibly weighted \) constraints overlapping sets variables , goal values given domain variables maximize number \( total weight , weighted case \) satisfied constraints problem np hard general , , therefore , natural study restricting allowed types constraints affects approximability problem known every boolean \( , two valued \) max csp problem finite set allowed constraint types either solvable exactly polynomial time else complete \( hence polynomial time approximation scheme unless p np open problem several years whether result extended non boolean max csp , much difficult analyze boolean case paper , make first step direction establishing result max csp three element domain moreover , present simple description polynomial time solvable cases problem description uses well known algebraic combinatorial property also show every hard three valued max csp problem contains , certain specified sense , one two basic hard max csp problems maximum k subgraph problems k 2 , 3
adaptive full duplex communications cognitive radio networks paper propose novel adaptive scheme full duplex communication secondary users \( \) cognitive radio network secondary network operates three modes cooperative sensing \( cs \) , full duplex transmit sensing \( \) , full duplex transmit receive \( \) cs mode , secondary nodes detect activity primary users \( \) novel cooperative mac protocol decide systems mode operation subsequent spectrum mode one senses activity continuously another node mode , would communicate asynchronous full duplex \( fd \) manner , maximum average collision analytical closed forms probability collision , average collision duration cumulative collision duration , well throughput network derived , performance proposed protocol terms mentioned metrics , effectiveness , advantages conventional methods sensing transmission verified via simulations
computational complexity spiking neural p systems shown standard spiking neural p system simulates turing machines less exponential time space overheads spiking neural p systems considered constant number neurons independent input length following construct universal spiking neural p system use rules simulates turing machines linear time 10 neurons
fault tolerant entity resolution crowd recent years , crowdsourcing increasingly applied means enhance data quality although crowd generates information especially complex problems entity resolution \( er \) , output quality crowd workers often noisy , workers may generate false data even simple tasks challenge address paper minimize cost task maximizing er result quality assumption unreliable input crowd purpose , first establish consistent er solution noisy worker answers part data interpretation problem focus next problem find next task maximizes information gain er result minimal additional cost compare robust data interpretation strategies alternative state art approaches incorporate notion fault tolerance , e , robustness noise experimental evaluation show approaches yield quality improvement least 20 two real world datasets furthermore , examine task worker assignment strategies well task techniques terms cost quality trade offs paper based synthetic datasets , draw conclusions minimize cost maintaining high quality er results
dependent types extensive games extensive games tools largely used economics describe decision processes community agents paper propose formal based assistant coq focuses mostly infinite extensive games coq proposes feature called dependent types , type object may depend type components instance , set choices set agent may depend using dependent types , describe formally general class strategy profiles , corresponds game used also discuss notions game theory described
measuring match evaluators cognitive distances panel members research groups journal level research groups evaluated expert panel , open question one determine match panel research groups paper , outline two quantitative approaches determine cognitive distance evaluators , based journals published use example data four research evaluations carried 2009 2014 university r n approach based journal map , similarity adapted publication vector \( \) approach based full journal similarity matrix approaches determine entity 's profile based journals published subsequently , determine euclidean distance profiles two entities indicator cognitive distance using bootstrapping approach , determine confidence intervals distances , present article refinement previous proposal operates level web science subject categories
comparison sensor attacks control systems attention security context control systems attacks occur real control systems throughout world , become clear attacks detection term come variety techniques attackers employ avoid detection show states system \( particular , reachable set corresponding attack \) two important types attacks employ squared fault detection method demonstrate imposes constraint attack sequence either generate \( zero attack \) generate rate indistinguishable normal operation \( hidden attack \)
randomized algorithm based threshold approximate star discrepancy present new algorithm estimating star discrepancy arbitrary point sets similar algorithm discrepancy approximation j \( \) , based optimization algorithm threshold improvements include , amongst others , non uniform sampling strategy suited higher dimensional inputs , rounding steps transform axis parallel boxes , discrepancy tested , emph critical test boxes critical test boxes provably yield higher discrepancy values , contain box exhibits maximum value local discrepancy provide comprehensive experiments test new algorithm randomized algorithm computes exact discrepancy frequently cases checked \( e , exact discrepancy point set computed feasible time \) importantly , higher dimension new method clearly better previously known methods
interpretable rumor detection attending user interactions address rumor detection learning differentiate community 's response real fake claims existing state art models based tree models model conversational trees however , social media , user might entire rather specific user propose post level attention model \( plan \) model long distance interactions tweets multi head attention mechanism transformer network investigated variants model \( 1 \) structure aware self attention model \( plan \) incorporates tree structure information transformer network , \( 2 \) hierarchical token post level attention model \( \) learns sentence representation token level self attention best knowledge , first evaluate models two rumor detection data sets data set well data sets show best models outperform current state art models data sets moreover , attention mechanism allows us explain rumor detection predictions token level post level
loop patterns extension kleene star operator expressive pattern matching arbitrary data structures kleene star operator important pattern construct representing pattern multiple times due simplicity usefulness , various pattern matching systems regular expressions example , similar pattern construct called repeated pattern however , following limitations \( \) cannot change pattern repeated depending current count , \( ii \) cannot apply arbitrary data structures trees graphs lists paper proposes loop patterns overcome limitations paper presents numerous working examples formal semantics loop patterns examples paper coded programming language , features non linear pattern matching non free data types
sparse sparse architecture search cnns resource constrained vast majority processors world actually units \( mcus \) , find widespread use performing simple control tasks applications ranging medical devices office equipment internet things \( iot \) promises machine learning many every day objects via tiny , mcus however , resource hardware platforms severely limit complexity machine learning models deployed example , although convolutional neural networks \( cnns \) achieve state art results many visual recognition tasks , cnn inference mcus challenging due severe finite memory limitations memory challenge associated cnns , various alternatives proposed fit within memory budget , cost prediction accuracy paper challenges idea cnns suitable deployment mcus demonstrate possible automatically design cnns generalize well , also small enough fit onto memory limited mcus sparse architecture search method combines neural architecture search pruning single , unified approach , learns superior models four popular iot datasets cnns find accurate 4 times smaller previous approaches , strict working memory constraint
homotopy methods multiplication modulo sets study cost multiplication modulo families polynomials following previous work , , propose algorithm relies homotopy fast evaluation interpolation techniques obtain quasi linear time complexity substantial families examples , result known applications given notably addition algebraic numbers small characteristic
coherent matching distance 2d persistent homology comparison multidimensional persistent numbers often based multidimensional matching distance metric rather simple define compute considering suitable family filtering functions associated lines positive slope , two main drawbacks first , natural link properties associated lines close consequence , part interesting information lost second , definition makes difficult study properties paper introduce new matching distance 2d persistent numbers , called coherent matching distance based matchings change take account definition trivial , must face presence multidimensional , e fact different paths space induce different matchings associated persistent diagrams paper prove coherent 2d matching distance well defined stable
lift flap context reasoning using object centered graphs benefit lift flap taking active role behind flap based context paper , introduce lift flap games computational models task reason scene context infer target behind flap natural image context reasoning critical many computer vision applications , object recognition semantic segmentation tackle problem , propose object centered graph representing scene configuration image node corresponds group objects belonging category infer target 's class label , introduce object centered graph network model consisting two sub networks classification sub network takes complete graph input outputs classification vector assigning probability class reinforcement learning sub network exploits class label dependencies learns joint probability among objects order generate multiple reasonable answers missing target evaluate model 's performance , carry human behavioral experiments lift flap games benchmark model makes reasonable compared humans , significantly outperforms models also demonstrate usefulness object centered graph network model context aware object recognition target visual search
public key goppa codes paper , code based public key based goppa codes presented scheme based several goppa code adding error possible attacks key size several choices parameters compared known schemes security level example , security level bits , obtain key size whereas classical scheme based goppa codes using list decoding requires key size
eeg based drowsiness estimation driving safety using deep q learning fatigue vital factor road one fatigue driving drowsiness paper , propose using deep q learning analyze \( eeg \) dataset captured simulated driving test measuring correlation drowsiness driving performance , experiment represents important brain computer interface \( bci \) paradigm especially application perspective adapt driving test fit reinforcement learning framework , thus formulate drowsiness estimation problem optimization q learning task latest deep q learning technologies attending characteristics eeg data , deep q network action estimate drowsiness results show trained model trace variations mind state satisfactory way testing eeg data , demonstrates feasibility new computation paradigm also show method outperforms supervised learning counterpart superior real applications best knowledge , first introduce deep reinforcement learning method bci scenario , method potentially generalized bci cases
minimizing latency quantum circuits mapping circuit fabric quantum computers exponentially faster classical counterparts terms solving specific , important problems biggest challenge quantum computing system environmental noise one way decrease effect noise \( hence , reduce overhead building fault tolerant quantum circuits \) reduce latency quantum circuit runs quantum circuit paper , novel algorithm presented scheduling , placement , routing quantum algorithm , realized target quantum circuit fabric technology algorithm , software tool , advances state art quantum methodologies methods considering key characteristics constraints quantum circuit fabric experimental results show presented tool improves results previous tool 41
towards 3d human pose estimation wild weakly supervised approach paper , study task 3d human pose estimation wild task challenging due lack training data , existing datasets either wild images 2d pose images 3d pose r n propose weakly supervised transfer learning method uses mixed 2d 3d labels unified deep neutral network presents two stage structure network state art 2d pose estimation sub network 3d depth regression sub network unlike previous two stage approaches train two sub networks sequentially separately , training end end fully exploits correlation 2d pose depth estimation sub tasks deep features better learnt shared representations , 3d pose labels controlled environments transferred wild images addition , introduce 3d geometric constraint 3d pose prediction , effective absence ground truth depth labels method achieves competitive results 2d 3d benchmarks
neural machine translation supervised attention attention appealing neural machine translation , since able encode source sentence generating alignment target word source words unfortunately , proved worse conventional alignment models accuracy paper , analyze explain issue point view ordering , propose supervised attention learned guidance conventional alignment models experiments two chinese english translation tasks show super attention mechanism yields better alignments leading substantial gains standard attention based nmt
polar coded distributed matrix multiplication propose polar coding mechanism distributed matrix multiplication polar codes provably achieve channel capacity advantage low encoding decoding complexity aspects polar codes enable scalable scheme compute nodes coded computation analyze polarization phenomenon context run times compute nodes characterize matrices real numbers design sequential decoder specifically polar codes erasure channels real valued input outputs proposed coded computation scheme implemented computing platform numerical results provided numerical results illustrate proposed coded computation scheme achieves significant speed finally , experiments conducted performance proposed coded computation technique tested solving least squares problem using gradient descent
reinforcement learning adaptive sampling optimized dnn compilation achieving faster execution shorter compilation time enable diversity innovation neural networks however , current paradigm executing neural networks either relies hand optimized libraries , traditional compilation heuristics , recently , simulated genetic algorithms work takes unique approach compiler optimizations neural networks reinforcement learning problem , whose solution takes fewer steps converge solution , dubbed release , comes sampling algorithm leverages clustering focus costly samples \( real hardware measurements \) representative points , entire subspace adaptive sampling reduces number samples , also improves quality samples better exploration shorter time , real hardware shows reinforcement learning adaptive sampling provides 4 speed optimization time , also improving inference time modern deep networks 5 6 experiments also confirm adaptive sampling even improve 's simulated 4
fast simple relational processing uncertain data paper introduces u relations , succinct purely relational representation system uncertain databases u relations support attribute level uncertainty using partitioning consider positive relational algebra extended operation computing possible answers , query logical level , evaluated , single relational algebra query u relation representation translation scheme essentially preserves size query terms number operations , particular , number standard techniques employed shelf relational database management systems effective optimizing processing queries u relations experiments show query evaluation u relations scales large amounts data high degrees uncertainty
less simultaneous view classification landmark detection ultrasound images ultrasound examination , common ultrasound examination , requires substantial manual efforts acquire standard views , views texts , record relevant measurements hence , automatic view classification landmark detection examination workflow however , challenging problem given inherent difficulties ultrasound modality , e g , low contrast large variations , also heterogeneity across tasks , e , one classification task views , one landmark detection task relevant view convolutional neural networks \( cnn \) demonstrated promising outcomes ultrasound image analytics traditional machine learning approaches , becomes impractical deploy multiple networks \( one task \) due limited computational memory resources existing ultrasound overcome limits , propose multi task learning framework handle tasks single network network integrated perform view classification landmark detection simultaneously also equipped global convolutional kernels , coordinate constraints , conditional adversarial module leverage performances experimental study based , ultrasound images , proposed simplified approach achieve \( 1 \) view classification accuracy better agreement two clinical experts \( 2 \) landmark based measurement errors par inter user variability multi task approach also benefits sharing feature extraction training process across tasks , result , outperforms approaches address task individually
localized dictionary design robust sonar advancements sonar image capture powerful classification schemes automatic target recognition \( recent work particularly seen application sparse reconstruction based classification \( src \) sonar , provides compelling accuracy rates even presence noise existing sparsity based sonar techniques however assume test images exhibit geometric pose consistent respect training set work addresses outstanding open challenge handling posed test sonar images relative training develop new localized block based dictionary design enable geometric , e pose robustness , dictionary learning method incorporated increase performance efficiency proposed src localized pose management \( \) , shown outperform state art feature svm approach , due power background clutter sonar images
lower bounds searching cell probe model consider fundamental problem data structures , static searching given subset size n , store queries form x \? efficiently study problem cell probe model introduced recently , beame obtained optimal bounds number needed deterministic query scheme associated storage scheme uses n \( 1 \) cells word size \( log \) \( 1 \) bits give new lower bound proof problem matches bounds beame lower bound proof following advantages works query schemes , beame 's proof works deterministic query schemes also extends address query schemes define paper , simpler beame 's proof prove lower bound using round elimination approach , , using tools information theory , prove strong round elimination lemma communication complexity enables us obtain tight lower bound problem strong round elimination lemma also extends quantum communication complexity also use round elimination lemma obtain rounds versus communication tradeoff problem , improving tradeoff et al believe round elimination lemma independent interest applications
cartesian stiffness matrix manipulators passive analytical approach paper focuses stiffness matrix computation manipulators passive proposes explicit analytical expressions efficient recursive procedure applicable general case allow obtaining desired matrix either analytical numerical form advantages developed technique ability produce singular non singular stiffness matrices illustrated application examples deal stiffness modeling two platforms
open challenges understanding development evolution speech forms roles self organization motivation active exploration article discusses open scientific challenges understanding development evolution speech forms , et al \( et al , 2015 \) based analysis mathematical models speech forms , focus assumptions , study fundamental question speech formed non speech , evolutionary scales particular , importance self organization , well role mechanisms motivation active driven exploration speech formation finally , discuss evolutionary perspective speech
boosting spatial reuse via multiple path multihop scheduling directional mmwave huge bandwidth available parts world , millimeter wave \( mmwave \) communications 60 band considered one promising candidates support wireless services due high propagation loss mmwave channels , beamforming likely adopted essential technique consequently , transmission 60 band inherently directional enables concurrent transmissions \( spatial reuse \) , fully exploited improve network capacity paper , propose multipath multihop scheduling scheme , known multipath multihop \( \) , mmwave wireless personal area networks \( \) , traffic across links low channel quality transmitted multiple paths multiple potential spatial reuse formulate problem mixed integer linear program \( \) , generally np hard enable implementation multipath multihop transmission practice , propose heuristic scheme including path selection , traffic distribution , efficiently solve formulated problem finally , extensive simulations , demonstrate achieves near optimal network performance terms transmission delay throughput enhances network performance significantly , compared existing protocols
data definitions present data definition framework enables convenient specification data types , primary motivation developing data definition framework teaching students reason programs using provide effective method defining , testing , reasoning data types context theorem framework routinely used purposes , also advanced users r n framework supports common data definition patterns , e g list types , map types , record types also provides support functions feature approach maintain characterization data definitions r n paper present data definition framework via sequence examples give complete characterization terms rules relations data definition induces , suitable restrictions data definition framework key component generation support , independently used , available community book
interference removal radar communication co existence random scattering case paper consider un cooperative spectrum sharing scenario , wherein radar system pre existing wireless communication system given order magnitude transmitted play , focus issue interference mitigation communication receiver explicitly account produced \( typically high power \) radar transmitter whose signal scattering centers \( whether targets clutter \) producing interference onto communication receiver , assumed operate un un scenario first show receiver design amounts solving non convex problem joint interference removal data next , introduce two algorithms , exploiting sparsity proper representation interference vector containing errors data block first algorithm relaxed constrained atomic norm minimization , latter relies two stage processing structure based alternating minimization algorithms demonstrated extensive simulations interestingly , two stage alternating minimization algorithm turns achieve satisfactory performance moderate computational complexity
community detection interaction networks many applications , common practice obtain network interaction counts thresholding pairwise count value analysis calls attention dependence certain methods , notably modularity , choice threshold essentially , threshold either network clusters automatically , making algorithm 's trivial , structure data , rendering clustering impossible fitting original interaction counts given , show minor modifications classical statistical methods outperform approaches community detection interaction datasets also introduce new hidden markov model inferring community structures vary time demonstrate features three real datasets club dataset , voting data u \( \) , temporal voting data u \( 2004 \)
robust nonlinear regression greedy approach employing kernels application image denoising consider task robust nonlinear regression presence noise outliers assuming unknown nonlinear function reproducing kernel space , goal estimate set associated unknown parameters due presence outliers , common techniques kernel ridge regression \( \) support vector regression turn inadequate instead , employ sparse modeling arguments explicitly model estimate outliers , adopting greedy approach proposed robust scheme , e , kernel greedy algorithm robust denoising \( \) , inspired classical orthogonal matching \( \) algorithm specifically , proposed method task like selection step theoretical results concerning identification outliers provided moreover , compared cutting edge methods , performance evaluated via set experiments various types noise finally , proposed robust estimation framework applied task image denoising , enhanced performance presence outliers demonstrated
characterizing cryptocurrency exchange scams indispensable trading platforms ecosystem , cryptocurrency exchanges emerging facilitate trading digital assets , also attackers number attacks reported targeting cryptocurrency exchanges , leading huge financial loss however , previous work research community systematically studied problem paper , make first effort identify characterize cryptocurrency exchange scams first identify 1 , 500 domains fake , collecting existing reports using generation techniques investigate relationship , identify 94 domain families 30 fake app families characterize impacts scams , reveal scams financial loss us least observe fake major app markets \( including google play \) users findings demonstrate identify prevent cryptocurrency exchange scams facilitate future research , publicly released identified domains fake community
gray box adversarial training adversarial samples perturbed inputs crafted machine learning systems training mechanism , called adversarial training , presents adversarial samples along clean samples introduced learn robust models order scale adversarial training large datasets , perturbations crafted using fast simple methods \( e g , gradient \) however , shown adversarial training converges minimum , model appears robust generating weaker adversaries result , models vulnerable simple black box attacks paper , \( \) demonstrate existing evaluation policy , \( ii \) introduce novel variants white box black box attacks , dubbed gray box adversarial attacks based propose novel evaluation method assess robustness learned models , \( iii \) propose novel variant adversarial training , named adversarial training uses intermediate versions models seed adversaries experimental evaluation demonstrates models trained using method exhibit better robustness compared trained model
deep zero shot learning scene sketch introduce novel problem scene sketch zero shot learning \( \) , challenging task , since \( \) different photo , gap common semantic domain \( e g , word vector \) sketch huge exploit common semantic knowledge bridge knowledge transfer , \( ii \) compared single object sketch , expressive feature representation scene sketch required accommodate high level abstraction complexity overcome challenges , propose deep embedding model scene sketch zero shot learning particular , propose augmented semantic vector conduct domain alignment fusing multi modal semantic knowledge \( e g , image , natural image , text description \) , adopt attention based network scene sketch feature learning moreover , propose novel distance metric improve similarity measure testing extensive experiments studies demonstrate benefit sketch specific design
recovery sequences subsequences case non periodic spectrum gaps paper investigates sequences periodic subsequences offers modification approach suggested papers arxiv arxiv shown exists class sequences dense class square sequences members recovered periodic subsequences associated certain spectrum new kind
less comprehensive framework number components ensemble classifiers number component classifiers chosen ensemble greatly impacts prediction ability paper , use geometric framework priori determining ensemble size , applicable existing batch online ensemble classifiers limited number studies ensemble size examining majority voting \( mv \) weighted majority voting \( \) almost designed batch mode , addressing online environments big data dimensions resource limitations , terms time memory , make determination ensemble size crucial , especially online environments mv aggregation rule , framework proves strong components add ensemble , accurate predictions achieve aggregation rule , framework proves existence ideal number components , equal number class labels , components completely independent strong enough giving exact definition strong independent classifier context ensemble challenging task , proposed geometric framework provides theoretical explanation diversity impact accuracy predictions conduct series experimental evaluations show practical value theorems existing challenges
investigation analysis hyper neuron pruning selectively update neurons unsupervised adaptation unseen domain data performance neural network model , indicating model 's failure generalize unseen data neural net pruning help reduce model 's size improve model 's generalization capacity well pruning approaches look low salient neurons less model 's decision hence removed model work investigates pruning approaches successful detecting neurons either high salient \( mostly active hyper \) low salient \( active \) , whether removal neurons help improve model 's generalization capacity traditional blind adaptation techniques update either whole subset layers , never explored selectively individual neurons across one layers focusing fully connected layers convolutional neural network \( cnn \) , work shows may possible selectively adapt certain neurons \( consisting hyper neurons \) first , followed full network fine tuning using task automatic speech recognition , work demonstrates removal hyper neurons model improve model 's performance domain speech data selective neuron adaptation ensure improved performance compared traditional blind model adaptation
gender bias resolution present empirical study gender bias resolution systems first introduce novel , schema style set minimal pair sentences differ gender schemas , evaluate confirm systematic gender bias three publicly available resolution systems , bias real world textual gender statistics
expected path length random manifolds manifold learning seeks low dimensional representation captures data current methods successfully learn representations , provide meaningful set operations associated representation working towards operational representation learning , latent space large class generative models random riemannian metric , provides us elementary operators computational tools unavailable random riemannian manifolds , study deterministic approximations derive tight error bounds expected distances
scheduling policies minimizing age information broadcast wireless networks consider wireless broadcast network base station sending time sensitive information number clients unreliable channels age information \( aoi \) , namely amount time since recently packet generated , captures information formulate discrete time decision problem find transmission scheduling policy minimizes expected weighted sum aoi clients network r n first show symmetric networks greedy policy , packet highest current age , optimal general networks , develop three low complexity scheduling policies randomized policy , max weight policy 's index policy , derive performance guarantees function network configuration best knowledge , first work derive performance guarantees scheduling policies attempt minimize aoi wireless networks unreliable channels numerical results show max weight 's index policies outperform scheduling policies every configuration simulated , achieve near optimal performance
deep representation learning clustering health tweets twitter prominent social media platform mining population level health data accurate clustering health related tweets topics important extracting relevant health insights work , propose deep convolutional autoencoders learning compact representations health related tweets , employed clustering compare method several conventional representation methods including words , term frequency inverse document frequency , latent allocation non negative matrix factorization 3 different clustering algorithms results show clustering performance using proposed representation learning scheme significantly outperforms conventional methods experiments different number clusters addition , propose constraint learned representations neural network training order enhance clustering performance , study introduces utilization deep neural network based architectures , e , deep convolutional autoencoders , learning informative representations health related tweets
lattice gaussian sampling markov chain monte carlo convergence rate decoding complexity sampling lattice gaussian distribution efficient way solving closest vector problem \( \) lattice decoding paper , decoding based lattice gaussian sampling investigated full details first , spectral gap transition matrix markov chain induced independent \( \) algorithm derived , exponential convergence rate target lattice gaussian distribution , decoding complexity derived \( e 2 \( lambda , mathbf c \) min 2 mathbf b \) , \( lambda , mathbf c \) represents euclidean distance query point mathbf c lattice lambda , mathbf b vector lattice basis mathbf b furthermore , decoding radius perspective bounded distance decoding \( \) given fixed number markov also derived , flexible trade decoding performance complexity finally , taking advantages k samples proposal distribution , independent multiple try \( \) algorithm proposed enhance exponential convergence rate adjusting k , independent sampler enjoys flexible decoding performance , independent algorithm case k 1 additionally , proposed decoding allows fully parallel implementation , beneficial practical interest
machine learning ac optimal power flow explore machine learning methods ac optimal \( \) task optimizing power generation transmission network according physical engineering constraints present two formulations machine learning problem 1 \) end end prediction task directly predict optimal generator settings , 2 \) constraint prediction task predict set active constraints optimal solution validate approaches two benchmark grids
kernel bounds structural pathwidth assuming distillation conjecture , pathwidth problem determining whether given graph g pathwidth k admits polynomial kernelization respect k present work studies existence polynomial kernels pathwidth respect , structural , parameters r n r n main result , unless np poly , pathwidth admits polynomial kernelization even parameterized vertex deletion distance clique , giving cross composition cross composition works also treewidth , improving previous lower bounds present authors pathwidth , result rules polynomial kernels respect distance various classes polynomial time solvable inputs , like interval cluster graphs r n r n leads question whether nontrivial structural parameters pathwidth admit polynomial kernelization answer , give collection graph reduction rules safe pathwidth analyze success results obtain polynomial respect following parameters size vertex cover graph , vertex deletion distance graph connected component star , vertex deletion distance graph connected component c vertices
representation mapping novel approach generate high quality multi lingual emotion past years , sentiment analysis increasingly shifted attention representational frameworks expressive semantic polarity \( positive , negative neutral \) however , formats \( like basic emotions , variants \) , rooted psychological research , tend number representation schemes emotion encoding thus , large amount emotion developed various research groups adopting one emotion representation format consequence , resources decreases systems using paper , propose solve methods tools map different representation formats onto mutual compatibility language resources present first large scale investigation representation mappings four diverse languages find evidence approach produces \( near \) quality emotion , even cross lingual settings finally , use models create new eight diverse languages
autoencoders unsupervised disentangling shape appearance work introduce autoencoders , generative model images shape appearance unsupervised manner template paradigm , shape represented canonical coordinate system \( \) observed image , appearance modeled , template , coordinates , thus variability due introduce novel techniques allow approach deployed setting autoencoders show method used unsupervised group wise image alignment show experiments expression humans , hands , , face manipulation , shape appearance interpolation , well unsupervised landmark localization powerful form unsupervised disentangling becomes possible template coordinates , allowing us successfully decompose face images , face images
design modelling control novel robot drive system current problem design small lightweight autonomous robots create sufficient traction soil implement load one promising solution offered drive system , spikes soil create traction combination soil spikes push design offers new vehicle control controlling spikes pushing main frame , vehicle perform tight validate idea , designed robot , capable creating high traction performing turns navigation new robot system performed actively pushing spikes , mounted soil , main frame back forward vehicle 2 length able turn , could follow straight line , using spikes push mechanism trajectory performed measurements suggest , vehicle uses spikes traction steering fully capable performing autonomous tasks fields
machine learning much current machine learning \( ml \) research lost connection problems larger world science perspective , exist limitations data sets investigate , metrics employ evaluation , degree results back domains changes needed conduct research increase impact ml \? present six impact challenges explicitly focus field \? energy attention , discuss existing obstacles must addressed aim ongoing discussion focus ml
hierarchical attention based recurrent highway networks time series prediction time series prediction studied variety domains however , still challenging predict future series given historical observations past exogenous data existing methods either fail consider interactions among different components exogenous variables may affect prediction accuracy , cannot model correlations exogenous data target data besides , inherent temporal dynamics exogenous data also related target series prediction , thus considered well address issues , propose end end deep learning model , e , hierarchical attention based recurrent highway network \( \) , incorporates spatio temporal feature extraction exogenous variables temporal dynamics modeling target variables single framework moreover , introducing hierarchical attention mechanism , adaptively select relevant exogenous features different semantic levels carry comprehensive empirical evaluations various methods several datasets , show outperforms state arts time series prediction , especially capturing changes time series
rewriting modulo modulo study termination rewriting modulo set equations calculus algebraic constructions , extension calculus constructions functions predicates defined higher order rewrite rules previous work , defined general syntactic conditions based notion computable closure ensuring termination combination rewriting beta reduction , show result preserved considering rewriting modulo set equations equivalence classes generated equations finite , equations linear satisfy general syntactic conditions also based notion computable closure includes equations like commutativity , provides original treatment termination modulo equations
parties logistic choice analysis inter intra group citation dynamics 2004 us presidential election 2004 us presidential election cycle marked internet based media social networking websites recognized features political landscape using longitudinal sample citation networks able test various strategic , , balance theoretic mechanisms exogenous factors political events propensity cite one another time temporal resolution data , utilize autoregressive network regression framework carry inference logistic choice process using combination based model selection criteria simulation based model adequacy tests , identify combination processes best choice behavior
learning detect vehicles clustering appearance patterns paper studies efficient means dealing intra category diversity object detection strategies occlusion orientation handling explored learning ensemble detection models visual clusters object instances detection scheme employed pixel features fast detection analysis provides insight design robust vehicle detection system , showing promise terms detection performance orientation estimation accuracy
graph neural networks attention mechanism session based recommendation problem personalized session based recommendation aims predict users' next click based sequential behaviors existing session based recommendation methods consider sessions user single sequence , ignoring relationship among sessions , complex transitions items collaborative relationship users items end , propose novel method , named graph neural networks attention mechanism , mainly consists two components one graph neural network \( \) , used capture complex transitions user session sequence compared traditional graph neural network \( \) model , also considers role users sequence product attention mechanism , attention mechanism machine translation explicitly model effect historical sessions current session two parts make possible learn multi level transition relationships items sessions user specific fashion extensive experiments conducted two real world data sets show significantly outperforms state art session based recommendation methods consistently
qos using hybrid fso rf based hierarchical model wireless multimedia sensor networks objective provide guaranteed packet delivery service time constrained sensor networks wireless network highly variable environment , available link bandwidth may vary network load since multimedia applications require higher bandwidth use fso links transmission main advantage fso links offer higher bandwidth security , rf links offer reliability routing network based directional routing protocol , sensors route data via multihop paths , powerful base station , cluster head modifications also incorporated mac layer improve qos systems
bounds list decoding rank metric codes far , polynomial time list decoding algorithm \( beyond half minimum distance \) codes codes seen rank metric equivalent solomon codes paper , provide bounds list size rank metric codes order understand whether polynomial time list decoding possible whether works exponential time complexity three bounds list size proven first one lower exponential bound codes shows codes polynomial time list decoding beyond johnson radius exists second , exponential upper bound derived , holds rank metric code length n minimum rank distance third bound proves exists rank metric code length n list size exponential length radius greater half minimum rank distance implies cannot exist polynomial upper bound depending n similar johnson bound hamming metric three rank metric bounds reveal significant differences bounds codes hamming metric
disease supervised adaptable 3d convolutional network early diagnosis , playing important role preventing progress treating 's disease \( ad \) , based classification features extracted brain images features accurately capture main ad related variations brain structures , , e g , size , shape , thickness , brain volume paper proposes predict ad deep 3d convolutional neural network \( 3d cnn \) , learn generic features capturing ad adapt different domain datasets 3d cnn built upon 3d convolutional autoencoder , pre trained capture shape variations structural brain scans fully connected upper layers 3d cnn fine tuned task specific ad classification experiments emph dataset preprocessing shown 3d cnn outperforms several conventional classifiers accuracy robustness abilities 3d cnn generalize features learnt adapt domains validated emph dataset
global scheduling multi mode real time applications upon platforms multi mode real time systems support applications different modes operation , mode characterized specific set tasks run time , systems , time , switch current operating mode another mode \( called new mode \) replacing current set tasks new mode thereby , ensuring timing requirements requires test performed tasks mode also \( \) protocol one mode another specified \( ii \) test transition performed propose two distinct protocols manage mode transitions upon uniform identical platforms run time , specific distinct task requirements protocol , formally establish analyses indicate whether timing requirements mode transition system performed assuming fixed task priority fixed priority schedulers
transfer learning based label method data uncertainty learning label \( llp \) , learning task provides unlabeled data 's label , widespread successful applications practice however , existing llp methods n't consider knowledge transfer uncertain data paper presents transfer learning based approach problem learning label \( llp \) transfer knowledge source task target task source target tasks contain uncertain data approach first objective model uncertain data deals transfer learning time , proposes iterative framework build accurate classifier target task extensive experiments shown proposed llp method obtain better accuracies less sensitive noise compared existing llp methods
parallel algorithms mapreduce framework applications parallel computational geometry paper , describe efficient mapreduce simulations parallel algorithms specified models also provide applications simulation results problems parallel computational geometry mapreduce framework , result efficient mapreduce algorithms sorting , 1 dimensional nearest neighbors , 2 dimensional convex , 3 dimensional convex , fixed dimensional linear programming case buffer size b \( n epsilon \) , small constant epsilon 0 , mapreduce algorithms applications run constant number rounds linear sized message complexity , high probability , guaranteeing high probability lists size \( b \)
necessary sufficient conditions surrogate functions pareto frontiers synthesis using gaussian processes paper introduces necessary sufficient conditions surrogate functions must satisfy properly define frontiers non solutions multi objective optimization problems new conditions work directly objective space , thus agnostic solutions evaluated therefore , real objectives user designed surrogates allowed , possibility linking independent objective surrogates illustrate practical consequences adopting proposed conditions , use gaussian processes surrogates monotonicity soft constraints degree flexibility , compare regular gaussian processes frontier surrogate method literature closest method proposed paper results show necessary sufficient conditions proposed managed constrained gaussian process , high quality surrogates capable synthesizing approximation pareto frontier challenging instances multi objective optimization , existing approach take theory proposed consideration defines surrogates greatly conditions describe valid frontier
weakly supervised disentangling recurrent transformations 3d view synthesis important problem graphics vision synthesize novel views 3d object single image particularly challenging due partial observability inherent 3d object onto image space , ill inferring object shape pose however , train neural network address problem attention specific object categories \( case faces \) training data paper , propose novel recurrent convolutional encoder decoder network trained end end task rendering objects starting single image recurrent structure allows model capture long term dependencies along sequence transformations demonstrate quality predictions human faces multi dataset dataset 3d chair models , also show ability latent factors variation \( e g , identity pose \) without using full supervision
simple fusion deep shallow learning acoustic scene classification past , acoustic scene classification systems based hand audio features input classifier nowadays , common trend adopt data driven techniques , e g , deep learning , audio representations learned data paper , propose system consists simple fusion two methods aforementioned types deep learning approach log scaled input convolutional neural network , feature engineering approach , collection hand crafted features input gradient boosting machine first show methods provide complementary information extent , use simple fusion strategy combine methods report classification accuracy method individually combined system acoustic scenes 2017 dataset proposed fused system outperforms individual methods classification accuracy 72 8 evaluation set , improving baseline system 11 8
probabilistic nearest neighbor queries uncertain moving object trajectories nearest neighbor \( nn \) queries trajectory databases received significant attention past , due application spatio temporal data analysis recent work considered realistic case trajectories uncertain however , simple uncertainty models proposed , allow accurate probabilistic search paper , gap addressing probabilistic nearest neighbor queries databases uncertain trajectories modeled stochastic processes , specifically markov chain model study three nearest neighbor query semantics take input query state trajectory q time interval queries , show polynomial time solution found problems solved , present exact query evaluation algorithms , general case , propose sophisticated sampling approach , uses bayesian inference guarantee sampled trajectories observation data stored database sampling approach used monte carlo based approximation solutions include extensive experimental study support theoretical results
evaluating effect generative adversarial networks generative adversarial networks \( gan \) present state art results generation samples following distribution input dataset however , gans difficult train , several aspects model previously designed hand neuroevolution well known technique used provide automatic design network architectures recently expanded deep neural networks model uses neuroevolution gan training algorithm provide stable training method automatic design neural network architectures makes use adversarial aspect gan components implement strategies training algorithm proposal evaluated fashion mnist mnist dataset compare results baseline based also results random search algorithm show method able discover efficient architectures fashion mnist mnist datasets results also suggest used training algorithm gans avoid common issues , mode collapse problem
sparse support recovery non smooth loss functions paper , study support recovery guarantees sparse regression using ell 1 norm regularizer non smooth loss function data fidelity precisely , focus detail cases ell 1 ell infty losses , contrast usual ell 2 loss losses routinely used account either sparse \( ell 1 loss \) uniform \( ell infty loss \) noise models , theoretical analysis performance still lacking article , extend existing theory smooth ell 2 case non smooth cases derive sharp condition ensures support vector recover stable small additive noise observations , long loss constraint size tuned proportionally noise level feature theory also support support stable , identify extended support show extended support stable small additive noise usefulness theory , give detailed numerical analysis support stability instability compressed sensing recovery different losses highlights different parameter regimes , ranging total support stability progressively increasing support instability
worse spam issues sampling software developers background reaching professional software developers crucial part empirical software engineering research one important method investigate state practice survey research random sample professional software developers survey possible , researchers rely various sampling strategies objective paper , report experience different sampling strategies employed , highlight issues , need maintain collection key demographics software developers assessment external validity studies method report based data two studies conducted past results developers public media proved effective efficient sampling strategy however , describe perspective researchers interested reaching goals like large number participants high response rate , also shed light onto implications different sampling strategies present one specific point debates research communities start discussion software engineering research community sampling strategies considered
learning serve experimental study new learning demonstrations framework learning demonstrations easy intuitive way show examples successful behavior robot however , fact humans optimize take advantage body robot , usually called problem robotics , often industrial robots executing task straightforward way shown movements often cannot utilize degrees freedom robot efficiently , moreover suffer execution errors letter , explore variety solutions address particular , learn sparse movement primitive parameters several demonstrations successful table serve number parameters learned using procedure independent degrees freedom robot moreover , ranked according importance regression task learning parameters , ranked , desirable feature combat curse dimensionality reinforcement learning real robot experiments table serve using learned movement primitives show representation capture successfully style movement parameters
automated detection classification cryptographic algorithms binary programs machine learning threats internet , particularly malicious software \( e , malware \) often use cryptographic algorithms actions even take control 's system \( case \) malware threats quickly time consuming traditional methods binary analysis effective detection classification cryptographic algorithms , speed program analysis efficiently combat malware r n thesis present several methods leveraging machine learning automatically discover classify cryptographic algorithms binary programs r n work necessary fully evaluate methods real world binary programs , results paper suggest machine learning used successfully detect identify cryptographic primitives code currently , techniques successfully detect classify cryptographic algorithms small single purpose programs , work proposed apply real world examples
enhanced channel estimation massive mimo via pilot design pilot contamination limiting factor massive multiple input multiple output \( mimo \) systems severely channel estimation prior works suggested pilot design across cells order reduce channel estimation error caused pilot contamination propose method pilot design using fractional programming minimize weighted mean squared error \( \) channel estimation particular , apply recently proposed quadratic transform expression allows effect pilot contamination expression resulting problem enables optimized closed form designed arbitrarily restricted given set orthogonal sequences , pilot optimization reduces assignment problem solved weighted bipartite matching furthermore , matrix fractional programming , obtain extension proposed method takes correlated rayleigh fading account finally , simulations demonstrate significant advantage proposed \( orthogonal \) pilot designs compared state art methods pilot contamination
canonical logic programs succinctly propositional formulas emph canonical \( logic \) programs \( cp \) refer normal logic programs augmented paper address question whether cp emph succinctly emph propositional formulas \( pf \) main result shows parity problem , represented pf emph exponential representations cp words , parity emph pf cp simply speaking , means exponential size generally inevitable translating set formulas pf equivalent program cp \( without introducing new variables \) furthermore , since shown also problem cp pf \( assuming mathsf p mathsf nc 1 poly \) , follows cp pf indeed succinctly view theory computation , result may also considered separation two emph models computation , e , identify language mathsf nc 1 poly set languages computable polynomial size cp programs
methods detecting paraphrase plagiarism paraphrase plagiarism one difficult challenges facing plagiarism detection systems occur texts look different , retain original meaning plagiarism detection systems \( many commercial based \) designed detect word co light modifications , unable detect severe semantic structural seen many academic documents hence many paraphrase plagiarism cases go paper , problem paraphrase plagiarism proposing methods detecting common techniques \( phenomena \) used texts \( namely lexical substitution , deletion word phrase \) , combined methods paraphrase detection model evaluated proposed methods model collections containing paraphrase texts experimental results show significant improvement performance methods combined \( proposed model \) running individually results also show proposed paraphrase detection model outperformed standard baseline \( based greedy string \) , previous studies
classification upper movements using convolutional neural network 3d inception block brain machine interface \( \) based \( eeg \) overcome movement patients real world applications healthy people ideally , system detects user movement transforms control signal robotic arm movement study , made progress toward user intention decoding successfully classified six different reaching movements right arm movement execution \( \) notably , designed experimental environment using robotic arm movement proposed convolutional neural network architecture \( cnn \) inception block robust classify executed movements result , confirmed classification accuracies six different directions show 0 executed session results proved proposed architecture approximately 6 13 performance increase compared conventional classification models hence , demonstrate 3d inception cnn architecture contribute continuous decoding
prospect theoretic analysis privacy preserving mechanism study problem privacy preserving mechanism design data collector obtain data individuals perform computations privacy threat , data collector adopts privacy preserving mechanism adding random noise computation result , cost reduced accuracy individuals decide whether contribute data faced privacy issue due intrinsic uncertainty privacy protection , model privacy related decision using prospect theory theory accurately models behavior uncertainty traditional expected utility theory , whose prediction always practical human behavior show data collector 's utility maximization problem involves polynomial high fractional order , root difficult compute analytically get around issue considering large population approximation , obtain closed form solution well approximates precise solution discover data collector considers realistic prospect theory based individual decision modeling would adopt conservative privacy preserving mechanism , compared case based expected utility theory modeling also study impact prospect theory parameters , concludes loss risk seeking individuals conservative mechanism individuals different prospect theory parameters , simulations demonstrate privacy protection first becomes stronger becomes weaker heterogeneity increases low value high one
joint cell user scheduling multi cell networks temporal fairness semi centralized joint cell user scheduling scheme interference coordination network proposed two different temporal fairness criteria main principle behind proposed scheme central entity selects cell pattern pattern set decision instant , subsequently un base stations schedule users associated cells , decisions made temporal fair basis although pattern sets easily static frequency reuse systems , propose general pattern set construction algorithm paper first fairness criterion , cells assigned receive temporal share ratio temporal share cell center section cell edge section set fixed desired value cells second fairness criterion based max min temporal fairness temporal share network wide worst case user numerical results provided validate effectiveness proposed scheme criteria impact choice cell pattern set also studied numerical examples various cellular topologies
ecg classification using 2 convolutional neural network paper , propose effective \( ecg \) classification method using deep two dimensional convolutional neural network \( cnn \) recently shows outstanding performance field pattern recognition every ecg transformed two dimensional image input data cnn classifier optimization proposed cnn classifier includes various deep learning techniques batch normalization , data augmentation , initialization , dropout addition , compared proposed classifier two well known cnn models ecg mit database used evaluation classifier result , classifier achieved 99 average accuracy 97 85 average sensitivity precisely validate cnn classifier , 10 fold cross validation performed evaluation involves every ecg test data experimental results successfully validated proposed cnn classifier transformed ecg images achieve excellent classification accuracy without manual pre processing ecg signals noise filtering , feature extraction , feature reduction
exploiting massive d2d collaboration energy efficient mobile edge computing article propose novel device device \( d2d \) crowd framework 5g mobile edge computing , massive crowd devices network edge leverage network assisted d2d collaboration computation communication resource sharing among key objective framework achieve energy efficient collaborative task network edge mobile users specifically , first introduce d2d crowd system model details , formulate energy efficient d2d crowd task assignment problem taking account necessary constraints next propose graph matching based optimal task assignment policy , evaluate performance extensive numerical study , shows superior performance 50 energy consumption reduction case local task finally , also discuss directions extending d2d crowd framework taking variety application factors
full duplex hybrid beamforming reduced complexity multi tap analog cancellation although hardware complexity analog self interference emerging full duplex multiple input multiple output \( mimo \) designs scale number transceiver antennas , exploiting benefits analog cancellation massive mimo systems antennas still quite impractical hybrid analog digital \( \) beamforming architectures considered candidate technology massive mimo large number antenna elements , much fewer numbers radio frequency \( rf \) chains paper , present novel architecture full duplex hybrid including multi tap analog cancellation reduced number simple efficient signal routing among transceiver rf chains proposed transceiver architecture , present joint design analog cancellation beamforming objective maximize full duplex rate performance representative computer simulation results millimeter wave channel model demonstrate effectiveness proposed architecture algorithmic framework enabling simultaneous uplink downlink communications reduced complexity analog cancellation
flips edge labelled pseudo triangulations show \( n 2 \) flips transform edge labelled pseudo triangulation set labels using , deletion flips , transform edge labelled pseudo triangulation \( n log c h log h \) flips , c number convex layers h number points convex
towards consumer centric grid behavioral perspective active consumer seen integral part emerging smart grid examples include demand side management programs , consumer energy storage energy units , active energy trading however , despite technological benefits consumer centric grid features , date , widespread adoption practice remains modest shed light challenge , paper explores potential prospect theory , winning theory , decision making framework help understand risk uncertainty impact decisions smart grid consumers introducing basic notions prospect theory , several examples drawn number smart grid applications developed results show better understanding role human decision making within smart grid optimizing operation deployment various technologies
instruments exploring innovation dynamics technological perspectives cells dynamics innovation nonlinear complex geographical , technological , economic selection environments expected interact provide analytical lens process terms different attributes addresses , classification codes , backward forward , etc \? two recently developed patent maps interactive overlay techniques google maps maps based citation relations among international patent classifications \( \) dynamic versions allow online comparisons using split various forms explored recently developed cooperative patent classifications \( \) u patent trade office \( \) patent office \( \) provide new options precise samples data patent statistics database \( \) among technologies mitigation change \( class \) , nine material technologies cells focus one \( \) lead case longitudinal development rao diversity based maps provides heuristics studying technological generations period study \( 2012 \) generations data data aggregates patent information countries different stages technological development , whereas one competitive technological edge
media selection highlights presidential debates political debates play important role shaping images , public often relies media outlets select bits political communication large pool utterances important research question understand factors impact selection process quantitatively explore selection process , build three decade dataset presidential debate post debate coverage first examine effect propose binary classification framework controls speaker debate situations find achieve accuracy 60 task , indicating media choices entirely obvious classifiers outperform average , mainly primary debates also compare important factors free responses data driven methods find interesting differences mentioned context , whereas data show well sentences distinct previous utterance speaker less sentences finally , examine aggregate effect media preferences towards different understand extent among media outlets analyzing bipartite graph built behavior data , observe decreasing trend coverage
deep generative model sparse graphs using text based learning augmentation generative examination networks graphs networks key research tool variety science fields , notably , biology , engineering social modeling generation graphs efficient sampling key challenge graphs particular , non uniqueness , high dimensionality vertices local dependencies edges may render task challenging apply recently introduced method , generative examination networks \( \) create first text based generative graph models using one line text formats graph representation , rnn generative model one line text format learns predict next available character training examination mechanism checking validating valid graphs generated achieved moderate high validity using dense strings \( random 67 8 0 6 , canonical 99 1 0 2 \) based results adapted widely used representation new input format , call linear graph input \( \) apart benefits short text format , major advantage include possibility augment format generative models evaluated overall performance reconstruction property space results show strings well suited machine learning augmentation essential performance model terms validity , uniqueness novelty lastly , format address smaller larger dataset graphs format easily adapted define another meaning characters used string address sparse graph problems used fields science
changing assembly modes without passing parallel singularities non 3 r p r planar parallel robots paper demonstrates general 3 dof three planar parallel robot change assembly modes without passing parallel singularities \( configurations mobile platform stiffness \) results purely theoretical , paper questions definition parallel singularities
computational intractability exact approximate dictionary learning efficient sparse coding reconstruction signal vectors via linear observations received tremendous amount attention last decade context , automated learning suitable basis dictionary training data sets certain signal classes use sparse representations particular importance regarding practical signal processing applications popular dictionary learning algorithms involve np hard sparse recovery problems iteration , may give complexity dictionary learning constitute actual proof computational intractability technical note , show learning dictionary given set training signals represented possible indeed np hard moreover , also establish hardness approximating solution within large factors optimal sparsity level furthermore , give np hardness non approximability results recent dictionary learning variation called sensor permutation problem along way , also obtain new non approximability result classical sparse recovery problem compressed sensing
spatially weighted anomaly detection regression model visual anomaly detection common several applications including medical production quality check although definition anomaly unknown trend data , many cases samples anomaly class given advance conventional methods cannot use available anomaly data , also robustness noise paper , propose novel spatially weighted reconstruction loss based anomaly detection likelihood value regression model trained known data spatial weights calculated region interest generated employing visualization regression model introduce ways combine various strategies propose state art method comparing methods three different datasets , empirically verify proposed method performs better others
active learning deep object detection great success deep models achieved past mainly large amounts labeled training data however , acquisition labeled data new tasks existing benchmarks challenging costly active learning make process labeling new data efficient selecting unlabeled samples , labeled , expected improve model paper , combine novel method active learning object detection incremental learning scheme enable continuous exploration new unlabeled datasets propose set uncertainty based active learning metrics suitable object detectors furthermore , present approach leverage class sample selection methods evaluated systematically continuous exploration context pascal voc 2012 dataset
two fold radius 1 hamming graphs lambda fold r packing hamming metric space code c radius r centered c cover vertex space lambda times well known r error correcting codes case lambda 1 propose asymptotic bounds q 2 fold 1 q grows , find maximum size binary 2 fold 1 packing length 9 96 , derive upper bounds size binary lambda fold 1 packing
limits dense packing equal spheres cube examine packing n spheres cube n close less number spheres regular cubic close packed \( \) arrangement p 3 2 spheres family , previous best known usually derived certain number spheres without changing initial structure paper , show better exist n leq p 3 2 2 introduce optimization method reveal improvements , present many new improvements n
extended answer uncertainty aware neural question generation paper , study automatic question generation , task creating questions corresponding text passages certain text serve answers propose extended answer aware network \( \) trained word based coverage mechanism \( \) decodes uncertainty aware beam search \( \) represents target answer sentence encoder , incorporates information extended answer representation gated answer attention tackle problem inadequate representation target answer reduce repetition , attending words different time steps training stage aims seek better balance model confidence words input text confidence generating words vocabulary conduct experiments squad dataset , results show approach achieves significant performance improvement
underwater color restoration using u net denoising autoencoder visual inspection underwater structures vehicles , e g vehicles \( \) , plays important role scientific , , commercial however , automatic extraction information using software tools characteristics quality captured videos contribution color underwater images , underwater denoising autoencoder \( \) model developed using denoising autoencoder u net architecture proposed network takes consideration accuracy computation cost enable real time implementation underwater visual tasks using end end autoencoder network underwater vehicles perception improved captured frames hence obtaining better performance underwater tasks related learning methods use generative adversarial networks \( gans \) generate color underwater images , knowledge paper first deal single autoencoder capable producing better results moreover , image pairs constructed training proposed network , hard obtain dataset underwater end , proposed model compared state art method
pyramid density aware attention net accurate crowd counting crowd counting , e , estimating number people crowded area , attracted much interest research community although many attempts reported , crowd counting remains open real world problem due vast scale variations crowd density within interested area , severe occlusion among crowd paper , propose novel pyramid density aware attention based network , , leverages attention , pyramid scale feature two branch decoder modules density aware crowd counting utilizes modules extract different scale features , focus relevant information , ones also address variation levels among different images density aware decoder \( \) purpose , classifier evaluates density level input features corresponding high low crowded modules finally , generate overall density map considering low high crowded density maps spatial attention meanwhile , employ two losses create precise density map input scene extensive evaluations conducted challenging benchmark datasets well demonstrate superior performance proposed terms accuracy counting generated density maps well known state arts
downlink coverage analysis heterogeneous cellular network paper , consider downlink signal interference plus noise ratio \( \) analysis heterogeneous cellular network k tier characterized base station \( bs \) arrangement according homogeneous poisson point process certain bs density , transmission power , random fading factors arbitrary distribution , arbitrary path loss exponent certain bias towards mobile station \( ms \) ms bs maximum instantaneous biased received power open access cell association scheme general setting , provide analytical characterization coverage probability ms
meta synthetic data one shot fine grained visual recognition one shot fine grained visual recognition often suffers problem training data new fine grained classes alleviate problem , shelf image generator applied synthesize additional training images , synthesized images often helpful actually improving accuracy one shot fine grained recognition paper proposes meta learning framework combine generated images original images , resulting training images improve one shot learning specifically , generic image generator updated training instances novel classes , meta image network \( \) proposed conduct one shot fine grained recognition well image reinforcement model trained end end manner , experiments demonstrate consistent improvement baselines one shot fine grained image classification benchmarks
approximation algorithms hardness k route cut problem study k route cut problem given undirected edge weighted graph g \( v , e \) , collection \( 1 , 1 \) , \( 2 , 2 \) , , \( r , r \) source sink pairs , integer connectivity requirement k , goal find minimum weight subset edges remove , connectivity every pair \( , \) falls k specifically , edge connectivity version , krc , requirement \( k 1 \) edge disjoint paths connecting g , vertex connectivity version , nc krc , requirement vertex disjoint paths prior work , poly logarithmic approximation algorithms known special case k 3 , non trivial approximation algorithms known value k 3 , except single source setting show \( k log 3 2 r \) approximation algorithm krc uniform edge weights , several polylogarithmic bi criteria approximation algorithms krc nc krc , connectivity requirement k constant factor complement upper bounds proving nc krc hard approximate within factor k eps fixed eps 0 r n turn study simpler version nc krc , one source sink pair present give simple bi criteria approximation algorithm case , show evidence even restricted version problem may hard approximate example , prove single source sink pair version nc krc constant factor approximation , assuming 's random k assumption
implementing large scale agile frameworks challenges recommendations based 13 agile transformation cases 15 years , article identifies nine challenges associated implementing safe , scale , , less , , mixed large scale agile frameworks challenges considered organizations large scale agile strategy article also provides recommendations practitioners agile researchers
jointly optimal beamforming previously proposed optimal \( maximum likelihood sense \) convolutional beamformer perform simultaneous denoising , showed superiority widely used filter conventional beamformer however , fully investigated components convolutional beamformer yield superiority end , paper presents new derivation convolutional beamformer allows us filter , special type \( non convolutional \) beamformer , referred beamformer , without loss optimality experiments , show superiority convolutional beamformer fact comes part
beyond multiplexing gain large mimo systems given common technical assumptions literature mimo system modeling , derive elementary results mutual information mimo system high snr large system limit consider mimo system r receive phi r transmit antennas phi 1 , removing many receive antennas obtain square system results mutual information loss per receive antenna solely given binary entropy function phi furthermore , calculate deviation growth mutual information linear growth versus number antennas show deviation additive mimo compound channels easily expressed terms transform spectrum channel matrix
weakly supervised video summarization hierarchical reinforcement learning conventional video summarization approaches based reinforcement learning problem reward received whole summary generated kind reward sparse makes reinforcement learning hard converge another problem labelling frame tedious costly , usually construction large scale datasets solve problems , propose weakly supervised hierarchical reinforcement learning framework , whole task several subtasks enhance summarization quality framework consists network worker network subtask , trained set task level binary label , requires much fewer labels conventional approaches guide , worker predicts importance scores video frames subtask policy gradient according global reward innovative defined sub rewards overcome sparse problem experiments two benchmark datasets show proposal achieved best performance , even better supervised approaches
identification wearable devices bluetooth wearable devices rise consumer market , wearables vital however , current security mechanisms focus validating user device indeed , wearables \( 1 \) wearable devices correct systems networks , \( 2 \) passive wearable devices , \( 3 \) information wearables devices fingerprinting via machine learning provide necessary cyber threat intelligence address cyber attacks work , introduce wearable fingerprinting technique focusing bluetooth classic protocol , common protocol used wearables iot devices specifically , propose non wearable device identification framework utilizes 20 different machine learning \( ml \) algorithms training phase classification process selects best performing algorithm testing phase furthermore , evaluate performance proposed wearable fingerprinting technique real wearable devices , including various shelf evaluation demonstrates feasibility proposed technique provide reliable cyber threat intelligence specifically , detailed accuracy results show average 98 5 , 98 3 precision recall identifying wearables using bluetooth classic protocol
experience report applying software testing academic results industry need automated test generation impact software engineering research current practices industry \? paper , report direct experience post working software engineering research projects , following five years two different companies \( first one collaboration post \) given background software engineering research , cutting edge techniques tools academia use daily work developing testing systems companies \? regarding validation verification \( main area research \) , answer rather short far , paper , report case , discuss challenging , complex open problems face industry academic particular , first discuss actual tools could use daily work , , discuss main open problems faced , particularly related environment simulators , unit web testing , popular topics academia presented , , regression testing lack impact type projects industry discussed finally , industrial experience , provide situation improved , particular related evaluated , greater open source projects
learning concepts first order logic counting study classification problems relational background structures hypotheses defined using logics counting aim paper find learning algorithms running time sublinear size background structure show hypotheses defined \( p \) formulas structures polylogarithmic degree learned sublinear time furthermore , prove structures unbounded degree sublinear learning algorithm first order formulas
implies learnable paper demonstrates fundamental learning prove following theorem statistical learning sequential prediction theory learnable e admits strategy predicts optimally result shown universal induction
convergence value iteration partially observable markov decision processes partially observable markov decision processes \( \) recently become popular among many ai researchers serve natural model planning uncertainty value iteration well known algorithm finding optimal policies typically takes large number iterations converge paper proposes method accelerating convergence value iteration method evaluated array benchmark problems found effective enabled value iteration converge iterations test problems
optimizing city scale traffic flows modeling isolated observations vehicle movements mobile phones internet things provide unprecedented opportunities researchers computational social scientists observe city scale human dynamics terms vehicles people moving around also enable policy researchers identify best strategies influence individuals order complex system achieve best utility however , mobility data become sparse individual level non trivial together isolated observations high fidelity models infer macroscopic dynamics paper , introduce discrete event decision process capture high fidelity dynamics complex system individual level terms collection events one minimum changes together induce complex behaviors derive particle filter algorithm connect isolated observations driving discrete event decision process agreement observations finally , solve partially observable markov decision process problem reducing learning inference task evaluation one synthesized dataset \( \) , one real synthesized dataset \( \) , three real world datasets \( de , , \) show discrete event decision process gives accurate estimation complex system dynamics due better integration high fidelity dynamics human mobility data
price anarchy tend 1 large auctions fisher markets well known , many classes markets efficient equilibria , depends agents non strategic , e true demands offered goods particular prices , words , price important question much equilibria face strategic behavior , e price anarchy \( poa \) market viewed mechanism \? r n often , poa bounds modest 4 3 2 , practice guarantee 25 50 economic value lost may paper asks whether significantly better bounds possible assumptions particular , look worst case guarantees improve following large settings r n large auctions auctions many copies item many agents show poa tends 1 market size increases , suitable conditions , mainly uncertainty numbers copies good demands gross condition also note assumption r n large fisher markets fisher markets class received considerable attention computer science literature large market one equilibrium , buyer makes small fraction total smaller fraction , larger market main condition demands based homogeneous monotone utility functions satisfy gross condition , poa tends 1 market size increases r n furthermore , setting , quantify tradeoff market size poa
shot learning attention based sequence sequence models end end approaches recently become popular means simplifying training deployment speech recognition systems however , often require large amounts data perform well large vocabulary tasks aim making end end approaches range researchers , explore potential use end end methods small vocabulary contexts smaller datasets may used significant small vocabulary systems difficulty expanding vocabulary beyond original training samples therefore also study strategies extend vocabulary examples per new class \( shot learning \) r n results show attention based encoder decoder competitive strong baseline small vocabulary keyword classification task , reaching 97 5 accuracy 's speech commands dataset also shows promising results shot learning problem simple strategy achieved 8 accuracy new keywords 10 examples new class score goes 88 4 larger set 100 examples
generic framework video understanding applied group behavior recognition paper presents approach detect track groups people video surveillance applications , automatically recognize behavior method track individuals moving together maintaining temporal group coherence first , people individually detected second , trajectories analyzed temporal window clustered using mean shift algorithm coherence value describes well set people described group furthermore , propose formal event description language group events recognition approach successfully validated 4 camera views 3 datasets , , shopping center
towards device deep bayesian active learning human activity recognition various health care applications assisted , fall detection etc , require modeling user behavior human activity recognition \( \) using mobile wearable based deep learning algorithms rise owing advancements computing however , two challenges need addressed first , deep learning model support device incremental training \( model \) real time incoming data points learn user behavior time , also resource friendly second , suitable ground technique \( like active learning \) help establish labels fly also selecting informative data points query hence , paper , propose , resource efficient deep model supports device incremental learning inference , capabilities represent model uncertainties approximations bayesian neural networks using dropout combined suitable acquisition functions active learning empirical results two publicly available fall detection datasets indicate achieves considerable efficiency boost inference across different users , substantially low number acquired pool points \( least 60 reduction \) incremental learning datasets various acquisition functions , thus demonstrating deployment incremental learning feasibility
loss function image segmentation using 3d fully convolutional deep networks fully convolutional deep neural networks carry excellent potential fast accurate image segmentation one main challenges training networks data imbalance , particularly problematic medical imaging applications lesion segmentation number lesion often much lower number non lesion training data lead predictions severely biased towards high precision low recall \( sensitivity \) , especially medical applications false much less false several methods proposed deal problem including balanced sampling , two step training , sample weighting , similarity loss functions paper , propose generalized loss function based index address issue data imbalance achieve much better trade precision recall training 3d fully convolutional deep neural networks experimental results multiple lesion segmentation magnetic images show improved score , coefficient , area precision recall curve test data based results suggest loss function generalized framework effectively train deep neural networks
lattice based transformer encoder neural machine translation neural machine translation \( nmt \) takes deterministic sequences source representations however , either word level subword level multiple choices split source sequence different word different subword vocabulary sizes diversity may affect nmt performance integrate different state art nmt model , transformer , propose lattice based encoders explore effective word subword representation automatic way training propose two methods 1 \) lattice positional encoding 2 \) lattice aware self attention two methods used together show complementary improve translation performance experiment results show lattice based encoders word level subword level representations conventional transformer encoder
part first among semantic part based benchmarking state art object recognition systems examination object recognition challenge \( , pascal voc \) reveals top performing classifiers typically exhibit small differences amongst terms error rate map better differentiate top , additional criteria required moreover , \( test \) images , performance scores based , predominantly contain fully visible objects therefore , test images , challenging conditions \( e g occlusion \) humans routinely recognize objects , need utilized benchmarking address concerns mentioned , make two contributions first , systematically vary level local object part content , global detail spatial context images pascal voc 2010 create new benchmarking dataset dubbed 12 second , propose object part based benchmarking procedure robustness range contextual settings benchmarking procedure relies semantic similarity measure naturally addresses potential semantic granularity differences category labels training test datasets , thus eliminating manual mapping use procedure 12 dataset benchmark top performing classifiers trained 2012 dataset results show proposed benchmarking procedure enables additional among state art object classifiers terms ability handle missing content object detail given capability additional , approach potentially existing benchmarking procedures used object recognition challenge
pixels sentiment fine tuning cnns visual sentiment prediction visual multimedia become part digital social lives , often capture moments tied deep automated visual sentiment analysis tools provide means extracting rich latent embedded media work , explore convolutional neural networks \( cnns \) , de computational machine learning tool particularly area computer vision , specifically applied task visual sentiment prediction fine tuning experiments using state art cnn via rigorous architecture analysis , present several modifications lead accuracy improvements prior art dataset images popular social media platform additionally present local patterns network learned associate image sentiment insight visual \( \) perceived model
serious game based tool purpose work designing implementing software patients constant training key factor type therapy patient play game well conduct voice training simultaneously guided exercise independently home voice information extracted evaluating long time progress
universal tasks difficulty composition decomposition note concepts task difficulty notion cognitive task use evaluation intelligent systems still issues view tasks mdp context reinforcement learning especially useful learning tasks however , alternate interaction accommodate well tasks usual artificial intelligence , especially , human evaluation particular , want general account , rewards responses , , especially , computational complexity algorithm behind agent solving task crucial determination difficulty task \( \) number computational steps required acquire acceptable policy task , includes exploration policies verification introduce notion asynchronous time stochastic tasks based interpretation , see task difficulty , instance difficulty \( relative task \) also task decompositions
entity embeddings categorical variables map categorical variables function approximation problem euclidean spaces , entity embeddings categorical variables mapping learned neural network standard supervised training process entity embedding reduces memory usage speeds neural networks compared one hot encoding , importantly mapping similar values close embedding space reveals intrinsic properties categorical variables applied successfully recent competition able reach third position relative simple features demonstrate paper entity embedding helps neural network generalize better data sparse statistics unknown thus especially useful datasets high cardinality features , methods tend also demonstrate embeddings obtained trained neural network boost performance tested machine learning methods considerably used input features instead entity embedding defines distance measure categorical variables used categorical data data clustering
image another image past , steganography text carrier , sender share key , text extracted key information embedded , image easily contrast , less embedded information , image good visual integrity , meet requirements capacity paper , focus challenges limitations improve capacity image steganography method based fully convolutional dense network \( densenet \) proposed us hidden network extracted network trained time dataset deep neural network derived various natural images imagenet experimental results show image steganography secret image extracted visually good effect , image high capacity high peak signal noise ratio image image full size hiding implemented
spectrum reservation contract design tv white space networks paper , study based tv white space market , white space devices \( \) purchase white space spectrum tv via third party geo location database \( db \) , serves spectrum , spectrum tv spectrum propose contract theoretic framework database 's spectrum reservation demand information framework , database offers set contract items form reservation amount corresponding payment , chooses best contract item based private information systematically study optimal reservation contract design \( maximizes database 's expected profit \) two different risk bearing schemes db bearing risk bearing risk , depending \( database \) risk reservation counter intuitively , show optimal contract db bearing risk leads higher profit database higher total network profit
minizinc optimization modulo theories back extended version optimization modulo theories \( omt \) extension smt allows finding models optimize objective functions paper aim bridging gap constraint programming \( cp \) omt , directions first , extended omt solver interface also used omt encoder omt solvers allows omt tools used combination large amount cp problems coming minizinc community second , introduced tool translating smt omt problems linear arithmetic bit vector theories minizinc allows minizinc solvers used large amount smt omt problems r n discussed main issues cope either directions performed extensive empirical evaluation comparing three state art omt based tools many state art cp tools \( \) cp problems coming minizinc challenge , \( ii \) omt problems coming mostly formal verification analysis also allowed us identify , terms efficiency correctness , one cope addressing cp problems omt tools , vice versa
learning search better teacher methods learning search structured prediction typically reference policy , existing theoretical guarantees demonstrating low regret compared reference many applications reference policy suboptimal goal learning improve upon learning search work even reference poor \? r n provide new learning search algorithm , , well relative reference policy , additionally guarantees low regret compared deviations learned policy local optimality guarantee consequently , improve upon reference policy , unlike previous algorithms enables us develop structured contextual bandits , partial information structured prediction setting many potential applications
mobile micro measures diseases among largest threats quality life economic social well developing countries measures well established , costly mitigate impact paper , argue mobile technology adds powerful , \( \) mobile devices us unprecedented ability measure model detailed behavioral patterns affected population , \( b \) enable delivery personalized behavioral recommendations individuals real time combine two ideas propose several strategies generate recommendations mobility patterns goal strategy large reduction , small impact normal course daily life evaluate strategies dataset show benefit mobile micro measures , even fraction population preliminary results demonstrate potential mobile technology complement measures like disease
impact csi distributed space time coding wireless relay networks consider two hop wireless network transmitter communicates receiver via relays forward \( af \) protocol recent works shown sophisticated linear processing beamforming distributed space time coding \( \) relays enables improve af performance however , relative utility strategies depend available channel state information transmitter \( csit \) , turn depends system parameters speed underlying fading channel training feedback procedures moreover , practical interest single transmit scheme handles different csit scenarios us consider unified approach based potentially provides diversity gain statistical csit exploits additional side information available individual power constraints relays , optimize power allocation pairwise error probability conditioned available csit minimized perfect csit propose gradient algorithm efficiently finds set relays switch partial statistical csit , propose simple algorithm yields non trivial solution maximum power allocation generalized noise relays moreover , derive closed form solutions 2 certain asymptotic regimes enable easy interpretation proposed algorithms found appropriate power allocation offer sufficient diversity power gain general network topology
note dual property puncturing codes consider sequence codes evaluating set evaluation points p 1 , , p n functions defining point q , sequence codes satisfying dual condition \( e containing time primal dual codes \) prove necessary condition , taking number evaluation points \( e puncturing \) , resulting codes still satisfy dual property condition called maximum sparse q
distributed algorithms complete partial information games interference channels consider gaussian interference channel independent direct cross link channel gains , independent identically distributed across time transmitter receiver user pair aims maximize long term average transmission rate subject average power constraint formulate stochastic game system three different scenarios first , assume user knows direct cross link channel gains later , assume user knows channel gains links receiver lastly , assume user knows direct link channel gain cases , formulate problem finding nash equilibrium \( ne \) variational \( \) problem present novel heuristic solving use heuristic solve ne power allocation games partial information also present lower bound utility user ne case games partial information obtain lower bound using like power allocation requires knowledge distribution user 's channel gains average power constraints users also provide distributed algorithm compute pareto optimal solutions proposed games finally , use bayesian learning obtain algorithm converges epsilon nash equilibrium incomplete information game direct link channel gain knowledge without requiring knowledge power policies users
learning better context intelligent information retrieval approach de n n de n n de n de e de la , av , \( \) , de 54 54 , cs paper proposes incremental method used system learn better descriptions context small number terms selected simple description analysis uses description initial search context using , set queries built search engine new terms used ne learned vocabulary performed number topics indicate learned vocabulary much original one time constructing queries retrieve
statistical mechanical assessment reconstruction limit compressed sensing toward theoretical analysis correlated signals provide scheme exploring reconstruction limits compressed sensing minimizing general cost function random measurement constraints generic correlated signal sources scheme based statistical mechanical replica method dealing random systems simple non trivial example , apply scheme sparse autoregressive model , first differences input signals correlated time series sparse , evaluate critical compression rate perfect reconstruction results good agreement numerical experiment signal reconstruction
adapting model representations descendants web today 's primary publication medium , making web important activity historical analytical purposes web pages increasingly interactive , resulting pages increasingly difficult client side technologies \( e g , javascript \) enable interactions potentially change client side state representation refer representations load embedded resources via javascript representations difficult resources representations result web pages either incomplete load embedded resources live web r n propose method discovering representations descendants \( representation states reachable client side events \) adapt et al model construct model descendants , measure number descendants embedded resources discovered proof concept approach identified average 38 5 descendants per seed , 70 9 reached event approach also added 15 6 times embedded resources frontier , rate 38 9 times simply using show dataset two levels descendants conclude proposed policies analysis storage requirements descendants
achieving secure differentially private computations multiparty settings sharing working sensitive data distributed settings healthcare finance major challenge due security privacy concerns secure multiparty computation \( smc \) viable , allowing distributed parties make computations parties learn data , final result although smc distributed settings , provide guarantees information individuals adversaries differential privacy \( dp \) utilized address however , achieving smc dp trivial task , either paper , propose novel secure multiparty distributed differentially private \( sm \) protocol achieve secure private computations multiparty environment specifically , protocol , simultaneously achieve smc dp distributed settings focusing linear regression distributed data , parties see data , infer information individuals final constructed statistical model statistical model function allows independent calculation local statistics computed protocol protocol implements homomorphic encryption smc functional mechanism dp achieve desired security privacy guarantees work , first introduce theoretical foundation sm protocol evaluate efficacy performance two different datasets results show one achieve individual level privacy proposed protocol distributed dp , independently applied party distributed fashion moreover , results also show sm protocol incurs minimal computational overhead , scalable , provides security privacy guarantees
social interaction aware trajectory prediction via wasserstein graph double attention network effective understanding environment accurate trajectory prediction dynamic obstacles indispensable intelligent mobile systems \( like autonomous vehicles social robots \) achieve safe high quality planning navigate highly interactive crowded scenarios due existence frequent interactions uncertainty scene evolution , desired prediction system enable relational reasoning different entities provide distribution future trajectories agent paper , propose generic generative neural system \( called social \) multi agent trajectory prediction , makes step forward explicit interaction modeling incorporating relational inductive biases dynamic graph representation leverages trajectory scene context information also employ efficient kinematic constraint layer applied vehicle trajectory prediction ensures physical feasibility also enhances model performance proposed system evaluated three public benchmark datasets trajectory prediction , agents cover , cyclists road vehicles experimental results demonstrate model achieves better performance various baseline approaches terms prediction accuracy
correlation heuristics constraint programming effective general purpose search strategies important component constraint programming introduce new idea , namely , using correlations variables guide search variable correlations measured maintained using domain changes constraint propagation propose two variable heuristics based correlation matrix , sum max evaluate correlation heuristics well known heuristics , namely , , impact based search activity based search experiments large set benchmarks show correlation heuristics competitive heuristics , fastest many series
nested wasserstein self imitation learning sequence generation reinforcement learning \( rl \) widely studied improving sequence generation models however , conventional rewards used rl training typically cannot capture sufficient semantic information therefore render model bias , sparse delayed rewards make rl exploration alleviate issues , propose concept nested wasserstein distance semantic matching exploit , novel nested wasserstein self imitation learning framework developed , encouraging model exploit historical high sequences enhanced exploration better semantic matching solution understood approximately executing proximal policy optimization wasserstein trust regions experiments variety conditional sequence generation tasks demonstrate proposed approach consistently leads improved performance
attention based hierarchical neural query query suggestions help users search engine refine queries previous work query mainly focused incorporating directly observable features query co occurrence semantic similarity structure features often set manually , result hidden dependencies queries users may propose model combines hierarchical structure session level neural network user level neural network model short long term search history user attention mechanism used capture user preferences quantify improvements state art rnn based query baselines query log dataset , improvements 21 86 22 99 terms 10 recall 10 , respectively , state art improvements especially large short sessions
hierarchical cellular automata visual saliency saliency detection , finding important parts image , become increasingly popular computer vision paper , introduce hierarchical cellular automata \( \) temporally evolving model detect salient objects consists two main components single layer cellular automata \( \) cellular automata \( cca \) unsupervised propagation mechanism , single layer cellular automata exploit intrinsic relevance similar regions interactions neighbors low level image features well high level semantic information extracted deep neural networks incorporated measure correlation different image patches hierarchical deep features , impact factor matrix coherence matrix constructed balance influences cell 's next state saliency values cells iteratively updated according well defined update rule furthermore , propose cca integrate multiple saliency maps generated different scales bayesian framework therefore , single layer propagation multi layer integration jointly modeled unified surprisingly , find improve existing methods applied , resulting similar precision level regardless original results cca act efficient pixel wise aggregation algorithm integrate state art methods , resulting even better results extensive experiments four challenging datasets demonstrate proposed algorithm outperforms state art conventional methods competitive deep learning based approaches
stiffness analysis parallel manipulators paper presents new stiffness modeling method parallel manipulators flexible links based multidimensional parameter model link flexibility localized 6 dof virtual describe coupling contrast works , method involves based link stiffness evaluation employs new solution strategy equations configuration , allows computing stiffness matrix architectures , including singular advantages developed technique confirmed application examples , deal comparative stiffness analysis two parallel manipulators 3 3 architectures accuracy proposed approach evaluated case study , focuses stiffness analysis parallel
center visual saliency contrast based full reference image quality index objective image quality assessment \( iqa \) imperative current multimedia intensive world , order assess visual quality image close human level ability many parameters color intensity , structure , , contrast , presence object , etc , draw human attention image psychological vision research suggests human vision biased center area image result , center part contains visually salient information , human attention even distortion part better perceived parts best knowledge , previous iqa methods considered fact paper , propose full reference image quality assessment \( iqa \) approach using visual saliency contrast however , give extra attention center increasing sensitivity similarity maps region evaluated method three large scale popular benchmark databases used current iqa researchers \( , live \) , total images 28 different kinds method compared 13 state art approaches comparison reveals stronger correlation method human evaluated values prediction quality score consistent distortion specific well distortion independent cases moreover , faster processing makes applicable real time application
robust logitboost adaptive base class abc logitboost logitboost influential boosting algorithm classification paper , develop robust logitboost provide explicit formulation tree split criterion building weak \( regression trees \) logitboost formulation leads numerically stable implementation logitboost propose abc logitboost multi class classification , combining robust logitboost prior work abc boost previously , abc boost implemented abc using algorithm extensive experiments multi class classification compare four algorithms , , \( robust \) logitboost , abc logitboost , demonstrate superiority abc logitboost comparisons learning methods including svm deep learning also available prior publications
large scale deep learning dataset present work progress learning 15 billion parameter deep learning network hpc architectures applied largest publicly available natural image video dataset released date recent advancements unsupervised deep neural networks suggest scaling networks model training dataset size yield significant improvements learning concepts highest layers train three layer deep neural network ! dataset dataset comprises approximately 99 2 million images , 000 user created videos 's image video sharing platform training network takes eight days 98 gpu nodes high performance computing center national encouraging preliminary results future research directions presented discussed
modular termination proofs general logic programs propose modular method proving termination general logic programs \( e , logic programs \) based notion acceptable programs , allows us prove termination truly modular way consider programs consisting hierarchy modules supply general result proving termination dealing module separately programs certain sense well , namely well well typed programs , derive simple verification technique iterative proof method examples show system allows greatly simplified proofs
lower bound online bin packing online bin packing problem , items sizes \( 0 , 1 arrive online packed size 1 goal minimize number used paper , present online bin packing algorithm asymptotic competitive ratio 1 first improvement years reduces gap lower bound 15 within well known framework , competitive ratio 1 achieved r n make two crucial changes framework first , algorithm 's decisions depend exact sizes items , instead types particular , item size \( 1 3 , 1 2 , use exact size determine packed together item size greater 1 2 second , carefully depending packed , use bound many certain kind exist optimal solution gives us better lower bounds optimal solution value show input , single weighting function constructed upper bound competitive ratio r n use idea simplify analysis , show algorithm fact 1 competitive \( proved 1 \) , 1 achieved within framework finally , give lower bound 1 new framework
optimizing query evaluations using reinforcement learning web search web search , typically candidate generation step selects small set documents collections containing many web pages subsequently ranked presented user , candidate generation involves index using designed match plans sequences different match criteria conditions work , pose match planning reinforcement learning task observe 20 reduction index blocks , small degradation quality candidate sets
subword encoding lattice lstm chinese word segmentation investigate lattice lstm network chinese word segmentation \( \) utilize words integrates character sequence features subsequences information matched lexicon matched subsequences serve information link start end characters directly gated units used control contribution multiple input links formula derivation comparison , show lattice lstm extension standard lstm ability take multiple inputs previous lattice lstm model takes word embeddings lexicon input , prove subword encoding give comparable performance benefit relying external contribution lattice lstm comes lexicon pretrained embeddings information , find lexicon information contributes pretrained embeddings information controlled experiments experiments show lattice structure subword encoding gives competitive better results previous state art methods four segmentation benchmarks detailed analyses conducted compare performance word encoding subword encoding lattice lstm also investigate performance lattice lstm structure different model works fails
mind class weight bias weighted maximum mean discrepancy unsupervised domain adaptation domain adaptation , maximum mean discrepancy \( mmd \) widely adopted discrepancy metric distributions source target domains however , existing mmd based domain adaptation methods generally ignore changes class prior distributions , e , class weight bias across domains remains open problem ubiquitous domain adaptation , caused changes sample selection criteria application scenarios show mmd cannot account class weight bias results degraded domain adaptation performance address issue , weighted mmd model proposed paper specifically , introduce class specific auxiliary weights original mmd exploiting class prior probability source target domains , whose challenge lies fact class label target domain unavailable account , proposed weighted mmd model defined introducing auxiliary weight class source domain , classification em algorithm suggested alternating assigning pseudo labels , estimating auxiliary weights model parameters extensive experiments demonstrate superiority weighted mmd conventional mmd domain adaptation
non line sight node localization based semi definite programming wireless sensor networks unknown position sensor localized three making time arrival \( \) measurements signal however , location errors large due fact measurements non line sight \( nlos \) paths paper , semi definite programming \( sdp \) based node localization algorithm nlos environments proposed ultra \( \) wireless sensor networks positions sensors estimated using distance estimates location aware well sensors however , absence line sight \( los \) paths , e g , indoor networks , nlos range estimates significantly biased result , nlos error decrease location accuracy , easy accurately distinguish los nlos measurements according information known prior probabilities distributions nlos errors , three different cases introduced respective localization problems addressed simulation results demonstrate algorithm achieves high location accuracy even case nlos los measurements
labelled transition systems space fully abstract universal domain model modal transition systems refinement , developed \( 27 \) , shown maximal points space model quotient labelled transition systems finite set events domain model prove quotient space whose compact , zero dimensional , ultra topology measures degree bisimilarity image finite labelled transition systems dense using show set labelled transition systems refine modal transition system , set , compact derive theorem logic implementation sets results extend systems also partially specified state , existing , operational , metric semantics par processes , render robust consistency measures modal transition systems , yield abstract interpretation compact sets labelled transition systems closed sets modal transition systems
por security protocol beyond action formal methods proved effective automatically analyze protocols past years , much research focused verifying trace equivalence protocols , notably used model many interesting privacy properties , e g , many tools checking trace equivalence rely naive expensive exploration concurrent actions , calls partial order reduction \( por \) techniques paper , present first por technique protocol rely action assumption trace equivalence problem problem , persistent sleep set techniques applied , show effectively apply results context symbolic report prototype implementation , improving tool
cross lingual unsupervised sense embeddings paper proposes sense induction representation learning model jointly learns bilingual sense embeddings align well vector space , cross lingual signal english chinese parallel corpus exploited capture distributed characteristics language pair model evaluated stanford contextual word similarity \( \) dataset ensure quality monolingual sense embeddings addition , introduce bilingual contextual word similarity \( \) , large high quality dataset evaluating cross lingual sense embeddings , first attempt measuring whether learned embeddings indeed aligned well vector space proposed approach shows superior quality sense embeddings evaluated monolingual bilingual spaces
generalized ldpc codes convolutional code constraints convolutional codes \( \) class spatially coupled like codes described \( 2 , 3 \) regular compact graph paper , introduce family \( v , c \) regular codes convolutional code constraints \( codes \) , form extension classical arbitrary regular graphs order characterize performance waterfall error floor regions , perform analysis density evolution thresholds well finite length ensemble weight minimum distances ensembles particular , consider various ensembles overall rate r 1 3 r 1 2 study trade variable node degree strength component codes also compare results corresponding classical ldpc codes equal degrees rates observed considered ldpc codes variable node degree v 2 , find code smaller v offers similar better performance terms map thresholds expense negligible loss minimum distance
deep reinforcement learning foreign exchange trading reinforcement learning interact environment suitable applications decision control systems therefore , used reinforcement learning method establish foreign exchange transaction , avoiding long standing problem trends deep learning predictions system design , optimized statistical policy , set three different actions , encoded continuous price period time heat map view angular field \( \) compared deep q learning \( dqn \) proximal policy optimization \( ppo \) algorithms test feasibility , analyzed three pairs , namely , , trained data units four hours 1 2018 30 2018 tested model performance using data 1 2018 31 2018 test results various models favorable investment performance achieved long model able handle complex random processes state able describe environment , validating feasibility reinforcement learning development trading strategies
caching improvement using adaptive user clustering article explore one promising technologies 5g wireless networks using small cell network , namely proactive caching using increase storage technologies studying users behavior , peak traffic reduced proactive caching content propose new method , , instead caching popular content , users within network clustered according content popularity caching done accordingly present also method estimating number clusters within network based information criterion analytically derive closed form expression probability propose optimization problem small base stations association clusters optimized
associated geometry identified satellite images importance following increase , life united states recent decades using satellite images street view images prior work demonstrated built environment , education , access care health factors however , assessment learned image feature relationships variation mortality rate across united states lacking r n objective investigate prediction level mortality rates u using satellite images r n design satellite images extracted google static maps application programming interface representing approximately 9 us population convolutional neural network trained using mortality rates 2015 predict mortality learned image features interpreted using additive feature explanations , clustered , compared mortality associated predictors r n main outcomes measures mortality predicted using satellite images r n results predicted mortality satellite images held test set strongly correlated true mortality rate \( r 0 72 \) learned image features clustered , identified 10 clusters associated education , , geographical region , age r n conclusion relevance application deep learning techniques sensed features built environment serve useful predictor mortality united states tools able identify image features associated health related outcomes targeted public health interventions
recommender system online service users online sites facing information requires manually construct queries huge amount matching user profiles becomes even problematic multimedia profiles although frequently cited typical application recommender systems , surprising lack work published area paper describe recommender system implemented perform quantitative comparison two collaborative filtering \( cf \) two global algorithms results show collaborative filtering significantly outperform global algorithms currently used sites blind experiment real users also confirmed users cf based recommendations global popularity recommendations recommender systems show great potential online could improve value service users improve service
predicting cloud services spike maintaining web services critical task time means loss revenue reputation \( reliable service \) current competitive web services market , loss reputation causes extensive loss future revenue address issue , developed spike , data mining tool predict service , half future predictions let organization team address problem \( e g cloud hardware order reduce likelihood \) spike utilizes \( \) regression tree learning \( \) \( b \) synthetic sampling \( handle rare spikes data \) \( c \) hyperparameter optimization \( learn best settings local data \) \( \) technique called topology sampling training vectors built extensive details individual node plus summary details neighbors experiments reported , spike predicted service spikes 30 future precision 75 also , spike performed relatively better widely used learning methods \( neural nets , random forests , logistic regression \)
evaluating ontology matching systems large multilingual real world test cases field ontology matching , systematic evaluation matching systems established ontology alignment evaluation \( \) , campaign evaluating ontology matching systems different groups researchers paper , report results campaign called 2011 5 evaluations campaign divided five tracks three tracks new improved compared previous campaigns overall , evaluated 18 matching systems discuss learned , terms scalability , multilingual issues ability deal real world cases different domains
supervised quantization similarity search paper , address problem searching semantically similar images large database present compact coding approach , supervised quantization approach simultaneously learns feature selection linearly transforms database points low dimensional discriminative subspace , data points transformed space optimization criterion quantized points approximate transformed points accurately , also semantically separable points belonging class lie cluster clusters corresponding classes , formulated classification problem experiments several standard datasets show superiority approach state art supervised hashing unsupervised quantization algorithms
reduced switching connectivity power efficient large scale antenna selection paper , explore reduced connectivity radio frequency \( rf \) switching networks reducing analog hardware complexity switching power losses antenna selection \( \) systems particular , analyze different hardware architectures implementing rf switching matrices required designs reduced number rf chains explicitly show fully flexible switching matrices , facilitate selection possible subset antennas attain maximum theoretical sum rates , present numerous drawbacks introduction significant losses , particularly massive multiple input multiple output \( mimo \) systems since disadvantages make fully flexible switching suboptimal energy efficiency sense , consider partially connected switching networks alternative switching architecture reduced hardware complexity , characterize work context , also analyze impact reduced switching connectivity analog hardware digital signal processing schemes rely channel power information overall , analytical simulation results shown paper demonstrate partially connected switching maximizes energy efficiency massive mimo systems reduced number rf chains , fully flexible switching offers sub optimal energy efficiency benefits due significant switching power losses
neural based natural language generation dialogue using rnn encoder decoder semantic aggregation natural language generation \( \) important component spoken dialogue systems paper presents model called encoder decoder extension recurrent neural network based encoder decoder architecture proposed semantic consists two components conventional attention calculated encoded input information , another attention mechanism stacked attentive order select aggregate semantic elements proposed model jointly trained sentence planning surface realization produce natural language utterances model extensively four different domains , experimental results showed proposed generator consistently outperforms previous methods domains
provably correct cases variational inference topic models variational inference efficient popular heuristic used various forms context latent variable models 's closely related expectation maximization \( em \) , applied exact em computationally infeasible despite popular , current theoretical understanding effectiveness inference based algorithms limited work provide first analysis instances variational inference algorithms converge global optimum , setting topic models r n specifically , show variational inference provably learns optimal parameters topic model natural assumptions topic word matrix topic priors properties topic word matrix must satisfy setting related topic expansion assumption introduced \( et al , 2013 \) , well anchor words assumption \( et al , \) assumptions topic priors related well known prior , introduced area topic modeling \( et al , \) r n well known initialization plays crucial role well variational based algorithms perform practice use fairly natural one similar currently used c , popular implementation variational inference topic models one overlapping clustering algorithm , inspired work \( et al , 2014 \) dictionary learning , simple efficient r n primary goal provide insights variational inference might work practice , multiplicative , rather additive nature variational inference updates forces us use fairly non standard proof arguments , believe general interest
achieving single sensor complex activity recognition multi sensor training data study , propose method single sensor based activity recognition , trained data multiple sensors performance complex activity recognition systems increases use enough sensors sufficient quality , however using rich sensors may feasible real life situations various reasons user , privacy , battery , costs many cases , one device smartphone available , challenging achieve high accuracy single sensor , complex activities method combines representation learning feature mapping leverage multiple sensor information made available training using single sensor testing real usage results show proposed approach improve f1 score complex activity recognition 17 compared training utilizing sensor data new user scenario
variational hamiltonian monte carlo multi modal sampling hamiltonian monte carlo \( \) sampling algorithm exploits hamiltonian dynamics construct efficient markov chain monte carlo \( \) , become increasingly popular machine learning statistics since uses gradient information target distribution , explore state space much efficiently random walk proposals however , probabilistic inference involving multi modal distributions difficult standard method , especially modes far away sampling algorithms often across places low probability paper , propose novel algorithm aims sample multi modal distributions effectively method improves hamiltonian dynamics reduce samples uses variational distribution explore phase space find new modes formal proof provided shows proposed method converge target distributions synthetic real datasets used evaluate properties performance experimental results verify theory show superior performance multi modal sampling
analytical modeling network functions network function \( \) considered one key technologies 5g mobile networks , network functions implemented software components virtual network functions \( \) running hardware paper , propose analytical model based open network g g model single multi tier designs , chains model flexible generic enough capture behavior systems validate model simulation specifically , validate lte mobility management entity three architecture use case also compare model art , terms computational complexity estimation error results show model computational complexity similar method analyzing 's networks additionally , model exhibits estimation error , measured relative error estimation mean response time , approximately equal 10 , whereas considered baseline systems roughly 60 90
unsupervised learning videos using temporal deep networks abstract work address challenging problem unsupervised learning videos existing methods utilize spatio temporal video frames regularization learning process typically , temporal coherence close frames used free form annotation , encouraging learned representations exhibit small differences frames type approach fails capture videos different content , hence learning less discriminative features propose two siamese architectures convolutional neural networks , corresponding novel loss functions , learn unlabeled videos , jointly exploit local temporal coherence frames , global discriminative margin used separate representations different videos extensive experimental evaluation presented , validate proposed models various tasks first , show learned features used discover actions scenes video collections second , show benefits unsupervised learning unlabeled videos , directly used prior supervised recognition tasks actions objects images , results show features even traditional heavily supervised pre training plus fine tuning strategy
real time segmentation dense detections segmentation complex full scene parsing task requiring simultaneous instance semantic segmentation high resolution current state art approaches cannot run real time , simplifying architectures improve efficiency severely accuracy paper , propose new single shot segmentation network leverages dense detections global self attention mechanism operate real time performance approaching state art introduce novel parameter free mask construction method substantially reduces computational complexity efficiently information object detection semantic segmentation sub tasks resulting network simple data flow require feature map sampling clustering post processing , enabling significant hardware acceleration experiments cityscapes coco benchmarks show network works 30 fps resolution , trading 3 relative performance degradation current state art faster inference
horn ice learning synthesizing contracts design learning algorithms synthesizing invariants using horn \( horn ice \) , extending ice learning model particular , describe decision tree learning algorithm learns nonlinear horn ice samples , works polynomial time , uses statistical heuristics learn small trees satisfy samples since verification proofs modeled using nonlinear horn , horn ice learning robust technique learn inductive annotations prove programs correct experiments show implementation algorithm able learn inductive invariants contracts efficiently variety sequential concurrent programs
differentially private algorithm range queries trajectories propose novel algorithm ensure epsilon differential privacy answering range queries trajectory data order guarantee privacy , differential privacy mechanisms add noise either data query , thus introducing errors queries made potentially decreasing utility information contrast state art , method achieves significantly lower error first data query aware approach queries key challenge answering range queries trajectory data ensure accurate count simply representing trajectory set instead emph sequence points generally lead highly inaccurate query answers sequential dependency location points trajectories , e , consistency trajectory data furthermore , trajectories generally distributed across city adding noise uniformly generally lead poor utility achieve differential privacy , algorithm adaptively adds noise input data according given query set first partitions data space uniform regions computes traffic density region regions densities , addition given query set , used estimate distribution trajectories space , ensures high accuracy given query set show accuracy efficiency algorithm using extensive empirical evaluations real synthetic data sets
network capability localizing node failures via end end path measurements investigate capability localizing node failures communication networks binary states \( normal failed \) end end paths given set nodes interest , localizing failures within set requires different observable path states associate different node failure events however , condition difficult test large networks due need possible node failures first contribution set sufficient necessary conditions identifying bounded number failures within arbitrary node set tested polynomial time addition network topology locations monitors , conditions also incorporate constraints imposed probing mechanism used consider three probing mechanisms differ according whether measurement paths \( \) arbitrarily controllable , \( ii \) controllable cycle free , \( iii \) \( determined routing protocol \) second contribution quantify capability failure localization \( 1 \) maximum number failures \( network \) failures within given node set localized , \( 2 \) largest node set within failures localized given bound total number failures measures \( 1 2 \) converted functions per node property , computed efficiently based sufficient necessary conditions demonstrate measures \( 1 2 \) proposed quantifying failure localization capability used evaluate impact various parameters , including topology , number monitors , probing mechanisms
sgx power cache attacks modern computing environments , hardware resources commonly shared , parallel computation widely used parallel tasks cause privacy security problems proper enforced intel proposed sgx create trusted execution environment within processor sgx relies hardware , claims runtime protection even os software components malicious however , sgx side channel attacks introduce powerful cache side channel attack provides system adversaries high resolution channel attack tool named able track memory accesses sgx high spatial temporal precision proof concept , demonstrate key recovery attacks commonly used implementations including believed previous scenarios results show sgx cannot protect critical data sensitive computations , efficient key recovery possible practical environment contrast previous works require measurements , first cache side channel attack real system recover keys minimal number measurements successfully recover keys table based implementations ten measurements
reliability maximization uncertain graphs network reliability measures probability target node reachable source node uncertain graph , e , graph every edge associated probability existence paper , investigate novel fundamental problem adding small number edges uncertain network maximizing reliability given pair nodes study np hardness approximation hardness problem , design effective , scalable solutions furthermore , consider extended versions problem \( e g , multiple source target nodes provided input \) support demonstrate family queries applications , including sensor network reliability maximization social influence maximization experimental results validate effectiveness efficiency proposed algorithms
visual relationship prediction via label clustering depth information paper , investigate use unsupervised label clustering technique demonstrate enables substantial improvements visual relationship prediction accuracy person context \( \) dataset propose group object labels similar patterns relationship distribution dataset fewer categories label clustering large classification space class imbalance issues , also potentially increases data samples clustered category propose incorporate depth information additional feature instance segmentation model additional depth prediction path relationship prediction model way bounding boxes segmentation masks unable evaluated proposed techniques performed various analysis validate benefits
analysis mu mu lambda sigma self adaptation evolution strategy repair projection applied constrained problem theoretical performance analysis \( mu mu , lambda \) sigma self adaptation evolution strategy \( sigma es \) presented considering constrained problem infeasible using projection onto boundary feasibility region closed form approximations used one generation progress evolution strategy approximate deterministic evolution equations formulated analyzing strategy 's dynamics evolution equations approximate one generation expressions , evolution strategy 's dynamics predicted derived theoretical results compared experiments assessing approximation quality shown steady state \( mu mu , lambda \) sigma es exhibits performance es optimizing sphere model unlike non \( 1 , lambda \) es , steady state behavior evolve boundary away boundary certain extent
achievability results statistical learning communication constraints problem statistical learning construct accurate predictor random variable function correlated random variable basis training sample joint distribution predictors constrained lie specified class , goal approach asymptotically performance best predictor class consider two settings learning agent access rate limited descriptions training data , present information theoretic bounds predictor performance achievable presence communication constraints proofs assume separation structure compression learning rely new class operational criteria specifically tailored joint design encoders learning algorithms rate constrained settings
combinatorial evolution forecasting communication protocol article addresses combinatorial evolution forecasting communication protocol wireless sensor net works \( \) morphological tree structure \( version tree \) used hierarchical model protocol three generations protocol set protocol change operations generated described change operations used items forecasting based com problems \( e g , clustering , knapsack problem , multiple choice knapsack problem \) two kinds preliminary communication protocol considered \( \) direct expert \( expert judgment \) based forecast , \( ii \) computation forecast \( \) \( usage decision making combinatorial optimization problems \) finally , aggregation obtained preliminary considered \( two aggregation strategies used \)
1 eps approximate sparse recovery problem central sparse recovery compressive sensing stable sparse recovery want distribution matrices r times n , x r n probability least 2 3 , algorithm recover x r n x x p 1 norm p measurement complexity problem well understood constant c 1 however , variety applications important obtain c 1 eps small eps 0 , complexity well understood resolve dependence eps number measurements required k sparse recovery algorithm , polylogarithmic factors central cases p 1 p 2 namely , give new algorithms lower bounds show number measurements required \( 1 eps p 2 \) k \( n \) p 2 , bound \( 1 eps \) k log \( n k \) tight constant factors also give matching bounds output required k sparse , case achieve \( 1 eps p \) k \( n \) shows complexity sparse non sparse outputs fundamental
analyzing locality mobile messaging traffic using framework mobile messaging services gained large share global unlike conventional services like phone calls , text messages , feature environment enabling federated potentially local service architecture present extensive large scale analysis communication patterns four popular mobile messaging services 28 countries analyze locality communication resulting impact user privacy show server architectures mobile messaging services highly centralized single countries forces messages drastically direct communication path , enabling transfer countries potentially traffic conduct work , developed measurement framework analyze traffic mobile messaging services allows carry automated experiments mobile messaging applications , applications require modifications applications
polynomial time algorithms submodular laplacian systems let g \( v , e \) undirected graph , l g mathbb r v times v associated laplacian matrix , b mathbb r v vector solving laplacian system l g x b numerous applications theoretical computer science , machine learning , network analysis recently , notion laplacian operator l f mathbb r v 2 mathbb r v submodular transformation f 2 v mathbb r e introduced , handle undirected graphs , directed graphs , , joint distributions unified manner study , show submodular laplacian system l f \( x \) b solved polynomial time furthermore , also prove even submodular laplacian system solution , solve regression form polynomial time finally , discuss potential applications submodular laplacian systems machine learning network analysis
towards adaptive state consistency distributed control plane state synchronisation clustered software defined networking controller deployments ensures instances controller state information order provide redundancy current implementations controllers use strong consistency model , configuration changes must across number instances applied network infrastructure large deployments , blocking process increases delay state synchronisation across cluster members consequently detrimental effect network operations require rapid response , fast quality service applications paper , introduce adaptive consistency model controllers employs concepts consistency models along novel cost based approach strict synchronisation employed critical operations affect large portion network resources less critical changes propagated across cluster nodes use simulation evaluate model demonstrate potential gains performance
new hardness results rainbow connectivity path edge colored graph said rainbow path two edges path color edge colored graph \( strongly \) rainbow connected exists \( \) rainbow path every pair vertices \( strong \) rainbow connectivity graph g , denoted \( src \( g \) , respectively \) \( g \) smallest number colors required edge color graph graph \( strong \) rainbow connected known emph even k decide whether rainbow connectivity graph k np hard k , decide whether \( g \) leq k np hard paper prove conjecture also show np hard decide whether src \( g \) leq k even g bipartite graph
unsupervised learning predictors unpaired input output samples unsupervised learning challenging problem machine learning especially deep learning among many scenarios , study unsupervised learning problem high economic value learning predict without costly pairing input data corresponding labels part difficulty problem lack evaluation measures paper , take practical approach unsupervised learning using success criterion supervised learning prediction tasks require presence paired input output training data particular , propose objective function aims make predicted outputs fit well structure output preserving correlation input predicted output experiment synthetic structural prediction problem show even simple linear classifiers , objective function already highly non convex demonstrate nature non convex optimization problem well potential solutions particular , show regularization via generative model , learning proposed unsupervised objective function converges optimal solution
deep learning based network adaptive real time video communications work proposes innovative approach handle packet loss real time video streaming scenarios sophisticated way predicting packet loss pattern time field deep learning model
improve performance transfer learning without fine tuning using based multi view learning breast cancer images breast cancer one common types cancer leading cancer related death causes women context 2018 challenge breast cancer images , compare one handcrafted feature five transfer learning feature based deep learning find deep learning networks pretrained imagenet better performance popular handcrafted features used breast cancer images best feature achieves average accuracy 79 30 improve classification performance , random forest based integration method used combine different feature groups together five deep learning feature groups combined , average accuracy improved 82 90 \( best accuracy 85 \) handcrafted features combined five deep learning feature groups , average accuracy improved 87 10 \( best accuracy \)
bounds asymmetric broadcast channel work contains two main contributions concerning hierarchical ensembles asymmetric broadcast channel first analysis optimal maximum likelihood \( ml \) decoders weak strong user two different methods code used , provide two competing error exponents second derivation exponents generalized stochastic likelihood decoder \( \) prove exponents least tight maximum random coding error exponents derived earlier work \( 2017 \) one ml based exponents , actually prove existence hierarchical achieve best random coding exponent exponent simultaneously users
fusing hierarchical convolutional features human body segmentation clothing fashion classification clothing fashion reflects common aesthetics people share recognize fashion time clothing meaningful individual industry paper , assumption clothing fashion changes year year , fashion time recognition problem mapped clothing fashion classification problem specifically , novel deep neural network proposed achieves accurate human body segmentation fusing multi scale convolutional features fully convolutional network , feature learning fashion classification performed parts avoiding influence image background experiments , 9 , fashion images 8 continuous years collected performance evaluation results demonstrate effectiveness proposed body segmentation fashion classification methods
multimodal feature fusion cnn based recognition empirical comparison people identification video based way walk \( e \) relevant task computer vision using non approach standard current approaches typically derive sequences binary energy maps subjects extracted images , process introduces large amount non stationary noise , thus , conditioning efficacy contrast , paper focus raw pixels , simple functions derived , advanced learning techniques extract relevant features therefore , present comparative study different convolutional neural network \( cnn \) architectures three low level features \( e gray pixels , optical flow channels depth maps \) two widely adopted challenging datasets b addition , perform comparative study different early fusion methods used combine information obtained kind low level features experimental results suggest \( \) use hand crafted energy maps \( e g \) necessary , since equal better results achieved raw pixels \( ii \) combination multiple modalities \( e gray pixels , optical flow depth maps \) different cnns allows obtain state art results task image resolution several times smaller previously reported results , \( iii \) selection architecture critical point make difference state art results poor results
contextual deep cnn based hyperspectral classification paper , describe novel deep convolutional neural networks \( cnn \) based approach called contextual deep cnn jointly exploit spatial spectral features hyperspectral image classification contextual deep cnn first applies multiple 3 dimensional local convolutional filters different sizes jointly exploiting spatial spectral features hyperspectral image initial spatial spectral feature maps obtained applying variable size convolutional filters combined together form joint spatio spectral feature map joint feature map representing rich spectral spatial properties hyperspectral image fed fully convolutional layers eventually predict corresponding label pixel vector proposed approach tested data performance comparison shows enhanced classification performance proposed approach current state art
fuzzy authentication using rank distance fuzzy authentication allows authentication based fuzzy matching two objects , example based similarity two strings hamming metric , two sets set difference metric aim paper show models algorithms secure fuzzy authentication , performed using rank metric schemes presented applied different scenarios applications
cave ar system design simulate debug multi user ar experiences despite advances augmented reality \( ar \) , process creating meaningful experiences technology still extremely challenging due different tracking implementations hardware constraints , developing ar applications either requires low level programming skills , done specific tools largely possibility ar experience existing development workflows also support ar experience , requiring process error content deploy physically test applications iteration mitigate limitations , propose cave ar , novel virtual reality system , custom ar experiences available tool , cave ar based concept representing global reference system ar content tracking information , mixing geographical information , architectural features , sensor data simulate context ar experience thanks novel abstraction existing tracking technologies , cave ar operates independently users' devices , integrates existing programming tools provide maximum flexibility application provides designers ways create modify ar application , even others using cave ar allows track users , currently , interact several different channels illustrate proposed development workflow demonstrate advantages system , introduce two use cases augmented reality application created tested compare cave ar workflow traditional development methods demonstrate importance simulation live application
rate region boundary z interference channel signaling paper provides complete characterization boundary achievable rate region , called pareto boundary , single antenna z interference channel \( z ic \) , interference noise users transmit complex gaussian signals allowed considering augmented complex formulation , derive necessary sufficient condition signaling optimal condition stated threshold interference channel coefficient , function user rate allows interpretations behavior achievable rates terms coefficient \( e , degree \) furthermore , optimal coefficient provided closed form simplicity obtained characterization interesting insights signaling outperforms proper signaling single antenna z ic also provide depth discussion optimal strategies properties pareto boundary
need know succinctly data itemsets data analysis inherently iterative process , know data greatly determines expectations , hence , result would find interesting mind , introduce well approach succinctly data collection itemsets using probabilistic maximum entropy model , iteratively find interesting , turn update model data accordingly include itemsets surprising regard current model , summary guaranteed non redundant algorithm present either mine top k interesting itemsets , use bayesian information criterion automatically identify model containing itemsets important describing data , words , need experiments synthetic benchmark data show discovered summaries succinct , correctly identify key patterns data models form attain high , inspection shows data well increasingly specific , yet non redundant itemsets
survey bayesian networks applications intelligent autonomous vehicles article reviews applications bayesian networks intelligent autonomous vehicles \( \) decision making point view , represents final step fully autonomous vehicles \( currently discussion \) , comes making high level decisions autonomous vehicles \( avs \) , humans last word based works cited article analysis done , modules general decision making framework variables many efforts made showing bayesian networks promising computer model decision making research go direction testing bayesian network models real situations addition applications , bayesian network introduced elements consider developing potential making high level calls
effective static adaptive carrier sensing mechanisms dense csma networks increasingly dense deployments wireless csma networks arising applications internet things call improvement mitigate interference among simultaneous wireless devices cost efficiency backward compatibility transceiver hardware , simple approach address interference appropriately carrier sensing thresholds wireless csma protocols , particularly dense wireless networks prior studies configuration carrier sensing thresholds based simplified conflict graph model , whereas paper considers realistic signal interference noise ratio model provide comprehensive study two effective wireless csma protocols cumulative interference power carrier sensing incremental interference power carrier sensing , two aspects \( 1 \) static approach sets universal carrier sensing threshold ensure interference safe transmissions regardless network topology , \( 2 \) adaptive approach carrier sensing thresholds dynamically based feedback transmissions also provide simulation studies evaluate ratio , fairness , approaches
certifiably globally optimal extrinsic calibration per sensor present certifiably globally optimal algorithm determining extrinsic calibration two sensors capable producing independent estimates problem previously solved using variety techniques , including local optimization approaches formal global optimality guarantees use quadratic objective function formulate calibration constrained quadratic program \( \) leveraging recent advances optimization , able use existing semidefinite program solvers obtain certifiably global optimum via dual problem problem formulation globally optimized existing general purpose solvers less second , regardless number measurements available noise level enables variety robotic platforms rapidly robustly compute globally optimal set calibration parameters without prior estimate operator intervention compare performance approach local solver extensive simulations multiple real datasets finally , present necessary observability conditions connect approach recent theoretical results analytically support empirical performance system
confidence prediction lexicon free ocr reliable accuracy score crucial real world applications ocr , since systems number false lexicon based ocr systems , deal essentially multi class classification problem , often employ methods explicitly taking account lexicon , order improve accuracy however , lexicon free scenarios , filtering errors requires explicit confidence calculation work show two explicit confidence measurement techniques , show able achieve significant reduction standard benchmarks dataset
energy efficient optimization wireless information power transfer large scale mimo systems employing energy beamforming letter , consider large scale multiple input multiple output \( mimo \) system receiver energy transmitter wireless power transfer support wireless information transmission energy beamforming large scale mimo system utilized address challenging problem long distance wireless power transfer furthermore , considering limitation power system , letter focuses maximization energy efficiency information transmission \( bit per \) satisfying quality service \( qos \) requirement , e delay constraint , jointly optimizing transfer duration transmit power solving optimization problem , derive energy efficient resource allocation scheme numerical results validate effectiveness proposed scheme
latent optimization non adversarial representation disentanglement disentanglement pose content key task artificial intelligence attracted much research interest current methods disentanglement include adversarial training introducing cycle constraints work , present novel disentanglement method use adversarial training , achieving state art performance method uses latent optimization architecture style transfer , enforce separation pose content overcome test generalization issues latent optimization , novel two stage approach extensive experiments , method shown achieve better disentanglement performance adversarial non adversarial methods use level supervision
submodular inference diffusion networks multiple trees diffusion propagation information , influence diseases take place increasingly larger networks observe node copies information , makes decision becomes networks often hidden since networks highly dynamic , changing growing rapidly , observe relatively small set network changes significantly scalable network inference based small set necessary understanding rapidly evolving dynamics diffusion article , develop scalable approximation algorithm provable near optimal performance based submodular maximization achieves high accuracy scenario , solving open problem first introduced et al \( 2010 \) experiments synthetic real diffusion data show algorithm practice achieves optimal trade accuracy running time
deep learning data alignment review deep registration networks registration process computes transformation sets data commonly , registration process divided four main steps target selection , feature extraction , feature matching , transform computation alignment accuracy result depends multiple factors , significant quantity input data , presence noise , outliers occlusions , quality extracted features , real time requirements type transformation , especially ones defined multiple parameters , like non rigid r n recent advancements machine learning could turning point issues , particularly development deep learning \( dl \) techniques , improve multiple computer vision problems abstract understanding input data paper , review deep learning based registration methods presented classify different papers proposing framework extracted traditional registration pipeline new learning based proposal strengths deep registration networks \( \) try solve alignment task either replacing part traditional pipeline network fully solving registration problem main conclusions extracted , one hand , 1 \) learning based registration techniques cannot always clearly classified traditional pipeline 2 \) approaches allow complex inputs like conceptual models well traditional 3d datasets 3 \) generality learning , current proposals still ad solutions finally , 4 \) topic still requires large effort reach general solutions able cope problems affect traditional approaches
recursive part decomposition network fine grained hierarchical shape segmentation deep learning approaches 3d shape segmentation typically formulated multi class labeling problem existing models trained fixed set labels , greatly limits flexibility opt top recursive decomposition develop first deep learning model hierarchical segmentation 3d shapes , based recursive neural networks starting full shape represented point cloud , model performs recursive binary decomposition , decomposition network nodes hierarchy share weights node , node classifier trained determine type \( \) criteria decomposition features extracted higher level nodes propagated lower level ones thus , meaningful decompositions higher levels provide strong contextual cues lower levels meanwhile , increase segmentation accuracy node , enhance recursive contextual feature shape feature extracted corresponding part method segments 3d shape point cloud number parts , depending shape complexity , showing strong generality flexibility achieves state art performance , fine grained semantic segmentation , public benchmark new benchmark fine grained segmentation proposed work also demonstrate application fine grained part image shape reconstruction
diversity multiplexing tradeoff double scattering mimo channels well known presence double scattering performance mimo channel , terms multiplexing gain diversity gain paper , closed form expression diversity multiplexing tradeoff \( \) double scattering mimo channels obtained shown , channel transmit antennas , receive antennas , depends ordered version triple \( , , \) , arbitrary , condition double scattering channel single scattering channel also established
multiview spectral clustering via structured low rank matrix factorization multiview data clustering attention single view counterparts due fact leveraging multiple independent complementary information multiview feature spaces outperforms single one multiview spectral clustering aims yielding data partition agreement local manifold structures seeking eigenvalue decompositions among methods , low rank representation \( \) effective , exploring multiview consensus structures beyond low boost clustering performance however , observed , classical paradigm still suffers following limitations multiview spectral clustering flexible local manifold structure , caused enforcing low rank data correlation agreement among views , strategy , therefore , cannot achieve satisfied views agreement worse still , intuitively flexible capture latent data clustering structures paper , first , present structured latent low dimensional data cluster representations , characterize data clustering structure view upon representation , second , laplacian regularizer imposed capable preserving flexible local manifold structure view third , present iterative multiview agreement strategy minimizing divergence objective among latent data cluster representations iteration optimization process , latent representation view serves views , intuitive process iteratively coordinates views fourth , data cluster representation flexibly encode data clustering structure view adaptive input cluster number end , finally , novel objective function proposed via efficient alternating minimization strategy complexity analysis also presented extensive experiments conducted real world multiview data sets demonstrate superiority state arts
comparative analysis switching dynamics different memristor models memristor , memory , emerging technology computational memory number different memristor models available based physical experiments use memristor computational memory element , one know internal state time driven current voltage paper , examine three widely used models make comparison internal state models changes respect input current voltage model , internal state changes linearly input current however , internal state modulation model controlled hand , model shows non linear variation internal state input current
secure computation bidirectional relay bidirectional relaying , relay helps two user nodes exchange equal length binary messages , active area recent research popular strategy involves modified gaussian mac , relay decodes xor two messages using naturally occurring sum symbols simultaneously transmitted user nodes work , consider gaussian mac bidirectional relaying additional secrecy constraint protection relay constraint , relay decode xor , fully individual messages users exploit symbol addition occurs gaussian mac design explicit strategies achieve perfect independence received symbols individual transmitted messages results actually hold general scenario messages two user nodes come finite group , relay must decode sum within group two messages provide lattice coding strategy study optimal rate versus average power trade offs asymptotically large dimensions
cloudsafe tool automated security analysis cloud computing cloud computing adopted widely , providing demand computing resources improve reduce operational costs however , new also new ways exploit cloud computing environment assess security cloud , graphical security models used , attack graphs attack trees however , existing models consider types threats , also security assessment functions difficult paper , propose new security assessment tool cloud named cloudsafe , automated security assessment cloud cloudsafe tool various tools frameworks automate security assessment process demonstrate applicability cloudsafe , conducted security assessment amazon , experimental results showed effectively security information cloud carry security assessment produce security reports users cloud service providers use security report generated cloudsafe understand security cloud used provided
times image captioning attention based image captioning models image per word however , attending per word rigid easy miss information attending times adjust attention position , find missing information back avoid generating word paper , show attending times per word gain improvements image captioning task , without increasing number parameters propose flexible two lstm model make convenient encode words captioning model uses two lstms encode word sequence attention sequence respectively information two lstms image feature combined predict next word experiments caption dataset show method outperforms state art using bottom features self critical training method , method gets bleu 4 , , l , scores 0 , 0 , 0 , 1 0 test split
framework adaptive radar detection homogeneous plus structured interference part ii detectors design paper deals problem adaptive multidimensional signal detection homogeneous gaussian unknown covariance matrix structured \( unknown \) deterministic interference aforementioned problem extends well known generalized multivariate analysis variance \( \) open literature part paper , obtained maximal invariant statistic \( mis \) problem consideration , enabling tool design suitable detectors possess constant false rate \( \) property , focus development several theoretically detectors problem consideration first , considered detectors shown function mis , thus proving property second , statistical equivalence among general signal model proved third , strong connections well known \( simpler \) scenarios analyzed adaptive detection literature established finally , simulation results provided comparison proposed receivers
fine grained information flow policies web standard web browser programming model , third party scripts included application execute application 's code application 's confidential data vulnerable leakage malicious code bugs third party scripts security mechanisms modern \( policy , cross resource sharing content security policies \) coarse programming model mechanisms \( extensions \) describe whether access certain data , whereas meaningful requirement allow untrusted scripts access confidential data need prevent scripts data side motivated gap , propose , policy mechanism allows website include fine grained policies confidential application data syntax javascript programming language policies associated element , specify aspects element third party domains access data policy allows , cannot pass data \( data derived \) scripts remote policy specify policies , small set new native javascript policies enforced using numerous existing proposals information flow tracking web integrated policies one proposal use evaluate performance overheads test examples
scalable diverse cross domain image translation recently , image image translation research remarkable progress although current approaches successfully generate diverse outputs perform scalable image transfer , properties combined single method address limitation , propose scalable diverse image image translation properties combined single generator diversity determined latent variable randomly sampled normal distribution scalability obtained conditioning network domain attributes additionally , also exploit attention mechanism generator focus domain specific attribute empirically demonstrate performance proposed method face mapping datasets beyond faces
uncertain future forecasting static images using variational autoencoders given scene , humans often easily predict set future events might however , generalized pixel level computer vision systems difficult machine learning ambiguity inherent predicting future paper , focus predicting dense trajectory pixels scene , specifically move scene , travel , course one second propose conditional variational autoencoder solution problem framework , direct inference image shapes distribution possible trajectories , latent variables encode necessary information available image show method able successfully predict events wide variety scenes produce multiple different predictions future ambiguous algorithm trained thousands diverse , realistic videos requires human labeling addition non semantic action prediction , find method learns representation applicable semantic vision tasks
transfer adversarial hashing hamming space retrieval hashing widely applied large scale image retrieval due storage retrieval efficiency existing work deep hashing assumes database target domain identically distributed training set source domain paper assumption transfer retrieval setting , allows database training set come different relevant domains however , transfer retrieval setting introduce two technical difficulties first , hash model trained source domain cannot work well target domain due large distribution gap second , domain gap makes difficult database points within small hamming ball consequence , transfer retrieval performance within hamming radius 2 significantly existing hashing methods paper presents transfer adversarial hashing \( \) , new hybrid deep architecture incorporates pairwise distribution cross entropy loss learn hash codes adversarial network align data distributions source target domains generate compact transfer hash codes efficient image retrieval source target domains comprehensive experiments validate yields state art hamming space retrieval performance standard datasets
predicting conversion mild cognitive impairments disease exploring impact neuroimaging nowadays , lot scientific efforts diagnosis 's disease \( ad \) applying deep learning methods neuroimaging data even 2017 , published papers dedicated ad diagnosis , whereas works considered problem mild cognitive impairments \( \) conversion ad however , conversion prediction important problem since approximately 15 patients converges ad every year current work , focusing conversion prediction using brain magnetic imaging clinical data , demographics , cognitive , genetic , first , applied state art deep learning algorithms neuroimaging data compared results two machine learning algorithms fit using clinical data result , models trained clinical data outperform deep learning algorithms applied images explore impact neuroimaging , trained deep feed forward embedding using similarity learning histogram loss available obtained 64 dimensional vector representation neuroimaging data use learned representation deep embedding allowed increase quality prediction based neuroimaging finally , current results dataset show neuroimaging affect conversion prediction , however , cannot increase quality prediction best results predicting ad conversion provided algorithm trained clinical embedding data resulting accuracy 0 76 0 area curve 0 86 0
beyond dirty paper coding multi antenna broadcast channel partial csit rate splitting approach imperfect channel state information transmitter \( csit \) inevitable modern wireless communication networks , results severe multi user interference multi antenna broadcast channel \( bc \) capacity multi antenna \( gaussian \) bc perfect csit known achieved dirty paper coding \( dpc \) , capacity capacity achieving strategy multi antenna bc imperfect csit remain unknown conventional approaches therefore rely applying communication strategies designed perfect csit imperfect csit setting work , break conventional routine make two major contributions first , show linearly rate splitting \( rs \) , relying split messages common private parts linear precoding transmitter , successive interference cancellation receivers , achieve larger rate regions dpc multi antenna bc partial csit second , propose novel achievable scheme , denoted dirty paper coded rate splitting \( \) , relies rs split user messages common private parts , dpc encode private parts show rate region achieved multiple input single output \( miso \) bc partial csit beyond conventional dpc linearly rs benefits capability rs partially decode interference partially treat interference noise , less sensitive csit , networks loads user deployments compared dpc existing transmission strategies proposed new benchmark best known achievable strategy multi antenna bc partial csit
detecting state sentences using cnn article study expression detection using machine learning neural networks methods test results using corpora messages also compare random forest classifier convolutional neural network reviews one sentence per review corpus
gan simpler model outperforms knowledge representation learning goal knowledge representation learning entities relations low dimensional , continuous vector space push model limit obtain better results great significance knowledge graph 's applications propose simple method , , whose main idea dynamic learning rate control training method achieves remarkable improvement , compared recent gan based method moreover , introduce new negative sampling entities , also relations , different probabilities also develop efficient way , fully utilizes parallel computing , speed evaluation model link prediction tasks experiments show method effective
deep anomaly detection generalized face face recognition achieved unprecedented results , human capabilities certain scenarios however , automatic solutions production easily simple identity attacks although much effort develop face models , generalization capacity still remains challenge real scenarios paper , introduce novel approach generalized attack detection \( \) problem anomaly detection perspective , deep metric learning model proposed , loss used regularization novel loss coined metric softmax , learning process towards discriminative feature representations embedding space finally , demonstrate benefits deep anomaly detection architecture , introducing shot probability estimation need classifier trained learned features conduct extensive experiments using framework provides largest aggregated dataset face results confirm approach able outperform state art methods considerable margin
computational technologies brain paper , described set computational technologies image analysis applications brain proposed technologies based one new variational principle constructs transformation determinant \( models local size changes \) vector \( models local \) goal research image research community determinant well vector used steps image analysis specifically , develop optimal control method non rigid registration new concept construction average transformation general robust method construction unbiased template set images computational examples presented show effects vector effectiveness optimal control methods non rigid registration method construction unbiased template
efficient polynomial time approximation scheme load balancing uniformly related machines consider basic problems non scheduling uniformly related machines given schedule , defined partition jobs subsets corresponding machines , c denotes completion time machine goal find schedule minimizes maximizes sum 1 c p fixed value p 0 1 minimization problem equivalent well known problem minimizing ell p norm vector completion times machines , 0 p 1 maximization problem interest main result efficient polynomial time approximation scheme \( \) one problems schemes use non standard application called shifting technique focus work \( total size jobs \) assigned machine introduce intervals work intervals defined resulting effect goal function sufficiently small allows partition problem sub problems \( subsets machines jobs \) whose solutions combined final solution using dynamic programming results first 's natural class load balancing problems
human assisted graph search ask questions consider problem human assisted graph search given directed acyclic graph \( unknown \) target node \( \) , consider problem finding target node \( \) asking human questions form target node reachable current node \? general problem applications many domains utilize human intelligence , including , workflows , image segmentation categorization , interactive search filter synthesis knowledge , work provides first formal algorithmic study optimization human computation problem study various dimensions problem space , providing algorithms complexity results framework algorithms used design crowd platforms mechanical
cnn based facial affect analysis mobile devices paper focuses design , deployment evaluation convolutional neural network \( cnn \) architectures facial affect analysis mobile devices unlike traditional cnn approaches , models deployed mobile devices must storage requirements retaining high performance therefore propose three variants established cnn architectures evaluate large , wild benchmark dataset facial images results show proposed architectures retain similar performance dataset baseline storage requirements achieving 58 accuracy eight class emotion classification average 0 prediction demonstrate feasibility deploying models real world applications , implement music recommendation interface based predicted user affect although cnn models trained context music recommendation , case study shows \( \) trained models achieve similar prediction performance benchmark dataset , \( ii \) users tend rate recommendations provided interface average runtime deployed models fps , suggesting proposed architectures also well suited real time deployment video streams
parametric shape optimization combined additive industrial practice , additive processes often followed post processing operations , , etc achieve desired surface quality dimensional accuracy hence , given part must 3d extra material enable phase combined additive technique optimized reduce costs saving time reducing material energy usage work , numerical methodology based parametric shape optimization proposed optimizing thickness extra material , allowing minimal operations ensuring requirements moreover , proposed approach novel algorithm generating inner structures leading reduced distortion improved weight reduction computational effort induced classical constrained optimization methods replacing objective constraint functions sparse grid surrogates numerical results effectiveness proposed approach
blockchains business process management challenges opportunities blockchain technology promises potential executing inter business processes without requiring central party single point trust \( failure \) paper impact business process management \( bpm \) structure discussion using two bpm frameworks , namely six bpm core capabilities bpm paper provides research directions investigating application blockchain technology bpm
smaller selection networks cardinality constraints encoding selection networks studied many years recently , successfully applied encode cardinality constraints sat solvers decrease size generated formula need constructions selection networks efficiently generated produce networks small sizes practical range two parameters n number inputs \( boolean variables \) k number selected items \( cardinality bound \) paper give analyze new construction smaller selection networks based pairwise selection networks introduced prove also standard encodings cardinality constraints selection networks preserve arc consistency
unlabeled data deployment classification images using knowledge transfer convolutional neural networks \( cnns \) extensively beneficial medical image processing medical images , lack annotated data transfer learning used solve problem lack labeled data cnns better training capability transfer learning used many different medical applications however , model transfer size original network knowledge distillation recently proposed transfer knowledge model another one useful cover transfer learning parts knowledge may knowledge distillation paper , novel knowledge distillation using transfer learning proposed transfer whole knowledge model another one proposed method beneficial practical medical image analysis small number labeled data available proposed process tested classification simulation results demonstrate using proposed method , knowledge extensive network transferred smaller model
learning local sketch descriptors multi view correspondence paper , study problem multi view sketch correspondence , take input multiple sketches different views object predict semantic correspondence among sketches problem challenging , since visual features corresponding points different views different end , take deep learning approach learn novel local sketch data contribute training dataset generating pixel level correspondence multi view line synthesized 3d shapes handle sparsity ambiguity sketches , design novel multi branch neural network integrates patch based representation multi scale strategy learn correspondence among multi view sketches demonstrate effectiveness proposed approach extensive experiments hand drawn sketches , multi view line rendered multiple 3d shape datasets
structured linear contextual bandits sharp geometric smoothed analysis bandit learning algorithms typically involve balance exploration exploitation however , many practical applications , worst case scenarios systematic exploration encountered work , consider smoothed setting structured linear contextual bandits adversarial contexts perturbed gaussian noise unknown parameter theta structure , e g , sparsity , group sparsity , low rank , etc propose simple greedy algorithms single multi parameter \( e , different parameter context \) settings provide unified regret analysis theta assumed structure regret bounds expressed terms geometric quantities gaussian associated structure theta also obtain regret bounds compared earlier work unstructured theta setting consequence improved analysis show implicit exploration smoothed setting simple greedy algorithm works
revenue monotonicity combinatorial auctions along substantial progress made recently designing near optimal mechanisms multi item auctions , interesting structural questions also studied particular , true always extract revenue market buyers value items higher another market \? paper obtain revenue monotonicity result general setting precisely , consider revenue maximizing combinatorial auction items n buyers bayesian setting , specified valuation function v set f nm independent item type distributions let rev \( v , f \) denote maximum revenue achievable f incentive compatible mechanism intuitively , one would rev \( v , g \) geq rev \( v , f \) distribution g stochastically dominates f surprisingly , \( 2012 \) showed always true even simple case v additive natural question arises deviations contained within bounds \? extent may monotonicity intuition still valid \? present approximate monotonicity theorem class \( \) valuation functions v , showing rev \( v , g \) geq c , rev \( v , f \) g stochastically dominates f v c 0 universal constant previously , approximate monotonicity known case n 1 et al \( 2014 \) class additive valuations , \( 2015 \) valuation functions
sparse matrix matrix multiplication representation architecture acceleration long version sparse matrix multiplication important components emerging systems paper , study main challenges accelerating sparse matrix multiplication \( \) situations data stored desired order \( row column order \) , propose compact high performance sparse format , allows random access dataset low memory access overhead show using format results 14 times speedup next , propose high performance architecture , uses mesh locate useful \( non zero \) computation design maximizes data reuse sharing input data among row column mesh also show , similar memory access assumptions , proposed architecture results 9 30 times speedup comparison state art
horizon mdp approach performance evaluation moving target defense networks paper , study problem assessing effectiveness proactive defense detection policy network based moving target defense model network system using probabilistic attack graph graphical security model given network system proactive defense strategy , intelligent attacker needs perform learn locations detection systems plan optimally reach target avoiding detection compute attacker 's strategy security evaluation , develop horizon planning algorithm risk sensitive markov decision process time varying reward function finally , implement defense attack strategies synthetic network analyze frequency network number detection systems influence success rate attacker study provides insights designing proactive defense strategies online multi stage attacks carried attacker
memory augmented dialogue management task oriented dialogue systems dialogue management \( dm \) next action dialogue system according current dialogue state , thus plays central role task oriented dialogue systems since dialogue management requires access local utterances , also global semantics entire dialogue session , modeling long range history information critical issue end , propose novel memory augmented dialogue management model \( \) employs memory controller two additional memory structures , e , slot value memory external memory slot value memory tracks dialogue state values semantic slots \( instance , , price , location \) , external memory representation hidden states traditional recurrent neural networks storing context information update dialogue state efficiently , also propose slot level attention user utterances extract specific semantic information slot experiments show model obtain state art performance outperforms existing baselines
deep tractable probabilistic models major concern automated decision making , applications ranging self driving cars kidney exchanges viewpoint automated systems , questions \( \) models scenarios extracted learnt automatically data \? \( b \) computed , given split second decision points faced system \? building deep tractable probabilistic learning , propose learning regime models scenarios automatically data reasoning report experiments compare system human three domains cancer , management , problems
swaphi protein database search xeon phi maximal sensitivity algorithm enabled wide use biological sequence database search unfortunately , high sensitivity comes expense quadratic time complexity , makes algorithm computationally big databases paper , present swaphi , first algorithm employing emerging xeon protein database search swaphi designed based scale approach , e alignment speed effectively utilizing coarse grained parallelism many co processing cores \( scale \) fine grained parallelism bit wide single instruction multiple data \( \) vectors per core \( \) searching large protein database , swaphi achieves performance 58 8 billion cell updates per second \( \) single xeon phi 4 four xeon moreover , swaphi using four xeon superior 16 cpu cores 8 cores , maximum speedup 1 1 86 , respectively swaphi freely available http swaphi net
image encryption scheme value feedback abstract many round based image encryption algorithms employ permutation diffusion structure structure found iteration round equal one secret permutation existing schemes recovered even higher round adopted paper , present single round permutation diffusion cipher gray image , value feedback mechanisms introduced known attacks specifically , firstly plaintext feedback technique permutation process develop different permutation sequences different plain images employ plaintext feedback diffusion generate equivalent secret key dynamically experimental results show new scheme large key space differential attack also efficient
feasible combinatorial matrix theory show well known 's min max theorem \( \) , fundamental result combinatorial matrix theory , proven first order theory la induction restricted sigma 1 b formulas improvement standard textbook proof requires pi 2 b induction , hence yield feasible proofs new approach la weak theory essentially captures ring properties matrices however , equipped sigma 1 b induction la capable proving , host combinatorial properties 's , 's 's theorems therefore , result min max type reasoning within feasible framework
co segmentation space time co located collections present co segmentation technique space time co located image collections prevalent collections capture various dynamic events , usually multiple , may contain multiple co occurring objects necessarily part intended foreground object , resulting traditional co segmentation techniques thus , common foreground object , introduce weakly supervised technique , assume small seed , given form single image take distributed approach , local belief models propagated similar images technique progressively foreground background belief models across entire collection technique exploits power entire set image without building global model , thus successfully overcomes large variability appearance common foreground object demonstrate method outperforms previous co segmentation techniques challenging space time co located collections , including dense benchmark datasets adapted novel problem setting
smoothness structure learning proxy data sets grow size , ability learning methods find structure increasingly time needed search large spaces generate score takes observed data account instance , bayesian networks , model chosen paper , super exponentially large search space fixed number variables one possible method alleviate problem use proxy , gaussian process , place true scoring function , training selection sampled networks prove use proxy well , bound smoothness commonly used scoring function bayesian network structure learning show , compared identical search strategy using network \? exact scores , proxy based search able get equivalent better scores number data sets fraction time
deep reinforcement learning based image captioning embedding reward image captioning challenging problem owing complexity understanding image content diverse ways describing natural language recent advances deep neural networks substantially improved performance task state art approaches follow encoder decoder framework , generates captions using sequential recurrent prediction model however , paper , introduce novel decision making framework image captioning utilize policy network value network generate captions policy network serves local guidance providing confidence predicting next word according current state additionally , value network serves global lookahead guidance evaluating possible extensions current state , goal predicting correct words towards goal generating captions similar ground truth captions train networks using actor reinforcement learning model , novel reward defined visual semantic embedding extensive experiments analyses coco dataset show proposed framework outperforms state art approaches across different evaluation metrics
focused dynamic attention model visual question answering visual question answering \( \) problems increasing interest multiple research disciplines solving problems requires techniques computer vision understanding visual presented image video , well ones natural language processing understanding semantics question generating answers regarding visual content modeling , existing methods adopt strategy extracting global features image video , fails capturing fine grained information spatial configuration multiple objects extracting features auto generated regions region based image recognition methods cannot essentially address problem may introduce features question work , propose novel focused dynamic attention \( \) model provide better aligned image content representation proposed questions aware key words question , employs shelf object detector identify important regions information regions global features via lstm unit question driven representations combined question representation fed reasoning unit generating answers extensive evaluation large scale benchmark dataset , , clearly demonstrate superior performance well established baselines
direct sum result information complexity learning many bits information required learn class hypotheses dimension \? mathematical setting follow et al \( 2018 \) , value interest mutual information \( \( \) \) input sample hypothesis learning algorithm introduce class functions dimension domain mathcal x information complexity least omega left \( log log frac mathcal x right \) bits consistent proper algorithm \( deterministic random \) et al proved similar \( quantitatively weaker \) result case 1 r n result fact special case general phenomenon explore define notion information complexity given class functions mathcal h intuitively , minimum amount information algorithm mathcal h must retain input ensure consistency prove direct sum result information complexity context roughly speaking , information complexity sums combining several classes
parallelizable global conformal parameterization simply connected surfaces via partial conformal surface parameterization useful graphics , imaging visualization , applications texture mapping , construction , registration , increasing capability storing data , dense 3d surface meshes common nowadays meshes higher resolution better smooth surfaces , pose computational difficulties existing parameterization algorithms work , propose novel parallelizable algorithm computing global conformal parameterization simply connected surfaces via partial maps given simply connected surface first smaller local conformal computed parallel boundaries parameterized subsequently integrated consistently using novel technique called partial , developed based conformal theory finally , solving equation using updated boundary conditions , obtain global conformal parameterization given surface , guaranteed quasi conformal theory including additional shape constraints , method easily extended achieve disk conformal parameterization simply connected open surfaces conformal parameterization 0 closed surfaces experimental results presented demonstrate effectiveness proposed algorithm compared state art conformal parameterization methods , method achieves significant improvement computational time accuracy
empirical analysis correlation syntax prosody relation syntax prosody \( syntax prosody interface \) active area research , mostly typically studied controlled conditions recently , prosody also successfully used data based training syntax however , gap controlled detailed study individual effects syntax prosody large scale application prosody syntactic parsing shallow analysis respective influences paper , close gap investigating significance correlations realization specific syntactic functions using linear mixed effects models large corpus read german texts using corpus , able analyze performed diverse set try optimize content delivery normalization speaker , obtain significant effects , e g subject function , compared object function , positive effect duration word , negative effect
evaluating word embedding models methods experimental results extensive evaluation large number word embedding models language processing applications conducted work first , introduce popular word embedding models discuss desired properties word models evaluation methods \( evaluators \) , evaluators intrinsic extrinsic two types intrinsic evaluators test quality representation independent specific natural language processing tasks extrinsic evaluators use word embeddings input features downstream task measure changes performance metrics specific task report experimental results intrinsic extrinsic evaluators six word embedding models shown different evaluators focus different aspects word models , correlated natural language processing tasks finally , adopt correlation analysis study performance consistency extrinsic intrinsic
flexible factor graph non linear least squares optimization framework many problems computer vision robotics non linear least squares optimization problems represented factor graphs , example , simultaneous localization mapping \( slam \) , structure motion \( \) , motion planning , control developed open source c python framework , solving factor graph based least squares problems compared existing frameworks least squares solvers , \( 1 \) full python api , enables agile development easy existing python projects , \( 2 \) wide list sparse linear solvers , including enabled sparse linear solvers benchmarking results shows offers comparable performances various types problems , flexible development experience
survey various data hiding techniques comparative analysis growth internet fast communication techniques recent years security confidentiality sensitive data become prime importance concern protect data access various methods data hiding like cryptography , hashing , authentication developed practice today paper one data hiding technique called steganography steganography process sensitive information media transfer securely underlying unreliable communication network paper presents survey various data hiding techniques steganography practice today along comparative analysis techniques
non iterative slam goal paper create new framework dense slam light enough micro robot systems based depth camera inertial sensor feature based direct methods two visual slam methods minimize error iterative solutions , computationally expensive overcome problem , propose non iterative framework reduce computational requirement first , reference system \( \) projection utilized 6 degree freedom \( dof \) data , point clouds matched independent spaces respectively second , based single key frame training , matching process carried frequency domain fourier transformation , provides closed form non iterative solution manner , time complexity reduced \( n log n \) , n number matched points frame best knowledge , method first non iterative online trainable approach data association visual slam compared state arts , runs faster speed obtains 3 maps higher resolution yet still comparable accuracy
finding formed communities central problem e commerce determining overlapping communities among individuals objects absence external identification tagging address problem introducing framework captures notion communities clusters determined relative among members end define call affinity system , set elements , vector characterizing preference elements set define natural notion \( potentially overlapping \) communities affinity system , members given community else outside community thus communities formed affinity system self determined self members r n provide tight polynomial bound number self determined communities function robustness community present polynomial time algorithm communities moreover , obtain local algorithm strong stochastic performance guarantee find community time nearly linear size community r n social networks fit particularly naturally within affinity system framework appropriately extract relatively sparse yet rich information social networks , analysis yields set efficient algorithms self determined communities social networks context social networks also connect analysis results \( alpha , beta \) clusters introduced , , , cite contrast polynomial bound prove number communities affinity system model , show exists family networks number \( alpha , beta \) clusters
cross layer scheduling beamforming smart grid powered small cell networks small cell networks \( \) multiple small cell base stations \( \) , joint design beamforming vectors , user scheduling investigated constraints proportional rate long term grid energy minimization problem formulated considered , powered smart grid natural energy since scheduled user indicators coupled beamforming vectors , formulated problem challenging handle order beamforming vectors scheduled user indicators , lyapunov optimization technique used result , practical two scale algorithm proposed allocate user scheduling indicators variables coarse grained granularity \( frame \) well obtain beamforming vectors fine grained granularity \( slot \) numerical results used verify performance proposed two scale algorithm
estimation inter sentiment correlations employing deep neural network models paper focuses sentiment mining sentiment correlation analysis web events although neural network models lot mining text information , little attention analysis inter sentiment correlations paper gap sentiment calculation inter sentiment correlations paper , social emotion divided six categories , , anger , , , two deep neural network models presented sentiment calculation three datasets , bodies , news articles collected , covering objective subjective texts varying lengths \( long short \) dataset , three kinds features extracted explicit expression , implicit expression , alphabet characters performance two models analyzed , respect three kinds features phenomenon interpretation anger \( \) \( gd \) subjective text , emotions easily considered anger contrast , objective news bodies , easy regard text caused \( gd \) means , may want emotion writing news , cause anger news published result reflects sentiment complexity
muscle estimation simulation using reinforcement learning control set time varying muscle generate desired motions system muscle cannot directly measured live subjects alternative approach estimate muscle activations using inverse motion driven simulation article , propose deep reinforcement learning method estimate muscle simulated systems , introduce custom made reward function faster point point tracking target motion moreover , deploy two new techniques , namely , based hard update dual buffer experience replay , avoid feedback training proposed method tested four simulated 2d 3d environments 6 24 results show models able learn muscle given motions nearly 100 , 000 simulated steps moreover , root mean square error point point reaching target across experiments less 1 length domain motion reinforcement learning method far conventional dynamic approaches muscle control derived set distributed neurons open paths neural activity interpretation phenomenon
investigation channel estimation techniques 1 bit quantization multiple antenna systems large scale multiple antenna systems identified promising technology next generation wireless systems however , scaling number receive antennas energy consumption also increase one possible solution use low resolution analog digital receiver paper considers large scale multiple antenna uplink systems 1 bit analog digital receive antenna since partially information loss caused coarse quantization , received signals firstly factor propose low resolution aware linear minimum mean squared error channel estimator 1 bit systems moreover , characterize analytically performance proposed channel estimator deriving upper bound bayesian rao bound numerical results provided illustrate performance proposed channel estimator
impact social learning privacy preserving data collection study model data collector obtains data users payment mechanism , aiming learn underlying state data private signal user represents knowledge state social interactions user also learn noisy versions social signals , called group thanks social learning , users information state beyond private signals based private signal learned group signals , user makes strategic decisions report privacy preserved version data data collector develop bayesian game theoretic framework study impact social learning users' data reporting strategies devise payment mechanism data collector accordingly findings reveal , general , desired data reporting strategy bayesian nash equilibrium form either symmetric randomized response \( \) strategy informative non \( nd \) strategy specifically , generalized majority voting rule applied user noisy group signals determine strategy follow , user plays nd strategy , reports privacy preserving data completely based group signals , independent private signal , indicates privacy cost zero reported data user plays nd strategy still informative underlying state based learned group signals result , data collector users benefit social learning privacy costs helps improve state estimation given payment budget derive bounds minimum total payment required achieve given level state estimation accuracy
mutual information optimized quantization ldpc decoding accurately modeled flash data high capacity flash memories use multi level cells \( \) store multiple bits per cell achieve high storage densities higher densities cause increased raw bit error rates \( \) , demand powerful error correcting codes low density parity check \( ldpc \) codes well known class capacity approaching codes channels however , ldpc codes use soft information flash read channel provides hard information low resolution soft information may obtained performing multiple reads per cell distinct word line r n select values word line maximize mutual information input output equivalent multiple read channel specified noise model results show maximum mutual information \( \) quantization provides better soft information ldpc decoding given quantization level constant ratio quantization approach also show adjusting ldpc code degree distribution quantized setting provides significant performance improvement
observing dialogue therapy forecasting behavioral codes automatically analyzing dialogue help understand guide behavior domains , interactions largely conversation paper , study modeling behavioral codes used treatment style called \( \) , effective addressing related problems specifically , address problem providing real time guidance dialogue \( 1 \) client behavioral codes , \( 2 \) codes utterances help guide conversation potentially tasks , define neural network models build upon recent dialogue modeling experiments demonstrate models outperform several baselines tasks also report results analysis reveals impact various network design tradeoffs modeling therapy dialogue
resource allocation downlink noma systems key techniques open issues article presents advances resource allocation \( \) downlink non orthogonal multiple access \( noma \) systems , focusing user pairing \( \) power allocation \( \) algorithms former pairs users obtain high capacity gain exploiting channel gain difference users , later power users cluster balance system throughput user fairness additionally , article introduces concept cluster fairness proposes next largest difference based algorithm capacity gain among noma clusters controlled manner furthermore , performance comparison multiple input multiple output noma \( mimo noma \) mimo conducted users pre defined quality service simulation results presented , validate advantages noma finally , article provides research downlink noma
computing persistent homology within coq persistent homology one active computational algebraic topology applications several contexts optical character recognition analysis point cloud data paper , report formal development programs compute persistent numbers , tool persistent homology , using coq proof assistant together extension aim necessary formalize underlying mathematical theory algorithms another example showing interactive theorem reached point enough tackle formalization nontrivial mathematical theories
greedy part assignment algorithm real time multi person 2d pose estimation human pose estimation multi person image involves detection various body parts grouping individual person clusters former task challenging due mutual occlusions , combinatorial complexity latter task high propose greedy part assignment algorithm exploits inherent structure human body achieve lower complexity , compared prior published works accomplished \( \) reducing number part candidates using estimated number people image , \( ii \) greedy sequential assignment part classes , following kinematic chain head \( iii \) greedy assignment parts part class set , person clusters \( \) limiting candidate person clusters proximal clusters using human data \( v \) using specific subset pre assigned parts establishing pairwise structural constraints show , steps result sparse body parts relationship graph reduces complexity also propose methods improving accuracy pose estimation \( \) person clusters significant body part \( ii \) parts multi person pose database , pose estimation using proposed method takes 0 14 seconds per image show , proposed algorithm , using large spatial structural context , achieves state art accuracy multi person pose datasets , demonstrating robustness approach
smoothness nonlinear system identification new light shed onto optimization problems resulting prediction error parameter estimation linear nonlinear systems shown smoothness objective function depends simulation length decay rate prediction model precisely , regions parameter space model , constant beta smoothness objective function might exponentially simulation length , making hard numerically find minima within regions , even , addition providing theoretical understanding problem , paper also proposes use multiple viable solution proposed method minimizes error prediction model observed values rather running prediction model entire dataset , original prediction error formulation , multiple data smaller subsets runs prediction model , making simulation length design parameter making possible solve problems would infeasible using standard approach equivalence original problem obtained including constraints optimization method illustrated parameter estimation nonlinear systems behavior , well neural network parameter estimation
theoretical numerical analysis approximate dynamic programming approximation errors study aimed answering famous question approximation errors iteration approximate dynamic programming \( \) affect quality final results considering fact errors iteration affect next iteration goal , convergence value iteration scheme deterministic nonlinear optimal control problems cost functions investigated considering errors existing approximating respective functions results around optimal solution obtained based quantities known general optimal control problem assumptions moreover , since presence approximation errors leads deviation results optimality , sufficient conditions stability system result obtained finite number value iterations , along estimation region , derived terms upper bound control approximation error finally , process implementation method problem investigated assumptions made theoretical developments verified sufficient conditions applied guaranteeing stability near optimality
prnu patterns iris sensors preserving iris recognition principle photo response non \( prnu \) used link image source , e , sensor produced work , investigate possible modify iris image acquired using one sensor order prnu noise pattern different sensor regard , develop image perturbation routine iteratively blocks pixels original iris image prnu pattern approaches target sensor experiments indicate efficacy proposed perturbation method prnu patterns present iris image still retaining biometric content
evaluating recommender system algorithms generating local music explore task local music recommendation provide personalized relevant tracks play live events within small area local tend , long tail generally little available user preference data associated creates start problem collaborative filtering based recommendation algorithms depend large amounts information make accurate recommendations paper , compare performance three standard recommender system algorithms \( item item neighborhood \( \) , alternating least squares implicit feedback \( \) , bayesian personalized ranking \( \) \) task local music recommendation using million dataset , modify standard evaluation procedure algorithms rank tracks local eight different despite fact techniques based matrix factorization \( , \) typically perform best large recommendation tasks , find neighborhood based approach \( \) performs best long tail local music recommendation
representation learning using edge semantics biomedical knowledge discovery representation learning provides new powerful graph analytical approaches tools highly valued data science challenge mining knowledge graphs since previous graph analytical methods mostly focused homogeneous graphs , important current challenge extending methodology heterogeneous graphs knowledge domains biomedical domain , complexity biology , entities genes , , , diseases , , relationships gene co expression , , activation therefore , semantics edges nodes critical representation learning knowledge discovery real world biomedical problems paper , propose model , represents graphs considering edge semantics edge type transition matrix trained expectation maximization approach , stochastic gradient descent model employed learn node embedding heterogeneous graph via trained transition matrix validated three biomedical domain tasks biomedical entity classification , compound gene prediction , biomedical information retrieval results show considering edge types node embedding learning heterogeneous graphs , significantly outperforms state art models three tasks propose method added value relative existing graph analytical methodology , real world context biomedical knowledge discovery applicability
domain adaptation ear recognition using deep convolutional neural networks , authors extensively investigated unconstrained ear recognition problem authors first shown importance domain adaptation , deep convolutional neural network \( cnn \) models used ear recognition enable domain adaptation , authors collected new ear data set using multi face data set , named multi ear data set authors depth effect ear image quality , example , aspect ratio , classification performance finally , authors addressed problem data set bias ear recognition field experiments data set shown domain adaptation leads significant performance improvement example , vgg 16 model used domain adaptation applied , absolute increase around 10 achieved combining different deep cnn models improved accuracy 4 experiments authors conducted examine data set bias , given ear image , able classify data set come 99 accuracy , indicates strong bias among ear recognition data sets
practical open loop optimistic planning consider problem online planning markov decision process given access generative model , restricted open loop policies e sequences actions budget constraint setting , open loop optimistic planning \( \) algorithm enjoys good theoretical guarantees conservative practice , show numerical experiments propose modified version algorithm upper confidence bounds , , leads better practical performances retaining sample complexity bound finally , propose efficient implementation significantly improves time complexity algorithms
fingerprint template using ridge feature transformation biometric verification system , leakage biometric data leads identity loss since original biometric data inherently linked user , various types attacks biometric system may reveal original template utility applications address security privacy concerns cancelable biometric introduced cancelable biometric constructs protected template original biometric template using transformation functions performs comparison templates transformed domain recent approaches towards cancelable fingerprint generation either rely points respect singular points \( core delta \) utilize absolute coordinate positions points paper , propose novel non ridge feature transformation method protect original fingerprint template information proposed method partitions fingerprint region number reference point employing ridge based co system nearest neighbor identified , ridge based features computed , cancelable template generated applying pairing function followed random projection evaluated method , databases experimental results proposed method outperforms existing methods literature moreover , security analysis demonstrates proposed method necessary requirements non , , diversity minor performance degradation caused due cancelable transformation
factors sparse polynomials sparse paper removed due error proof \( 4 12 stated true \) authors would like paper 's main result positive characteristic f field prime characteristic p , polynomial x 1 p x 2 p ldots x n p following factor \( x 1 x 2 ldots x n \) p 1 , sparsity n p
strong direct product conjecture holds relations public randomized one way communication complexity let f subset x x x z relation let public one way communication complexity f , worst case error 1 3 , denoted r 1 , 1 3 \( f \) show computing f k \( k independent copies f \) , \( k r 1 , 1 3 \( f \) \) communication provided , success exponentially small k strong direct product conjecture relations public one way communication complexity r n show new tight characterization public one way communication complexity tight characterization shown j , , use new characterization show direct product result may also independent interest
optimal routing decode forward based cooperation wireless networks investigate cooperative wireless relay networks nodes help data transmission study different coding strategies single source single destination network many relay nodes given ways nodes , natural routing problem , e , determining ordered set nodes relay data source destination find given route , decode forward strategy , information theoretic cooperative coding strategy , achieves rates significantly higher achievable usual multi hop coding strategy , point point non cooperative coding strategy construct algorithm find optimal route \( terms rate maximizing \) decode forward strategy since algorithm runs time worst case , propose heuristic algorithm runs polynomial time heuristic algorithm outputs optimal route nodes transmit independent codewords implement coding strategies using practical low density parity check codes compare performance strategies different
matrix completion via max norm constrained optimization matrix completion well studied uniform sampling model trace norm regularized methods perform well theoretically numerically setting however , uniform sampling model range applications standard trace norm relaxation poorly underlying sampling scheme non uniform r n paper propose analyze max norm constrained empirical risk minimization method noisy matrix completion general sampling model optimal rate convergence established norm loss context approximately low rank matrix reconstruction shown max norm constrained method rate optimal yields unified robust approximate recovery guarantee , respect sampling distributions computational effectiveness method also discussed , based first order algorithms solving convex optimizations involving max norm regularization
high capacity image steganography gans image steganography procedure hiding messages inside techniques cryptography aim prevent adversaries reading secret message , steganography aims presence message paper , propose novel technique hiding arbitrary binary data images using generative adversarial networks allow us optimize perceptual quality images produced model show approach achieves state art 4 4 bits per pixel , detection tools , effective images multiple datasets enable fair comparisons , released open source library available online https url
interaction laws introduce study functor functor monad comonad interaction laws mathematical objects describe interaction computations behaviors effect performing machines monad comonad interaction laws objects category functor functor interaction laws show , suitable generalizations concepts dual dual , functor resp monad interacting given functor comonad dual comonad interacting given monad dual relate monad comonad interaction laws show functor functor interaction laws spaces category taken day convolution structure 's category spaces structure whose objects monad comonad interaction laws
multi channel reverse dictionary model reverse dictionary takes description target word input outputs target word together words match description existing reverse dictionary methods cannot deal highly variable input queries low frequency target words successfully inspired description word inference process humans , propose multi channel reverse dictionary model , mitigate two problems simultaneously model comprises sentence encoder multiple predictors predictors expected identify different characteristics target word input query evaluate model english chinese datasets including dictionary definitions human written descriptions experimental results show model achieves state art performance , even outperforms popular commercial reverse dictionary system human written description dataset also conduct quantitative analyses case study demonstrate effectiveness robustness model code data work obtained https url
neural programmer propose neural programmer \( npi \) recurrent compositional neural network learns represent execute programs npi three learnable components task agnostic recurrent core , persistent key value program memory , domain specific encoders enable single npi operate multiple perceptually diverse environments distinct learning compose lower level programs express higher level programs , npi reduces sample complexity increases generalization ability compared sequence sequence lstms program memory allows efficient learning additional tasks building existing programs npi also environment \( e g scratch read write pointers \) cache intermediate results computation , long term memory burden recurrent hidden units work train npi fully supervised execution traces program example sequences calls conditioned input rather training huge number relatively weak labels , npi learns small number rich examples demonstrate capability model learn several types compositional programs addition , sorting , 3d models furthermore , single npi learns execute programs 21 associated
non parametric learning models consider problem structure learning models learn relational features used derive feature representations knowledge base relational features first order rules partially grounded local model obtain feature representations propose method learning relational features model using relational tree distances empirical evaluation real data sets demonstrates superiority approach classical rule learning
tournament solutions via margin tournament solutions frequently used select winners set alternatives based pairwise comparisons alternatives prior work shown several common tournament solutions tend select large winner sets therefore low discriminative power paper , propose general framework tournament solutions order distinguish winning alternatives , also non winning ones , introduce notion margin \( mov \) tournament solutions mov robustness measure individual alternatives winners , mov captures distance dropping winner set , non winners , distance set case , distance measured terms pairwise comparisons would order achieve desired outcome common tournament solutions , including top cycle , set , banks set , determine complexity computing mov provide worst case bounds mov winners non winners results also viewed perspective manipulation
secure geo sensor network model wireless geo sensor networks \( \) suitable critical applications environments due flexibility deployment low power geo sensor nodes easily security threats like battery attack may give rise type attack , legitimate sensor nodes going low power sleep state sensor node 's battery power working due limited capability sensor nodes , difficult prevent sensor node type attack appears interaction paper , framework secure model \( \) proposed , based dynamic load distribution mechanism heterogeneous environment considers hybrid detection approach using three modules anomaly detection , decision making reduce probability false detection , compared existing approaches
paws paraphrase adversaries word existing paraphrase identification datasets lack sentence pairs high lexical overlap without models trained data fail distinguish pairs like new new paper introduces paws \( paraphrase adversaries word \) , new dataset , well formed paraphrase non paraphrase pairs high lexical overlap challenging pairs generated controlled word back translation , followed paraphrase judgments human state art models trained existing datasets performance paws \( 40 accuracy \) however , including paws training data models improves accuracy 85 maintaining performance existing tasks contrast , models capture non local contextual information fail even paws training examples , paws provides effective driving progress models better exploit structure , context , pairwise comparisons
making neural programming architectures generalize via recursion empirically , neural networks attempt learn programs data poor moreover , difficult reason behavior models beyond certain level input complexity order address issues , propose augmenting neural architectures key abstraction recursion application , implement recursion neural programmer framework four tasks grade addition , sort , topological sort , demonstrate superior interpretability small amounts training data recursion problem smaller drastically reduces domain neural network component , making tractable prove guarantees overall system 's behavior experience suggests order neural architectures robustly learn program semantics , necessary incorporate concept like recursion
multi exposure image fusion based exposure compensation paper proposes novel multi exposure image fusion method based exposure compensation multi exposure image fusion method produce images without color regions , using different however , conventional works , unclear determine appropriate exposure values , moreover , difficult set appropriate exposure values time due time constraints proposed method , input multi exposure images basis relationship exposure values pixel values , relationship obtained assuming digital camera linear response function use local contrast enhancement method also considered improve input multi exposure images compensated images finally combined one existing multi exposure image fusion methods experiments , effectiveness proposed method evaluated terms mapped image quality index , statistical , discrete entropy , comparing proposed one conventional ones
framework learning controller lyapunov based constraint application paper , focus problem direct way design stable controller nonlinear system framework learning controller lyapunov based constraint proposed , intended transform designing controller straightforward way make controller solving optimization lyapunov constraint , novel way design global stability guaranteed controller directly firstly , optimization problem subject lyapunov based constraints formulated , tracking error objective function minimize secondly , controller combines given form neural networks , finally , solution controller method optimization problem analyzed , leverage deep learning technologies boost solution results two simulations 2 order linear nonlinear systems demonstrate method proposed high performance speed convergence , tracking error smoothness amplitude control output results simulation nonlinear system , noise , uncertainty parameters difference reference output method high performance robustness generalization
graph clustering dynamic embedding graph clustering \( community detection \) long drawn enormous attention research web mining information networks recent literature topic reached consensus node link structures integrated reliable graph clustering , especially unsupervised setting however , existing methods based shallow models often suffer content noise sparsity work , propose utilize deep embedding graph clustering , motivated well recognized power neural networks learning intrinsic content representations upon , capture dynamic nature networks principle influence propagation calculate dynamic network embedding network clusters detected based stable state embedding unlike existing embedding methods task agnostic , simultaneously solve underlying node representations optimal clustering assignments end end manner provide insight , theoretically analyze interpretation network clusters find underlying connections two widely applied approaches network modeling extensive experimental results six real world datasets including social networks citation networks demonstrate superiority proposed model state art
minimum probability flow learning fitting probabilistic models data often difficult , due general intractability partition function propose new parameter estimation technique require computing intractable normalization factor sampling equilibrium distribution model achieved establishing dynamics would transform observed data distribution model distribution , setting objective minimization divergence data distribution distribution produced running dynamics time score matching , minimum velocity learning , certain forms divergence shown special cases learning technique demonstrate parameter estimation ising models , deep belief networks independent component analysis model natural scenes ising model case , current state art techniques outperformed least order magnitude learning time , lower error recovered coupling parameters
keyword extraction using centrality measures networks keyword extraction important problem natural language processing , applications ranging summarization semantic search document clustering graph based approaches keyword extraction avoid problem large domain training corpus applying variants pagerank algorithm network words although graph based approaches knowledge easily online systems , remains largely open whether benefit centrality measures pagerank paper , experiment array centrality measures word phrase networks , analyze performance four benchmark datasets centrality measures perform well better pagerank , much simpler \( e g , degree , strength , neighborhood size \) furthermore , centrality based methods give results competitive , cases , better two strong unsupervised baselines
hybrid dynamic damping scheme energy variable increasing research efforts made improve energy efficiency variable \( \) reduction energy consumption however , harvesting energy systems remains explored study proposes novel variable damping module design enabling energy exploiting effect dc proposed damping module uses four combine dynamic , hybrid approach enables energy without reduction range damping achievable numerical simulations physical experiment presented proposed module shows optimal trade task performance energy efficiency
fair regression quantitative definitions reduction based algorithms paper , study prediction real valued target , risk score rate , guaranteeing quantitative notion fairness respect protected attribute gender call class problems emph fair regression propose general schemes fair regression two notions fairness \( 1 \) statistical parity , asks prediction independent protected attribute , \( 2 \) bounded group loss , asks prediction error restricted protected group remain pre determined level study two notions fairness , schemes applicable arbitrary continuous losses , least squares regression , logistic regression , regression , many tasks schemes require access standard risk minimization algorithms \( standard classification least squares regression \) providing theoretical guarantees optimality fairness obtained solutions addition analyzing theoretical properties schemes , empirically demonstrate ability fairness accuracy frontiers several standard datasets
learning dense voxel embeddings 3d neuron reconstruction show dense voxel embeddings learned via deep metric learning employed produce highly accurate segmentation neurons 3d microscopy images metric graph arbitrary set short long range edges constructed dense embeddings generated convolutional network partitioning metric graph long range repulsive constraints produce initial segmentation high precision , substantial improvements objects convolutional embedding net without modification systematic caused complex self objects proposed method achieves state art accuracy challenging problem 3d neuron reconstruction brain images acquired serial section microscopy alternative , object centered representation could generally useful computational tasks automated neural circuit reconstruction
geographical map registration fusion lidar aerial level globally accurate consistent maps autonomous vehicles navigation long achieved board real time kinematic \( \) gps open areas however dealing urban environments , gps experience multipath urban , , inside environments paper present strategies efficiently local maps geographical coordinate systems integration gps information extracted precisely geo high resolution aerial orthogonal imagery dense lidar point clouds obtained moving vehicle horizontal plane , accurately aerial sparse , robust long term like landmarks used anchor points link lidar aerial image sensing , spatial uncertainties remaining lidar points cannot directly measured identified achieved 15 absolute average global accuracy using precisely geo aerial imagery ground truth enabling fusion ground vehicle board sensor features features extracted aerial images traffic lane also useful cooperative sensing unbiased accurate global reference experimental results presented demonstrating accuracy consistency maps operating large areas
language classification bilingual word embedding graphs study role second language bilingual word embeddings monolingual semantic evaluation tasks find strongly weakly positive correlations stream task performance second language similarity target language additionally , show bilingual word embeddings employed task semantic language classification joint semantic spaces vary meaningful ways across second languages results support hypothesis semantic language similarity influenced structural similarity well contact
pipeline interventions introduce emph pipeline intervention problem , defined directed acyclic graph set stochastic matrices transitions successive layers graph model people different populations presented opportunities , eventually leading reward model , individuals initial position \( e node first layer graph \) according fixed probability distribution , stochastically progress graph according transition matrices , reach node final layer graph node final layer emph reward associated pipeline intervention problem asks best make costly changes transition matrices people 's stochastic transitions graph , subject budget constraint consider two objectives social welfare maximization , fairness motivated maximin objective seeks maximize value population \( starting node \) emph least expected value consider two variants maximin objective turn distinct , depending whether demand deterministic solution allow objective , give efficient approximation algorithm \( additive \) constant width networks also characterize price fairness setting ratio highest achievable social welfare highest social welfare consistent maximin optimal solution finally show polynomial width networks , even approximating maximin objective constant factor np hard , even networks constant depth shows restriction width positive results essential
maximal information leakage based privacy preserving data mechanisms often necessary training data public domain , protecting privacy certain sensitive labels use information theoretic measures develop privacy preserving data mechanisms mechanism involves data vectors manner balance privacy utility trade use maximal information leakage output data vector confidential label privacy metric first study theoretical bernoulli gaussian model study privacy utility trade mean gaussian distributions perturbed show optimal solution case utility measured using probability error adversary consider application framework data driven setting provide empirical approximation mutual information performing experiments mnist data sets , show proposed framework achieves equivalent better privacy previous methods based mutual information
dynamical simrank search time varying networks article , study efficient dynamical computation pairs time varying graphs em et al 's approach requires \( r 4 n 2 \) time \( r 2 n 2 \) memory graph n nodes , r target rank low rank \( 1 \) first consider edge update new node insertions show simrank update delta response every link update rank one matrix equation provides incremental method requiring \( 2 \) time \( n 2 \) memory worst case update pairs similarities k iterations \( 2 \) speed computation , propose lossless pruning strategy captures affected areas delta unnecessary retrieval reduces time incremental simrank \( k \( \) \) , number edges old graph , \( le n 2 \) size affected areas delta , practice , n 2 \( 3 \) also consider edge updates node insertions , three cases , according end edge new node case , devise efficient incremental algorithm support new node insertions \( 4 \) next design efficient batch incremental method handles similar sink edges simultaneously redundant edge updates \( 5 \) achieve linear memory , devise memory efficient strategy dynamically updates pairs column column \( \) memory , without need store \( n 2 \) pairs old simrank scores experimental studies various datasets demonstrate solution substantially outperforms existing incremental simrank methods , faster memory efficient million scale graphs
diversity gain one shot communication molecular timing channels study diversity one shot communication molecular timing channels considered channel model transmitter simultaneously large number information particles , information encoded time release receiver decodes information based random time arrival information particles characterize asymptotic exponential decrease rate probability error function number released particles denote quantity system diversity gain , depends number particles transmitted well receiver detection method three types detectors considered \( ml \) detector , linear detector , detector based first arrival \( \) among transmitted particles show random propagation characterized right sided unimodal densities zero mode , detector equivalent ml detector , significantly outperforms linear detector moreover , even densities positive mode , diversity gain achieved detector close achieved ml detector much higher gain achieved linear detector
towards detecting social media spread false well monitoring stream news social media latest updates paper , describe methodology developed within project collection sampling conversational , well tool developed facilitate annotation identify ones describe annotation task conducted collected 2014 present findings results show collect effectively social media identify multiple associated range would hard identify relying existing techniques need manual input specific keywords
transfer learning segmenting reduced hyperspectral images deep learning established state art multiple fields , including hyperspectral image analysis however , training large capacity segment imagery requires representative training sets data human dependent time consuming , especially observation scenarios , hyperspectral data transfer costly time constrained letter , show effectively deal limited number size available hyperspectral ground truth sets , apply transfer learning building deep feature also , exploit spectral dimensionality reduction make technique applicable hyperspectral data acquired using different sensors , may capture different numbers hyperspectral experiments , performed several benchmarks statistical tests , approach allows us effectively train well generalizing deep convolutional neural nets even using significantly reduced data
finding short words prefix codes study problems finding shortest word length given prefix code done two different settings code defined arbitrary decoder recognizing star code defined decoder \( whose size equivalent total length words code \) first case every varepsilon 0 prove n 1 varepsilon inapproximability binary maximal prefix codes , theta \( log n \) inapproximability finite binary maximal prefix codes n frac 1 2 varepsilon inapproximability finite binary prefix codes c inapproximability mean non existence c approximation polynomial time algorithm assumption p ne np , n number states decoder input second case , propose approximation exact algorithms conjecture finite maximal prefix codes problem solved polynomial time also study related problems finding shortest shortest avoiding word
transactional frequent subgraph mining distributed memory systems transactional frequent subgraph mining identifies frequent subgraphs collection graphs research problem wide applicability increasingly requires higher scalability single machine solutions address needs big data use cases introduce , advanced approach frequent subgraph mining utilizes features provided distributed memory systems determines complete set frequent subgraphs arbitrary string labeled directed occur social , business knowledge networks optimized runtime minimal network traffic memory aware extensive performance evaluation large graph collections shows scalability effectiveness pruning optimization techniques
unified backpropagation multi objective deep learning common practice deep convolutional neural architectures employ fully connected layers followed softmax activation minimize cross entropy loss classification recent studies show substitution addition softmax objective cost functions support vector machines linear analysis highly beneficial improve classification performance hybrid neural networks propose novel paradigm link optimization several hybrid objectives unified backpropagation highly burden extensive boosting independent objective functions complex formulation gradients hybrid loss functions linked basic probability assignment evidence theory conduct experiments variety scenarios standard datasets evaluate advantage proposed approach consistent improvements classification performance deep convolutional neural networks
active testing efficient robust framework estimating accuracy much recent work visual recognition aims scale learning massive , annotated datasets address problem scaling evaluation models large scale datasets noisy labels current protocols require human user either \( \) small fraction test set ignore rest , else correct errors annotation found manual inspection results work , formulate problem one active testing , examine strategies efficiently querying user obtain rate performance estimate minimal demonstrate effectiveness proposed active testing framework estimating two performance metrics , precision k mean average precision , two popular computer vision tasks , multi label classification instance segmentation show approach able save significant human annotation effort robust alternative evaluation protocols
software engineering hardware design high level synthesis \( \) tools fpga development mainstream , allowing design architectures using languages c , c , move languages significant benefits , many aspects traditional software engineering still , exploited developers practice furthermore , designing reconfigurable architectures requires support hardware constructs , shift registers , native cpu oriented languages address gap , developed , collection software tools , hardware modules , code samples , designed enhance productivity developers goal two fold first , create community driven edge development , move , provides powerful abstractions provided second , collect wide range example codes , minimal proofs concept , larger , real world applications , directly work offered open source library , containing files , c , scripts , examples codes , receptive contribution benefit developers , general functionality examples
semi supervised rare disease detection using generative adversarial network rare diseases affect relatively small number people , limits investment research developing efficient method rare disease detection crucial first step towards subsequent clinical research paper , present semi supervised learning framework rare disease detection using generative adversarial networks method takes advantage large amount unlabeled data disease detection achieves best results terms precision recall score compared baseline techniques
data augmentation autoencoders unsupervised anomaly detection paper proposes autoencoder \( \) used improving performance class classifiers purpose detecting anomalies traditional one class classifiers \( \) perform poorly certain conditions high dimensionality sparsity also , size training set plays important role performance one class classifiers autoencoders widely used obtaining useful latent variables high dimensional datasets proposed approach , capable deriving meaningful features high dimensional datasets data augmentation time augmented data used training algorithms experimental results show proposed approach enhance performance algorithms also outperforms well known approaches
joint vision based navigation control obstacle avoidance dynamic environments work addresses problem coupling vision based navigation systems aerial vehicles \( \) robust obstacle avoidance capabilities former formulated maximization point interest , latter modeled repulsive areas whole problem optimal control problem \( \) , solved leveraging state art numerical optimization resulting trajectories well suited achieve specified goal location avoiding obstacles safety margin minimizing probability track target interest combining technique proper shaping \( e g augmenting shape obstacle velocity , obstacle detection uncertainties \) results robust obstacle avoidance behaviour validate approach within extensive simulated experiments demonstrating \( \) capability satisfy constraints , \( ii \) avoidance even challenging situations release paper open source implementation
distributed adaptive algorithm sparse parameter estimation gaussian mixture noise distributed adaptive algorithm estimation sparse unknown parameters presence noise proposed paper based normalized least mean fourth \( \) criterion first step , local adaptive algorithm modified zero norm order speed convergence rate also reduce steady state error power sparse conditions , proposed algorithm extended distributed scenario improvement estimation performance achieved due cooperation local adaptive filters simulation results show superiority proposed algorithm comparison conventional algorithms
multimodal meaning representation generic dialogue systems architectures unified language agents essential design multi agents architectures type interaction \( linguistic , multimodal , including particular aspects force feedback \) , type application \( command dialogue , request dialogue , database querying \) , concepts common need generic meta model order tend towards task independent systems , need modules parameterization procedures paper , focus characteristics meta model designed represent meaning linguistic multimodal applications meta model called multimodal interface language , first specified framework project want test relevant completely different context \( different task , different interaction type , different linguistic domain \) detail exploitation framework project , draw conclusions role parameterization task independent dialogue
post quantum cryptography cyclic high order currently active post quantum cryptography \( \) solutions search , attempts find cryptographic protocols attacks means instance polynomial time algorithm numerical field problems like integer factorization \( \) discrete \( \) use non commutative non structures , among others , valid choices kinds protocols case , focus permutation high order belonging symmetric group using one way functions \( \) , derived key exchange procedure relies combinatorial operations pose hard search problems assumed belonging time complexity class obvious advantages present protocols conceptual simplicity , fast throughput implementations , high security need arithmetic operations therefore extended precision libraries features make suitable low performance low power consumption platforms like smart , keys
popular matchings limits tractability consider popular matching problems bipartite non bipartite graphs strict preference lists known every stable matching min size popular matching subclass max size popular matchings called dominant matchings well studied bipartite graphs always exist simple linear time algorithm find one r n show stable dominant matchings two tractable popular matchings bipartite graphs precisely , show np complete decide g admits popular matching neither stable dominant also show number related hardness results , \( tight \) inapproximability maximum weight popular matching problem non bipartite graphs , show strong negative result np hard decide whether popular matching exists , result holds replace popular dominant r n positive side , show following results graph identify subclass dominant matchings called strongly dominant matchings show linear time algorithm decide strongly dominant matching exists show efficient algorithm compute popular matching minimum cost graph edge costs bounded treewidth
triangle representations planar graphs prove every planar graph intersection graph triangles plane
improving model based control active exploration reconstruction uncertainty optimization model based predictions future trajectories dynamical system often suffer , forcing model based control algorithms plan often , thus computationally expensive , suboptimal reliable work , propose model agnostic method estimating uncertainty model \? predictions based reconstruction error , using control exploration experiments show , uncertainty estimation used improve control performance wide variety environments choosing predictions model also used active learning explore efficiently environment planning trajectories high uncertainty , allowing faster model learning
exploiting power holistic survey network layer multipath internet inherently multipath network underlying network single path , connecting various nodes would unfortunately , traditional internet technologies designed around assumption single working path source destination lack native multipath support network performance even underlying network connected redundant multiple paths computer networks exploit power , diverse collection paths resource single resource , inherent redundancy internet opens new opportunities , promising increased throughput \( concurrent usage multiple paths \) increased reliability fault tolerance \( use multiple paths redundant \) many emerging trends networking internet 's future multipath , including use multipath technology data center computing availability multiple heterogeneous radio interfaces wireless \( wi fi cellular \) wireless devices mobile devices heterogeneous access networks development standardization multipath transport protocols multipath aim paper provide comprehensive survey literature network layer multipath solutions present detailed investigation two important design issues , namely , control plane problem compute select data plane problem split flow computed paths main contribution paper systematic main design issues network layer multipath routing along broad ranging survey vast literature network layer also highlight open issues identify directions future work
two algorithms compressed sensing sparse tensors compressed sensing \( cs \) exploits sparsity signal order integrate acquisition compression cs theory enables exact reconstruction sparse signal relatively linear measurements via suitable nonlinear minimization process conventional cs theory relies data representation , results good compression ratios expense increased computational complexity applications involving color images , video sequences , multi sensor networks , data high order , thus represented form standard applications cs higher order data typically involve representation data long vectors turn measured using large sampling matrices , thus huge computational memory burden chapter , introduce generalized tensor compressed sensing \( gtcs \) unified framework compressed sensing higher order tensors preserves intrinsic structure data reduced computational complexity reconstruction demonstrate gtcs offers efficient means representation multidimensional data providing simultaneous acquisition compression tensor modes addition , two reconstruction procedures , serial method \( gtcs \) parallelizable method \( gtcs p \) , capable tensor based noisy observations compare performance proposed methods compressed sensing \( \) multi way compressed sensing \( \) demonstrate experimentally gtcs outperforms terms reconstruction accuracy \( within range compression ratios \) processing speed major disadvantage methods \( well \) achieved compression ratios may worse offered
learning semantic correspondence exploiting object level prior address problem semantic correspondence , , establishing dense flow field images different instances object scene category propose use images annotated binary foreground masks synthetic geometric train convolutional neural network \( cnn \) task using masks part signal provides object level prior semantic correspondence task offers good compromise semantic flow methods , amount training data limited cost manually selecting point correspondences , semantic alignment ones , regression single global geometric transformation images may sensitive image specific details background clutter propose new cnn architecture , dubbed , implements idea leverages new differentiable version function end end training , loss combines mask flow consistency smoothness terms experimental results demonstrate effectiveness approach , significantly outperforms state art standard benchmarks
gender based characters fewer case study twitter public increasingly data social media sites measure public provide timely public includes exploration public views important social issues gender based \( \) study , examine big \( social \) data consisting nearly million tweets collected twitter period ten months analyze public opinion regarding , nature practices geographical location gender demonstrate utility computational social science mine insight corpus influence transient events factors reveal public awareness regarding tolerance suggest opportunities intervention measurement intervention effectiveness non organizations policy development
new efficient matching method web services substitution internet considered extensive market world keep reputation , must real problems result distribution diversity protocols used communications web service technology significantly effects distribution heterogeneity , several problems performance \( , load use , high cost cpu time \) faced situation , move direction substitution web services context , propose effective technique substitution based new method matching allows detecting expressing matching web services pairwise considering ontology also , method performs discovery similar web service using efficient method similarity measurement
driver identification using sensor data single turn automotive continue advance , cars becoming sensors perform driving operations sensors help car navigate , reduce accidents , provide however , also used learn drivers paper , propose method predict , sensor data collected single turn , identity driver given set individuals problem terms time series classification , dataset contains sensor one turn , repeated several times multiple drivers build classifier find unique patterns individual 's driving style , visible data even short road segment test approach , analyze new dataset collected , test vehicles equipped automotive data storing sensor real show turns particularly well suited detecting variations across drivers , especially compared focus 12 frequently made turns dataset , include , urban , highway , , obtaining accurate identification results learning useful insights driver behavior variety settings
using bluetooth low energy smartphones map social networks social networks important role individual 's health , propagation health related features network , correlations network structures using bluetooth enabled smartphones measure social connectivity alternative traditional paper based data collection however studies employing technology restricted limited sets investigated feasibility using bluetooth low energy \( \) protocol , present users' smartphones , measure social connectivity custom application designed android ios app simultaneously broadcast via perform periodic discovery scans devices app two android two ios , combination devices tested foreground , background locked states connectivity successfully measured test cases , except two ios devices locked state smartphones locked state majority day , severely limits ability measure social connectivity users' smartphones currently feasible use bluetooth low energy map social networks , due ios devices detect another ios device locked state technology successfully implemented android devices , represents smaller market share partially fully compatible devices
testing whether linear equations causal free probability theory approach propose method whether linear relations two high dimensional variables x due causal influence x x earlier proposed called trace method extended regime dimension observed variables exceeds sample size based previous work , conditions characterize causal relation x moreover , describe statistical test argue causal directions typically common cause full theoretical analysis presented deterministic case approach seems valid noisy case , , additionally present approach based sparsity constraint discussed method yields promising results simulated real world data
bounded treewidth graphs let k integer two vertex k colorings graph emph adjacent differ exactly one vertex graph emph k mixing proper k coloring transformed sequence adjacent proper k colorings graph \( 2 \) mixing , treewidth graph \( 2006 \) prove shortest sequence two \( 2 \) colorings quadratic , problem left open et al \( 2012 \) r n proved graph k mixing k least maximum degree plus two improve 's bound using number , worst number colors greedy coloring
social autonomous vehicles autonomous vehicles \( avs \) reduce traffic accidents , sometimes choose two , running sacrificing passenger save defining algorithms help avs make decisions challenge found participants six amazon mechanical studies avs \( , avs greater good \) would like others buy , would avs protect costs study participants enforcing avs would less buy av accordingly , algorithms may increase adoption technology
estimation utility maximizing bounds potential outcomes estimation individual treatment effects often used basis contextual decision making fields healthcare , education , economics however , many real world applications sufficient decision maker upper lower bounds potential outcomes decision alternatives , allowing evaluate trade benefit risk mind , develop algorithm directly learning upper lower bounds potential outcomes treatment non treatment theoretical analysis highlights trade complexity learning task confidence resulting bounds cover true potential outcomes , complex learning task suggest novel algorithm maximizes utility function maintaining valid potential outcome bounds illustrate different properties algorithm , highlight used guide decision making using two semi simulated datasets
deterministic algorithms skewed matrix products recently , presented randomized approximation algorithm multiplication real valued matrices building upon work detecting frequent items data streams continue line research present new em deterministic matrix multiplication algorithms r n motivated applications data mining , first consider case real valued , nonnegative n n input matrices b , show obtain deterministic approximation weights individual entries , well p norm , product algorithm simple , space efficient runs one pass input matrices user defined b \( 0 , n 2 \) algorithm runs time \( n cdot text sort \( n \) \) space \( n b \) approximation entries within additive factor b , c sum , j c 1 norm matrix c text sort \( n \) time required sort n real numbers linear space building upon result et al show skewed matrix products \( common situation many real life applications \) algorithm efficient achieves better approximation guarantees previously known randomized algorithms r n input matrices restricted nonnegative entries , present new deterministic group testing algorithm detecting nonzero entries matrix product large absolute value algorithm clearly outperformed randomized matrix multiplication algorithms , obtain first \( n 2 varepsilon \) time deterministic algorithm matrix products \( sqrt n \) nonzero entries
mining top k association rules recommendation recommender systems important e commerce companies well researchers recently , association rules proposed start recommendation however , existing approaches globally strong rules therefore users may receive recommendation paper , propose mine top k association rules user first define three measures association rules source coverage measures user size , target coverage measures item size , confidence measures strength association confidence measure , rules ranked according strength propose algorithms training recommender suggesting items user experimental publicly available data set results indicate appropriate setting avoid fitting time , help obtaining high recommending accuracy
entity recognition language document connection network eu eu case law developed application aiming federated search eu contains 1 million documents , daily updates database holds documents eu sources online well public documents national office application termed provides search besides free text metadata \( list \) , features hierarchical data structures \( concept hierarchy trees \) codes classification well subject terms links particular document documents \( case law documents well , national decisions eu etc \) tables directed graph networks choosing document , relations documents real time network network graphs help identifying key documents referred many documents \( \) sets documents predominantly \( citation networks \)
value bandit feedback offline recommender system evaluation academic literature , recommender systems often evaluated task next item prediction procedure aims give answer question given natural sequence user item interactions time , predict item user interact time 1 \? evaluation results obtained said methodology used proxy predict system perform better online setting online setting , however , poses different question given natural sequence user item interactions time , get user interact item time 1 \? causal perspective , system performs intervention , want measure effect next item prediction often used fall back objective information interventions effects \( shown recommendations whether received click \) unavailable type data available , however , provide great value reliably estimating online recommender system performance series simulated experiments environment , show traditional offline evaluation schemes fall short additionally , show called bandit feedback exploited effective offline evaluation accurately reflects online performance
design optical character recognition system camera based devices paper presents complete optical character recognition \( ocr \) system camera captured image graphics embedded textual documents devices first , text regions extracted , regions lines characters characters recognition module set 100 business images , captured cell phone camera , achieved maximum recognition accuracy compared , open source based powerful ocr engine , present recognition accuracy moreover , developed technique computationally efficient low memory applicable devices
two way networks adaptation useless two way networks , nodes act sources messages allows adaptation interaction nodes node 's channel inputs may functions message \( \) previously received signals best adapt key two way communication , rendering challenging however , examples exist point point channels adaptation beneficial capacity perspective ask whether examples exist multi user two way networks r n first consider deterministic two way channel models binary modulo 2 addition channel generalization , linear deterministic channel deterministic models obtain capacity region two way multiple access broadcast channel , two way z channel two way interference channel \( ic \) cases permit nodes adapt channel inputs past outputs \( except linear deterministic two way ic permit 2 4 nodes fully adapt \) however , show adaptation useless capacity region perspective capacity achieved strategies channel inputs use adapt previous inputs finally , consider gaussian two way ic , show partial adaptation useless interference strong strong weak interference regimes , show non adaptive scheme utilized parallel directions achieves within constant gap symmetric rate fully \( regimes \) partially \( remaining regimes \) adaptive models r n central technical contribution derivation new , computable outer bounds allow adaptation inner bounds follow non adaptive achievability schemes corresponding one way channel models
scalable verification markov decision processes markov decision processes \( mdp \) useful model concurrent process optimisation problems , verifying numerical methods often intractable existing approaches scale well limited memoryless schedulers present basis scalable verification , using \( 1 \) memory representation history dependent schedulers thus facilitate scalable learning techniques use massively parallel verification
context aware embedding targeted aspect based sentiment analysis attention based neural models employed detect different aspects sentiment target targeted aspect based sentiment analysis \( \) however , existing methods specifically pre train reasonable embeddings targets aspects may result targets aspects vector representations different contexts context dependent information address problem , propose novel method refine embeddings targets aspects embedding refinement utilizes sparse coefficient vector adjust embeddings target aspect context hence embeddings targets aspects refined highly words instead using context independent randomly vectors experiment results two benchmark datasets show approach yields state art performance task
variability importance reference standards evaluating machine learning models purpose use quantify errors \( dr \) grading based individual majority decision , train improved automated algorithm dr grading design retrospective analysis participants retinal images dr programs methods images algorithm , u board ophthalmologists , retinal specialists consensus retinal specialists reference standard main outcome measures agreement different well algorithm , measured \( quadratic weighted \) kappa score compare performance different forms manual grading algorithm various dr \( e g , mild worse dr , moderate worse dr \) , measured area curve \( auc \) , sensitivity , results retinal specialists majority decision ophthalmologists , common missing \( \) \( \) , \( 20 \) , \( 16 \) relative reference standard , kappa individual retinal specialists , ophthalmologists , algorithm 0 82 0 91 , 0 80 0 , 0 , respectively moderate worse dr , majority decision ophthalmologists sensitivity 0 0 algorithm sensitivity 0 , 0 , auc 0 mild worse dr , algorithm sensitivity 0 , 0 , auc 0 using small number consensus tuning dataset higher resolution images input , algorithm improved auc 0 0 moderate worse dr conclusions reduces errors dr grading small set dr allows substantial improvements algorithm performance resulting algorithm 's performance par individual u board ophthalmologists retinal specialists
multiparty communication complexity testing triangle freeness paper initiate study property testing simultaneous non simultaneous multi party communication complexity , focusing testing triangle freeness graphs consider textit coordinator model , k players private inputs , coordinator receives input coordinator communicate players , players cannot communicate model , ask input graph divided players , player edges , many bits players coordinator need exchange determine graph triangle free , textit far triangle free \? r n general communication protocols , show tilde \( k \( nd \) 1 4 k 2 \) bits sufficient test triangle freeness graphs size n average degree \( degree need known advance \) textit simultaneous protocols , one communication round , give protocol uses tilde \( k sqrt n \) bits \( sqrt n \) tilde \( k \( nd \) 1 3 \) omega \( sqrt n \) , , average degree need known advance show average degree \( 1 \) , simultaneous protocol asymptotically optimal logarithmic factors higher degrees , able give lower bounds testing triangle freeness , give evidence problem hard showing finding edge triangle hard , even least constant fraction edges must removed order make graph triangle free
asynchronous peak detection molecular communication molecular communication requires low complexity symbol detection algorithms deal many sources uncertainty inherent channels paper proposes two variants high performance asynchronous peak detection algorithm receiver makes independent observations first variant low complexity measures largest observation within sampling interval second variant adds decision feedback mitigate inter symbol interference although algorithm require synchronization transmitter receiver , results demonstrate bit error performance symbol symbol detection using first variant better using single sample whose sampling time chosen priori second variant shown performance comparable energy detector variants algorithm demonstrate better resilience timing existing detectors
unsupervised learning disentangled interpretable representations sequential data present hierarchical variational autoencoder , learns disentangled interpretable representations sequential data without supervision specifically , exploit multi scale nature information sequential data explicitly within hierarchical graphical model imposes sequence dependent priors sequence independent priors different sets latent variables model evaluated two speech corpora demonstrate , qualitatively , ability transform linguistic content manipulating different sets latent variables quantitatively , ability outperform vector baseline speaker verification reduce word error rate much train test scenarios automatic speech recognition tasks
whether code wireless relay channel throughput benefits random linear network codes studied extensively wireless erasure networks often assumed nodes within network perform coding operations energy constrained systems , however , coding subgraphs chosen control number coding nodes maintaining throughput paper , explore strategic use network coding wireless packet erasure relay channel according throughput energy metrics relay channel , single source communicates single sink aid half duplex relay flow model used describe case source relay coding , markov chain models proposed describe packet evolution source relay coding addition transmission energy , take account coding show coding relay alone operating fashion neither throughput energy efficient given set system parameters , analysis determines optimal amount time relay transmission , coding performed
adversarial approach unsupervised zero shot image image translation image image translation models shown remarkable ability transferring images among different domains existing work follows setting source domain target domain keep training inference phases , cannot generalized scenarios translating image unseen domain another unseen domain work , propose unsupervised zero shot image image translation \( \) problem , aims learn model transfer translation knowledge seen domains unseen domains accordingly , propose framework called introducing adversarial training scheme , learns model domain domain specific feature distribution semantically consistent vision attribute modalities domain invariant features disentangled shared encoder image generation carry extensive experiments datasets , results demonstrate effectiveness proposed method task moreover , shows significant accuracy improvements state art zero shot learning methods
higher category models pi calculus present approach modeling computational using higher category theory specifically present fully abstract semantics pi calculus interpretation consistent , interpreting terms typed , simultaneously providing explicit interpretation rewrite rules standard operational 2 one key contributions , inspired reactions , method restricting application 2 interpreting rewrites specific contexts
vector linear multicast networks vector linear network coding \( lnc \) generalization conventional scalar lnc , data unit transmitted every edge l dimensional vector data symbols base field gf \( q \) vector lnc choices coding operations intermediate nodes , popular conjecture benefit vector lnc scalar lnc terms alphabet size data units exist \( \) multicast networks vector linearly solvable dimension l gf \( q \) scalar linearly solvable field size paper introduces systematic way construct multicast networks , subsequently establish explicit instances positive answer conjecture infinitely many alphabet sizes respect arbitrary prime p hand , paper also presents explicit instances special property vector linear solution dimension l gf \( 2 \) scalar linear solutions gf \( \) 2 n l n , odd even discovery also given base field , multicast network vector linear solution dimension l necessarily vector linear solution dimension l
games fixed rank hierarchy games propose new hierarchical approach understand complexity open problem computing nash equilibrium game specifically , investigate hierarchy games \( , b \) results restricting rank matrix b fixed rank k every fixed k , class strictly generalizes class zero sum games , special case general games show even k 1 set nash equilibria games consist arbitrarily large number connected components question exact polynomial time algorithms find nash equilibrium remains open games fixed rank , provide polynomial time algorithms finding epsilon approximation
instance normalization missing ingredient fast paper revisit fast method introduced et al \( 2016 \) show small change architecture results significant qualitative improvement generated images change limited batch normalization instance normalization , apply latter training testing times resulting method used train high performance architectures real time image generation code made available github https url full paper found arxiv
multilevel constructions coding packing geometric lattice special multilevel constellations constructed binary codes , construction c , relevant applications mathematics \( sphere packing \) communication problems \( multi stage decoding efficient vector quantization \) work , explore properties construction c , particular geometric propose new multilevel construction , motivated bit coded modulation , call construction c star explore geometric minimum distance properties construction c star , discuss potential superior packing efficiency respect construction c
compact indexes flexible top k retrieval self index based retrieval system capable rank safe evaluation top k queries framework generalizes greedy approach et al \( 2010 \) handle multi term queries , including phrases propose two techniques significantly reduce ranking time wide range popular information retrieval \( \) relevance measures , first , elements document array according document weight second , introduce repetition array , generalizes 's \( \) document frequency structure document subsets combining document repetition array , achieve attractive functionality space trade offs provide extensive evaluation system sized collections
multiscale mixing patterns networks mixing networks tendency nodes attributes , metadata , link property often found social networks , higher tendency links occurring people age , , political belief quantifying level assortativity \( preference linking nodes different attributes \) shed light organization complex networks common practice measure level assortativity according assortativity coefficient , modularity case categorical metadata global value average level assortativity across network may representative statistic mixing patterns heterogeneous example , social network spanning may exhibit local differences mixing patterns consequence differences , introduce approach localize global measure describe assortativity , across multiple scales , node level consequently , able capture qualitatively evaluate distribution mixing patterns network find , many real world networks , distribution assortativity skewed , , multimodal method provides lens closely examine mixing patterns networks
group k means study learn multiple dictionaries dataset , approximate data point sum codewords chosen corresponding dictionary although theoretically low approximation errors achieved global solution , effective solution well studied practice solve problem , propose simple yet effective algorithm textit group k means specifically , take dictionary , two selected dictionaries , group k means cluster centers , deal approximation issue minimizing approximation errors besides , propose hierarchical initialization non convex problem experimental results well validate effectiveness approach
ant routing algorithm minimize network power consumption energy consumption infrastructure concerns development power efficient networking equipment algorithms old equipment almost constant amount power regardless traffic load , efforts minimize total energy usage modifying routing decisions aggregate traffic minimal set links , creating opportunity power equipment low traffic new equipment , power profile functions depending offered load , presents new challenges optimal routing goal power links , aggregate spread traffic devices operate network usage paper present algorithm , making use ant algorithm , computes , decentralized manner , routing tables minimize global energy consumption moreover , resulting algorithm also able track changes offered real time network links show load energy consumption energy saving routing algorithm load links simply links increase energy consumption obtained power 10 20 interval real networks
accuracy wyner model cellular networks wyner model widely used model analyze cellular networks due simplicity analytical tractability key aspects include fixed user locations deterministic homogeneous interference intensity clearly significant simplification real cellular system , random user locations interference levels vary several orders magnitude cell , common wyner model nevertheless captures essential aspects cellular interactions true \? answer question , consider uplink downlink transmissions , outage based average based metrics uplink , metrics , conclude wyner model fact quite accurate systems sufficient number simultaneous users , e g , broadly inaccurate otherwise processing , tdma shown suboptimal terms average throughput , sharp contrast predictions using wyner model turning downlink , wyner model highly inaccurate outage since depends largely user locations however , average sum throughput , wyner model serves acceptable simplification certain special cases interference parameter set appropriately
semi supervised learning neural machine translation end end neural machine translation \( nmt \) made remarkable progress recently , nmt systems rely parallel corpora parameter estimation since parallel corpora usually limited quantity , quality , coverage , especially low resource languages , appealing exploit monolingual corpora improve nmt propose semi supervised approach training nmt models concatenation labeled \( parallel corpora \) unlabeled \( monolingual corpora \) data central idea reconstruct monolingual corpora using autoencoder , source target target source translation models serve encoder decoder , respectively approach exploit monolingual corpora target language , also source language experiments chinese english dataset show approach achieves significant improvements state art smt nmt systems
design first sub wing aerial vehicle report first sub wing vehicle able mimic wing wing amplitude 90 circ wing amplitude 80 circ demonstrated also smallest wing span \( single wing length 3 \) device reported yet mass scale fly assembly made simple requires together 5 components contrast higher part count intensive assembly scale increases speed success rate fully device low operational \( \) makes testing easy enable deployment autonomous sub aerial vehicles
global consistency topological sorting based maximal spanning tree problem introduce new type fully computable problems , dedicated maximal spanning tree problems , based choice consistency problems show interest , describe new compact representation specific spanning trees , identifying efficient spanning tree sub problem next , compare problem pareto based one last , propose algorithm solving associated consistency problem
deep k means training parameter sharing harder cluster assignments deep convolutions current trend pushing cnns deeper convolutions created demand achieve higher compression gains cnns convolutions computation parameter amount \( e g , , resnet wide resnet \) , high energy consumption convolutions limits deployment mobile devices end , proposed simple yet effective scheme convolutions though applying k means clustering weights , compression achieved weight sharing , k cluster centers weight assignment indexes introduced novel relaxed k means regularization , tends make hard assignments convolutional layer weights k learned cluster centers training additionally propose improved set metrics estimate energy consumption cnn hardware implementations , whose estimation results verified consistent previously proposed energy estimation tool actual hardware measurements finally evaluated deep k means across several cnn models terms compression ratio energy consumption reduction , observing promising results without accuracy loss code available https url
learning navigate complex environments learning navigate complex environments dynamic elements important developing ai agents work formulate navigation question reinforcement learning problem show data efficiency task performance dramatically improved relying additional auxiliary tasks leveraging multimodal sensory inputs particular consider jointly learning goal driven reinforcement learning problem auxiliary depth prediction loop closure classification tasks approach learn navigate raw sensory input complicated 3d , approaching human level performance even conditions goal location changes frequently provide detailed analysis agent behaviour , ability , network activity dynamics , showing agent implicitly learns key navigation abilities
evaluating cnns principle closure deep convolutional neural networks \( cnns \) widely known outstanding performance classification regression tasks high dimensional data made popular powerful tool large variety applications industry academia recent publications show easy tasks \( humans \) challenging state art cnns attempt describe humans visual elements given principles paper evaluate regarding performance classifying correctness well known triangles , heavily rely principle closure therefore created various datasets containing valid well variants triangle findings suggest objects utilizing principle closure challenging applied network architectures appear adapt effect closure
effects degree correlations security good bad study influence degree correlations network mixing security model security among agents using dependence graph employ population game model capture interaction among many agents strategic various security measures choose overall network security measured call average risk exposure \( \) neighbors , proportional total \( expected \) number attacks network r n first show exists unique pure strategy nash equilibrium population game , prove agents larger degrees dependence graph see higher smaller degrees , overall network security experienced agents increases attacks network finally , using finding , demonstrate effects network mixing depend \( cost \) effectiveness security measures available agents security measures effective , increasing assortativity dependence graph results higher hand , security measures effective losses attacks , increasing assortativity reduces experienced agents
independent set epg graphs paper consider maximum independent set problem \( mis \) b 1 epg graphs epg \( edge intersection graphs paths grid \) introduced cite class graphs whose vertices represented simple paths grid two vertices adjacent corresponding paths share least one edge underlying grid restricted class b k epg denotes epg graphs every path k study mis b 1 epg graphs cite authors prove mis np complete b 1 epg graphs , provide polynomial 4 approximation article study approximability fixed parameter tractability mis b 1 epg show mis b 1 epg unless p np , even one shape path , even path part horizontal part length 3 optimal , show paths horizontal part bounded constant , mis admits finally , show mis fpt standard parameterization b 1 epg restricted three shapes path , w 1 hard b 2 epg status general b 1 epg \( four shapes \) left open
random spiking systematic evaluation defenses adversarial examples image classifiers often suffer adversarial examples , generated adding small amount noises input images classifiers years , many defense mechanisms proposed , different researchers made claims effectiveness argue primarily due inconsistent assumptions attacker 's knowledge end , present analysis possible adversarial models , propose evaluation framework comparing different defense mechanisms part framework , introduced powerful realistic adversary strategy propose new defense mechanism called random spiking \( rs \) , generalizes dropout introduces random noises training process controlled manner carefully chosen placement , rs incurs negligible negative impact prediction accuracy evaluations proposed framework suggest rs delivers better protection adversarial examples many existing schemes
challenges context time reinforcement learning introducing space fortress benchmark research deep reinforcement learning \( rl \) around improving performance benchmarks like learning environment however , benchmarks miss important characteristics like context dependent strategy temporal sensitivity often present real world domains result , rl research focused challenges , resulting algorithms understand critical changes context , little notion real world time tackle issue , paper introduces game space fortress rl benchmark incorporates characteristics show existing state art rl algorithms unable learn play space fortress game confirm poor performance due rl context reward sparsity also identify independent along vary context temporal sensitivity , allowing space fortress used testbed understanding characteristics combination also release space fortress open source environment
densely connected cnns audio detection detecting audio automatically , accurate enough , expected great help research community working , interested monitoring based audio field estimate accurate state art machine learning approaches , audio detection challenge involving large audio datasets recently paper , experiments using several types convolutional neural networks \( e standard cnns , residual nets densely connected nets \) reported framework challenge solution since best performing compact models , leading 88 22 area receiver operator curve score test set challenge \( ranked 30 \) 1 performance gains obtained data augmentation time frequency shifting , model parameter training ensemble methods using geometric mean , attempts training dataset samples test set automatic predictions used pseudo labels consistently degraded performance
parboiled2 based approach effective generators parsing expressions grammars scala today 's world , parsing ubiquitous developers parse logs , queries databases websites , programming natural languages ecosystem , syntax , runtime speed , developers choose parboiled2 generates grammars parsing expression grammars \( \) following open source libraries chosen parboiled2 parsing http streaming first http server module scala implementation minimal , scala interface http scala dsl testing http api scala simple scala library building parsing library uses wide range scala provide required functionality also discuss extensions particular , show implementation internal scala dsl features intuitive syntax semantics demonstrate parboiled2 extensively uses scala typing verify dsl integrity also show connections inner structures parboiled2 , give better understanding compose effective grammars finally , grammar expanded scala effective runtime code
decentralized coordinate descent data detection precoding massive mu mimo massive multiuser \( mu \) multiple input multiple output \( mimo \) promises significant improvements spectral efficiency compared small scale mimo typical massive mu mimo base station \( bs \) designs rely centralized linear data detectors high complexity , data rates , input output \( \) bandwidth executed single computing fabric resolve complexity bandwidth , propose new decentralized algorithms data detection precoding use coordinate descent methods computations across multiple computing , minimizing bandwidth proposed decentralized algorithms achieve near optimal error rate performance multi throughput sub 1 ms latency implemented multi gpu cluster half precision floating point arithmetic
deep reinforcement learning explicitly represented knowledge variable state action spaces focus class real world domains , hierarchical knowledge required task many problems represented manner , network testing , targeted advertising medical diagnosis formalization , task sequentially request information sample build knowledge hierarchy suitable learned information analyzed , resulting complex variable action space present combination techniques knowledge hierarchy explicitly represented given deep reinforcement learning algorithm input process hierarchical input , employ hierarchical multiple instance learning cope complex action space , factor hierarchical softmax end end differentiable model trained , standard deep reinforcement learning algorithm demonstrate method set classification domains , task achieve best accuracy set budget amount information retrieved compared baseline algorithms , method achieves better results , also better generalization
variation research collaboration patterns across academic ranks ability manage effective becoming increasingly important criteria policies academic advancement rise policies leads development indicators permit measurement propensity different ranks , examine role several variables collaboration , first among disciplines work apply innovative approach based individual propensity collaboration measure differences propensity across academic ranks , choice collaboration forms , international analysis based scientific production period 2006 2010 , 200 , 000 publications indexed web science shows assistant propensity collaboration clearly greater higher ranks vice versa , higher ranks , quite clearly , greater propensity international level
decoding failure probability codes moderate density parity check \( \) codes defined codes parity check matrix whose row weight \( sqrt n \) n length n code decoded like ldpc codes decode much less errors ldpc codes number errors decode case order theta \( sqrt n \) despite fact proved useful cryptography key exchange mechanisms also proposed type however case , parameters proposed cite cite attack exploits fact decoding failure probability non negligible show attack choosing parameters conservative way first show codes decode simple bit decoder pattern left \( frac sqrt n log log n log n right \) errors previous attack cost significantly increasing key size scheme show reasonable assumption decoding failure probability almost exponentially two iterations bit additional assumption even proved exponentially unbounded number iterations show case increase key size required attack cite moderate
performance analysis block markov superposition transmission short codes paper , consider asymptotic finite length performance block markov superposition transmission \( bmst \) short codes , viewed new class spatially coupled \( sc \) codes generator matrices short codes \( referred em basic codes \) coupled modified extrinsic information transfer \( \) analysis takes account relation mutual information \( \) bit error rate \( \) presented study convergence behavior bmst codes using modified analysis , investigate impact various parameters bmst code performance , thereby providing theoretical guidance designing implementing practical bmst codes suitable sliding window decoding , present performance comparison bmst codes sc low density parity check \( sc ldpc \) codes basis equal decoding latency also presented comparison computational complexity simulation results show , equal decoding latency constraint , bmst codes using repetition code basic code outperform \( 3 , 6 \) regular sc ldpc codes waterfall region higher computational complexity
dual cross shared rnn aspect term polarity co extraction paper focuses two related subtasks aspect based sentiment analysis , namely aspect term extraction aspect sentiment classification , call aspect term polarity co extraction former task extract aspects product service opinion document , latter identify polarity expressed document extracted aspects existing algorithms address two separate tasks solve one one , perform one task , complicated real applications paper , treat two tasks two sequence labeling problems propose novel dual cross shared rnn framework \( \) generate aspect term polarity pairs input sentence simultaneously specifically , involves dual recurrent neural network extract respective representation task , cross shared unit consider relationship experimental results demonstrate proposed framework outperforms state art baselines three benchmark datasets
routing let p x monotone orthogonal n vertices call p simple histogram upper boundary single edge double histogram horizontal left boundary right boundary two points p q p co visible \( axis parallel \) p q completely lies p r graph g \( p \) p , connect two vertices p edge co visible r n consider routing preprocessing g \( p \) may p obtain label routing table vertex p , must able route packet two vertices p , step may use label target node , routing table neighborhood current node , packet r n present routing scheme double sends data packet along path whose length \( unweighted \) shortest path distance scheme , labels , routing tables , need \( log n \) bits case simple , obtain routing scheme optimal routing paths , \( log n \) bit labels , one bit routing tables ,
optimal puncturing polar codes fixed information set given polar code construction , existing literature puncturing polar codes focuses finding optimal puncturing pattern , selecting information set paper find optimal puncturing pattern information set fixed puncturing coded bits corresponding worst quality bit channels , called worst quality puncturing \( \) , proposed , analyzed minimize bit channel quality loss positions simulation results show outperforms best existing puncturing schemes information set fixed
indicator research front activity measuring organization uncertainty reduction document sets using scientific literature model scholarly discourse , research evolving set related documents publication expected contribute development research front specific combinations words cited references paper considered knowledge paper new words combinations words expected represent variation , paper time selectively organization field using context relevant references mutual information among three dimensions words , cited references , sequence numbers used indicator extent organization structures uncertainty research front \? effect discovery \( \) previously existing field used test case , method applied science studies focus using various sample emerging research front citation analysis
intent driven network current strong divide applications network control plane desirable many reasons network regarding purposes applications , result , unable optimize alternative approach , explored paper , applications network abstract assumptions e g , application run within local domain semantic potential enable network better application intent , also optimize network resource usage across applications refer approach driven \( \) , sketch design serve towards practical realization concept within today 's internet
meet subtyping generalized algebraic \( \) considered well understood , adding language notion subtyping comes mean parameter \? answer turns quite subtle involves fine grained properties subtyping relation interesting design questions allow variance annotations definitions , study soundness , present sound complete algorithm check work may applied real world ml like languages explicit subtyping , languages general subtyping constraints
utility maximizing sequential sensing finite horizon consider problem optimally utilizing n resources , unknown binary state state resource state dependent noisy measurements depending state , utilizing resource results either reward penalty per unit time objective sequential strategy decision sensing exploitation time maximize expected utility \( e , total reward total penalty sensing cost \) finite horizon l formulate problem partially observable markov decision process show optimal strategy based two time varying thresholds resource optimal selection rule sense particular resource since full characterization optimal strategy generally intractable , develop low complexity policy shown simulations offer near optimal performance problem finds applications spectrum access , strategies , sequential resource allocation problems
dual approach atomic broadcast extended version many distributed systems work common shared state systems , distributed agreement necessary consistency increasing number servers , systems become single server failures , increasing relevance fault tolerance atomic broadcast enables fault tolerant distributed agreement , yet costly solve practical algorithms linear work per broadcast message allconcur approach reduces work , connecting servers via sparse resilient overlay network yet , redundancy , limiting reduction work paper , propose allconcur , atomic broadcast algorithm limitation intervals failures , achieves minimal work using redundancy free overlay network failures occur , automatically switching resilient overlay network performance evaluation non failure scenarios , allconcur achieves comparable throughput non fault tolerant distributed agreement algorithm outperforms allconcur , terms throughput latency furthermore , evaluation failure scenarios shows allconcur 's expected performance robust regard failures thus , realistic use cases , leveraging redundancy free distributed agreement intervals failures improves performance significantly
alternative theorem propose reductions boolean formulas \( \) new approach showing fixed parameter linear algorithms problems parameterized treewidth demonstrate feasibility approach giving new algorithms several well known problems artificial intelligence general complete second level polynomial hierarchy reduction show resulting algorithms essentially optimal dependence treewidth problems consider already known fixed parameter linear using 's theorem dynamic programming , argue approach clear advantages techniques one hand , contrast 's theorem , get concrete tight guarantees runtime dependence treewidth hand , avoid tedious dynamic programming , showing normalization results formulas , upper bounds often lines
surprising linear relationship predicts test performance deep networks given two networks training loss dataset , would drastically different test losses errors \? better understanding question generalization may improve practical applications deep networks paper show cross entropy loss surprisingly simple induce significantly different generalization performances two networks architecture , meta parameters training error one either networks different levels data simply networks weights different gaussian standard deviations recent theoretical results overfitting shows effects due intrinsic problem measuring test performance cross entropy exponential type loss , decomposed two components minimized sgd one related expected classification performance however , factor component loss , linear relationship training test losses transformation , classical generalization bounds surprisingly tight empirical training loss close expected test loss furthermore , empirical relation classification error normalized cross entropy loss approximately monotonic
retrospective mixture generators task oriented dialogue response generation dialogue response generation \( drg \) critical component task oriented dialogue systems \( \) purpose generate proper natural language responses given context , e g , historical utterances , system states , etc state art work focuses better tackle drg end end way typically , studies assume token drawn single distribution output vocabulary , may always optimal responses vary greatly different , e g , domains , system actions propose novel mixture generators network \( \) drg , assume token response drawn mixture distributions consists chair generator several expert generators expert specialized drg w r particular intent chair coordinates multiple experts combines output generated produce appropriate responses propose two strategies help chair make better decisions , namely , retrospective mixture generators \( \) mixture generators \( \) former considers historical expert generated responses current time step latter also considers possible expert generated responses future encouraging exploration order differentiate experts , also devise global local \( \) learning scheme forces expert specialized towards particular intent using local loss trains chair experts coordinate using global loss carry extensive experiments benchmark dataset significantly outperforms state art methods terms automatic human evaluations , demonstrating effectiveness drg
automatic paper summary generation visual textual information due recent artificial intelligence \( ai \) research , including computer vision \( cv \) , become impossible researchers fields keep exponentially increasing number response situation , paper proposes paper summary generation \( \) task using simple effective method automatically generate academic paper summary raw data realized combination vision based supervised components detector language based unsupervised important sentence , applicable trained format show quantitative evaluation ability simple vision based components extraction , qualitative evaluation system extract visual item sentence helpful understanding processing via , accepted computer vision pattern recognition \( \) 2018 available believed proposed method provide better way researchers important academic papers
stable nash equilibria medium access games symmetric altruistic behavior consider effects altruistic behavior random medium access control \( slotted aloha \) local area communication networks , iterative , two player game asymmetric player demands , find hamiltonian dynamics purely altruistic behavior though positions interior nash equilibrium points change presence altruistic behavior , nature local asymptotic stability region partially altruistic behavior neither interior nash equilibrium point locally asymptotically stable also , power control game single nash equilibrium , show stability changes function parameter variations altruistic game frameworks discussed considering power \( instead throughput \) based costs linear utility functions
identifying self technical two step approach keeping track managing self technical \( satds \) important maintaining healthy software project requires much time effort human experts identify satds manually currently , automated solutions high enough precision recall identifying satds fully automate process solve problems , propose two step framework called identifying satds first finding easy find satds automatically close 100 precision via novel pattern recognition technique , applying machine learning techniques human experts manually identifying rest hard find satds reduced human effort simulation studies ten software projects show identify satds efficiently \( less human effort \) prior state art methods
understanding graph understanding map potential applications based previously proposed concept understanding tree , paper introduces two concepts understanding graph understanding map , explores potential applications understanding graph understanding map special cases mind map , semantic network , concept map two main differences firstly , data sources constructing understanding map understanding graph simple secondly , relations concepts understanding graph understanding map based characteristics , applications include quantitatively measuring concept 's complexity degree , quantitatively measuring concept 's importance degree domain , computing optimized learning sequence concept etc study involves evaluating performances applications
discrete attacks submodular optimization applications text classification adversarial examples carefully constructed modifications input completely change output classifier humans despite successful attacks continuous data \( image audio samples \) , generating adversarial examples discrete structures text proven significantly challenging paper formulate attacks discrete input set function optimization task prove set function submodular popular neural network text classifiers simplifying assumption finding guarantees 1 1 e approximation factor attacks use greedy algorithm meanwhile , show use gradient classifier guide greedy search empirical studies proposed optimization scheme show significantly improved attack ability efficiency , three different text classification tasks various baselines also use joint sentence word technique maintain original semantics syntax text validated human subject evaluation subjective metrics quality semantic coherence generated adversarial text
conditional hardness sensitivity problems recent years become popular study dynamic problems sensitivity setting instead allowing arbitrary sequence updates , sensitivity model allows apply batch updates small size original input data sensitivity model particularly appealing since recent strong conditional lower bounds fast algorithms many dynamic problems , shortest paths , , subgraph connectivity r n paper prove conditional lower bounds sensitivity problems example , show boolean matrix multiplication \( \) conjecture combinatorial algorithms cannot compute \( 4 3 epsilon \) approximate diameter undirected unweighted dense graph truly preprocessing time truly subquadratic update query time result surprising since static setting clear whether reduction diameter possible show conjecture many problems , approximate shortest paths , cannot solved faster scratch even one two edge insertions give lower bounds strong exponential time hypothesis pairs shortest paths conjecture many lower bounds also hold static data structures sensitivity required finally , give first algorithm \( 1 epsilon \) approximate radius , diameter , problems directed undirected unweighted graphs case single edges failures algorithm truly running time graphs truly subquadratic number edges tight w r conditional lower bounds obtain
recent match queries line suffix trees suffix tree able efficiently locate pattern indexed string , general recent copy pattern online stream , desirable applications study general version problem recent match supporting queries arbitrary patterns , step processing online stream present 's suffix tree construction algorithm optimal time queries , maintaining indexing time within logarithmic factor size indexed string show algorithm applicable sliding window indexing , sketch possible optimization use special case compression
unsupervised risk estimation using conditional independence structure show estimate model 's test error unlabeled data , distributions different training distribution , assuming certain conditional preserved train test need assume optimal predictor train test , true distribution lies parametric family also efficiently differentiate error estimate perform unsupervised discriminative learning technical tool method moments , allows us exploit conditional absence fully specified model framework encompasses large family losses including log exponential loss , extends structured output settings hidden markov models
negotiation automation architecture buyer behavior pattern prediction component era services , growth e commerce transactions , need development intelligent negotiation systems consists feasible architecture , reliable framework flexible multi agent based protocols developed specialized negotiation languages complete semantics support message passing buyers possible using web services internet key issue negotiation automation paper review classical negotiation methods existing architectures frameworks proposing new framework architecture , key feature framework component prediction probabilistic behavior pattern recognition buyer , along classical approaches negotiation frameworks architectures negotiation complex activity automate without human intervention future also develop new protocol facilitate automation types negotiation strategies like , , auctions , framework
blind lossless watermarking framework medical applications based deep neural networks nowadays , development public network usage , medical information transmitted throughout watermarking system help confidentiality medical information distributed internet medical images , regions interest \( roi \) contain diagnostic information watermark embedded non regions interest \( \) keep diagnostic information without distortion recently , roi based watermarking attracted attention medical research community roi map used embedding key improving confidentiality protection purposes however , existing works , roi map used embedding process must sent side information along image side information disadvantage makes extraction process non blind also , existing algorithms recover original cover image extraction watermark paper , propose framework blind lossless watermarking , iteratively significance proposed framework satisfying confidentiality patient information blind watermarking system , preserves diagnostic medical information image throughout watermarking process deep neural network used recognize roi map embedding , extraction , recovery processes extraction process , roi map embedding process recognized without requiring additional information hence , watermark extracted
learned hierarchical rank pooling networks work , present novel temporal encoding methods action activity classification extending unsupervised rank pooling temporal encoding method two ways first , present discriminative rank pooling shared weights video representation parameters action classifiers estimated jointly given training dataset labelled vector sequences using optimization formulation learning problem frame level features vectors obtained convolutional neural network \( cnn \) , rank pool network activations jointly estimate parameters model , including cnn filters fully connected weights , end end manner coined end end trainable rank cnn importantly , model make use existing convolutional neural network architecture \( e g , vgg \) without modification introduction additional parameters , extend rank pooling high capacity video representation , called hierarchical rank pooling hierarchical rank pooling consists network rank pooling functions , encode temporal semantics arbitrary long video based rich frame level features non linear feature functions temporal sub sequence encoders one top , build high capacity encoding network dynamic behaviour video resulting video representation fixed length feature vector describing entire video used input standard machine learning classifiers demonstrate approach task action activity recognition obtained results comparable state art methods three important activity recognition benchmarks classification performance 76 7 map , 4 , 6 ucf101
decoders variational autoencoder latent spaces variational autoencoders learn unsupervised data representations , models frequently converge minima fail preserve meaningful semantic information example , variational autoencoders autoregressive decoders often collapse , learn ignore encoder input work , demonstrate adding auxiliary decoder latent space prevent collapse , successful auxiliary decoding tasks domain dependent auxiliary decoders increase amount semantic information encoded latent space visible semantic information variational autoencoder 's representation weakly correlated rate , distortion , evidence lower bound compared popular strategies modify training objective , regularization latent space generally increased semantic information content
circle principle logic programs aggregates paper presents knowledge representation language n n n n n n n mathcal log n n n n n extends asp aggregates goal language based simple syntax clear intuitive mathematical semantics give properties n n n n n n n mathcal log n n n n n , algorithm computing answer sets , comparison approaches
novel hybrid approach using sms detection based paper proposes novel hybrid approach detection based distributed generations \( dg \) based combination slip mode frequency shift \( sms \) active rate change frequency \( \) relay frequency relay passive methods approach utilized force dg lose stable operation frequency allowed range frequency threshold performance proposed approach evaluated ieee , multiple dg operation simulation results demonstrate effectiveness proposed approach detection , especially loads high quality factor operates accurately condition load switching power system operation normal condition words , holds benefits sms , also drawbacks less non detection faster response
energy efficient joint unicast multicast beamforming multi antenna user terminals paper studies energy efficient joint transmit receive beamforming multi cell multi user multiple input multiple output systems consider conventional network energy efficiency metric users receive streams addition group specific common streams certain rate constraints goal use transmission resources efficiently improve energy efficiency , users equipped multiple antennas numerical results show achieved energy efficiency gains using additional degrees freedom transmission private message
pose consensus based dual algebra application decentralized formation control mobile manipulators paper presents solution based dual algebra general problem pose \( e , position orientation \) consensus systems composed multiple rigid bodies dual algebra used model poses also distributed control laws , making proposed technique easily applicable formation control general robotic systems proposed pose consensus protocol guaranteed convergence interaction among agents represented directed graphs directed spanning trees , general result compared literature formation control order illustrate proposed pose consensus protocol extension problem formation control , present numerical simulation large number free agents also application cooperative manipulation using real mobile manipulators
cognitive mimo rf fso cooperative relay communication mobile nodes imperfect channel state information work performance cognitive radio based decode forward mixed multiple input multiple output \( mimo \) radio frequency free space optical \( rf fso \) cooperative relay system multiple mobile secondary primary user nodes effect imperfect channel state information \( csi \) arising due channel estimation error also considered secondary user transmitters \( \) relay power control symbol detection processes respectively unique aspect work fixed proportional interference power constraints employed limit interference primary user receivers \( \) analytical results derived characterize exact asymptotic outage bit error probabilities system practical conditions node mobility imperfect csi , together impairments optical channel , path loss , , errors , orthogonal space time block coded transmission relay finally , simulation results presented yield various interesting insights system performance benefits versus channel estimation
cooperative network navigation fundamental limit interpretation localization tracking moving nodes via network navigation gives rise new paradigm , nodes exploit temporal spatial cooperation infer positions based intra inter node measurements cooperation significantly improve performance , imposes information processing network design operation paper , establish theoretical framework cooperative network navigation determine fundamental limits navigation accuracy using equivalent fisher information analysis introduce notion carry information , provide interpretation navigation information evolution time framework navigation information obtained temporal spatial cooperation , leading deep understanding information evolution network benefit cooperation
neural network quantization adaptive bit deep neural networks adaptive configurations gained increasing attention due instant flexible deployment models platforms different resource budgets paper , investigate novel option achieve goal enabling adaptive bit weights activations model first examine benefits challenges training quantized model adaptive bit , experiment several approaches including direct adaptation , training joint training discover joint training able produce comparable performance adaptive model individual models propose new technique named level \( \) improve quantized models lowest bit width proposed techniques applied models including v2 resnet 50 , demonstrate bit width weights activations new option adaptively deep neural networks , offering distinct opportunity improved accuracy efficiency trade well instant adaptation according platform constraints real world applications
centrality parallelizable dense matrix multiplication general infrastructure scalable algorithms sparse matrix multiplication enable succinct high performance implementation numerical methods graph algorithms theoretical practical quality novel sparse matrix multiplication routines tensor framework \( \) via mfbc maximal frontier centrality algorithm sparse matrix multiplication algorithms consequently mfbc perform asymptotically less communication previous approaches graphs n vertices average degree k , show p processors , mfbc performs factor p 1 3 less communication known alternatives k n p 2 3 p processors needed fit problem memory , costs associated algorithm reduced factor \( n k \) sqrt p using processors multiplication square dense matrices sqrt p achievable r n formulate implement mfbc weighted graphs , leveraging specially designed functions prove correctness new formulation allows parallelism oblivious c implementation mfbc achieve good scalability extremely sparse relatively dense graphs library automatically space distributed data decompositions sparse matrix multiplication algorithms resulting code outperforms well known library factors 8 shows robust performance design methodology general readily graph problems
lost appearance invariant place recognition using visual semantics human visual scene understanding remarkable able recognize revisited place direction first , even presence extreme variations appearance capability especially driving human driver recognize reverse direction along route first time , without turn back look difficulty problem exceeds addressed past appearance viewpoint invariant visual place recognition \( \) research , part large parts scene commonly observable directions consequently , shown paper , precision recall performance current state art viewpoint appearance invariant techniques orders magnitude would closed loop system current solutions predominantly rely camera lidar sensing suitable engineering solution one clearly different humans navigate , also implications naturally humans could interact communicate navigation system paper develop suite novel semantic appearance based techniques enable first time high performance place recognition challenging scenario first propose novel local semantic tensor \( lost \) images using convolutional feature maps state art dense semantic segmentation network , verify spatial semantic arrangement top matching candidates , develop novel approach mining semantically salient correspondences
closest vector problem arising therapy planning paper consider problem finding vector written nonnegative integer linear combination given 0 1 vectors , generators , l 1 distance vector given target vector minimized prove closest vector problem np hard approximate within \( \) additive error , dimension vector space show problem approximated within \( 3 2 \) additive error polynomial time , rounding optimal solution natural lp relaxation problem also observe particular case target vector integer generators form matrix , problem solved polynomial time r n closest vector problem arises therapy plans context , target nonnegative integer matrix generators certain 0 1 matrices whose satisfy consecutive ones property mainly consider version problem set generators comprises matrices nonzero row number ones least certain constant set generators encodes called minimum separation constraint
tracking orientation lengths extended object extended object tracking considers simultaneous estimation kinematic state shape parameters moving object based varying number noisy detections main challenge extended object tracking high dimensionality estimation problem study presents compact closed form expressions recursive kalman filter explicitly estimates orientation lengths extended object based detections object surface \( according gaussian distribution \) existing approaches either based monte carlo approximations allow explicitly maintaining parameters performance novel approach demonstrated respect state art means simulations
face face identity digital identity using bitcoin blockchain fundamental purpose blockchain technology enable persistent , consistent , distributed storage information increasingly common authentication systems leverage property allow users carry personal data device hash data signed trusted blockchain compared instance , 2015 , mit introduced schema publication academic certificates based principle work , propose way users obtain based face face validated record blockchain moreover , order provide , instead storing hash , make use scheme store one perform zero knowledge proofs identity also enforce confidentiality underlying data users control secret show schema implemented bitcoin 's blockchain save bandwidth grouping using trees minimize number bitcoin transactions need sent finally , describe system users gain access services thanks identity records proposal
topology analysis international networks based debates united complex , high dimensional unstructured data often difficult extract meaningful patterns especially case dealing textual data recent studies machine learning , information theory network science developed several novel instruments extract semantics unstructured data , build network relations approaches serve efficient tool dimensionality reduction pattern detection paper applies semantic network science extract proximity international , focusing data general debates un general assembly topics high international community un general debate corpus \( \) covers high level debates un general assembly 2014 , covering un states research three main steps first , latent allocation \( \) used extract topics un , therefore semantic information assigned vector exposure topics identified intermediate output used construct network countries based information theoretical metrics links capture similar patterns topic distributions topology networks analyzed network properties like density , path length clustering finally , identify specific topological features networks using map equation framework detect communities networks countries
driven sampling online social networks driven sampling \( \) commonly used method data hidden communities , e , lack unbiased sampling frames face social make identify obtaining accurate statistical data communities important , instance , often different health greater population , without good statistics hard expensive effectively reach pre treatment interventions online social networks \( \) potential transform better present new protocol \( \) show via simulation performs standard protocol terms sampling accuracy approaches accuracy markov chain monte carlo random
max cost discrete function evaluation problem budget propose novel methods max cost discrete function evaluation problem \( \) budget constraints motivated applications clinical diagnosis patient sequence \( possibly expensive \) tests decision made goal develop strategies minimizing max costs problem known np hard greedy methods based specialized functions proposed develop broad class emph admissible functions admit , classes polynomials , loss functions allow flexible design provably optimal approximation bounds flexibility important datasets max cost sensitive outliers outliers bias max cost examples require large number tests classification design admissible functions allow accuracy cost trade result \( log n \) guarantees optimal cost among trees corresponding classification accuracy levels
consistent optimization ams logistic loss minimization paper , theoretically justify approach popular among participants machine learning challenge optimize approximate median significance \( ams \) approach based following two stage procedure first , real valued function learned minimizing surrogate loss binary classification , logistic loss , training sample , threshold tuned separate validation sample , direct optimization ams show regret resulting \( \) classifier measured respect squared ams , regret underlying real valued function measured respect logistic loss hence , prove minimizing logistic surrogate consistent method optimizing ams
multiclass weighted loss instance segmentation cells propose new multiclass weighted loss function instance segmentation cells primarily motivated need quantify model behavior cells might help us understanding mechanisms ultimately help researchers developing effective cancer treatment segmenting individual cells regions challenging feature distribution shared cell foreground similar thus pixels proper classes present two novel weight maps applied weighted cross entropy loss function take account class imbalance cell geometry binary ground truth training data augmented learning model handle foreground background also third class framework allows training using u n et experiments formulations shown superior results compared similar schemes , outperforming binary class models significant improvement boundary adequacy instance detection validate results manually annotated images cells
analytical moment regularizer gaussian robust networks despite impressive performance deep neural networks \( dnns \) numerous vision tasks , still exhibit yet understand one behaviour subtle sensitive dnns various noise attacks line research around developing training noise robust networks work , propose new training regularizer aims minimize probabilistic expected training loss dnn subject generic gaussian input provide efficient simple approach approximate regularizer arbitrary deep networks done leveraging expression output mean shallow neural network avoiding need memory computationally expensive data augmentation conduct extensive experiments various datasets including mnist , , demonstrating effectiveness proposed regularizer particular , show networks trained proposed regularizer benefit boost robustness equivalent performing 3 21 data augmentation
formation co authorship networks availability large amount information including citation co authorship data makes imperative systematic approach enable author personal academic network effective method could one 's co authorship network set , recent practice relationships \( e g , \) many online social networks r n paper , propose unsupervised approach automatically detect network circle represents densely community researchers model unsupervised method combines variety node features node similarity measures model built rich co authorship network data 8 authors first level evaluation , model achieves 13 improvement terms overlapping modularity compared best among four state art community detection methods , conduct task based evaluation two basic frameworks collaboration prediction considered circle information \( obtained model \) included feature set experimental results show including circle information detected model improves prediction performance 9 87 15 25 average terms auc \( area \) p 20 \( precision top 20 \) respectively compared case , circle information present
improving entity linking modeling latent entity type information existing state art neural entity linking models employ attention based words context model pre trained entity embeddings word embeddings assess topic level context compatibility however , latent entity type information context , causes models often link incorrect entities incorrect type tackle problem , propose latent entity type information entity embeddings based pre trained bert addition , integrate bert based entity similarity score local context model state art model better capture latent entity type information model significantly outperforms state art entity linking models standard benchmark \( \) detailed experiment analysis demonstrates model type errors produced direct baseline
towards learning planning imperfect information games current state art playing many important perfect information games , including go , combines planning deep reinforcement learning self play extend approach imperfect information games present , novel approach playing imperfect information games within expert iteration framework inspired use online outcome sampling , online search algorithm imperfect information games place training online , neural strategy used improve accuracy , allowing learning planning feedback loop imperfect information games
adapting resilient propagation deep learning resilient propagation \( rprop \) algorithm popular backpropagation training feed forward neural networks various applications standard rprop however difficulties context deep neural networks typically gradient based learning algorithms paper , propose modification rprop combines standard rprop steps special drop technique apply method training deep neural networks components ensemble formulations results mnist dataset show proposed modification standard rprop 's problems demonstrating improved learning speed accuracy
dynamic curriculum learning imbalanced data classification human attribute analysis challenging task field computer vision , since data largely imbalance distributed common techniques sampling cost sensitive learning require prior knowledge train system address problem , propose unified framework called dynamic curriculum learning \( \) online adaptively adjust sampling strategy loss learning single batch , resulting better generalization discrimination inspired curriculum learning , consists two level curriculum schedulers \( 1 \) sampling data distribution imbalanced balanced also easy hard \( 2 \) loss controls learning importance classification metric learning loss learning two schedulers , demonstrate framework new state art performance widely used face attribute dataset pedestrian attribute dataset
low frequency compensated synthetic impulse responses improved far field speech recognition propose method generating low frequency compensated synthetic impulse responses improve performance far field speech recognition systems trained augmented datasets design linear phase filters adapt simulated impulse responses distributions corresponding real world captured impulse responses synthetic impulse responses used augment clean speech data dataset 1 evaluate performance method real world test set practice , low frequency compensated synthetic dataset reduce word error rate 8 8 far field speech recognition
round compression parallel matching algorithms decade success em massive parallel computation \( mpc \) frameworks , mapreduce , , , one reasons success fact frameworks able accurately capture nature large scale computation particular , compared classic distributed algorithms models , frameworks allow much local computation fundamental question arises context though leverage additional power obtain even faster parallel algorithms \? r n prominent example em maximum matching problem one classic graph problems well known model one compute 2 approximate maximum matching \( log n \) rounds however , exact complexity problem mpc framework still far understood et al showed machine n 1 omega \( 1 \) memory , problem also solved 2 approximately constant number rounds techniques , well approaches developed follow work , though get fundamental way roughly \( log n \) rounds near linear memory regime thus entirely possible regime , captures particular case sparse graph computations , best mpc round complexity matches one already get model , without need take advantage extra local computation power r n paper , finally possibility , break \( log n \) round complexity bound even case em slightly sublinear memory per machine fact , improvement em almost exponential able \( 2 epsilon \) approximation maximum matching , fixed constant epsilon 0 , \( \( log log n \) 2 \) rounds
constructing f graph symmetric constraint subspace clustering based studying low rank subspace clustering \( \) l2 graph subspace clustering algorithms , propose f graph subspace clustering algorithm symmetric constraint \( \) , constructs new objective function symmetric constraint f norm , whose significant advantage obtain closed form solution coefficient matrix , take absolute value element coefficient matrix , retain k largest coefficients per column , set elements 0 , get new coefficient matrix finally , performs spectral clustering new coefficient matrix experimental results face clustering motion segmentation show algorithm reduce running time , also achieve higher accuracy compared state art representation based subspace clustering algorithms , algorithm feasible
structural synthesis gxw specifications define gxw fragment linear temporal logic \( \) basis synthesizing embedded control software safety critical applications since gxw includes use weak operator able specify number diverse programmable logic control \( \) problems , industrial training sets gxw controller specifications , develop novel approach synthesizing set communicating actor based controllers synthesis algorithm means structure gxw specifications , generates set dedicated communicating sub controllers according formula structure subsequent step , constraint solving identifies tries resolve potential individual gxw specifications structural approach gxw synthesis supports requirements generated control code regimes safety critical software synthesis gxw specifications compared completeness full synthesis indeed experimental results suggest gxw synthesis scales well industrial sized control synthesis problems 20 input output beyond
stochastic based method workflow scheduling cloud cloud computing provides engineers scientists place run complex computing tasks finding workflow 's deployment configuration cloud environment easy traditional workflow scheduling algorithms based heuristics , e g reliability greedy , cost greedy , cost time balancing , etc , recently , meta heuristic methods , genetic algorithms methods slow suitable dynamic cloud environment paper introduces \( randomized instance order types \) , stochastic based method workflow scheduling groups tasks workflow virtual machines via probability model uses effective surrogate based method assess large amount potential scheduling experiments study cases showed times faster traditional methods generating comparable results methods
neighborhood information based probabilistic algorithm network abstract many real world applications modelled complex networks , networks include internet , disease networks , transport networks , power grids , protein structures others network integrity robustness important ensure crucial networks protected networks network structure integrity controlled set key nodes , find optimal combination nodes network ensure network structure integrity np complete problem despite extensive studies , existing methods many limitations still many problems paper presents probabilistic approach based neighborhood information node importance , namely , neighborhood information based probabilistic algorithm \( nipa \) also define new centrality based importance measure \( \) , combines contribution ratios neighbor nodes target node two hop node information proposed nipa tested different network benchmarks compared three methods optimal attack strategy \( oas \) , high first \( \) high degree first \( \) experiments suggest proposed nipa effective among four methods general , nipa identify crucial node combination higher effectiveness , set optimal key nodes found proposed nipa much smaller heuristic centrality prediction addition , many previously weakly connected nodes identified , become crucial part newly identified optimal nodes thus , strategies protection ensure network integrity key issues future research topics also discussed
noisy private information retrieval channel coding information retrieval consider problem noisy private information retrieval \( \) n non communicating databases , storing set messages model , answer strings bit , rather emph noisy memoryless channels aim characterizing capacity model function statistical information measures noisy channels entropy mutual information derive general upper bound retrieval rate form max min optimization use achievable schemes problem asymmetric traffic constraints random coding arguments derive general lower bound retrieval rate upper lower bounds match 2 3 , n , noisy channel results imply separation channel coding retrieval optimal except adapting traffic ratio databases refer emph almost separation next , consider private information retrieval problem multiple access channels \( mac \) mac , database responses reach user multiple access channel \( mac \) responses together stochastic way show additive mac conjunction mac , channel coding retrieval scheme emph unlike show retrieval scheme depends properties mac , particular aspect cases , provide schemes achieve full capacity without loss due privacy constraint , implies user exploit nature channel improve privacy finally , show full unconstrained capacity always determining capacity selection channel
multi granularity testing criteria deep learning systems deep learning \( dl \) defines new data driven programming paradigm constructs internal system logic crafted neuron network set training data seen wide adoption dl many safety critical scenarios however , studies shown state art dl systems suffer various lead severe consequences applied real world applications currently , testing adequacy dl system usually measured accuracy test data considering limitation accessible high quality test data , good accuracy performance test data provide confidence testing adequacy generality dl systems unlike traditional software systems clear controllable logic functionality , lack interpretability dl system makes system analysis detection difficult , could potentially real world deployment paper , propose , set multi granularity testing criteria dl systems , aims rendering multi testbed depth evaluation proposed testing criteria demonstrated two well known datasets , five dl systems , four state art adversarial attack techniques dl potential usefulness light construction generic robust dl systems
tools edge graphs maximum degree three graph g maximum degree delta let gamma denote largest fraction edges delta edge showed gamma geq frac 13 15 g cubic cite notion delta minimum edge introduced cite order extend called em edge graphs maximum degree 3 propose english translation structural properties already present cite , \( \) delta minimum edge graphs maximum degree 3
document retrieval collections document retrieval aims finding important documents pattern appears collection strings traditional pattern matching techniques yield brute force document retrieval solutions , motivated research tailored indexes offer near optimal performance however , experimental study establishing alternatives actually better brute force , perform best depending collection characteristics , carried paper address exploring relationship nature underlying collection performance current methods via extensive experiments show established solutions often practice brute force alternatives also design new methods offer superior time space trade offs , particularly collections
improving deep transformer depth scaled initialization attention general trend nlp towards increasing model capacity performance via deeper neural networks however , simply layers popular transformer architecture machine translation results poor convergence high computational overhead empirical analysis suggests convergence poor due gradient vanishing caused interaction residual connections layer normalization propose depth scaled initialization \( \) , decreases parameter variance initialization stage , reduces output variance residual connections gradient back propagation normalization layers address computational cost , propose attention \( \) combines simplified self attention attention decoder side results translation tasks five translation directions show deep substantially outperform base counterpart terms bleu \( 1 1 bleu average 12 layer models \) , matching decoding speed baseline model thanks efficiency improvements
cyclic codes planar functions cyclic codes subclass linear codes applications consumer , data storage systems , communication systems efficient encoding decoding algorithms paper , almost perfect nonlinear functions planar functions finite fields employed construct number classes cyclic codes lower bounds minimum weight classes cyclic codes developed minimum weights classes codes constructed paper determined dimensions codes flexible many codes presented paper optimal almost optimal sense meet bound linear codes ten open problems regarding cyclic codes highly nonlinear functions also presented
sequence labeling practical approach take practical approach solving sequence labeling problem assuming domain expertise computational resources end , utilize universal end end bi lstm based neural sequence labeling model applicable wide range nlp tasks languages model combines morphological , semantic , structural cues extracted data arrive informed predictions model 's performance evaluated eight benchmark datasets \( covering three tasks pos tagging , ner , , four languages english , german , , \) observe state art results four 2012 \( english ner \) , \( ner \) , 2014 \( german ner \) , corpus \( german pos tagging \) , competitive performance rest
developing practical reactive synthesis tool experience learned experience developing using termite , first reactive synthesis tool intended use software development practitioners identify main making reactive synthesis accessible software developers describe key features termite designed overcome , including imperative c like specification language , interactive source level , user guided code generator based experience applying termite real world reactive software , identify several practical use reactive synthesis technology hope findings help define future research practical reactive synthesis
learned perceptual image enhancement learning typical image enhancement pipeline involves minimization loss function enhanced reference images l2 losses widely used functions purpose , necessarily lead perceptually compelling results paper , show adding learned reference image quality metric loss significantly improve enhancement operators metric implemented using cnn \( convolutional neural network \) trained large scale dataset labelled preferences human loss allows us perform back propagation learning framework simultaneously optimize similarity given ground truth reference perceptual quality perceptual loss used train parameters image processing operators , extra complexity inference time experiments demonstrate loss effective tuning variety operators local mapping
gpop cache work efficient framework graph processing partitions past decade seen development many shared memory graph processing frameworks intended reduce effort developing high performance parallel applications however , many frameworks , based vertex centric edge centric suffer several issues poor cache utilization , memory accesses , heavy use synchronization primitives theoretical , overall performance scalability r n paper , generalize recent partition centric paradigm pagerank computation novel graph processing partitions \( gpop \) framework exploits locality partitioning dramatically improve cache performance variety graph algorithms achieves high scalability enabling completely lock atomic free computation built analytical performance model enables use hybrid source partition centric communication modes way ensures work efficiency iteration simultaneously boosting high bandwidth sequential memory accesses finally , gpop framework designed mind completely away underlying programming model details user provides easy program set ability selectively continue active vertex set across iterations r n extensively evaluate performance gpop variety graph algorithms , using several large datasets observe gpop incurs 8 5 less l2 cache compared , respectively terms execution time , gpop 6 faster , respectively
generalized degrees freedom network coded cognitive interference channel study two user cognitive interference channel \( cic \) one transmitters \( primary \) knowledge linear combination \( appropriate finite field \) two information messages refer channel model network coded cic , since linear combination may result linear network coding scheme implemented backbone network paper , characterize generalized degrees freedom \( gdof \) gaussian network coded cic achievability , use novel compute forward \( \) dirty paper coding \( dpc \) , based nested lattice codes consequence gdof characterization , show mixed data \( linear combinations information messages \) provides em multiplicative gain gaussian cic , power ratio signal noise \( snr \) interference noise \( \) larger certain threshold example , snr , network coded cognition yields 100 gain classical gaussian cic
leaf benchmark federated settings modern federated networks , wearable devices , mobile phones , autonomous vehicles , generate massive amounts data day data help learn models improve user experience device however , learning federated settings presents new challenges stages machine learning pipeline machine learning community tackle challenges , critical time ensure developments made area grounded real world assumptions end , propose leaf , modular benchmarking framework learning federated settings leaf includes suite open source federated datasets , rigorous evaluation framework , set reference implementations , toward capturing obstacles practical federated environments
deriving verb predicates clustering arguments hand built verb clusters widely used classes \( , \) proved useful , limited coverage verb classes automatically induced corpus data \( , 2016 \) , hand , give clusters much larger coverage , adapted specific corpora twitter present method clustering outputs multiple argument types , e g \( person , person \) , \( person , emotion \) make use novel low dimensional embedding arguments produce high quality clusters verb different clusters depending argument type resulting verb clusters better hand built clusters predicting , sentiment , control tweets
triangles disk graphs transmission graphs let subset mathbb r 2 set n sites , associated radius r 0 disk graph \( \) undirected graph vertex set undirected edge two sites , st leq r r , e , disks centers respective r r disk graphs used model sensor networks similarly , transmission graph \( \) directed graph vertex set directed edge site site st leq r , e , lies disk center radius r r n provide algorithms detecting \( directed \) triangles , generally , computing length shortest cycle \( \) \( \) \( \) problems notoriously hard general , better solutions exist special graph classes planar graphs obtain similarly efficient results disk graphs transmission graphs precisely , show shortest \( euclidean \) triangle \( \) \( \) found \( n log n \) expected time , \( weighted \) \( \) found \( n log n \) expected time , develop new tools range searching may independent interest
insights patterns via analysis web usage logs key factor people 's overall health hence , understanding nature dynamics population wide preferences time space public health date , studies small samples participants via logs treatment data propose complementary source population data obtained via web logs main contribution spatiotemporal analysis population wide preferences lens logs widely distributed web browser add , using access volume users seek via search proxy actual consumption discover variation preferences expressed via access two main periodic components , one , exist characteristic regional differences terms within united states second study , identify users show evidence made decision lose weight characterize interests express search queries focus changes queries particular last , time series obtained queries time aligned data , aimed understanding behavioral data captured web logs might identify potential relationships health problems preliminary study , focus patterns identified time patterns failure , increases
projection bank high dimensional data medium length binary codes recently , high dimensional feature representations , e g , fisher vector , achieved excellent performance visual recognition retrieval however , representations always cause extremely heavy computational storage costs even become large scale applications existing techniques transfer high dimensional data binary codes , still require reduced code length relatively long maintain acceptable accuracies target better balance computational efficiency accuracies , paper , propose novel embedding method called binary projection bank \( \) , effectively reduce high dimensional representations medium dimensional binary codes without sacrificing accuracies instead using conventional single linear projections , proposed method learns bank small projections via max margin constraint optimally preserve intrinsic data similarity systematically evaluated proposed method three datasets , ucf101 , showing competitive retrieval recognition accuracies compared state art approaches , significantly smaller memory lower coding complexity
visual generation adversarial learning visual dialogue task requires agent conversation image human represents extension visual question answering task agent needs answer question image , needs light previous dialogue taken place key challenge visual dialogue thus maintaining consistent , natural dialogue answer questions correctly present novel approach combines reinforcement learning generative adversarial networks \( gans \) generate human like responses questions gan helps overcome relative training data , tendency typical based approach generate answers , gan integrated attention mechanism generates human interpretable reasons answer means discriminative model gan task assessing whether candidate answer generated human , given provided reason significant generative model produce high quality answers well supported associated reasoning method also generates state art results primary benchmark
block stochastic gradient descent large scale reconstruction parallel network iterative algorithms many advantages linear image reconstruction compared back projection based methods however , iterative methods tend significantly higher computational complexity overcome , parallel processing schemes several computing nodes desirable popular methods row action methods , update entire image simultaneously column action methods , require access measurements node large scale reconstruction limited storage capacity node , data communication overheads nodes becomes significant performance limiting factor reduce overhead , proposed row action method method based stochastic gradient descent method update entire image iteration , reduces node communication increase convergence speeds , importance sampling strategy proposed compare existing stochastic methods show effectiveness efficiency properties also explored , including ability incorporate total variation \( tv \) regularization automatic parameter tuning
dna gan learning disentangled representations multi attribute images disentangling factors variation always challenging problem representation learning existing algorithms suffer many limitations , disentangling factors , bad quality generated images encodings , lack identity information , etc paper , propose supervised algorithm called dna gan trying different attributes images latent representations images dna like , individual piece represents independent factor variation piece certain piece two latent representations , obtain another two different representations could decoded images order obtain realistic images also disentangled representations , introduce discriminator adversarial training experiments multi datasets demonstrate effectiveness method advantage overcoming limitations existing methods
cell probe bounds online edit distance pattern matching problems give cell probe bounds computation edit distance , hamming distance , convolution longest common stream model , fixed string n symbols given one delta bit symbol time stream symbol , distance fixed string suffix recent symbols stream reported cell probe model strongest model computation showing data structure lower bounds , particular popular word model r n first give omega \( \( delta log n \) \( w log log n \) \) lower bound time give output online hamming distance convolution , w word size bound relies new encoding scheme first time holds even w small single bit r n consider online edit distance longest common problems bit probe model \( w 1 \) constant sized input alphabet give lower bound omega \( sqrt log n \( log log n \) 3 2 \) applies problems second set results relies new encoding scheme well carefully constructed hard distribution r n finally , online edit distance problem show \( \( log n \) 2 w \) upper bound cell probe model bound gives contrast new lower bound also exponential gap known cell probe model complexities
towards generative adversarial networks new paradigm education medical students typically view thousands images order train eye detect subtle visual patterns necessary diagnosis nevertheless , constraints often make difficult access quickly query images user specified feature set paper , use conditional generative adversarial network \( gan \) synthesize pixel conditioning status demonstrate conditional gan learns features distinguish non training convolutional neural network exclusively images sampled gan achieving auc 0 95 held set real images conduct additional analysis images sampled gan describe ongoing work validate efficacy
successive embedding classification loss aerial image classification deep neural networks effective means automatically classify aerial images easy training data critical trained neural networks robust variations exist training test environments address overfitting problem aerial image classification , consider neural network successive transformations input image embedded feature representations ultimately semantic class label , train neural networks optimize image representations embedded space addition optimizing final classification score demonstrate networks trained dual embedding classification loss outperform networks classification loss also study embedding loss different network layers also find moving embedding loss commonly used feature space classifier space , space softmax , leads best classification performance aerial images network 's embedded representations reveal embedding loss encourages greater separation target class clusters training testing partitions two aerial image classification benchmark datasets , aid code publicly available github
sharing non costs multiple resources optimally cost sharing games , existence efficiency pure nash equilibria depends method used share costs consider general class resource allocation problems set resources used heterogeneous set users cost resource \( non decreasing \) function set users assumption costs resources shared uniform cost sharing protocols , e , protocols use local information resource 's cost structure users determine cost , exactly quantify resulting pure nash equilibria specifically , show tight bounds prices stability anarchy games submodular cost functions , respectively , asymptotically tight bound games arbitrary set functions upper bounds well known cost sharing protocol , lower bounds hold arbitrary uniform cost sharing protocols even valid games costs , e , games cost resource depends cardinality set users
automated construction sparse bayesian networks unstructured probabilistic models domain information algorithm automated construction sparse bayesian network given unstructured probabilistic model causal domain information expert developed implemented goal obtain network explicitly reveals much information regarding conditional independence possible network built adding one node time expert 's information greedy heuristic tries keep number added step minimum used guide search next node add probabilistic model answer queries domain practice model implemented various ways example , model could statistical independence test operating empirical data operating set independence domain
lossless block coding examine lossless data compression average delay perspective encoder receives input symbols one per unit time source binary codewords buffer bits fixed rate receiver decoder input symbol encoder viewed status update source system performance characterized status update age , defined number time units \( symbols \) decoder output behind encoder input upper bound average status age derived exponential bound probability error streaming source coding delay apart influence error exponent describes convergence error , upper bound also scales constant term error probability however , error exponent lead accurate description status age small delay small age optimal block coding scheme proposed based approximation average age streaming source coding system g 1 queue compare scheme error exponent optimal coding scheme uses method types show maximizing error exponent equivalent minimizing average status age
chunkflow distributed hybrid cloud processing large 3d images convolutional nets common process biomedical images using 3d convolutional networks \( \) challenging even images acquired today light microscopy introduce chunkflow , software framework convnet processing local cloud gpus cpus image volume divided overlapping , processed convnet , results together yield output image convnet tasks cloud queue tasks executed local cloud gpus cpus thanks fault tolerant architecture chunkflow , cost greatly reduced utilizing cloud instances chunkflow currently supports gpus cpus illustrate usage , large 3d brain image serial section microscopy processed 3d convnet u net style architecture chunkflow provides operations general use , operations composed flexibly command line interface
global second order pooling convolutional networks deep convolutional networks \( \) fundamental , besides large scale visual recognition , lot vision tasks primary goal characterize complex boundaries thousands classes high dimensional space , critical learn higher order representations enhancing non linear modeling capability recently , global second order pooling \( \) , plugged end networks , attracted increasing , achieving much better performance classical , first order networks variety vision tasks however , effectively introduce higher order representation earlier layers improving non linear capability still open problem paper , propose novel network model introducing across lower higher layers exploiting holistic image information throughout network given input 3d tensor previous convolutional layer , perform obtain covariance matrix , nonlinear transformation , used tensor scaling along channel dimension similarly , perform along spatial dimension tensor scaling well way , make full use second order statistics holistic image throughout network proposed networks evaluated large scale imagenet , experiments shown outperformed non counterparts achieving state art results
achieving greater concurrency execution smart contracts using object semantics popular blockchain several others execute complex transactions blocks user defined scripts known smart contracts , block chain consists multiple transactions smart contracts added miner correct block blockchain , execute smart contract transactions \( sct \) sequentially later execute sct block current era multi core processors , employing serial execution transactions , fail utilize cores properly result poor throughput adding concurrency using object semantics smart contracts execution , achieve better efficiency higher throughput authors used read write \( \) concurrent execution sct working higher level operations provide greater concurrency , better throughput reduces number paper , develop efficient framework execute sct miner using optimistic object based software transactional memory systems \( \) multi version \( mv ostm \) proposed block includes sct , final states shared data items , hash previous block block graph \( \) captures relations among transactions later , execute sct help given miner verify final state validation successful proposed block blockchain miner gets incentive otherwise proposed block mv ostm ostm miner performs 4 3 average serial miner along , mv ostm ostm outperforms average serial
exploring neural net augmentation bert question answering squad 2 0 enhancing machine capabilities answer questions topic considerable focus recent years nlp research language models like embeddings language models \( \) 1 bidirectional encoder representations \( bert \) 2 successful developing general purpose language models optimized large number downstream language tasks work , focused augmenting pre trained bert language model different output neural net architectures compared performance question answering task posed stanford question answering dataset 2 0 \( squad 2 0 \) 3 additionally , also fine tuned pre trained bert model parameters demonstrate effectiveness adapting specialized language tasks best output network , cnn performs question answering tasks f1 scores 75 64 85 respectively
multi data driven approach enhance distribution system observability paper presents novel data driven method determines daily consumption patterns customers without smart \( sms \) enhance observability distribution systems using proposed method , daily consumption customers extracted billing data based three machine learning models first model , spectral clustering algorithm used infer typical daily load profiles customers sms typical daily load behavior represents distinct class behavior second module , multi learning model trained estimate consumption using energy data customers class third stage leverages recursive bayesian learning method branch current state estimation estimate daily load profiles customers without sms proposed data driven method tested verified using real utility data
computing approximate equilibria sequential adversarial games descent paper , present descent , new algorithm compute approximate equilibria two player zero sum extensive form games imperfect information , direct policy optimization worst case prove following optimization , player 's strategy converges asymptotically zero , hence players employ optimization , joint policies converge nash equilibrium unlike play \( \) regret minimization \( \) , convergence result policies optimized rather average policies experiments demonstrate convergence rates comparable four benchmark games case using function approximation , find algorithm outperforms version two games , , best knowledge , first result imperfect information games among class algorithms
subset seed automaton study pattern matching automaton introduced 1 purpose seed based similarity search show definition provides compact automaton , much smaller one obtained applying construction study properties automaton present efficient implementation automaton construction also present experimental results show automaton successfully applied general situations
lower bounds graph exploration using local policies give lower bounds various natural node edge based local strategies exploring graph consider problem setting arbitrary graph well abstraction geometric exploration space robot , extensively studied consider local exploration policies use time last visit least frequently local greedy strategies select next step exploration path strategies previously considered et al \( 2011 \) scenario last visit visit frequency edges work consider case associated nodes , case dual graphs geometric spaces could intuitively natural likely efficient surprisingly , alternate strategies give worst case exponential time exploration , whereas least frequently strategy edges bounded exploration time , shown et al \( 2011 \)
need topology awareness generative models manifold assumption learning states data lie approximately manifold much lower dimension input space generative models learn generate data according underlying data distribution generative models used various tasks , data augmentation generating variation images paper addresses following question generative models need aware topology underlying data manifold data lie \? paper suggests answer demonstrates security critical applications , generative model based defenses adversarial examples provide theoretical experimental results support claims
citation based clustering publications using citnetexplorer clustering scientific publications important problem research demonstrate two software tools , citnetexplorer , used cluster publications analyze resulting clustering solutions citnetexplorer used cluster large set publications field publications clustered based direct citation relations citnetexplorer used together analyze resulting clustering solutions tools use support analysis clustering solutions , citnetexplorer focusing analysis level individual publications focusing analysis aggregate level provided paper shows clustering publications created analyzed using freely available software tools using approach presented paper , able carry sophisticated cluster analyses without need deep knowledge clustering techniques without requiring advanced computer skills
label novel neural network architecture nested ner named entity recognition \( ner \) one best studied tasks natural language processing however , approaches capable handling nested structures common many applications paper introduce novel neural network architecture first entities entities nested structures , labels independently unlike previous work , label approach predicts real valued instead discrete segmentation structures , allow combine word nested entity embeddings maintaining groups entities single vectors across multiple levels evaluate approach using corpus , achieves state art f1 6 , improved contextual embeddings \( bert \) 82 4 , overall improvement close 8 f1 points previous approaches trained data additionally compare bilstm crfs , dominant approach flat ner structures , demonstrating ability predict nested structures impact performance simpler cases
partially causally consistent shared memory lower bounds algorithm focus paper causal consistency em partially distributed shared memory \( dsm \) system provides abstraction shared read write registers maintaining causal consistency distributed shared memory systems received significant attention past , mostly em full wherein replica copy registers shared memory ensure causal consistency , causally updates must performed update performed given replica therefore , mechanism tracking causal dependencies required , vector number vector elements equal number context full paper , investigate causal consistency em partially systems , wherein replica may store subset shared registers building past work , paper makes three key contributions 1 present necessary condition metadata \( refer em \) must maintained replica able track accurately necessary condition identifies set directed edges em share graph replica 's must keep track 2 present algorithm achieving causal consistency using matches necessary condition , thus showing condition necessary sufficient 3 define measurement space size present lower bound \( bits \) size lower bound matches algorithm several special cases
general non probabilistic theory inductive reasoning probability theory , interpreted , provides excellent , best available account inductive reasoning general definite rules change subjective probabilities information experience induction belief change one topic , basic rules simply respect information received similar general rules 1 hence , fundamental reason success probability theory exists well concept conditional probability still , people , reasons , various concerns probability theory one starting point intuitively , notion plain belief believe true \( false neither \) probability theory , however , offers formal counterpart notion believing probability 1 , probability 1 plain belief clearly believing giving probability larger 1 c , believing believing b usually taken equivalent believing b 4 thus , seems formal representation plain belief take non probabilistic route indeed , representing plain belief seems easy enough simply represent epistemic state set believed true , since make common assumption plain belief closed , conjunction believed true yet provide theory induction , e answer question epistemic states represented changed information experience partial answer new information compatible old epistemic state , new epistemic state simply represented conjunction new information old answer partial cover quite common case new information old , however , important complete answer cover case , otherwise , would represent plain belief crucial problem good completion epistemic states represented simply conjunction believed true , answer cannot though lot work , representation epistemic states proposed , far know , provides complete solution problem paper , want suggest solution 4 , fully solution , certain satisfied , section 2 , content formally defining intuitively explaining proposal compare proposal probability theory section 3 turn theory proposing homomorphic probability theory important thus equally easily , moreover computationally simpler section 4 contains comparison various kinds logics , particular conditional logic , 's functions potential related theories , theory belief functions
towards models availability security evaluation cloud computing moving target defense security one relevant concerns cloud computing evolution cyber security threats , developing innovative techniques attacks importance one recent method improve cloud computing security moving target defense \( \) makes use dynamic reconfiguration environments attackers knowledge system state however , still mechanism evaluate trade offs availability security using cloud computing evaluation measurements complex one needs deal events failures attacks overcome challenge , propose set models evaluate availability security cloud computing environments expected results include quantification availability security levels different conditions \( e g , different software aging rates , varying workloads , different attack \)
empirical evaluation rule extraction recurrent neural networks rule extraction black box models critical domains require model validation implementation , case scoring medical diagnosis though already challenging problem statistical learning general , difficulty even greater highly non linear , recursive models , recurrent neural networks \( rnns \) , fit data , study extraction rules second order recurrent neural networks trained recognize grammars show production rules extracted trained rnns certain cases rules outperform trained rnns
investigation hamiltonian quantum markov network graphical models various applications science engineering include physics , , etc usage graphical models needs complex computations order evaluation marginal functions , powerful methods including mean field approximation , belief propagation algorithm etc quantum graphical models recently developed context quantum information computation , quantum statistical physics , possible generalization classical probability theory quantum theory main goal paper primary generalization markov network , type graphical models , quantum case applying quantum statistical physics investigated markov network role hamiltonian terms conditional independence simple examples quantum statistical physics
model based detector presence inter cell interference paper , consider problem reducing bit error rate flash based state \( \) cells subject inter cell interference \( \) observing outputs adjacent cells correlated due common , propose novel channel model accurately represent true flash channel model , equivalent finite state markov channel model , allows use sum product algorithm calculate accurate posterior distributions individual cell inputs given joint outputs cells easily mapped log likelihood ratios inputs soft ldpc decoder output available high precision , simulation showed significant reduction bit error rate obtained , reaching 99 99 reduction compared current methods , coupling strong realistic case low precision output , scheme provides less impressive improvements due information loss process quantization improve performance new detector quantized case , propose new iterative scheme multiple times detector decoder simulations showed iterative scheme significantly improve bit error rate even quantized case
function assistant tool querying paper , describe function assistant , lightweight python based toolkit querying exploring source code using natural language toolkit designed help end users target api quickly find information functions high level natural language queries descriptions given text query background api , tool finds candidate functions performing translation text known representations api using semantic parsing approach \( 2017 \) automatically learned example text code pairs example toolkit includes features building translation pipelines query engines arbitrary source code projects explore last feature , perform new experiments 27 well known python projects github
models visually grounded speech signal attention bilingual experiment english investigate behaviour attention neural models visually grounded speech trained two languages english experimental results show attention focuses behaviour holds true two different languages also draw artificial neural attention human attention show neural attention focuses word human attention finally , investigate two visually grounded monolingual models used perform cross lingual speech speech retrieval languages , bilingual \( speech image \) corpora part speech tags alignments distributed community research
aesthetics residual use computational methods evaluate aesthetics gained interest recent years due convolutional neural networks availability new annotated datasets studies area focused designing models take account individual preferences prediction value propose model based residual learning capable learning subjective , user specific preferences aesthetics , state art methods keeping limited number user specific parameters model model also used enhancement , suitable content based hybrid recommender systems amount computational resources limited
deep neural framework contextual affect detection short simple text emotion represent strong emotions reading along context , e , sentence express extreme anger well depending context paper , propose contextual affect detection \( \) framework learns inter dependence words sentence , time inter dependence sentences dialogue proposed framework based gated recurrent unit \( \) , assisted contextual word embeddings diverse hand crafted feature sets evaluation analysis suggest model outperforms state art methods 5 9 14 dataset , respectively
based representation texts complex networks approach abstract interesting model represent texts graph \( also called network \) word \( co occurrence \) representation , known capture mainly features texts study , propose novel network model , based similarity content text considering representation , characterized networks respect measurements developed network science area characterized measurements according properties regarding ability real shuffled texts , capture information regarding content similarity text order compare results sophisticated approach , employed methodology based comparing real shuffled texts , results revealed real texts tend well defined community structure characteristic related organization subjects real texts network based measurements found able real shuffled texts used features classifier result , obtained accuracy 98 72 order compare different methodology , used based features classifier , yielding accuracy rate 70 8 proposed network based features employed analyze , found compatible real texts according considered characteristics
review deep learning techniques 3d sensed data classification past decade deep learning driven progress 2d image understanding despite advancements , techniques automatic 3d sensed data understanding , point clouds , however , range important applications indoor robotics navigation national scale remote sensing high demand algorithms learn automatically understand classify 3d sensed data paper review current state art deep learning architectures processing unstructured euclidean data addressing background concepts traditional methodologies review current main approaches , including rgb , multi view , fully end end architecture designs datasets category explained finally , give detailed discussion future deep learning 3d sensed data , using literature justify areas future research would
max wasserstein distance use gans generative adversarial nets \( gans \) variational auto encoders significantly improved distribution modeling capabilities , showing promise dataset augmentation , image image translation feature learning however , model high dimensional distributions , sequential training stacked architectures common , increasing number hyper parameters well training time , sample complexity distance metrics remains one factors gan training first show recently proposed wasserstein distance compelling sample complexity properties compared wasserstein distance improve wasserstein distance analyze develop max wasserstein distance enjoys compelling sample complexity reducing projection complexity , max estimation finally illustrate proposed distance trains gans high dimensional images resolution easily
learning policies regression policy gradient based reinforcement learning algorithms coupled neural networks shown success learning complex policies model free continuous action space control setting however , explicitly parameterized policies limited scope chosen parametric probability distribution show likelihood based policy gradient , related objective optimized advantage weighted regression approach models policy implicitly network , gives agent freedom approximate distribution action dimension , limiting capabilities commonly used unimodal gaussian parameterization spectrum policies makes algorithm suitable problems gaussian policies cannot fit optimal policy moreover , results mujoco physics simulator benchmarks comparable superior state art policy methods
deep reinforcement learning acquire navigation skills wheel robots complex environments mobile robot navigation complex dynamic environments challenging important problem reinforcement learning approaches fail solve tasks efficiently due reward , temporal complexities high dimensionality spaces inherent problems present novel approach train action policies acquire navigation skills wheel robots using deep reinforcement learning policy maps map image observations commands navigate target position avoiding obstacles propose acquire navigation skill learning exploiting number navigation behaviors also introduce domain technique improve training samples demonstrate experimentally significant improvement terms data efficiency , success rate , robustness sensory data , also quality skills
simple approach learn polysemous word embeddings many nlp applications require polysemous words existing methods learn polysemous word vector representations involve first detecting various senses optimizing sense specific embeddings separately , involved single sense learning methods evaluating methods also problematic , rigorous quantitative evaluations space limited , especially compared single sense embeddings paper , propose simple method learn word representation , given context method requires learning usual single sense representation , coefficients learnt via single pass data propose several new test sets evaluating word sense induction , relevance detection , contextual word similarity , significantly currently available tests results tests show method simple , achieves excellent results compared state art models unsupervised polysemous word representation learning
proportional volume sampling approximation algorithms optimal design study optimal design problems goal choose set linear measurements obtain accurate estimate unknown vector dimensions study optimal design variant objective minimize average variance error maximum likelihood estimate vector measured problem also finds applications sensor placement wireless networks , sparse least squares regression , feature selection k means clustering , matrix approximation paper , introduce proportional volume sampling obtain improved approximation algorithms optimal design main result obtain improved approximation algorithms optimal design problem introducing proportional volume sampling algorithm results nearly optimal bounds asymptotic regime number measurements done , k , significantly dimension also give first approximation algorithms k small including k proportional volume sampling algorithm also gives approximation algorithms optimal design objectives optimal design generalized ratio objective matching improving previous best known results interestingly , show similar guarantee cannot obtained e optimal design problem also show optimal design problem np hard approximate within fixed constant k
computational models consumer confidence large scale online attention data crowd instances complex technical systems shaped interactions large numbers individuals individual behavior decision making consumer agents determined complex psychological dynamics include assessment present future economic conditions well others , potentially leading feedback affect macroscopic state economic system propose large scale interactions 's online resources reveal complex dynamics collective , including assessment future system states introduce behavioral index chinese consumer confidence \( \) computationally large scale online search behavior google trends data macroscopic variable consumer confidence results indicate computational may reveal components complex dynamics consumer collective economic phenomenon , potentially leading improved refined economic forecasting
measures edge resistance r \( g \) graph g minimum number edges removed g obtain graph \( g \) edge colorable paper resistance parameters measure far graph edge colorable let r v \( g \) minimum number vertices removed g obtain class 1 graph show r \( g \) r v \( g \) \? \? \( g \) 2 \? , bound best possible
mixed objective deep residual question answering traditional models question answering optimize using cross entropy loss , encourages exact answers cost overlapping answers sometimes equally accurate propose mixed objective combines cross entropy loss self critical policy learning objective uses rewards derived word overlap solve evaluation metric optimization objective addition mixed objective , improve dynamic networks \( \) deep residual encoder inspired recent work deep self attention residual networks proposals improve model performance across question types input lengths , especially long questions requires ability capture long term dependencies stanford question answering dataset , model achieves state art results 75 1 exact match accuracy 1 f1 , ensemble obtains 78 9 exact match accuracy 86 0 f1
constructive strict abstract c modern modal logic theory strict classical propositional calculus one well work unary box , however , strict greater expressive power allows make ordinary syntax particular , logic determined popular semantics intuitionistic k becomes proper extension minimal normal logic binary even extension minimal logic strength , near trivial , preserves binary unary setting fact , discovered functional programming community study particular focus interpretations intuitionistic terms extensions , e , arithmetic
program size complexity self paths prove lemma abstract tile assembly model , model central theory algorithmic self assembly since field theory suggests , result proves , small differences nature abstract square gives rise different expressive capabilities r n cooperative abstract tile assembly model , square using multi sided cooperation one , two precise control tile directly exploited algorithmic tasks including growth specified shapes using tile types , well simulation turing machines even self simulation self assembly systems cooperative required computational tasks \? simpler \( temperature 1 \) model poor control local events least one side led conjecture impossible exhibit precisely controlled growth computationally defined shapes r n , prove result show planar system attempts grow large controlled tile efficient must also grow infinite non algorithmic \( \) structures simple closed form description , else suffer blocking intended algorithmic structures result holds directed systems , gives explicit upper bound \( 8 \) 4 1 \( 5 sigma 6 \) , size sigma size seed assembly , beyond path
fuzzy based horizontal anomaly detection online social networks use social network basic functionality today 's life advent online social media , information available utilization come threat several anomalies anomalies major cause online allow information access users well information one anomalies act attacker horizontal anomaly anomalies caused user variable behavior towards different sources horizontal anomalies difficult detect network paper , self fuzzy approach \( \) used detection , recovery , removal horizontal anomalies efficiently accurately proposed approach operates five , namely , missing links , reputation gain , significant difference , trust properties , trust score proposed approach evaluated three datasets benchmark dataset , synthetic dataset , real time traffic results show accuracy proposed model 10 30 percent anomalies synthetic dataset 98 99 88 percent evaluation dataset demonstrates proposed approach better existing solutions provides 99 97 percent detection rate class real time traffic , proposed model operates average accuracy 99 42 99 90 percent detection rate
based algorithm finding k shortest simple paths directed graph present algorithm k shortest simple path problem weighted directed graphs \( \) based 's algorithm similar problem paths allowed contain cycles contrast algorithms , based 's algorithm solve replacement path problems worst case running time par state art algorithms using algorithm , one may find \( \) simple paths single shortest path tree computation \( n \) additional time per path well cases , n number nodes number edges computational results show random graphs large road networks , well cases quite common algorithm faster existing algorithms order magnitude , running time far better due small dispersion
sparse graph codes non adaptive quantitative group testing paper considers problem quantitative group testing non adaptive testing strategy quantitative group testing scheme , set tests designed identify defective items among large population items , outcome test shows number defective items tested group two models defective items \( \) deterministic , \( ii \) randomized deterministic model , exact number defective items , k , known , whereas randomized model item defective probability frac k n , independent items , n total number items work , propose non adaptive quantitative group testing algorithm using sparse graph codes bi regular bipartite graphs left degree ell right degree r binary error correcting codes show deterministic randomized models , algorithm requires c \( \) k \( log \( frac ell n c \( \) k 1 \) 1 \) 1 tests recover defective items probability approaching one \( n k grow unbounded \) , c \( \) constant depends results theoretical analysis reveal using error correcting binary code 1 , 2 , 3 , compared geq 4 , leads fewer number tests simulation results show proposed strategy significantly reduces required number tests identifying defective items probability approaching one compared recently proposed scheme
direct approach multi class boosting extensions boosting methods combine set accurate form highly accurate predictor despite practical importance multi class boosting , received far less attention binary counterpart work , propose fully multi class boosting formulation directly multi class problem without multiple binary classification problems contrast , previous multi class boosting algorithms decompose multi boost problem multiple binary boosting problems explicitly deriving dual primal optimization problem , able construct column generation based fully approach boosting directly optimizes multi class classification performance new approach updates weak coefficients every iteration , manner flexible enough accommodate various loss functions example , enables us introduce structural sparsity mixed norm regularization group sparsity feature sharing boosting shared features particularly beneficial complex prediction problems features expensive compute experiments various data sets demonstrate direct multi class boosting generalizes well , better , range competing multi class boosting methods end result highly effective compact ensemble classifier trained distributed fashion
evaluating software based fingerprint detection using convolutional networks local binary patterns growing use biometric authentication systems past years , fingerprint detection become increasingly important work , implement evaluate two different feature extraction techniques software based fingerprint detection convolutional networks random weights local binary patterns techniques used conjunction support vector machine \( svm \) classifier dataset augmentation used increase classifier 's performance variety preprocessing operations tested , frequency filtering , contrast , region interest filtering experiments made datasets used detection competition years 2009 , 2011 2013 , almost 50 , 000 real fake images best method achieves overall rate 95 2 correctly classified samples improvement test error compared best previously published results
representation finite automata give unique string representation , , initially connected deterministic finite automata \( \) n states alphabet k symbols show generate strings n k , enumeration provides alternative way obtain exact number
delay free concurrency faulty persistent memory non memory \( \) promises persistent main memory remains correct despite loss power line research algorithms recover system since expected remain , concurrent data structures algorithms must guarantee left consistent state system , execution continued upon recovery however , prospect every concurrent data structure algorithm used architectures r n paper , present construction takes concurrent program reads , shared memory makes persistent , e , continued one processes fault importantly converted algorithm constant computational delay \( preserves instruction counts process within constant factor \) , well constant recovery delay \( process recover fault constant number instructions \) show first simple transformation , present optimizations make practical , allowing tradeoff better constant factors computational delay , sometimes increased recovery delay also provide optimized transformation works normalized lock free data structure , thus allowing efficient constructions large class concurrent algorithms experimentally evaluate transformations applying queue
adaptive sliding mode control aerial vehicles work addresses problem robust control first , mathematical model derived considering factors , external , uncertain dynamics strong coupling adaptive sliding mode control algorithm developed objective controlling track desired various conditions , sliding mode control law modified proposed gain adaptation scheme improve control transient tracking performance extensive simulation studies comparisons experimental data carried results show proposed control scheme achieve strong robustness adaptable parametric variations
supervised saliency map driven segmentation images lesion segmentation first step automatic recognition systems difficulties images color , occlusion , corners , color make lesion segmentation task order detect lesion presence problems , propose supervised saliency detection method tailored images based discriminative regional feature integration \( \) method incorporates multilevel segmentation , regional contrast , property , background descriptors , random forest create saliency scores region image improved saliency detection method , , added new features regional property descriptors also , order achieve robust regional background descriptors , thresholding algorithm proposed obtain new pseudo background region findings reveal superior detecting lesion salient object images proposed overall lesion segmentation framework uses detected saliency map construct initial mask lesion thresholding operations initial mask evolving level set framework fit better lesion 's boundaries results evaluation tests three public datasets show proposed segmentation method outperforms conventional state art segmentation algorithms performance comparable recent approaches based deep convolutional neural networks
data motifs lens towards fully understanding big data ai workloads complexity diversity big data ai workloads make understanding difficult challenging paper proposes new approach modelling characterizing big data ai workloads consider big data ai pipeline one classes units computation performed different initial intermediate data inputs class unit computation captures common requirements individual implementations , hence call data motif first time , among wide variety big data ai workloads , identify eight data motifs take run time workloads , including matrix , sampling , logic , transform , set , graph , sort statistic implement eight data motifs different software micro benchmarks open source big data ai benchmark suite 4 0 \( publicly available http url \) , perform comprehensive characterization data motifs perspective data sizes , types , sources , patterns lens towards fully understanding big data ai workloads believe eight data motifs promising abstractions tools big data ai benchmarking , also domain specific hardware software co design
distributed learning dynamics social groups study distributed learning process observed human groups social learning process appears settings individual group trying decide time , distributed manner , option select among shared set options specifically , consider stochastic dynamics group every individual selects option following two step process \( 1 \) select random individual observe option individual previous time step , \( 2 \) adopt option stochastic quality good time step various distributed learning appear nature , also studied social science literature perspective individual , attractive feature learning process simple heuristic requires extremely limited computational mean group could simple , distributed essentially memoryless process lead group whole perform optimally \? show answer question distributed learning highly effective identifying best option close optimal group overall analysis also gives quantitative bounds show fast convergence stochastic dynamics prior work theoretical work related learning dynamics either deterministic special cases asymptotic setting finally , observe infinite population dynamics stochastic variant classic multiplicative weights update \( \) method consequently , arrive following interesting converse learning dynamics finite population considered viewed novel distributed low memory implementation classic method
trainable clock less spiking neural network memristive spiking neural networks \( \) explored attempt mimic brain 's capability learn recognize low power architecture highly scalable r array weights drivers attractive option snn recognition \( akin reading weight \) requires small amplitude bias applied across minimize conductance change learning \( akin writing weight \) requires large amplitude bias produce conductance change bias amplitude requirement perform reading writing simultaneously , akin biology , major challenge solutions suggested literature rely time division multiplexing read write operations based , approximations ignoring reading writing paper , overcome challenge present clock less approach wherein reading writing performed different frequency domains enables learning recognition simultaneously snn validate scheme circuit simulator translating two feed forward iris classifying snn demonstrate software equivalent performance system performance affected voltage dependence conductance realistic , despite overall , approach enables direct implementation biological snn algorithms hardware
algorithms intersection graphs multiple intervals pseudo disks intersection graphs planar geometric objects intervals , disks , rectangles pseudo disks well studied motivated various applications , et al considered algorithmic questions intersection graphs intervals interval union distinct intervals \( parameter \) graphs referred multiple interval graphs subsequent work et al 2010 also considered disks geometric shapes paper revisit algorithmic questions via recent developments computational geometry minimum weight dominating set problem , give simple \( log \) approximation multiple interval graphs , improving previously known bound 2 also show np hard obtain \( \) approximation case fact , results hold intersection graph set pseudo disks much larger class obtain omega \( 1 \) approximation maximum weight independent set intersection graph pseudo disks results based simple reductions existing algorithms appropriately bounding union complexity objects consideration
edge faster 2 k edge problem one given undirected graph g integer k , question whether k edges g becomes bipartite 2006 , et al j , 72 \( 8 \) , 2006 proposed algorithm solving problem time \( 2 k 2 \) today , algorithm textbook example application iterative compression technique despite extensive progress understanding parameterized complexity graph separation problems recent years , significant improvement upon result yet reported r n present algorithm edge works time \( 1 k nm \) , first algorithm running time dependence parameter better 2 k end , combine general iterative compression strategy et al j , 72 \( 8 \) , 2006 , technique proposed 2014 , using polynomial time solvable relaxation form valued constraint satisfaction problem guide bounded depth branching algorithm , involved measure analysis recursion tree
compressed coded distributed computing communication overhead one major performance large scale distributed computing systems , particular machine learning applications , compression techniques used reduce load communication combining intermediate results computation task much possible recently , via development coded distributed computing \( cdc \) , shown possible enable coding opportunities across intermediate results different computation tasks reduce communication load propose new scheme , named compressed coded distributed computing \( short , compressed cdc \) , jointly exploits two techniques \( e , combining intermediate results computation coding across intermediate results different computations \) significantly reduce communication load computations linear aggregation \( reduction \) intermediate results final stage prevalent machine learning \( e g , distributed training algorithms partial gradients computed final stage \) particular , compressed cdc first combines several intermediate results single computation , utilizes multiple combined packets create coded multicast packet simultaneously useful multiple computations characterize achievable communication load compressed cdc show substantially outperforms combining methods cdc scheme
learning word relatedness time search systems often focused providing relevant results , assuming corpora user needs focus present however , many corpora today significant longitudinal collections ranging 20 years web years understanding temporal intent user relevant historical content become significant challenge common search features , query expansion , leverage relationship terms cannot function well across times relationships vary temporally work , introduce temporal relationship model extracted longitudinal data collections model supports task identifying , given two words , relate present algorithmic framework task show application task query expansion , achieving high gain
semantics context absolute first order logic computation call semantics language variables absolute variables map fixed entities , semantics absolute variable copy give lattice based , sets based , algebraic absolute semantics first order logic possibly open predicates directly interpreted lattice elements sets algebra elements , subject suitable interpretations particular , universal quantification phi interpreted using new notion finite limit using novel dual substitution r n interest semantics non trivial technical details , also offer certain advantages existing semantics also fact semantics exist suggests new way looking variables logic computation , may well suited demands modern computer science
decoding square free goppa codes f p propose new , efficient non deterministic decoding algorithm square free goppa codes f p prime p code question degree average distance closest codeword least \( 4 p \) 1 , proposed decoder correct \( 2 p \) errors high probability correction capability higher distribution error uniform , approaching reaching errors particular error value occurs much often others exclusively makes method interesting \( semantically secure \) based decoding problem goppa codes
impact general channel aging conditions downlink performance massive mimo recent works identified massive multiple input multiple output \( mimo \) key technology achieving substantial gains spectral energy efficiency additionally , turn low cost , prone hardware impairments , effective attractive way cost efficient applications concerning massive mimo systems context , impact channel aging , severely affects performance , investigated considering generalized model specifically , show shift due users' relative movement , well phase noise due noisy local , contribute channel aging end , first propose joint model , effects , investigate performance massive mimo system based inevitable time varying nature realistic mobile communications , derive deterministic signal noise interference ratios \( \) maximum ratio transmission \( \) regularized zero forcing \( \) precoding analysis demonstrates performance comparison conditions , importantly , also reveals interesting properties regarding effects user mobility phase noise particular , large antenna limit behavior depends effects , burden due user mobility much detrimental phase noise even moderate user \( 30 h \) , whereas negative impact phase noise lower mobility conditions moreover , massive mimo systems favorable even general channel aging conditions nevertheless , demonstrate transmit power user maintain certain quality service scaled , , text 1 sqrt \( number base station antennas \) , indicates joint effects phase noise user mobility power scaling law achievable sum rate
using rank aggregation expert search academic digital libraries task expert finding getting increasing attention information retrieval literature however , current state art still lacking principled approaches combining different sources evidence paper explores usage unsupervised rank aggregation methods principled approach combining multiple expertise , derived textual , graph structure citation patterns community experts , profile information experts specifically two unsupervised rank aggregation approaches well known information retrieval literature , namely experiments made dataset academic publications area computer science adequacy methods
predicting performance software configurations many software systems offer configuration options functionality non functional properties \( e g , performance \) often , users interested \( performance \) optimal configuration , find , due missing information influences individual configuration options interactions past , various supervised machine learning techniques used predict performance configurations identify optimal one literature , large number machine learning techniques sampling strategies select unclear , though , extent affect prediction accuracy conducted comparative study regarding mean prediction accuracy predicting performance configurations considering 6 machine learning techniques , 18 sampling strategies , 6 subject software systems found learning technique sampling strategy strong influence prediction accuracy observed learning techniques \( e g , random forests \) outperform learning techniques \( e g , k nearest neighbor \) cases moreover , prediction accuracy strongly depends subject system , combination learning technique sampling strategy optimal cases , considering tradeoff accuracy measurement overhead , line famous free theorem
discovering network behind disease spatial heterogeneity great interest recently studying spread disease presented method inverse problem discover effectively topology heterogeneous network reveal transmission parameters stochastic network dataset disease early growth phase populations combination models meta population network model described stochastic differential equations probability density functions derived equations used maximal likelihood estimation topology parameters method tested computationally synthesized datasets dataset
explicitly learning disentangled representation underlying structure rendering image generation without tuple supervision focus explicitly learning disentangled representation natural image generation , underlying spatial structure rendering structure independently controlled respectively , yet using tuple supervision setting significant since tuple supervision costly sometimes even unavailable however , task highly unconstrained thus ill posed address problem , propose introduce auxiliary domain common underlying structure space target domain , make partially shared latent space assumption key idea encourage partially shared latent variable represent similar underlying spatial structures domains , two domain specific latent variables present two domains respectively achieved designing two parallel generative networks common rendering architecture \( \) , generative behaviors model shared underlying structure model spatially dependent relation rendering underlying structure thus , propose \( gans disentangling underlying structure rendering \) method also propose quantitative criterion \( normalized \) quantify comparison state art methods shows significantly outperform
prediction infinite words automata classic problem sequence prediction , predictor receives sequence values tries next value appears predictor point predictor 's correct paper consider case predictor automaton values drawn finite set e , sequence infinite word examine predictive capabilities finite automata , pushdown automata , stack automata \( generalization pushdown automata \) , finite automata relate predicting automata purely periodic words , ultimately periodic words , words , describing novel prediction algorithms sequences
optical flow augmented semantic segmentation networks automated driving motion dominant automated driving systems optical flow typically computed detect moving objects estimate depth using triangulation paper , motivation leverage existing dense optical flow improve performance semantic segmentation provide systematic study , construct four different architectures use rgb , flow , concatenated two stream rgb flow evaluate networks two automotive datasets namely virtual kitti cityscapes using state art flow estimator flownet v2 also make use ground truth optical flow virtual kitti serve ideal estimator standard optical flow algorithm study effect noise using flow ground truth virtual kitti , two stream architecture achieves best results improvement 4 iou expected , large improvement moving objects like , cars 38 , 28 6 increase iou flownet produces improvement 2 4 average iou larger improvement moving objects corresponding 26 , 11 5 , cars cityscapes , flow augmentation provided improvement moving objects like train increase 17 7 iou
layer applicability metric transfer learning deep neural networks trained large datasets learn features generic whole dataset , specific individual classes dataset learned features tend towards generic lower layers specific higher layers network methods like fine tuning made possible ability one filter apply multiple target classes much like human brain behavior , also used cluster separate classes however , best knowledge metric applicable learned features specific classes paper propose definition metric measuring applicability learned features individual classes , use applicability metric estimate input applicability produce new method unsupervised learning call
prediction benign breast cancer data mining approach healthcare applications much data science playing role , healthcare also finds prominent application breast cancer top type cancer amongst women away , 000 lives alone high mortality rate due breast cancer need attention , early detection done time potential state art technology development , data mining finds multi fold application predicting cancer work focuses different classification techniques implementation data mining predicting benign breast cancer breast cancer data set used experimental dataset attribute thickness used evaluation class performances algorithms boost 1 , decision table , j , , regression , multiclass classifier , perceptron , naive bayes , random forest random tree analyzed data set keywords data mining , classification techniques , , breast cancer , classification algorithms
computing current trends open problems computing emerged new compelling paradigm deployment applications services represents evolution cloud programming models , abstractions , platforms , wide adoption cloud technologies chapter , survey existing platforms industry , academia , open source projects , identify key characteristics use cases , describe technical challenges open problems
relational division rank aware databases present survey existing approaches relational division rank aware databases , discuss issues present approaches , outline generalizations several types classic division like operations work model generalizes model data considering tuples relations annotated ranks , indicating degrees tuples relations match queries approach utilizes complete basic structures degrees argue unlike classic model , relational fundamental operations cannot general expressed means operations addition , compare existing proposed operations identify counterparts queries formulated relational introduce pseudo tuple calculus ranked model used show mutual various forms presented paper
cloud storage case study today 's live world constant connectivity , many people looking cloud services order store files access using cloud services , users access files internet connection however , cloud storage convenient , also presents security perspective , increasing popularity cloud storage platforms , makes investigation exploits much difficult , especially since many platforms mobile devices well computers able use services paper presents investigation one popular cloud platforms running 8 1 remaining artefacts different usage namely , download , 8 1 presented
towards automatic threat detection survey advances deep learning within x ray security imaging x ray security widely used maintain transport security , significance poses particular interest automated systems paper aims review x ray security imaging algorithms field conventional machine learning contemporary deep learning applications first part briefly discusses classical machine learning approaches within x ray security imaging , latter part investigates use modern deep learning algorithms proposed taxonomy sub use deep learning approaches supervised , semi supervised unsupervised learning , particular focus object classification , detection , segmentation anomaly detection tasks paper explores well established x ray datasets provides performance benchmark based current future trends deep learning , paper finally presents discussion future directions x ray security imagery
normalized mutual information binary classifications correspondence studies basic problem classifications evaluate different classifiers although conventional performance indexes , accuracy , commonly used classifier selection evaluation , information based criteria , mutual information , becoming popular feature model work , propose assess classifiers terms normalized mutual information \( \) , novel well defined compact range classifier evaluation derive close form relations normalized mutual information respect accuracy , precision , recall binary classifications exploring relations among , reveal actually set nonlinear functions , power exponent form , performance index relations also expressed respect precision recall , false rate \( recall \)
computing lower rank approximations matrix polynomials given input matrix polynomial whose coefficients floating point numbers , consider problem finding nearest matrix polynomial rank specified value generalizes problem finding nearest matrix polynomial singular lower bound dimension given previous paper authors paper prove lower rank matrices minimal distance always exist , satisfy conditions , isolated non minimal solutions addition , present iterative algorithm , given input sufficiently close rank matrix , produces matrix algorithm efficient proven converge given sufficiently good starting point implementation demonstrates effectiveness numerical robustness algorithm practice
acyclic games iterative voting consider iterative voting models position within general framework acyclic games game forms specifically , classify convergence results based underlying assumptions agent \( order players \) action \( better \) r n main technical result providing complete conditions several variations voting particular , show \( \) traditional lexicographic tie , game converges order players weak restriction actions \( b \) randomized tie guaranteed converge arbitrary agent schedulers , initial state emph path better nash equilibrium thus show first separation restricted weak game forms , thereby open question , 2011 addition , another conjecture regarding strongly acyclic voting rules
dealing sparse rewards reinforcement learning successfully complex environment obtain desired outcome difficult task , recently believed capable humans perception time , especially introduction deep reinforcement learning , greatly increased difficulty tasks automated however , traditional reinforcement learning agents requires environment able provide frequent extrinsic rewards , known accessible many real world environments project aims explore contrast existing reinforcement learning solutions difficulties environment provide sparse rewards different reinforcement solutions implemented several video game environments varying difficulty varying frequency rewards , properly investigate applicability solutions project introduces novel reinforcement learning solution combining aspects two existing state art sparse reward solutions , driven exploration unsupervised auxiliary tasks
user modeling combining access logs page content semantics paper proposes approach modeling users large web sites based combining different data sources access logs content pages combined semantic information web pages , users accesses users web site assumption dealing large web site providing content large number users site proposed approach represents user set features derived different data sources , feature values may missing users enables user modeling based provided characteristics targeted user subset approach evaluated real world data compare performance automatic assignment user predefined user segment different data sources used represent users
technical report conversational question answering conversational question answering challenging task since requires understanding conversational history project , propose new system , involves tagging multi task , adversarial training , knowledge distillation linguistic post process strategy single model achieves 90 4 \( f1 \) test set without data augmentation , outperforming current state art single model 2 6 f1
towards standardization data data license paper provides taxonomy data fields artificial intelligence machine learning paper 's goal build towards common framework data akin open source software increased transparency conceptual existing language two benefits approach proposed paper parallel , benefits may help efficient markets data tools concepts better define data used fields ai ml paper 's approach new family data license language textit data license \( \) new license , authors developed web based tool generate license language paper
deep learning detecting multiple space time action tubes videos work , propose approach spatiotemporal localisation \( detection \) classification multiple concurrent actions within temporally videos framework composed three stages stage 1 , appearance motion detection networks employed score actions images optical flow stage 2 , appearance network detections combining motion detection scores , respective spatial overlap stage 3 , sequences detection boxes likely associated single action instance , called action tubes , constructed solving two energy problems via dynamic programming first pass , action paths spanning whole video built linking detection boxes time using class specific scores spatial overlap , second pass , temporal performed ensuring label consistency detection boxes demonstrate performance algorithm challenging ucf101 , j 21 datasets , achieving new state art results across board significantly increasing detection speed test time achieve huge forward action detection performance report 20 11 gain map \( mean average precision \) j 21 datasets respectively compared state art
resource allocation network integrated device device communications using smart relays increasing number autonomous heterogeneous devices future mobile networks , efficient resource allocation scheme required maximize network throughput achieve higher spectral efficiency paper , performance network integrated device device \( d2d \) communication investigated d2d traffic carried relay nodes optimization problem formulated allocating radio resources maximize end end rate well qos requirements cellular d2d user equipment total power constraint numerical results show distance threshold beyond relay assisted d2d communication significantly improves network performance compared direct communication d2d
new alignment methods discriminative book summarization consider unsupervised alignment full text book human written summary presents challenges seen text alignment problems , including disparity length , , expectation individual words phrases align , since large passages single summary phrase present two new methods , based hidden markov models , specifically targeted problem , demonstrate gains book summarization task still much room improvement , unsupervised alignment holds intrinsic value offering insight features book summarization
differential privacy sampling gaussian prior show sampling gaussian prior detailed algorithm 2 \( , 2013 \) already differentially private theorem 1 show enjoys competitive privacy loss mathcal \( 2 \) rounds finally , theorem 2 show one control privacy loss desirable epsilon level appropriately increasing variance samples gaussian posterior increases regret term mathcal \( frac 2 epsilon \) previous result sampling literature \( \( , 2015 \) \) adds term mathcal \( frac k 3 epsilon 2 \) regret order achieve privacy level furthermore , result use basic sampling modifications whereas result \( , 2015 \) required sophisticated constructions
compressive imaging using fast transform coding propose deterministic sampling strategies compressive imaging based frames show sampling strategies result multi scale measurements related 2d wavelet transform demonstrate effectiveness proposed strategies numerical experiments
dataset towards efficient training distillation based domain specific models real time cnn based object detection models applications like surveillance achieve high accuracy computationally expensive recent works shown 10 reduction computation cost inference using domain specific networks however , prior works focused inference domain model requires frequent , training costs pose significant bottleneck address , propose dataset pipeline reduce size dataset training , based prediction difficulty images easy classify since contribute little improving accuracy difficulty measured using proposed confidence loss metric little computational overhead dataset extended optimize image resolution improve training inference costs develop fixed angle , long duration video datasets across several domains , show dataset size factor reduce total training time accuracy loss even improvement codes available https url
hr sar net deep neural network urban scene segmentation high resolution sar data synthetic radar \( sar \) data becoming increasingly available wide range users commercial service providers reaching 0 segmenting sar data still requires , limiting potential large scale use show possible automatically reliably perform urban scene segmentation next resolution sar data \( 0 \) using deep neural networks \( dnns \) , achieving pixel accuracy 95 mean iou 67 data collected region 2 2 presented dnn effective , small parameters computationally simple enough achieve throughput around using single gpu identify additional sar receive antennas data multiple massively improve segmentation accuracy describe procedure generating high quality segmentation ground truth multiple inaccurate building road annotations , crucial achieving segmentation results
breast cancer detection using convolutional neural networks breast cancer prevalent accounts among women cancer patients diagnosis technique manual proven tedious , subjective , challenging deep learning techniques field medical image analysis hence study , proposed convolutional neural networks \( cnns \) breast mass detection minimize overheads manual analysis cnn architecture designed feature extraction stage adapted region proposal network \( \) region interest \( roi \) portion faster r cnn automated breast mass detection model detects mass region benign \( \) images proposed model , images collected different , locally images different preprocessing stages gaussian filter , median filter , bilateral filters extracted region breast background image performance model test dataset found detection accuracy 91 86 , sensitivity 94 67 auc 2
robustness analysis value signal temporal logic previous work introduced logic stl , n extension signal temporal logic \( stl \) allows value n paper , define robustness measures stl n adapting robustness measures previously introduced n metric temporal logic \( \) furthermore , present n algorithm stl robustness computation , implemented n tool application stl robustness analysis n demonstrated case studies
opesci fd automatic code generation finite difference models project , introduce opesci fd , python built symbolic mathematics automatically generate finite difference models high level description model equations investigate applying framework generate program used imaging implement 3d velocity fd scheme example demonstrate advantages , flexibility accuracy framework design opesci fd aims allow rapid development , analysis optimisation finite difference programs opesci fd foundation development opesci project team , building research presented report report concludes developments already way , well scope extension equations numerical schemes
source coding block memory causally controllable side information recently proposed set source coding side information machine allows decoder select actions order control quality side information actions depend message received encoder previously measured samples side information , cost constrained moreover , final estimate source decoder function encoder 's message depends causally side information sequence previous work characterized rate distortion cost function special case source machine memoryless work , motivated related channel coding model introduced , rate distortion cost function characterization extended model block memory various special cases studied including block side information request models
deep filter banks texture recognition description segmentation visual key role image understanding important semantics images , texture representations pool local image descriptors manner tremendous impact diverse applications paper make several contributions texture understanding first , instead focusing texture instance material category recognition , propose human interpretable vocabulary texture attributes describe common texture patterns , new texture dataset benchmarking second , look problem recognizing materials texture attributes realistic imaging conditions , including appear clutter , developing corresponding benchmarks top recently proposed dataset third , revisit classic texture representations , including visual words fisher vectors , context deep learning show excellent efficiency generalization properties convolutional layers deep model used filter banks obtain manner state art performance numerous datasets well beyond , efficient method apply deep features image regions , well benefit transferring features one domain another
modeling neural dynamics speech production using state space variational autoencoder characterizing neural encoding behavior remains challenging task many research areas due part complex noisy spatiotemporal dynamics brain activity important aspect modeling neural encodings involves separation robust , relevant signals background activity , often contains signals brain processes information previous behavioral events achieve separation , develop two branch state space variational autoencoder \( \) model individually describe instantaneous foreground signals context dependent background signals modeled speech brain dynamics using smoothed gaussian mixture models applying proposed model track dynamics one multiple hours , find model predict speech related dynamics accurately latent factor inference algorithms results demonstrate separately modeling instantaneous speech slow context dependent brain dynamics enhance tracking performance , important implications development advanced neural encoding decoding models various sub disciplines
distributed function computation confidentiality set terminals observe correlated data seek compute functions data using interactive public communication time , required value private function data remains eavesdropper observing communication general , private function functions computed nodes different show class functions securely computable conditional entropy data given value private function greater least rate interactive communication required related source coding task single letter formula provided rate special cases
solving sat bayesian inference backtracking search inference bayes nets \( bayes \) important problem numerous applications probabilistic reasoning counting number satisfying assignments propositional formula \( sat \) closely related problem fundamental theoretical importance problems , others , members class sum products \( \) problems paper show standard backtracking search augmented simple scheme \( caching \) solve sum products problem time complexity least good state art exact algorithm , also achieve best known time space tradeoff furthermore , backtracking 's ability utilize flexible variable allows us prove achieve exponential speedup standard algorithms instances r n r n ideas presented utilized number solvers applied various types sum product problem 's system 's exploited fact backtracking naturally exploit problem 's structure achieve improved performance range problem instances empirical evidence performance gain published works describing solvers , provide references works
improving style transfer metrics style transfer methods produce transferred image rendering content image manner style image seek understand improve style transfer r n requires quantitative evaluation procedures , current evaluation qualitative , mostly involving user studies describe novel quantitative evaluation procedure procedure relies two statistics effectiveness \( e \) statistic measures extent given style transferred target , coherence \( c \) statistic measures extent original image 's content preserved statistics human preference targets larger values e \( resp c \) reliably human subjects comparisons style \( resp content \) r n use statistics investigate relative performance number neural style transfer \( \) methods , several properties admissible methods lie pareto frontier \( e improving e reduces c vice versa \) three methods admissible universal style transfer produces good c weak e modifying optimization used loss produces method strong e strong c modified cross layer method slightly better e strong cost c histogram loss improves e statistics method , make method admissible surprisingly , style weights relatively little effect improving scores , variability transfer explained style \( meaning selecting \)
model agnostic structured sparsification learnable channel recent advances convolutional neural networks \( cnns \) usually come expense considerable computational overhead memory network compression aims alleviate issue training compact models comparable performance however , existing compression techniques either dedicated expert design compromise moderate performance drop end , propose model agnostic structured sparsification method efficient network compression proposed method automatically induces sparse representations convolutional weights , thereby implementation compressed model highly optimized group convolution address problem inter group communication learnable channel mechanism proposed approach model agnostic highly negligible performance drop extensive experimental results analysis demonstrate approach performs state art network pruning methods code publicly available review process
information theoretic approach privacy ensuring usefulness electronic data sources providing necessary privacy guarantees important problem problem need analytical framework quantify safety information \( privacy \) still providing benefit \( utility \) multiple legitimate information consumers state art approaches predominantly focused privacy paper presents first information theoretic approach promises analytical model guaranteeing tight bounds much utility possible given level privacy vice versa
recurrent value functions despite recent reinforcement learning , value based methods often suffer high variance performance paper , illustrate continuous control setting state art methods perform poorly whenever sensor noise introduced overcome issue , introduce recurrent value functions \( \) alternative estimate value function state propose estimate value function current state using value function past states along trajectory due nature formulation , natural way learning emphasis function selectively important states first , establish 's asymptotic convergence properties settings demonstrate robustness partially observable domain continuous control tasks finally , provide qualitative interpretation learned emphasis function
general loss bounds universal sequence prediction bayesian framework ideally suited induction problems probability observing x time , given past observations x 1 x 1 computed rule true distribution mu sequences x 3 known problem , however , many cases one even reasonable estimate true distribution order overcome problem universal distribution defined weighted sum distributions mu , set distributions including mu generalization induction , set semi measures systems predict , given x 1 x 1 receive loss l x x true next symbol sequence considered proven using universal prior nearly good using unknown true distribution mu furthermore , games , defined sequence , observations , rewards studied time needed reach winning bounded terms relative entropy mu extensions arbitrary , partial delayed prediction , active systems discussed
known plaintext attacks compressed sensing based encryption quantitative analysis despite encoding , compressed sensing \( cs \) may used provide limited form data protection random encoding matrices used produce sets low dimensional measurements \( \) paper , quantify theoretical means resistance least complex form kind encoding known plaintext attacks standard cs random matrices recent multiclass encryption schemes based , show number candidate encoding matrices match typical plaintext pair large search true encoding matrix results practical known plaintext attacks fact even closely related signal recovery encoding matrix uncertainty fail practical attacks applying cs random matrices multiclass encryption scheme signals images tracks , showing extracted information true encoding matrix plaintext pair leads significant signal recovery quality increase theoretical empirical evidence , although secure , standard cs multiclass encryption schemes feature level security known plaintext attacks , therefore increasing negligible cost encryption method resource limited sensing applications
comparative design scaling control inertial paper comparative framework design inertial planar aerial define inertial template , model behavior , leverage linear dynamics reveal design constraints linking task body designs capable inertial designs lead morphology generally complex , advance notion , whereby choice physical design appropriate control policy yields system whose closed loop dynamics sufficiently captured template permit designs take place far simpler parameter space approach effective accurate diverse design spaces existing platforms , enabling performance comparison shared task space analyze examples literature find advantages body type , conclude provide highest potential performance reasonable designs thus motivated , build physical example tail robot present empirical evidence efficacy
simplified weighted sum function average sensitivity paper simplify definition weighted sum boolean function used compute use show new function essentially properties previous one particular , bound average sensitivity weighted sum boolean function remains simplification
infrared visible image fusion using latent low rank representation infrared visible image fusion important problem field image fusion applied widely many fields better preserve useful information source images , paper , propose novel image fusion method based latent low rank representation \( \) simple effective first time introduced image fusion firstly , source images decomposed low rank parts \( global structure \) saliency parts \( local structure \) , low rank parts fused weighted average strategy , saliency parts simply fused sum strategy finally , fused image obtained combining fused low rank part fused saliency part compared fusion methods experimentally , proposed method better fusion performance state art fusion methods subjective objective evaluation code fusion method available https url
indexed labels loop iteration dependent costs present extension labelling approach , technique resource consumption information source code approach , core compiler large fragment c assembly project , differences arise cost portion code , whether due code transformation loop advanced architecture features \( e g cache \) propose address formally indexing cost labels iterations containing occur indexes transformed compilation , back source code produce dependent costs r n proposed changes implemented 's untrusted prototype compiler large fragment c assembly
single anchor localization orientation performance limits using massive arrays mimo vs beamforming next generation cellular networks experience combination , millimeter wave \( mm wave \) communications massive antenna arrays thanks beamforming capability well high angular resolution provided massive arrays , one single access point \( ap \) acting anchor node could used localization estimation , thus avoiding sized dedicated context , paper aims investigating localization orientation performance limits employing massive arrays ap mobile side thus , first asymptotically demonstrate rao bound \( \) massive array regime , presence multipath , propose comparison mimo beamforming terms array structure , time synchronization error multipath components among different array configurations , consider also random weighting trade high diversity gain mimo high guaranteed arrays evaluating different array configurations , results show interplay diversity beamforming gain well benefits achievable varying number array elements terms localization accuracy
weighted consensus problem , consensus problem consists set trees classify set species single tree several definitions consensus exist literature paper focus weighted consensus problem , problem unknown complexity status far prove weighted consensus problem np hard give 1 2 factor approximation problem process , propose procedure previously known randomized 1 3 factor approximation also investigate fixed parameter tractability problem
straight estimator wasserstein gradient flow straight \( st \) estimator widely used technique back gradients discrete random variables however , effective method theoretical justification paper , show st interpreted simulation wasserstein gradient flow \( \) based understanding , theoretical foundation established justify convergence properties st , another estimator variant proposed , exhibits superior performance distributions infinite support , e g , poisson distributions empirically , show st proposed estimator , applied different types discrete structures \( including bernoulli poisson latent variables \) , exhibit comparable even better performances relative state art methods results widespread adoption st estimator represent helpful step towards exploring alternative gradient discrete variables
boundary first conformal maps surface plane without angles maps become fundamental building block problems geometry processing , numerical simulation , computational design yet existing methods provide little direct control shape domain , else demand expensive nonlinear optimization boundary first \( \) linear method conformal parameterization faster traditional linear methods , yet provides control quality comparable sophisticated nonlinear schemes key insight boundary data many conformal mapping problems efficiently constructed via formula together pair operators boundary known , map easily extended rest domain since computation demands single factorization real matrix , cost 50 less previously published technique boundary controlled conformal result , opens real time editing fast optimization high resolution maps , direct control boundary length angle show method used construct maps sharp corners , singularities , minimal area distortion , unit disk also demonstrate first time surface directly onto given target shape
large scale convex optimization dense wireless cooperative networks convex optimization powerful tool resource allocation signal processing wireless networks network density expected drastically increase order accommodate exponentially growing mobile data traffic , performance optimization problems new era characterized high dimension large number constraints , poses significant design computational challenges paper , present novel two stage approach solve large scale convex optimization problems dense wireless cooperative networks , effectively detect modeling flexibility proposed approach , original large scale convex problem transformed standard programming form first stage via matrix , needs copy problem parameters channel state information \( csi \) quality service \( qos \) requirements structure standard form capability yielding certificates enabling parallel computing achieved solving homogeneous self dual embedding primal dual pair standard form solving stage , operator splitting method , namely , alternating direction method multipliers \( admm \) , adopted solve large scale homogeneous self dual embedding compared second order methods , admm solve large scale problems parallel modest accuracy within reasonable amount time simulation results demonstrate speedup , scalability , reliability proposed framework compared state art modeling frameworks solvers
rapidly mixing markov chains comparison techniques survey survey existing techniques bound mixing time markov chains mixing time related geometric parameter called conductance measure edge expansion bounds conductance typically obtained technique called canonical paths idea find set paths , one every source destination pair , edge heavily congested however , canonical paths approach cannot always show rapid mixing rapidly mixing chain allow flow pair states spread along multiple paths prove large class markov chains canonical paths capture rapid mixing allowing multiple paths route flow still help great deal proofs , illustrated result \( \) rapid mixing markov chain sampling 0 1 knapsack solutions r n different approach prove rapid mixing coupling path coupling variant discovered \( \) often reduces complexity designing good present several applications path coupling proofs rapid mixing lead much better bounds mixing time known using conductance , moreover coupling based proofs typically simpler question whether coupling made work whenever chain rapidly mixing question negative \( \) , showed coupling strategy prove rapid mixing chain sampling perfect near perfect matchings
knowledge consistent complex event processing real time persistent streams emerging applications internet things \( iot \) systems \( \) present novel challenges big data platforms performing online analytics ubiquitous sensors iot deployments able generate data streams high velocity , include information variety domains , large disk complex event processing \( cep \) recognized important real time computing paradigm analyzing continuous data streams however , existing work cep largely limited relational query processing , two gaps query specification execution \( 1 \) relational query model higher level knowledge semantics , \( 2 \) query evaluation across temporal spaces span past , present future events allow accessible analytics data streams properties different disciplines , help span velocity \( real time \) volume \( persistent \) dimensions article , introduce knowledge cep \( cep \) framework provides domain aware knowledge query constructs along temporal operators allow end end queries span across real time persistent streams translate query model efficient query execution online offline data streams , proposing several optimizations mitigate overheads introduced evaluating semantic predicates high volume data streams particular , also address temporal consistency issues arise fault recovery query plans span boundary real time persistent streams proposed model execution approaches implemented prototype semantic cep engine , validate query model using domain aware cep queries real world smart power grid application , experimentally analyze benefits optimizations executing queries , using event streams iot deployment results show able processing throughput 3 , 000 events , 30 improvement baseline sufficient support smart , consistent processing within 20 stream long semantic cep model introduced query across real time persistent streams models capability illustrated using case studies smart grid approaches translate model scalable execution discussed evaluated
simple machine learning method commonsense reasoning short le 2018 short le \( 2018 \) \( simple method commonsense reasoning \) three serious cited paper discusses data driven approaches cannot considered serious models commonsense reasoning needed natural language understanding general , reference resolution , particular
optimal feedback rate sharing strategy zero forcing mimo broadcast channels paper , consider multiple input multiple output broadcast channel limited feedback users share feedback rates firstly , find optimal feedback rate sharing strategy using zero forcing transmission scheme transmitter random vector quantization user mathematically prove equal sharing sum feedback size among users optimal strategy low signal noise ratio \( snr \) region , allocating whole feedback size single user optimal strategy high snr region snr region , propose simple numerical method find optimal feedback rate sharing strategy based analysis show equal allocation sum feedback rate partial number users optimal strategy also shown proposed simple numerical method applicable finding optimal feedback rate sharing strategy different path losses users taken account proposed feedback rate sharing scheme extended system stream control still useful systems techniques regularized zero forcing cap
fast calculation correlations recognition systems computationally efficient classification system architecture proposed utilizes fast tensor vector multiplication algorithm apply linear operators upon input signals approach applicable wide variety recognition system architectures ranging single stage matched filter bank classifiers complex neural networks number hidden layers
policy crowdsourcing state research crowdsourcing policy making \? article answer question collecting , , extensive body research investigating policy crowdsourcing , within new framework built fundamental field first define universal characteristics three general crowdsourcing techniques \( virtual labor markets , tournament crowdsourcing , open collaboration \) , examine relative trade offs modality compare three types crowdsourcing different stages policy cycle , order literature spanning domains finally discuss research trends crowdsourcing public policy , highlight research gaps literature r n keywords crowdsourcing , policy cycle , crowdsourcing trade offs , policy processes , policy stages , virtual labor markets , tournament crowdsourcing , open collaboration
quality metric language dsl linked data quality assessment growing number linked open datasets number amongst data consumers regard quality quality assessment requires significant effort consideration , including definition data quality metrics process assess datasets based definitions quality assessment framework linked data allows domain specific metrics plugged offers , abstractions expressive power , focusing representation quality metrics provides expressive power defining sophisticated quality metrics integration enables efficient processing execution thus comprehensive assessment extremely large datasets streaming way also describe novel ontology enables reuse , sharing querying definitions finally , evaluate proposed dsl cognitive dimensions framework
approximating unweighted tree augmentation via lift project part tap part , study special case unweighted tree augmentation problem \( tap \) via \( sum squares \) system special case , called stems particular type configuration tap , prove ratio sdp relaxation \( lp relaxation \) leq frac 3 2 epsilon , epsilon 0 small constant obtain result designing polynomial time algorithm tap achieves approximation guarantee \( epsilon \) relative sdp relaxation algorithm combinatorial solve sdp relaxation , analysis relies sdp relaxation r n generalize combinatorial analysis integral solutions previous literature fractional solutions identifying properties fractional solutions system via decomposition result , \( 2011 \) r n also , present example tap approximation guarantee tight algorithm r n part ii paper , extend methods part prove results relative sdp relaxation tap
hybrid blind robust image watermarking technique based transform paper , robust blind image watermarking method proposed protection digital images hybrid method relies combining two well known transforms discrete fourier transform \( \) discrete transform \( \) motivation behind combination enhance robustness requirement achieved using coefficients robustness improvement applying coefficients magnitude watermark embedded modifying coefficients band using secret key security proposed method enhanced applying transform \( \) watermark embedding experiments conducted natural images results show , compared state art methods , proposed method robust wide range attacks preserving high
single camera 3d pointer input device present new algorithm single camera 3d reconstruction , 3d input human computer interfaces , based precise tracking object , , pattern colored system , user provides one labelled image pointer , measurements colored , camera 's projection matrix systems much higher cost complexity , requiring combinations multiple cameras , , pointers sensors instead relying information multiple devices , examine single view closely , integrating geometric appearance constraints robustly track pointer presence occlusion objects probing objects known geometry pointer , demonstrate acceptable accuracy 3d localization
tasks lightweight task offloading exploiting times parallel adaptive mesh refinement balancing dynamically adaptive mesh refinement \( amr \) codes inherently difficult , since codes balance computational memory meshes change time , modern start exhibit performance propose novel lightweight scheme x traditional balancing reactive diffusion approach uses online measurements time tasks ranks tasks deployed ranks otherwise would , processed high priority , made available ranks approach time meaningful work non blocking , asynchronous distributed without global data view tests simulation code running explicit high order dg scheme \( developed engine , http url \) method 's potential found speed 2 3 ill balanced scenarios without logical modifications code base
solving influence diagrams using branch bound search branch bound approach solving diagrams previously proposed literature , appears never implemented evaluated due difficulties computing effective bounds branch bound search paper , describe efficiently compute effective bounds , develop practical tion depth first branch bound search influence diagram evaluation outperforms existing methods solving influence diagrams multiple stages
domain aware siamese network visual object tracking visual object tracking fundamental task field computer vision recently , siamese achieved state art performance recent benchmarks however , siamese fully utilize semantic information pre trained networks trained image classification task furthermore , pre trained siamese architecture category label leads unnecessary overfitting paper , propose learn domain aware , fully utilizing semantic information producing class agnostic using ridge regression network moreover , reduce sparsity problem , solve ridge regression problem differentiable weighted dynamic loss function , dubbed , improves feature learning training phase generalization capability domains extensive experiments performed five tracking benchmarks including validation set well , , , , testing set achieves state art performance benchmarks running fps
flow faster efficient decision algorithms probabilistic simulations strong weak simulation relations proposed markov chains , n strong simulation strong probabilistic simulation relations n proposed probabilistic automata however , decision algorithms strong n weak simulation markov chains , strong simulation n probabilistic automata efficient , makes yet unclear whether n used effectively non probabilistic counterparts n paper presents drastically improved algorithms decide whether n \( discrete continuous time \) markov chain strongly weakly simulates n another , whether probabilistic automaton strongly simulates another n key innovation use parametric maximum flow techniques n computations also present novel algorithm deciding strong n probabilistic simulation probabilistic automata , n polynomial complexity via reduction lp problem extending n algorithms probabilistic automata continuous time counterpart , n retain complexity strong strong probabilistic n simulations
admm based decoder binary linear codes aided deep learning inspired recent advances deep learning \( dl \) , work presents deep neural network aided decoding algorithm binary linear codes based concept deep , design decoding network alternating direction method multipliers \( admm \) decoder addition , propose two improved versions proposed network first one transforms penalty parameter set iteration dependent ones , second one adopts specially designed penalty function , based piecewise linear function numerical results show resulting dl aided decoders outperform original admm decoder various low density parity check \( ldpc \) codes similar computational complexity
sequential vae lstm anomaly detection time series order support stable web based applications services , anomalies performance status detected timely moreover , performance trend across time series predicted paper , propose \( sequential vae lstm \) , neural network model based vae \( variational auto encoder \) lstm \( long short term memory \) work first attempt integrate unsupervised anomaly detection trend prediction one framework moreover , model performs considerably better detection prediction vae lstm work alone unsupervised anomaly detection , achieves competitive experimental results compared state art methods public datasets trend prediction , outperforms several classic time series prediction models experiments public dataset
sparse plus low rank autoregressive identification neuroimaging time series paper considers problem identifying multivariate autoregressive \( ar \) sparse plus low rank graphical models based corresponding problem formulation recently presented , use alternating direction method multipliers \( admm \) efficiently solve scale sizes encountered neuroimaging applications apply decomposition synthetic real neuroimaging datasets specific focus information encoded low rank structure model particular , illustrate information captures spatio temporal structure original data , generalizing classical component analysis approaches
occlusion edge detection rgb frames using deep convolutional networks edges images range point view important mobile robot tasks although extracted range extracting images videos would extremely trained deep convolutional neural network \( cnn \) identify occlusion images videos rgb rgb inputs use cnn features automatically occlusion edges appearance edges quantitative occlusion results , qualitative results provided demonstrate trade high resolution analysis frame level computation time real time robotics applications
cognitive mac protocols general primary network models consider design cognitive medium access control \( mac \) protocols enabling secondary \( \) transmitter receiver pair communicate set primary \( \) channels specifically , propose cognitive mac protocols optimized slotted un slotted primary networks slotted structure , objective maximize secondary throughput maintaining synchronization secondary pair interference primary network differentiate two sensing scenarios first , secondary transmitter capable sensing primary channels , whereas senses subset primary channels second scenario cases , propose blind mac protocols efficiently learn statistics primary traffic line asymptotically achieve throughput obtained prior knowledge primary traffic statistics available un slotted structure , objective maximize secondary throughput satisfying interference constraint primary network sensing dependent optimized primary channel yielding mac protocol outperforms previously proposed techniques rely single sensing period optimization
stability stochastic approximations controlled markov noise temporal difference learning interested understanding stability \( almost \) stochastic approximation algorithms \( sas \) driven process analyzing class algorithms important , since many reinforcement learning \( rl \) algorithms sas driven process paper , present easily sufficient conditions stability convergence sas driven process many rl applications involve continuous state spaces analysis readily ensures stability continuous state applications , traditional analyses compared literature , analysis presents two fold generalization \( \) markov process may evolve continuous state space \( b \) process need ergodic given stationary policy temporal difference learning \( td \) important policy evaluation method reinforcement learning theory developed , used analyze generalized td \( 0 \) , important variant td theory also used analyze td formulation supervised learning forecasting problems
gaussian multiple access via compute forward lattice codes used compute forward paradigm suggest alternative strategy standard gaussian multiple access channel \( mac \) receiver decodes integer linear combinations messages recover messages paper , multiple access technique called compute forward multiple access \( \) proposed analyzed two user mac , shown without time sharing , entire capacity region using single user decoder soon signal noise ratios 1 sqrt 2 partial analysis given two users finally , strategy extended called dirty mac , two signals known non causally two transmitters distributed fashion scheme extends previously known results gives new achievable rate regions
certifiably robust interpretation deep learning deep learning interpretation essential explain reasoning behind model predictions understanding robustness interpretation methods important especially sensitive domains medical applications since interpretation results often used downstream tasks although gradient based saliency maps popular methods deep learning interpretation , recent works show vulnerable adversarial attacks paper , address problem provide defense method deep learning interpretation show version popular method , computes average saliency maps random perturbations input , certifiably robust adversarial perturbations obtain result extending recent bounds certifiably robust smooth classifiers interpretation setting experiments imagenet samples validate theory
customized facial constant positive air pressure masks sleep characterized one common involves mask delivers continuous air flow maintain steady air pressure masks designed average facial model often difficult adjust due poor fit actual patient characterized gaps mask face , mask leads air leakage suggest fully automatic approach designing personalized mask interface using facial depth interfaces generated proposed method accurately fit geometry face , easy proposed method utilizes depth sensors 3d technologies efficiently design customized masks patients sleep
options end end continuous action tasks present new results learning temporally extended actions , using options framework \( al , \) achieve goal work option architecture \( al 2017 \) using cost train proximal policy optimization \( al 2017 \) instead vanilla policy gradient results mujoco domains , lead interesting questions given option , issue directly connected use sets
learning end end multimodal sensor policies autonomous navigation sensor fusion indispensable improve accuracy robustness autonomous navigation setting however , space end end control , multimodal received limited attention work , propose novel stochastic regularization technique , called sensor dropout , multimodal sensor policy learning outcomes also introduce auxiliary loss policy network along standard drl loss help reduce action variations multimodal sensor policy empirical testing demonstrate proposed policy 1 \) operate minimal performance drop noisy environments , 2 \) remain functional even face sensor subset failure finally , visualization gradients , show learned policies conditioned latent input distribution despite multiple sensory observations spaces true sensor fusion efficacy multimodal policy shown simulations , popular open source car game video seen https url
communication efficient edge ai algorithms systems artificial intelligence \( ai \) achieved remarkable wide range fields , ranging speech processing , image classification drug discovery driven growth data , advances machine learning \( especially deep learning \) , easy access powerful computing resources particularly , wide scale deployment edge devices \( e g , iot devices \) generates unprecedented scale data , provides opportunity derive accurate models develop various intelligent applications network edge however , enormous data cannot sent end devices cloud processing , due varying channel quality , traffic congestion privacy concerns pushing inference training processes ai models edge nodes , edge ai emerged promising alternative ai edge requires close cooperation among edge devices , smart phones smart vehicles , edge servers wireless access points base stations , however result heavy communication overheads paper , present comprehensive survey recent developments various techniques overcoming communication challenges specifically , first identify key communication challenges edge ai systems introduce communication efficient techniques , algorithmic system perspectives training inference tasks network edge potential future research directions also
tree structured neural machine aware sentence generation different sequential data , sentences natural language structured linguistic grammars previous generative conversational models chain structured decoder ignore structure human language might generate responses less satisfactory relevance study , aim incorporate results linguistic analysis process sentence generation high quality conversation generation specifically , use dependency transform response sentence dependency tree construct training corpus sentence tree pairs tree structured decoder developed learn mapping sentence tree , different types hidden states used local dependencies internal tree node training acceleration , propose tree method , transforms trees equivalent trees , proposed tree structured search method , model able generate responses form dependency trees , finally sequences system output experimental results demonstrate proposed framework outperforms baseline methods 11 15 increase ratio
divide partitioning online social networks online social networks \( \) terms scale scope last years unprecedented growth networks present challenges terms system design one way cope partitioning large networks assigning partitions different machines however , social networks possess unique properties make partitioning problem non trivial main contribution paper understand different properties social networks properties guide choice partitioning algorithm using large scale measurements representing real , first characterize different properties social networks , evaluate qualitatively different partitioning methods cover design space different trade offs involved understand light properties social networks show choice partitioning scheme help improve performance
hybrid network coding describe novel extension subspace codes networks , suitable use network viewed communication system introduces dimension symbol errors show symbol occur significantly large number different basis vectors transmitted network min cut networks much smaller length transmitted codewords , new family codes outperforms subspace code counterparts r n proposed coding scheme , termed hybrid network coding , derive two upper bounds size codes bounds represent variation sphere packing bound show simple concatenated scheme represents combination subspace codes solomon codes asymptotically optimal respect bound finally , describe two efficient decoding algorithms concatenated subspace codes certain cases smaller complexity subspace decoders
controlled natural language processing latest addition human species artificial intelligence \( ai \) thus far , ai made significant progress low low risk scenarios playing go currently transition toward medium scenarios visual thesis , argue need incorporate controlled de entanglement first class object succeed transition present mathematical analysis information theory show employing leads controlled de entanglement relevant factors variation various levels based , highlight results initial experiments efficacy proposed framework conclude experiments show applicability framework scalability , flexibility
social graphs via uncertainty semantics rather social graphs generalizing super nodes edges adding removing nodes edges satisfy given privacy parameters , recent methods exploit semantics uncertain graphs achieve privacy protection entities relationship techniques deterministic graph uncertain form paper , propose generalized model based uncertain matrices keep expected node degrees equal graph analyze two recently proposed schemes show fitting model also point disadvantages method present several techniques gap finally , support fair comparisons , develop new tradeoff quantifying framework leveraging concept location privacy research experiments large social graphs demonstrate effectiveness schemes
weakly supervised completion moment detection using temporal attention monitoring action towards completion offers fine grained insight actor 's behaviour work , target detecting completion moment actions , moment action 's goal successfully accomplished potential applications surveillance human robot interactions previous effort required human annotations completion moment training \( e full supervision \) work , present approach moment detection weak video level labels given complete incomplete sequences , action , learn temporal attention , along completion prediction frames sequence also demonstrate approach used completion moment supervision available evaluate compare approach actions three datasets , namely , ucf101 ac , show temporal attention improves detection weakly supervised fully supervised settings
bandwidth management live migration wireless fog computing 5g networks live virtual machine migration aims enabling dynamic balanced use networking computing physical resources data centers , lead reduced energy consumption , analytically characterize , prototype software test optimal bandwidth live migration wireless channel paper present optimal complexity bandwidth \( \) qos live migration wireless channel smartphone access point goal minimization migration induced communication energy service level agreement \( \) induced hard total migration time , overall available bandwidth
multipath network object detection recent coco object detection dataset presents several new challenges object detection particular , contains objects broad range scales , less images , requires precise localization address challenges , test three modifications standard fast r cnn object detector \( 1 \) connections give detector access features multiple network layers , \( 2 \) structure exploit object context multiple object , \( 3 \) integral loss function corresponding network improve localization result modifications information flow along multiple paths network , including features multiple network layers multiple object views refer modified classifier multipath network multipath network object proposals , well suited localization small objects , adapt pipeline predict segmentation masks addition bounding boxes combined system improves results baseline fast r cnn detector selective search overall 4x small objects placed second coco 2015 detection segmentation challenges
network load analysis mapreduce applications paper , study dependency configuration parameters network load fixed size mapreduce applications phase propose analytical method model dependency approach consists three key phases profiling , modeling , prediction first stage , application run several times different sets mapreduce configuration parameters \( number number \) profile network load application phase given cluster , relation parameters network load modeled multivariate linear regression evaluation , three applications \( , parsing , \) utilized evaluate technique 4 node mapreduce private cluster
decomposition forecast error prediction markets analyze sources error prediction market order bound difference security 's price ground truth estimates consider cost function based prediction markets automated market maker security prices according history trade decompose forecasting error three components sampling error , arising possess noisy estimates ground truth market maker bias , resulting use particular market maker \( e , cost function \) facilitate trade convergence error , arising , point time , market prices may still goal make explicit tradeoffs error components , influenced design decisions functional form cost function amount market consider specific model exponential utility exponential family representing noisy estimates ground truth setting , sampling error number grows , tradeoff two components provide upper lower bounds market maker bias convergence error , demonstrate via numerical simulations bounds tight results yield new insights question set market 's parameter forecasting benefits enforcing coherent prices across
pose estimation forecasting real time control propose use proportional \( \) control based policy learned via reinforcement learning \( rl \) estimate forecast 3d human pose videos method learns directly videos motion capture data consisting various complex human motions \( e g , , , , motion transitions \) propose video conditioned recurrent control technique forecast physically valid stable future motions arbitrary length also introduce value function based fail safe mechanism enables method run single pass algorithm video data experiments controlled wild data show approach outperforms previous art quantitative metrics visual quality motions , also robust enough transfer directly real world scenarios additionally , time analysis shows combined use pose estimation forecasting run 30 fps , making suitable real time applications
network wide distributed carrier frequency estimation compensation paper , propose fully distributed algorithm frequency estimation decentralized systems proposed algorithm , node estimates frequency local computations limited exchange information direct neighbors algorithm require centralized information processing knowledge global network topology shown analytically proposed algorithm always converges optimal estimates regardless network topology simulation results demonstrate fast convergence algorithm show estimation mean squared error node centralized e r rao bound within iterations message exchange therefore , proposed method low overhead scalable network size
stability analysis continuous time systems random switching signal technical note stability analysis continuous time systems random switching signal switching signal characteristics time consists fixed part random part stochastic stability systems studied using lyapunov approach necessary sufficient condition established terms linear matrix inequalities effect random switching signal system stability illustrated numerical example results intuition
statistics ratio non constrained arbitrary alpha mu random variables general framework applications paper , derive closed form exact expressions main statistics ratio squared alpha mu random variables , interest many scenarios future wireless networks generalized distributions suitable fit field data importantly , different previous proposals , expressions general sense valid non constrained arbitrary values parameters alpha mu distribution thus , probability density function , cumulative distribution function , moment generating function , higher order moments given terms \( \) h function provide efficient code \( ii \) easily computable series expressions used performance analysis number wireless communication systems , including either interference limited scenarios , spectrum sharing , full duplex physical layer security networks , present application proposed framework moreover , closed form expressions classical distributions , derived special cases alpha mu distribution , provided validity proposed expressions confirmed via monte carlo simulations
predicting next season designs high fashion fashion large fast changing industry fashion trends beneficial fashion designers , consumers , however , fashion trends often perceived due enormous amount factors involved paper , propose fashion trend prediction framework design neural network models leverage structured fashion show data , learn fashion collection embedding , train rnn lstm models capture style evolution proposed framework consists \( 1 \) embedding learning model uses fashion images learn every season 's collection embedding , \( 2 \) next season fashion design prediction model leverage concept style trend predict next season design given designers experiments collected dataset across years fashion shows , framework achieve best performance 78 42 auc average 95 individual predicting next season 's design
sliding bloom filters bloom filter method reducing space \( memory \) required representing set allowing small error probability paper consider emph sliding bloom filter data structure , given stream elements , supports membership queries set last n elements \( sliding window \) , allowing small error probability formally define data structure relevant parameters analyze time memory requirements needed achieve give low space construction runs \( 1 \) time per update high probability \( , sequences high probability operations take constant time \) provide almost matching lower bound space shows construction best possible space consumption additive lower order term
differentially private neighborhood based recommender systems privacy issues recommender systems become hot topic systems every corner life contrast fact many secure multi party computation protocols proposed prevent information leakage process recommendation computation , little done information leakage recommendation results paper , apply differential privacy concept neighborhood based recommendation methods \( \) probabilistic framework first present solution , directly noise training process , differential find maximum parameters similarity connect differential privacy exploiting recent observation sampling scaled posterior distribution bayesian model results provably differentially private systems experiments show solutions allow promising accuracy modest privacy budget , second solution yields better accuracy sampling asymptotically converges also compare solutions recent differentially private matrix factorization \( mf \) recommender systems , show solutions achieve better accuracy privacy budget small interesting result mf systems often offer better accuracy differential privacy applied
incorporating evaluation type theory syntax semantics rm small ctt rm qe version 's type theory includes evaluation operators similar programming language evaluation possible reason rm small ctt rm qe interplay syntax semantics expressions , result , formalize syntax based mathematical algorithms present syntax semantics rm small ctt rm qe give several examples illustrate usefulness evaluation rm small ctt rm qe give proof system rm small ctt rm qe , sketch proof system could look like
feedback reduction mimo broadcast channel heterogeneous fading paper considers feedback load reduction multiuser multiple input multiple output \( mimo \) broadcast channel users' channel distributions homogeneous cluster based feedback scheme proposed range possible signal noise ratio \( snr \) users divided several clusters according order statistics users' snrs cluster corresponding threshold , users compare measured instantaneous snrs thresholds determine whether many bits use feed back instantaneous snrs user 's instantaneous snr lower certain threshold , user feed back feedback load reduction thus achieved given number clusters , sum rate loss using cluster based feedback scheme investigated minimum number clusters given maximum sum rate loss derived simulations , shown , number users large , full multiuser diversity achieved proposed feedback scheme , efficient conventional schemes
stochastic greedy sparse reconstruction support selection sparse reconstruction sparse support selection , e , tasks inferring arbitrary dimensional sparse vector mathbf x k nonzero entries n measurements linear combinations components , often encountered machine learning , computer vision , signal processing existing greedy based algorithms achieve optimal n mathcal \( k log frac k \) sampling complexity computational complexity linear size data cardinality constraint k however , mathcal \( \) computational complexity still large scale datasets paper , present first sparse support selection algorithm arbitrary sparse vectors achieves exact identification optimal subset n mathcal \( k log frac k \) measurements tilde mathcal \( \) computational complexity proposed scheme utilizes idea randomly restricting search space greedy method manner reduce computational cost maintaining order sampling complexity existing greedy schemes simulation results including application algorithm task column subset selection demonstrate efficacy proposed algorithm
regional towards learning transferable universal adversarial perturbations defenses paper focuses learning transferable adversarial examples specifically defense models \( models defense adversarial attacks \) particular , show simple universal perturbation series state art defenses r n adversarial examples generated existing attacks generally hard transfer defense models observe property regional adversarial perturbations suggest defenses less robust homogeneous perturbations therefore , propose effective paradigm customized gradient transformer module transform existing perturbations homogeneous ones without explicitly forcing perturbations universal , observe well trained gradient transformer module tends output input independent gradients \( hence universal \) fitting phenomenon experiments demonstrate work significantly outperforms prior art attacking algorithms \( either image dependent universal ones \) average improvement 14 0 attacking 9 defenses black box setting addition cross model , also verify homogeneous perturbations well transfer across different vision tasks \( attacking semantic segmentation task testing object detection task \)
note selling optimally two uniformly distributed goods provide new , much simplified straightforward proof result 2011 regarding revenue maximizing mechanism selling two goods uniformly valuations intervals c , c 1 , additive buyer done explicitly defining optimal dual solutions relaxed version problem , convexity requirement bidder 's utility optimality comes directly structure , use exact c 0 c geq 0 turns corresponding optimal primal solution feasible selling mechanism , thus initial relaxation comes without loss , revenue follows however , 0 c 0 's case , providing first clear example convexity provably come free , even two item setting
customized adversarial training improved robustness adversarial training become one effective methods improving robustness neural networks however , often suffers poor generalization clean perturbed data paper , propose new algorithm , named customized adversarial training \( \) , adaptively perturbation level corresponding label training sample adversarial training show proposed algorithm achieves better clean robust accuracy previous adversarial training methods extensive experiments
algorithmic aspects optimal channel coding central question information theory determine maximum success probability achieved sending fixed number messages noisy channel first studied work shannon , established simple expression characterizing quantity limit multiple independent uses channel , consider general setting one use channel observe maximum success probability expressed maximum value submodular function using connection , establish following results 1 \) simple greedy polynomial time algorithm computes code achieving \( 1 e 1 \) approximation maximum success probability factor \( 1 e 1 \) improved arbitrarily close 1 cost slightly reducing number messages sent moreover , np hard obtain approximation ratio strictly better \( 1 e 1 \) problem computing maximum success probability 2 \) shared quantum entanglement sender receiver increase success probability factor \( 1 \( 1 e 1 \) \) addition , factor tight one allows arbitrary non signaling box sender receiver 3 \) give tight bounds one shot performance meta converse poor
active code replacement data analytics platform \( board board distributed data analytics \) platform executing concurrent data analytics tasks targets reference vehicles automotive industry particular focus rapid underlying message passing infrastructure implemented external python applications perform data analytics tasks work performed clients \( board \) central cloud server performs tasks \( board \) automatically deployed , parts system , potentially address issue , added ability execute user defined python modules clients well server modules without part system even iterations ongoing assignment use cases iterative b testing machine learning algorithms modifying experimental algorithms fly
fly adaptation regression forests online camera relocalisation camera relocalisation important problem computer vision , applications simultaneous localisation mapping , virtual augmented reality navigation common techniques either match current image known poses coming , establish 2d 3d correspondences current image points scene order estimate camera pose recently , regression forests become popular alternative establish correspondences achieve accurate results , must trained offline target scene , preventing relocalisation new environments paper , show limitation adapting pre trained forest new scene fly adapted forests achieve relocalisation performance par offline forests , approach runs , making desirable real time systems require online relocalisation
compressive phase retrieval via generalized approximate message passing phase retrieval , goal recover signal x c n n n linear measurements c n n recent theory established intensity measurements necessary sufficient recover generic x , great interest reducing number measurements exploitation sparse x , known compressive phase retrieval work , detail novel , probabilistic approach compressive phase retrieval based generalized approximate message passing \( \) algorithm present numerical study proposed algorithm , demonstrating excellent phase transition behavior , robustness noise , runtime experiments suggest approximately 2 n 2 n \( n k \) intensity measurements recover k sparse bernoulli gaussian signals gaussian entries k n meanwhile , sparse pixel image randomly fourier intensity measurements 30 db measurement snr , achieved output snr less 28 db 100 random trials , median runtime 7 3 seconds compared recently proposed , sparse , algorithms , experiments suggest superior phase transition orders magnitude faster sparsity problem dimensions increase
dual view representation learning adapting stance classifiers new domains address issue limited number annotations stance classification new domain , adapting domain classifiers domain adaptation existing approaches often align different domains single , global feature space \( view \) , may fail fully capture languages used expressing , leading reduced stance data paper , identify two major types stance expressions distinct , propose tailored dual view adaptation network \( \) adapt expressions across domains proposed model first learns separate view domain transfer expression channel selects best adapted parts views optimal transfer find learned view features easily aligned stance discriminative either views , leading transferable overall features combining views results extensive experiments show method enhance state art single view methods matching stance data across different domains , consistently improves methods various adaptation tasks
rrt optimal motion planning systems linear differential constraints present rrt , incremental sampling based approach asymptotically optimal motion planning robots linear differential constraints approach extends rrt , introduced robots \( et al 2011 \) , using fixed final state free final time controller exactly optimally pair states , cost function expressed trade duration trajectory control effort approach generalizes earlier work extending rrt systems , guarantees asymptotic optimality system controllable linear dynamics , state spaces dimension approach applied non linear dynamics well using first order approximations addition , show rich subclass systems dynamics matrix , closed form solutions optimal trajectories derived , computational overhead algorithm compared traditional rrt minimum demonstrate potential approach computing asymptotically optimal trajectories three challenging motion planning scenarios \( \) planar robot 4 state space double dynamics , \( ii \) aerial vehicle 10 state space dynamics , \( iii \) car like robot 5 state space non linear dynamics
tag clusters information retrieval interfaces paper presents design next generation information retrieval system based tag co subsequent clustering help users getting access digital data information visualization form tag clusters current problems like absence semantics tags difficulty adding additional search arguments solved evaluation , based upon systems quality indicators , found tag clusters perceived useful tag clouds , much , use
union random sums network vulnerability analysis let mathcal c c 1 , ldots , c n set n pairwise disjoint convex sets constant description complexity , let pi probability density function \( short \) non negative , let k sum c disk radius r , r random non negative number drawn independently distribution determined pi show expected complexity union k 1 , ldots , k n \( n 1 varepsilon \) varepsilon 0 constant depends varepsilon description complexity sets mathcal c , pi c convex vertices , show expected complexity union \( 2n log n \) r n bounds hold stronger model given arbitrary multi set r r 1 , ldots , r n expansion , non negative real number members mathcal c random permutation , equally likely chosen expectations respect r n also present application results problem arises analyzing vulnerability network physical attack
flocking generalized factor analysis propose new modeling paradigm large dimensional aggregates stochastic systems generalized factor analysis \( \) models models describe data sum flocking plus component flocking component describes sort collective motion admits much simpler mathematical description whole ensemble component describes weakly correlated noise first discuss static representations characterize rigorous way properties two components wide sense stationary sequences character existence models completely extraction flocking component random field discussed simple class separable random fields
self orthogonality self matrix product codes commutative let r commutative ring identity paper studies problem self orthogonality self matrix product codes \( \) r methods well special matrices introduced construction characterization codes \( special case \) also given concrete examples presented throughout paper
stronger baseline multilingual word embeddings , \( 2017 \) id \( sentence id \) method applies tuples containing sentence id word sentence shown strong baseline learning multilingual embeddings inspired recent work concept based embedding learning propose sc id , extension id given sentence aligned corpus , use sampling extract concepts processed manner perform experiments parallel corpus across 1000 languages show sc id yields 6 performance increase word translation task ad , provide evidence sc id easily widely applicable reporting competitive results across 8 tasks based corpus
segmenting objects locations present new , simple approach instance segmentation images compared many dense prediction tasks , e g , semantic segmentation , arbitrary number instances made instance segmentation much challenging order predict mask instance , mainstream approaches either follow strategy used mask r cnn , predict category masks first use clustering techniques group pixels individual instances view task instance segmentation completely new perspective introducing notion instance categories , categories pixel within instance according instance 's location size , thus instance mask segmentation classification solvable problem instance segmentation decomposed two classification tasks demonstrate much simpler flexible instance segmentation framework strong performance , achieving par accuracy mask r cnn outperforming recent instance accuracy hope simple strong framework serve baseline many instance level recognition tasks besides instance segmentation
formal verification higher order probabilistic programs reasoning approximation convergence bayesian inference optimization probabilistic programming provides convenient writing succinct rigorous descriptions probabilistic models inference tasks several probabilistic programming languages , including , , derive expressiveness powerful combination continuous distributions , conditioning , higher order functions although important practical applications , features fundamental challenges program semantics verification several recent works offer promising answers challenges , primary focus semantics issues r n r n paper , take step developing suite logics , named proving properties programs written expressive probabilistic higher order language continuous sampling operations primitives conditioning distributions logics mimic reasoning style proofs using carefully selected key results probability theory logics illustrated formal verification several examples statistics , probabilistic inference , machine learning show expressiveness giving sound embeddings existing logics particular , parametric way showing semantics idea \( unary relational \) logics soundness follows interpreting programs quasi spaces \( \) , recently proposed variant spaces good structure interpreting higher order probabilistic programs
learning read focused machine reading recent efforts achieved tremendous progress machine reading biomedical literature , assembly extracted interactions large scale models protein signaling however , batch machine reading literature today 's scale \( alone indexes 1 million papers per year \) due cost processing overhead work , introduce focused reading approach guide machine reading biomedical literature towards literature read answer biomedical query efficiently possible introduce family algorithms focused reading , including intuitive , strong baseline , second approach uses reinforcement learning \( rl \) framework learns explore \( search \) exploit \( \) demonstrate rl approach capable answering queries baseline , efficient , e , reading fewer documents
investigating neural machine translation training corpus based machine translation \( mt \) systems either statistical mt \( smt \) neural mt \( nmt \) availability high quality parallel data important today ever , nmt shown many studies outperform smt , mostly large parallel corpora available cases data limited , smt still outperform nmt r n recently researchers shown back translating monolingual data used create synthetic parallel corpora , turn used combination parallel data train high quality nmt system given large collections new parallel text become available quite , become norm building state art nmt systems , especially resource poor scenarios r n however , many unknown factors regarding actual effects back data translation capabilities nmt model accordingly , work investigate using back data training corpus separate dataset well combined human generated parallel data affects performance nmt model use larger amounts back data train range nmt systems german english , resulting translation performance
deep semantic multimodal hashing network scalable multimedia retrieval hashing widely applied multimodal retrieval large scale multimedia data due efficiency computation storage particularly , deep hashing received unprecedented research attention recent years , owing perfect retrieval performance however , existing deep hashing methods learn binary hash codes preserving similarity relationship without exploiting semantic labels data points , result suboptimal binary codes work , propose novel deep semantic multimodal hashing network scalable multimodal retrieval , two sets modality specific hash functions jointly learned explicitly preserving inter modality similarities intra modality semantic labels specifically , assumption learned hash codes optimal task specific classification , two stream networks jointly trained learn hash functions embedding semantic labels hash codes different previous deep hashing methods , tied particular forms loss functions , proposed deep hashing framework flexibly integrated different types loss functions addition , bit balance property investigated generate binary codes bit 50 probability 1 1 moreover , unified deep multimodal hashing framework proposed learn compact high quality hash codes exploiting feature representation learning , inter modality similarity preserving learning , semantic label preserving learning hash functions learning bit balanced constraint simultaneously conduct extensive experiments unimodal cross modal retrieval tasks three widely used multimodal retrieval datasets experimental result demonstrates significantly outperforms state art methods
multi task learning target dependent sentiment classification detecting aggregating sentiments toward people , organizations , events expressed unstructured social media become critical text mining operations early systems detected sentiments whole passages , whereas recently , target specific sentiments greater interest paper , present , multi task target dependent sentiment classification system informed feature representation learnt related auxiliary task passage level sentiment classification auxiliary task uses gated recurrent unit \( \) states , followed auxiliary fully connected layer outputs passage level predictions main task , contribute auxiliary per token representations word embeddings main task , separate auxiliary main send states different fully connected layer , trained main task extensive experiments using two auxiliary datasets three benchmark datasets \( one new , introduced us \) main task demonstrate outperforms state art baselines using word level sensitivity analysis , present evidence prior systems make incorrect target specific predictions miss sentiments expressed words independent target
decentralized multi agent plan repair dynamic environments achieving joint objectives teams cooperative planning agents requires significant coordination communication efforts single agent system facing plan failure dynamic environment , , attempts repair failed plan general benefit terms time complexity however , multi agent settings communication complexity might much higher importance , possibly high communication overhead might even certain domains decentralized systems , coordination enforced achieve joint objectives , attempts repair failed multi agent plans lead lower communication overhead scratch r n contribution presented paper firstly , formally introduce multi agent plan repair problem formally present core hypothesis underlying work secondly , propose three algorithms multi agent plan repair reducing problem specialized instances multi agent planning problem finally , present results experimental validation core hypothesis paper
fast computation finite fields using elliptic curves propose randomized algorithm compute finite fields using elliptic curves compute two fields cardinality q n , algorithm takes left \( n log 2 q max ell \( ell n ell 1 log 2 q ell log \) right \) time , ell runs n q \( q 1 \) n ell denotes highest power ell n prior work , best known run time dependence n quadratic run time dependence n worst quadratic subquadratic n large prime factor particular , n run time linear n natural density least 3 10 approach finding map elliptic curves finite fields formulate computational problem concerning maps whose resolution would solve finite field problem run time linear n
qualitative action recognition wireless radio signals human machine systems human machine systems required deep understanding human behaviors existing research action recognition focused different actions , however , quality executing action received little attention thus far paper , study quality assessment driving behaviors present , system assess quality actions based radio signals system includes three key components , deep neural network based learning engine extract quality information changes signal strength , gradient based method detect signal boundary individual action , fusion policy improve recognition performance noisy environment using quality information , differentiate triple body status accuracy 97 , identification among 15 drivers , average accuracy 88 results show , via dedicated analysis radio signals , fine grained action characterization achieved , facilitate large variety applications , smart driving
evolution robotics systems novelty search novelty search recent artificial evolution technique challenges traditional evolutionary approaches novelty search , solutions based novelty , rather quality respect predefined objective lack predefined objective convergence caused deceptive fitness function paper , apply novelty search combined evolution neural controllers homogeneous robots empirical study conducted simulation , use common robotics task aggregation , challenging task sharing energy station results show novelty search deception , notably effective bootstrapping evolution , find solutions lower complexity fitness based evolution , find broad diversity solutions task even non deceptive , novelty search achieves solution similar obtained traditional fitness based evolution study also encompasses variants novelty search work fitness based evolution combine exploratory character novelty search character objective based evolution show variants improve performance novelty search overall , study shows novelty search promising alternative evolution controllers robotic
edge host partitioning deep neural networks feature space encoding resource constrained internet things platforms paper introduces partitioning inference task deep neural network edge host platform iot environment present dnn encoding pipeline , propose transmit output feature space intermediate layer host lossless lossy encoding feature space proposed enhance maximum input rate supported edge platform reduce energy edge platform simulation results show partitioning dnn end convolutional \( feature extraction \) layers coupled feature space encoding enables significant improvement energy efficiency throughput baseline configurations perform entire inference edge host
commutative languages composition methods commutative languages property \( slip \) naturally recognized real time space multi counter machines show languages similarly recognized , relying developing , recent results family regular \( \) languages language defined regular language alphabet includes terminal alphabet marked copy new conditions , ensuring union concatenation languages closed , presented applied commutative slip languages paper contributes knowledge family , introduces novel techniques language composition , based arithmetic act language open problems
deep cnn multi layer neighbor component embedding face hallucination current face hallucination methods , whether shallow learning based deep learning based , try learn relationship model low resolution \( lr \) high resolution \( hr \) spaces help training set mainly focus modeling image prior either model based optimization discriminative inference learning however , input lr face tiny , learned prior knowledge longer effective performance drop solve problem , paper propose general face hallucination method integrate model based optimization discriminative inference particular , exploit model based prior , deep convolutional neural networks \( cnn \) prior plugged super resolution optimization model aid image adaptive laplacian regularization additionally , develop high frequency details compensation method face image facial components performing face hallucination multi layer neighbor embedding manner experiments demonstrate proposed method achieve promising super resolution results tiny input lr faces
rnns evolving equilibrium manifold vanishing gradients recurrent neural networks \( rnns \) particularly well suited modeling long term dependencies sequential data , notoriously hard train error time either exponential rate number works attempt mitigate effect gated recurrent units , well chosen parametric constraints , connections , develop novel perspective seeks evolve hidden state equilibrium manifold ordinary differential equation \( \) propose family novel rnns , namely em recurrent neural networks \( \) overcome gradient decay explosion effect lead recurrent models evolve equilibrium manifold show equilibrium points stable , leading fast convergence fixed points furthermore , account long term dependencies , efficiently recall informative aspects data past show achieve state art accuracy many challenging data sets 3 , 1 5 model size reduction , similar prediction cost relative vanilla rnns
empirical comparison algorithms network community detection detecting clusters communities large real world graphs large social information networks problem considerable interest practice , one typically chooses objective function captures intuition network cluster set nodes better internal connectivity external connectivity , one applies approximation algorithms heuristics extract sets nodes related objective function look like good communities application interest paper , explore range network community detection methods order compare understand relative performance systematic biases clusters identify evaluate several common objective functions used formalize notion network community , examine several different classes approximation algorithms aim optimize objective functions addition , rather simply objective asking approximation best cluster size , consider size resolved version optimization problem considering community quality function size provides much lens examine community detection algorithms , since objective functions approximation algorithms often non obvious size dependent behavior
latent variable modeling diversity mutual angular regularization latent variable models \( lvms \) large family machine learning models providing principled effective way extract underlying patterns , structure knowledge observed data due growth volume complexity data , several new challenges emerged cannot effectively addressed existing lvms \( 1 \) capture long tail patterns carry crucial information popularity patterns distributed power law fashion \? \( 2 \) reduce model complexity computational cost without modeling power lvms \? \( 3 \) improve interpretability reduce redundancy discovered patterns \? addresses three challenges discussed , develop novel regularization technique lvms , controls geometry latent space learning enable learned latent components lvms diverse sense different , long tail coverage , low redundancy , better interpretability propose mutual angular regularizer \( mar \) encourage components lvms larger mutual angles mar non convex non smooth , great challenges optimization cope issue , derive smooth lower bound mar optimize lower bound instead show monotonicity lower bound closely aligned mar lower bound desirable surrogate mar using neural network \( nn \) instance , analyze mar affects generalization performance nn two popular latent variable models restricted machine distance metric learning , demonstrate mar effectively capture long tail patterns , reduce model complexity without sacrificing improve interpretability
learning fairness aware relational structures development fair machine learning models effectively bias discrimination important problem attention recent years necessity encoding complex relational dependencies among features variables predictions require development fair , yet expressive relational models work , introduce fair , fairness aware structure learning algorithm learning relational structures , incorporates fairness measures learning relational graphical model structures approach able encode wide range fairness metrics statistical parity difference , , , equal opportunity , including recently proposed relational fairness measures existing approaches employ fairness measures pre determined model structures post prediction , fair directly learns structure optimizing fairness measures hence able remove structural bias model demonstrate effectiveness learned model structures compared state art fairness models quantitatively qualitatively datasets representing three different modeling scenarios \) relational dataset , ii \) prediction dataset widely used studying discrimination , iii \) recommender systems dataset results show fair learn fair , yet interpretable expressive structures capable making accurate predictions
implementation perceptron network highly uniform passive memristive circuits progress field neural computation use hardware efficient conventional recent works shown mixed signal integrated memristive circuits , especially passive \( \) variety , may increase neuromorphic network performance dramatically , far behind digital counterparts major obstacle , however , relatively memristor technology limited functionality demonstrated date experimentally demonstrate operation one hidden layer perceptron classifier entirely mixed signal integrated hardware , two passive memristive arrays , board integrated discrete cmos components demonstrated perceptron network , whose complexity almost higher compared previously reported functional neuromorphic classifiers based passive memristive circuits , achieves classification fidelity within 3 percent obtained simulations , using training approach successful improvements technology , specifically variations v characteristics
optimal node density two dimensional sensor arrays problem optimal node density ad sensor networks deployed making two dimensional correlated random fields considered using symmetric first order conditional autoregressive markov random field model , large deviations results used characterize asymptotic per node information gained array result allows analysis node density maximizes information energy constraint , yielding insights trade offs among information , density energy
gpu accelerated mobile multi view style transfer estimated 60 smartphones 2018 equipped multiple cameras , enabling wide variety 3d enabled applications 3d success 3d photo platforms \( facebook 3d photo , , etc \) depend steady user generated content platforms must provide simple image manipulation tools facilitate content creation , akin traditional photo platforms neural style transfer , recent advancements gpu technology , one tool enhancing traditional however , single view neural style transfer multi view scenario produces visually inconsistent results slow mobile devices present gpu accelerated multi view style transfer pipeline style consistency views demand performance mobile platforms pipeline modular creates high quality depth effects image pair
multi modal sentiment analysis using deep canonical correlation analysis paper learns multi modal embeddings text , audio , video views modes data order improve upon stream sentiment classification experimental framework also allows investigation relative contributions individual views final multi modal embedding individual features derived three views combined multi modal embedding using deep canonical correlation analysis \( \) two ways \) one step ii \) two step paper learns text embeddings using bert , current state art text encoders highly optimized algorithm dominates contribution views , though view contribute final result classification tasks carried two benchmark datasets new debate emotion data set , together demonstrate one step outperforms current state art learning multi modal embeddings
design program repair insights repairnator project program repair research made tremendous progress last years , software development help developers gain productivity paper , investigate concept program repair present repairnator repairnator autonomous agent monitors test failures , bugs , runs program repair tools patch found , repairnator reports developers time writing , repairnator uses three different program repair systems operating since 2017 total , studied 11 test failures 1 open source software projects github , generated patches 15 different bugs months , number hard technical challenges make various design engineering decisions gives us unique experience area paper , upon repairnator order share knowledge automatic program repair community
generalized median graph via iterative alternate computing graph prototype may constitute core element clustering classification tasks however , computation np hard problem , even simple classes graphs paper , propose efficient approach based block coordinate descent compute generalized median graph set graphs approach relies clear definition optimization process handles labeling edges nodes iterative process optimizes edit operations perform graph nodes edges several experiments different datasets show efficiency approach
sleep fatigue pattern analysis using large scale social complexities fatigue drawn much attention researchers across various disciplines short term fatigue may cause safety issue driving thus , dynamic systems designed track driver fatigue long term fatigue could lead , eventually affect individuals physical psychological health traditional methodologies evaluating fatigue require sophisticated equipment also enormous time paper , attempt develop novel efficient method predict individual 's fatigue rate human facial cues goal predict fatigue rate based associate fatigue rate user behaviors , collected nearly 1 million 10 , users first detect faces identify demographics using automatic algorithms next , investigate fatigue distribution different age , gender , groups work represents promising way assess sleep fatigue , study provides viable efficient computational framework user fatigue modeling large scale via social media
distributed h infinity tracking control discrete time multi agent systems high dimensional leader paper considers distributed h infinity leader following tracking problem class discrete time multi agent systems high dimensional dynamic leader assumed output information leader available , dynamics subject perturbations achieve distributed h infinity leader following tracking , new class control protocols proposed based feedback nearest neighbors well distributed state estimator assumptions dynamics leader communication topology contains directed spanning tree , sufficient conditions obtained enable track leader achieving desired h infinity leader following tracking performance numerical simulations illustrate effectiveness theoretical analysis
improving malware detection accuracy extracting icon information detecting malware files commonly using statistical machine learning models models commonly use features extracted structure files , propose files also help better predict malware propose innovative machine learning approach extract information proposed approach consists two steps 1 \) extracting icon features using summary , histogram gradients \( \) , convolutional autoencoder , 2 \) clustering based extracted icon features using publicly available data using machine learning experiments , show proposed icon clusters significantly boost efficacy malware prediction models particular , experiments show average accuracy increase 10 icon clusters used prediction model
evolution internet economic ecosystem evolution internet many ways traffic characteristics , topologies business relationships among autonomous components important understand \( \) evolution , interplay dynamics may affect future evolution services propose network aware , macroscopic model captures characteristics interactions application network providers , show leads market equilibrium ecosystem analyzing driving forces dynamics market equilibrium , obtain fundamental cause effect internet evolution , explain historical recent furthermore , likely future , model help application network providers make informed business decisions succeed competitive ecosystem
minimal set fragments achieves maximal parse accuracy aim finding minimal set fragments achieves maximal parse accuracy data oriented parsing experiments street journal show counts almost arbitrary fragments within parse trees important , leading improved parse accuracy previous models tested \( precision 90 8 recall 90 6 \) dependency relations previous models contribute higher parse accuracy
optimal generalized decision trees via integer programming decision trees popular class predictive models decades due interpretability good performance categorical features however , always robust tend data additionally , allowed grow large , lose interpretability paper , present novel mixed integer programming formulation construct optimal decision trees specified size take special structure categorical features account allow combinatorial decisions \( based subsets values feature \) node show good accuracy achieved small trees using sized training sets optimization problems solve easily tractable modern solvers
unified watermark removal framework deep learning systems limited data deep neural networks \( dnns \) achieved tremendous success various fields however , training models scratch could computationally expensive requires lot training data recent work explored different watermarking techniques protect pre trained deep neural networks potential however , could vulnerable adversaries aim removing work , propose , unified watermark removal framework based fine tuning , rely knowledge even watermarking schemes firstly , demonstrate properly designing learning rate schedule fine tuning , adversary always able remove furthermore , conduct comprehensive study realistic attack scenario adversary limited training data effectively remove without model functionality weak threat model , propose incorporate two techniques \( 1 \) weight \( \) algorithm , proposed catastrophic forgetting phenomenon \( 2 \) unlabeled data augmentation \( \) , leverage auxiliary unlabeled data sources extensive evaluation shows effectiveness diverse watermark embedding schemes particular , significantly decrease amount labeled training data needed effective watermark removal , unlabeled data samples used necessarily need drawn distribution benign data model evaluation experimental results demonstrate fine tuning based watermark removal attacks could pose real threats pre trained models , thus highlights importance investigation watermarking problem
ads analysis 2016 facebook ads campaign one key aspects united states free fair elections allow transfer power one next 2016 us presidential election due foreign influence , , election significant portion influence carried via social media paper , look specifically 3 , 500 facebook ads ads released may 10 , 2018 us intelligence committee analyzed ads using natural language processing techniques determine textual semantic features associated effective ones clustered ads time various campaigns labeled parties associated also studied effectiveness ads individual , campaign party basis effective ads tend less positive sentiment , focus past events specific personalized nature effective campaigns also show similar characteristics duration ads suggest division rather election
deep learning sentiment analysis survey deep learning emerged powerful machine learning technique learns multiple layers representations features data produces state art prediction results along success deep learning many application domains , deep learning also used sentiment analysis recent years paper first gives overview deep learning provides comprehensive survey current applications sentiment analysis
combine ppo improve exploration introduce two approaches combining neural evolution strategy \( \) proximal policy optimization \( ppo \) parameter transfer parameter space noise parameter transfer ppo agent parameters transferred agent parameter space noise directly add noise ppo parameters demonstrate ppo could benefit methods experimental comparison discrete action environments well continuous control tasks
learning probabilistic relational dynamics multiple tasks ways agent 's actions affect world often modeled using set relational probabilistic planning rules paper addresses problem learning rule sets multiple related tasks take hierarchical bayesian approach , system learns prior distribution rule sets present class prior distributions parameterized rule set prototype stochastically modified produce task specific rule set also describe coordinate algorithm iteratively optimizes task specific rule sets prior distribution experiments using algorithm show transferring information related tasks significantly reduces amount training data required predict action effects blocks world domains
improvements graph based authentication schemes 2010 , , introduced graph based authentication schemes present protocols , introduce new schemes problems
computing downward stacked counter automata downward closure language l words set \( necessarily \) members l well known downward closure language regular although downward closure seems promising abstraction , language classes automaton downward closure known computable r n shown stacked counter automata , downward closure computable stacked counter automata finite automata storage mechanism obtained emph adding blind emph building hence , generalize pushdown blind counter automata r n class languages accepted automata precisely hierarchy obtained context free languages alternating two closure operators constraints taking algebraic extension main tool computing downward new concept annotations second application annotations , shown hierarchy strict every level
privacy aware smart progress challenges next generation energy network , called smart grid \( \) , promises tremendous increases efficiency , safety , flexibility managing electricity grid compared energy network needed today ever , global energy consumption growing unprecedented rate energy sources \( \) must integrated grid human development
speech chain multimodal chain leveraging cross modal data augmentation semi supervised learning previously , machine speech chain , based sequence sequence deep learning , proposed mimic speech perception production behavior chains separately processed speaking automatic speech recognition \( asr \) text speech synthesis \( tts \) simultaneously enabled semi supervised learning received unpaired data unfortunately , speech chain study limited speech textual modalities fact , natural communication actually multimodal involves visual sensory systems although said speech chain reduces requirement full amount paired data , case still need large amount unpaired data research , take step construct multimodal chain design closely chain architecture combines asr , tts , image captioning , image production models single framework framework allows training component without requiring large number parallel multimodal data experimental results also show asr trained without speech text data cross modal data augmentation remains possible proposed chain , improves asr performance
multi modal cycle consistent generalized zero shot learning generalized zero shot learning \( gzsl \) , set classes split seen unseen classes , training relies semantic features seen unseen classes visual representations seen classes , testing uses visual representations seen unseen classes current methods address gzsl learning transformation visual semantic space , exploring assumption distribution classes semantic visual spaces relatively similar methods tend transform unseen testing visual representations one seen semantic features instead semantic features correct unseen class , resulting low accuracy gzsl classification recently , generative adversarial networks \( gan \) explored synthesize visual representations unseen classes semantic features synthesized representations seen unseen classes used train gzsl classifier approach shown boost gzsl classification accuracy , however , guarantee synthetic visual representations generate back semantic feature multi modal cycle consistent manner constraint result synthetic visual representations represent well semantic features paper , propose use constraint based new regularization gan training forces generated visual features reconstruct original semantic features model trained multi modal cycle consistent semantic compatibility , synthesize representative visual representations seen , importantly , unseen classes proposed approach shows best gzsl classification results field several publicly available datasets
exact byzantine consensus arbitrary directed graphs local broadcast model consider byzantine consensus synchronous system nodes connected network modeled directed graph , e , communication links neighboring nodes necessarily bi directional directed graph model motivated wireless networks wherein asymmetric communication links occur classical point point communication model , message sent communication link private two nodes link allows byzantine faulty node , e , send inconsistent information neighbors paper considers local broadcast model communication , wherein transmission node received identically neighbors allows neighbors detect faulty node 's attempt , effectively faulty nodes ability send information different neighbors r n prior work obtained sufficient necessary conditions undirected graphs able achieve byzantine consensus local broadcast model paper , obtain tight conditions directed graphs able achieve byzantine consensus binary inputs local broadcast model results obtained paper provide insights trade communication ability achieve consensus
performance evaluation optimization b n v routing aerial ground based mobile ad networks reliable efficient end end communication within ground air based mobile mesh networks major challenge routing protocols due mobility related dynamics channel properties resulting mesh network topology paper , evaluate performance novel better approach mobile networking \( b n \) v routing protocol vehicular mesh networks propose mobility predictive extension explicitly addresses highly dynamic communication networks order enable large scale analysis , present open source simulation model , validated field experiments within comprehensive evaluation campaign vehicle \( v2x \) aerial vehicle \( \) scenarios , shown predictive b n v based approach significantly better suited maintaining reliable connectivity within highly mobile mesh networks established routing protocols
sigan siamese generative adversarial network identity preserving face hallucination though generative adversarial networks \( gans \) high quality high resolution \( hr \) faces low resolution \( lr \) faces , cannot ensure identity face hallucination , making hr faces difficult recognize address problem , propose siamese gan \( sigan \) reconstruct hr faces visually corresponding top siamese network , proposed sigan consists pair two identical generators one discriminator incorporate reconstruction error identity label information loss function sigan pairwise manner iteratively optimizing loss functions generator pair discriminator sigan , achieve visually face reconstruction also ensure reconstructed information useful identity recognition experimental results demonstrate sigan significantly outperforms existing face hallucination gans objective face verification performance achieving promising visual quality reconstruction moreover , input lr faces unseen part training dataset , sigan still achieve reasonable performance
object copy platform population based probabilistic programming work considers dynamic memory management population based probabilistic programs , using particle methods inference programs exhibit pattern allocating , , potentially , collections similar objects successive generations objects may data structures , , lists , arrays , trees , may random , possibly unbounded , size simple case n particles , generations , objects , generation , dense representation requires \( \) memory , sparse representation requires \( log \) memory , based existing theoretical results work describes object copy write platform automate saving programmer core idea using labeled directed , vertices represent objects , edges pointers , labels necessary specific labeling scheme proposed high performance pattern platform implemented probabilistic programming language , using smart pointers , hash tables , reference counting collection tested empirically number realistic probabilistic programs , shown significantly reduce memory use execution time manner consistent theoretical expectations enables copy write imperative programmer , deep copies object oriented programmer , place write optimizations functional programmer
selective encoding sentence summarization propose selective encoding model extend sequence sequence framework sentence summarization consists sentence encoder , selective gate network , attention equipped decoder sentence encoder decoder built recurrent neural networks selective gate network constructs second level sentence representation controlling information flow encoder decoder second level representation tailored sentence summarization task , leads better performance evaluate model english , 2004 msr sentence summarization datasets experimental results show proposed selective encoding model outperforms state art baseline models
extended depth field imaging using deep learning based phase recovery encodes three dimensional \( 3d \) information sample form intensity however , decode original sample image \( \) , phase recovery needed , general time consuming perform demonstrate convolutional neural network \( cnn \) based approach simultaneously performs phase recovery significantly extend depth field \( dof \) reconstruction speed imaging , cnn trained using pairs randomly back propagated corresponding focus phase recovered images training phase , cnn takes single back propagated 3d sample input rapidly achieve phase recovery reconstruct focus image sample significantly extended dof deep learning based dof extension method non iterative significantly improves algorithm time complexity image reconstruction \( nm \) \( 1 \) , n number individual object points particles within sample volume , represents focusing search space within object point particle needs individually focused results highlight unique opportunities created data enabled statistical image reconstruction methods powered machine learning , believe presented approach broadly applicable computationally extend dof imaging modalities
variational bayesian approximation log evaluating log determinant positive definite matrix ubiquitous machine learning applications range gaussian processes , minimum volume , metric learning , kernel learning , bayesian neural networks , point processes , markov random fields partition functions discrete graphical models order avoid canonical , yet , mathcal \( n 3 \) computational cost , propose novel approach , complexity mathcal \( n 2 \) , based constrained variational bayes algorithm compare method , approaches show state art performance synthetic real world datasets
using soft constraints learn semantic models descriptions shapes contribution paper provide semantic model \( using soft constraints \) words used web users describe objects language game game one user describes selected object scene , another user object described given description needs non ambiguous accurate enough allow users described shape correctly r n build semantic models descriptions need analyzed extract syntax classes used modeled meaning descriptions using soft constraints way meaning r n descriptions generated system account context object avoid ambiguous descriptions , allowed users described object correctly 72 times
exploiting cpu fpga efficient flexible cnn inference acceleration deep convolutional neural networks \( cnns \) obtain outstanding results tasks require human level understanding data , like image speech recognition however , computational load significant , development cnn specialized work presents , flexible efficient hardware software solution acceleration cnns leverages usage arm cores powerful flexible convolution specific processor deployed reconfigurable logic convolution specific processor convolution engine programmable soft core , arm processors supervision allowing controlled software ultra fine granularity methodology opens way cooperative heterogeneous computing takes care cnn , arm cores execute hard parts computational graph , taking advantage vector engines speed computation stack , supports end end cnn based classification peak performance , energy efficiency w thanks heterogeneous computing model , platform improves upon state art , achieving frame rate 5 5 frames per second \( fps \) end end execution vgg 16 6 resnet 18
top induction decision trees rigorous guarantees inherent limitations consider following heuristic building decision tree function f 0 , 1 n pm 1 place influential variable x f root , f x 0 f x 1 left right respectively tree varepsilon approximation f analyze quality heuristic , obtaining near matching upper lower bounds r n circ upper bound every f decision tree size every varepsilon \( 0 , 2 \) , heuristic builds decision tree size \( log \( varepsilon \) log \( 1 varepsilon \) \) r n circ lower bound every varepsilon \( 0 , 2 \) le 2 tilde \( sqrt n \) , f decision tree size heuristic builds decision tree size tilde omega \( log \) r n also obtain upper lower bounds monotone functions \( sqrt log varepsilon \) tilde omega \( sqrt 4 log \) respectively lower bound \( 2004 \) \( 2009 \) r n upper bounds yield new algorithms properly learning decision trees uniform distribution show algorithms motivated widely employed empirically successful top decision tree learning heuristics , 5 , achieve provable guarantees compare current fastest algorithm \( ehrenfeucht , \) lower bounds shed new light limitations heuristics r n finally , revisit classic work ehrenfeucht extend give first uniform distribution proper learning algorithm achieves polynomial sample memory complexity , matching state art runtime
polar codes memory polar codes memory \( pcm \) proposed paper pair consecutive code blocks containing controlled number mutual information bits shared mutual information bits block help failed block recover underlying polar codes employ decoding scheme successive cancellation \( sc \) decoding \( pcm sc \) , belief propagation \( \) decoding \( pcm \) , successive cancellation list \( scl \) decoding \( pcm scl \) analysis shows packet error rate \( per \) pcm decreases order per squared maintaining complexity underlying polar codes simulation results indicate pcm sc , per comparable \( less 0 3 db \) alone scl decoding two lists block length n per pcm scl l lists match alone scl decoding lists two hardware decoders pcm also implemented serial \( \) decoder low latency \( \) decoder n , synthesis results show worst case , latency pcm decoder 16 1 adaptive scl decoder l 2 , throughput improved 13 times compared
complexity non probabilistic justification logic logic mathsf probabilistic logic defined adding non probability operators basic justification logic mathsf j paper establish upper lower bounds complexity problem logic mathsf main result paper complexity problem mathsf remains complexity problem underlying logic mathsf j , 2 p complete implies probability operators increase complexity logic , although expressiveness language
precision learning towards use known operators neural networks paper , consider use prior knowledge within neural networks particular , investigate effect known transform within mapping input data space output domain demonstrate use known transforms able change maximal error bounds r n order explore effect , consider problem x ray material decomposition example incorporate additional prior knowledge demonstrate non linear function known physical properties system able reduce prediction errors improving prediction quality values 0 54 0 88 r n approach applicable wide set applications physics signal processing provide prior knowledge transforms also maximal error estimation network understanding could within context precision learning
real time robust 3d lidar localization localization , position , important problem robotics research paper , propose novel approach long term localization changing environment using 3d lidar first create map real environment using gps lidar , divide map several small parts targets cloud registration , improve robustness also reduce registration time allows us different kinds , optimize accuracy frequency localization results evaluate algorithm ground vehicle \( \) using lidar wheel encoder , obtain localization results 20 fusion algorithm also localize degree field view \( \) using map captured six months , algorithm shows great robustness , test results show achieve accuracy 10 cm tested period six months crowded successfully distance
deep inspection distribution parts study via deep neural networks distribution important assets electricity supply need maintained good condition ensure protect community safety , maintain reliability supply , meet however , maintaining large assets expensive challenging task address , recent approaches imagery data captured reducing cost manual inspection , manual analysis image still required , several image based automated inspection systems proposed paper , target two major challenges tiny object detection extremely imbalanced datasets , currently wide deployment automatic inspection propose novel two stage detection method focus object interest address imbalanced dataset problem , propose well schemes iteratively adapt model large intra class variation major class balance contributions loss class finally , integrate components together devise novel automatic inspection framework extensive experiments demonstrate proposed approaches effective boost performance compared baseline methods
learning defectives graph group tests paper deals abstraction unified problem drug discovery identification identification involves identification disease drug discovery involves finding , called lead , eventually function protein paper , lead , defectives , mixture non normal items defective could presence test , test containing defective positive contain associated goal paper identify defectives , , high probability , words , learn defectives graph \( \) efficiently group tests propose probabilistic non adaptive pooling design , probabilistic two stage adaptive pooling design decoding algorithms learning two stage adaptive pooling design , show sample complexity number tests required guarantee recovery , defectives , high probability , e , upper bound , exceeds proposed lower bound logarithmic multiplicative factor number items non adaptive pooling design , show upper bound exceeds proposed lower bound logarithmic multiplicative factor number items
visualization correction automated segmentation tracking 5 stem cell image sequences results present application enables quantitative analysis 5 \( x , , z , , channel \) large microscopy images image sequences show stem cells together vessels , enabling quantification dynamic behaviors stem cells relation , applications cancer biology application automatically segments , tracks , image sequence data allows user view edit results automated algorithms 3 window simultaneously stem cell tree 2 window using gpu store render image sequence data enables hybrid computational approach inference based approach utilizing user provided automatically correct related system cpu gpu handles 3 visualization tasks conclusions exploiting computer hardware , developed application run facilitate rapid iteration biological experiments need visualization analysis tools 5 live cell image data combine accurate unsupervised processes intuitive visualization results validation interface allows data set 100 accuracy , ensuring downstream data analysis accurate tool first combine aspects , leveraging obtained utilizing validation information stereo visualization improve low level image processing tasks
systems unsupervised news translation task 2019 paper describe translation system used unsupervised news shared task 2019 fourth machine translation \( \) follow strategy et al \( \) , creating seed phrase based system phrase table cross lingual embedding mappings trained monolingual data , followed neural machine translation system trained synthetic parallel data synthetic corpus produced monolingual corpus tuned model refined iterative back translation focus handling named entities , e part vocabulary cross lingual embedding mapping suffers system bleu score 15 3 german shared task
approach language identification based networks study address problem training language identification using labeled unlabeled speech samples form vectors propose neural network architecture also handle set languages utilize modified version recently proposed network training procedure optimizes reconstruction costs stack denoising autoencoders show approach successfully applied case training dataset composed labeled unlabeled acoustic data results show enhanced language identification 2015 language identification dataset
perceptually weighted rank correlation indicator objective image quality assessment field objective image quality assessment \( iqa \) , , uniform weights quality levels assume pair images , two popular rank correlation indicators indicators successfully measure average accuracy iqa metric ranking multiple processed images however , two important perceptual properties first , sorting accuracy \( \) high quality images usually important poor quality images many real world applications , top ranked images users second , due subjective uncertainty making judgments , two perceptually similar images usually , ranks contribute evaluation iqa metric accurately compare different iqa algorithms , paper , explore perceptually weighted rank correlation indicator , rewards capability correctly ranking high quality images attention toward rank specifically , focus valid pairwise comparison images whose quality difference exceeds given sensory threshold \( st \) meanwhile , image pair assigned unique weight determined quality level rank deviation modifying perception threshold , illustrate sorting accuracy sophisticated st curve rather single rank correlation coefficient proposed indicator offers new insight interpreting visual perception behavior furthermore , applicability indicator validated recommending robust iqa metrics degraded enhanced image data
matrix product master worker platforms paper aimed designing efficient parallel matrix product algorithms heterogeneous master worker platforms matrix product well understood homogeneous 2d arrays processors \( e g , algorithm outer product algorithm \) , three key hypotheses render work original innovative r n centralized data assume matrix files , must , master r n heterogeneous star shaped platforms target fully heterogeneous platforms , computational resources different computing r n limited memory investigate large problems , cannot assume full matrix stored worker memories used subsequent updates \( \) r n efficient algorithms resource selection \( deciding workers \) communication ordering \( input result messages \) , report set numerical experiments various platforms de university however , point first version report , experiments limited homogeneous platforms
multihop energy efficient clustering data aggregation protocol sensor network consists large number tiny sensors connected low power wireless communications routing data protocols wsn assume homogeneous network architecture , sensors capabilities terms battery power , communication , sensing , storage , processing however continued advances processors low power communications enabled development wide variety nodes one type node integrated wsn , called heterogeneous multihop short distance communication important scheme reduce energy consumption sensor network nodes densely deployed wsn paper \( multihop energy efficient clustering data aggregation protocol heterogeneous wsn \) proposed analyzed protocol combines idea multihop communications clustering achieving best performance terms network life energy consumption introduces sleep state three tier architecture cluster heads save energy network consists three types sensor nodes normal , advance super become cluster head round normal nodes use residual energy based scheme advance super nodes act relay node reduce transmission load normal node cluster head cluster heads round
early observations performance google compute engine scientific computing although cloud computing emerged business applications industry , public cloud services widely accepted scientific computing academia recently available google compute engine \( gce \) claimed support high performance computationally intensive tasks , little evaluation studies found reveal gce 's scientific capabilities considering fundamental performance benchmarking strategy early stage evaluation new cloud services , followed cloud evaluation experiment methodology \( \) benchmark gce also compare amazon , help understand elementary capability gce dealing scientific problems experimental results analyses show potential advantages , possible threats applying gce scientific computing example , compared amazon 's service , gce may better applications require frequent disk operations , may yet single based parallel computing following evaluation methodology , different evaluators fundamental evaluation gce based fundamental evaluation results , suitable gce environments established case studies solving real science problems
interplay network structure gradient convergence deep learning regularization output consistency behavior dropout layer wise pretraining learning deep networks fairly well studied however , understanding asymptotic convergence backpropagation deep architectures related structural properties network design choices \( like denoising dropout rate \) less clear time interesting question one may ask whether network architecture input data statistics may guide choices learning parameters vice versa work , explore association structural , aspects interaction parameter convergence rates present framework address questions based convergence backpropagation general objectives using first order information analysis suggests interesting relationship feature denoising dropout building upon results , obtain setup provides systematic guidance regarding choice learning parameters network sizes achieve certain level convergence \( optimization sense \) often statistical attributes inputs results supported set experimental evaluations well independent empirical observations reported groups
non coherent detection molecular communications study non coherent detection schemes molecular communication \( \) systems require knowledge channel state information \( csi \) particular , first derive optimal maximum likelihood \( ml \) multiple symbol \( ms \) detector systems special case optimal ms detector , show optimal ml symbol symbol \( ss \) detector equivalently written form threshold based detector , optimal decision threshold constant depends statistics channel main challenge ms detector complexity associated calculation optimal detection metric overcome issue , propose approximate ms detection metric expressed closed form reduce complexity even , develop non coherent decision feedback \( \) detector suboptimal blind detector finally , derive analytical expressions bit error rate \( \) optimal ss detector , well upper lower bounds optimal ms detector simulation results confirm analysis reveal effectiveness proposed optimal suboptimal detection schemes compared benchmark scheme assumes perfect csi knowledge , particularly number observations used detection sufficiently large
survey signed network mining social media many real world relations represented signed networks positive negative links , result signed network analysis attracted increasing attention multiple disciplines increasing prevalence social media networks , signed network analysis developing measuring theories mining tasks article , present review mining signed networks context social media discuss promising research directions new frontiers giving basic concepts unique properties principles signed networks classify review tasks signed network mining representative algorithms also tasks extensively studied formal definitions also propose research directions expand field signed network mining
benchmarking improving measurement accuracy cloud investigate measurement procedure , helps improve accuracy performance comparison experiments conducted shared machines executing measured parallel evaluating relative performance together , rather individually specifically , analyze behavior procedure multiple cloud environments use experimental evidence answer multiple research questions concerning assumption underlying procedure demonstrate improvements accuracy ranging 2 12 \( 5 average \) tested \( \) workloads , 82 4x \( 4x average \) cpu 2017 workloads
terrain classification slip estimation ground robots via deep learning plays critical role areas ground vehicles ground mobile robots since understanding estimating variables vehicle terrain interaction may mean success failure entire research applies state art algorithms deep learning two key problems estimating wheel slip classifying terrain ground robot three data sets collected ground robotic platforms \( mit single wheel testbed , , robot \) employed order compare performance traditional machine learning methods \( e support vector machine \( svm \) multi layer perceptron \( \) \) deep neural networks \( dnns \) convolutional neural networks \( cnns \) work also shows impact certain tuning parameters network architecture \( , dnn cnn \) play performance methods paper also contributes deep discussion learned implementation dnns cnns methods extended solve problems
learning adversary paper , propose method , learning adversary , learn robust network method takes finding adversarial examples step new simple way finding adversarial examples presented experimentally shown lastly , experimental results shows learning method greatly improves robustness learned network
fixed rank matrix riemannian low rank optimization motivated problem learning linear regression model whose parameter large fixed rank non symmetric matrix , consider optimization smooth cost function defined set fixed rank matrices adopt geometric framework optimization riemannian quotient manifolds study underlying several well known fixed rank matrix exploit riemannian quotient geometry search space design class gradient descent trust region algorithms proposed algorithms generalize previous results fixed rank symmetric positive semidefinite matrices , apply broad range applications , scale high dimensional problems geometric basis recent contributions learning fixed rank non symmetric matrices make connections existing algorithms context low rank matrix completion discuss relative usefulness proposed framework numerical experiments suggest proposed algorithms state art manifold optimization offers effective framework design machine learning algorithms learn fixed rank matrix
new bounds circulant johnson embeddings paper circulant johnson \( jl \) embeddings , important class structured random jl embeddings , formed column signs circulant matrix generated random vector help recent techniques matrix valued inequalities , obtain new bound k \( epsilon 2 log \( 1 delta \) \( n \) \) gaussian circulant jl embeddings moreover , using transform technique \( also called 's \) , extend result case bounds paper offer small improvement current best bounds gaussian circulant jl embeddings certain parameter regimes derived using direct methods
type constrained representation learning knowledge graphs large knowledge graphs increasingly add value various applications require machines recognize understand queries semantics , search question answering systems latent variable models increasingly gained attention statistical modeling knowledge graphs , showing promising results tasks related knowledge graph completion besides storing world , schema based knowledge graphs rich semantic descriptions entities relation types allow machines understand notion things semantic relationships work , study type constraints generally support statistical modeling latent variable models precisely , integrated prior knowledge form type constraints various state art latent variable approaches experimental results show prior knowledge relation types significantly improves models 77 link prediction tasks achieved improvements especially prominent low model complexity enforced , crucial requirement models applied large datasets unfortunately , type constraints neither always available always complete e g , become fuzzy entities lack proper typing show cases , beneficial apply local closed world assumption approximates semantics relation types based observations made data
deep continuous conditional random fields asymmetric inter object constraints online multi object tracking online multi object tracking \( mot \) challenging problem many important applications including intelligence surveillance , robot navigation , autonomous driving existing mot methods , individual object movements inter object relations mostly modeled separately relations still manually tuned addition , inter object relations mostly modeled symmetric way , argue optimal setting tackle difficulties , paper , propose deep continuous conditional random field \( \) solving online mot problem track detection framework consists unary pairwise terms unary terms estimate objects across time based visual appearance information modeled deep convolution neural networks , able learn discriminative visual features association asymmetric pairwise terms model inter object relations asymmetric way , encourages high confidence help correct errors low confidence affected low confidence ones much trained end end manner better adapting influences visual information well inter object relations extensive experimental comparisons state arts well detailed component analysis proposed two public benchmarks demonstrate effectiveness proposed mot framework
healthy versus pathological learning muscle segmentation using deep convolutional encoder decoders automatic segmentation pathological patients diseases challenging task due huge variability muscle shape , size , location , texture reliable fully automated segmentation method magnetic images could greatly help plan interventions predict outcomes eliminating time consuming manual segmentation efforts purpose work three fold first , investigate feasibility pathological muscle segmentation using deep learning techniques , given limited amount available annotated data second , address learning healthy pathological data comparing different learning schemes terms model third , extended versions deep convolutional encoder decoder architectures using encoders pre trained non medical data proposed improve segmentation accuracy aspects evaluated one fashion dataset 24 patients focus 4 different including well , relevant segmentation model partially pre trained imagenet jointly exploits inter patient healthy pathological annotated data performance scores 82 4 , 82 0 , 0 82 8 , , absolute surface estimation errors 2 except 2 contributions offer new perspectives force inference context management
video summarization using deep semantic features paper presents video summarization technique internet video provide way overview content challenging problem finding important informative parts original video requires understand content furthermore content internet videos diverse , ranging home videos , makes video summarization much prior knowledge almost available tackle problem , propose use deep video features encode various levels content semantics , including objects , actions , scenes , improving efficiency standard video summarization techniques , design deep neural network maps videos well descriptions common semantic space jointly trained associated pairs videos descriptions generate video summary , extract deep features segment original video apply clustering based summarization technique evaluate video summaries using dataset well baseline approaches results demonstrated advantages incorporating deep semantic features video summarization technique
construction quasi cyclic self dual codes one one correspondence ell quasi cyclic codes finite field mathbb f q linear codes ring r mathbb f q \( 1 \) using correspondence , prove every ell quasi cyclic self dual code length ell finite field mathbb f q obtained building construction , provided \( mathbb f q \) 2 q 1 4 , prime p , q primitive element mathbb f p determine possible weight binary ell quasi cyclic self dual code length p ell \( p prime \) terms p improve result 3 constructing new binary cubic \( e , ell quasi cyclic codes length 3 ell \) optimal self dual codes lengths 30 , , 42 , \( type \) , 54 also find quasi cyclic optimal self dual codes lengths 40 , 50 , 60 5 , obtain new 8 quasi cyclic self dual 40 , 20 , 12 code mathbb f 3 new 6 quasi cyclic self dual 30 , 15 , 10 code mathbb f 4 7 , find new 4 quasi cyclic self dual 28 , 14 , 9 code mathbb f 4 new 6 quasi cyclic self dual 42 , 21 , 12 code mathbb f 4
novel scheme energy efficient low latency mobile devices 5g networks improved mobile device battery lifetime latency critical requirements enhancing mobile services user experience long term evolution \( lte \) networks adopted \( \) baseline solution battery lifetime however , every cycle , mobile device processing unit monitors decodes control signaling , thus instances without actual data allocation leads unnecessary energy consumption fact together long start power times prevent adopting frequent , turn leads considerable latency work , novel scheme described studied , tackle trade latency battery lifetime future 5g networks , seeking thus facilitate always available experience , rather always analytical simulation based results show proposed scheme promising approach control user plane latency energy consumption , device operating power saving mode aim article describe overall system operating principle associated signaling methods , receiver processing solutions essential implementation aspects additionally , advantages compared based systems shown demonstrated , analysis system energy efficiency latency characteristics , special emphasis future 5g grade mobile devices
deep attention model patients optimization patient throughput time \( ed \) important task systems reason , index \( \) system patient introduced help guide manual estimation levels , used rank patients resources however , despite improvements managing medical resources , system greatly depends 's subjective judgment thus prone human errors , propose novel deep model based word attention mechanism designed predicting number resources ed patient would need approach incorporates routinely available continuous \( structured \) data medical text \( unstructured \) data , including patient 's , past medical history , list , assessment collected , 500 ed three years large urban using structured unstructured data , proposed approach achieves auc 88 task identifying resource intensive patients \( binary classification \) , accuracy 44 predicting exact category number resources \( multi class classification task \) , giving estimated lift performance 16 accuracy furthermore , attention mechanism proposed model provides interpretability assigning attention scores notes crucial decision making implementation approaches real systems working human health
learning latent spatio temporal compositional model human action recognition action recognition important problem multimedia understanding paper addresses problem building expressive compositional action model model one action instance video ensemble spatio temporal number discrete temporal anchor frames , decomposed layout parts way , model identify spatio temporal graph \( \) represent latent structure actions emph e g triple , high model comprises four layers \( \) batch leaf nodes bottom detecting various action parts within video patches \( ii \) nodes bottom , e switch variables leaf nodes structural variability \( iii \) nodes within anchor frame verifying spatial composition \( \) root node top aggregating scores temporal anchor frames moreover , contextual interactions defined leaf nodes spatial temporal domains model training , develop novel weakly supervised learning algorithm iteratively determines structural configuration \( e g production leaf nodes associated nodes \) along optimization multi layer parameters fully exploiting spatio temporal interactions , approach handles well large intra class action variance \( emph e g different views , individual , spatio temporal structures \) experimental results challenging databases demonstrate superior performance approach methods
optimality group testing algorithms consider bernoulli group testing k \( \) defectives , \( 0 , 1 \) practical definite defectives \( \) detection algorithm known optimal 1 2 give new upper bound rate , showing strictly suboptimal 0 41 also show algorithm algorithms based linear programming achieve rate least high , particular also optimal 1 2
approach combining rules temporal interval based event action logics transactional update logics important problem addressed within event driven architecture \( \) correctly efficiently capture process event action based logic paper bridge gap knowledge representation \( \) approaches based events actions event calculus , one hand , event condition action \( \) rules extending approach active databases view events instantaneous sequences events , propose based rules \( rules \) novel interval based event logic present concrete based syntax , semantics implementation evaluate approach theoretically , experimentally example derived common industry use cases illustrate benefits
binary ensemble neural network bits per network networks per bit binary neural networks \( \) studied extensively since run dramatically faster lower memory power consumption floating point networks , thanks efficiency bit operations however , contemporary bnns whose weights activations single bits suffer severe accuracy degradation understand , investigate representation ability , speed bias variance bnns extensive experiments conclude error bnns predominantly caused intrinsic instability \( training time \) non robustness \( train test time \) inspired investigation , propose binary ensemble neural network \( \) leverages ensemble methods improve performance bnns limited efficiency cost ensemble techniques broadly believed helpful strong classifiers deep neural networks , analyses experiments show naturally perfect fit boost bnns find , faster much robust state art binary networks , even accuracy full precision floating number network architecture
net labelling energy based adversarial learning local prior robust localisation identification essential part automated analysis contribution work task two fold \( 1 \) inspired human expert , contain sufficient information labelling thereby , propose shaped network architecture \( termed net \) efficiently combines information across \( 2 \) net , present energy based adversarial training regime encodes local structure prior network , thereby enabling achieve state art performance standard metrics benchmark dataset scans without post processing inference
long range fine manipulation tasks time delay network conditions present coarse fine approach based semi autonomous system using vision guidance system optimized long range tasks time delay network conditions require prior knowledge remote scene system self exploration behavior senses remote freely mounted eye hand web self exploration stage estimates hand eye calibration provides interface via real time 3d geometric reconstruction human operator able specify visual task interface coarse fine controller remote robot enabling system work high latency networks large motions guided coarse 3d estimation , whereas fine motions use image cues \( \) network data transmission cost minimized sending sparse points final image human side experiments multiple tasks conducted show system 's capability work long range tasks
discrete dubins paths dubins path shortest path bounded result non motion planning \( absence obstacles \) dubins path consists either arc followed segment followed another arc , three dubins , dubins original proof uses advanced calculus later , dubins result using control theory techniques , , , , , c , , r n introduce study discrete constrained motion show shortest bounded paths structure dubins paths properties dubins paths follow results limiting case gives new , discrete proof dubins result
survey security blockchain systems since inception , blockchain technology shown promising application initial cryptocurrency current smart contract , blockchain applied many fields although studies security privacy issues blockchain , systematic examination security blockchain systems paper , conduct systematic study security threats blockchain survey corresponding real attacks examining popular blockchain systems also review security enhancement solutions blockchain , could used development various blockchain systems , suggest future directions research efforts area
non asymptotic converse bounds refined asymptotics two lossy source coding problems paper , revisit two multi terminal lossy source coding problems lossy source coding problem side information available encoder one two decoders , term kaspi problem \( kaspi , \) , multiple description coding problem one semi deterministic distortion measure , refer problem \( , \) kaspi problem , first present properties optimal test channels subsequently , generalize notion distortion information density lossy source coding problem kaspi problem prove non asymptotic converse bound using properties optimal test channels well defined distortion information density finally , discrete memoryless sources , derive refined asymptotics includes second order , large moderate deviations asymptotics converse proof second order asymptotics , apply theorem derived non asymptotic converse bound achievability proof follows first proving type covering lemma tailored kaspi problem , properly expanding well defined distortion information densities finally applying theorem generalize methods used kaspi problem problem result , obtain properties optimal test channels minimum sum rate function , non asymptotic converse bound refined asymptotics discrete memoryless sources since successive refinement problem special case problem , product , obtain non asymptotic converse bound successive refinement problem , strict generalization non asymptotic converse bound sources \( , , 2017 \)
ask neurons neural based approach answering questions images address question answering task real world images set visual turing test combining latest advances image representation natural language processing , propose neural image qa , end end formulation problem parts trained jointly contrast previous efforts , facing multi modal problem language output \( answer \) conditioned visual natural language input \( image question \) approach neural image qa performance previous best approach problem provide additional insights problem analyzing much information contained language part provide new human baseline study human consensus , related inherent challenging task , propose two novel metrics collect additional answers extends original dataset consensus
problem solving programming tool end user within graphical spreadsheet environments main idea use general purpose functions possible , based functions create multilevel formulas solve real world programmable spreadsheet problems beyond providing framework theoretic background tools support , order demonstrate power lies within , present converted table , based table , data retrieval tasks , algorithms , coding full details
memory driven mixed low precision quantization enabling deep network inference paper presents novel end end methodology enabling deployment low error deep networks fit memory computational limitations resource constrained edge devices , exploit mixed low compression , 8 , 4 2 bit uniform quantization , model inference graph integer operations approach aims determining minimum bit precision every activation weight tensor given memory constraints device achieved rule based iterative procedure , number bits memory layers , aiming memory constraints quantization aware step , fake quantized graph converted inference integer model integer channel normalization \( \) layers , introduce negligible loss demonstrated models report latency accuracy evaluation mixed precision family networks experimental results demonstrate end end deployment integer network accuracy device flash memory , improving 8 accuracy respect previously published 8 bit implementations
secrecy performance antenna selection aided mimo systems paper , authors consider multiple input multiple output \( mimo \) system consisting one source , one destination , one eavesdropper , node equipped arbitrary number antennas improve security source destination transmissions , authors investigate antenna selection source propose optimal antenna selection \( oas \) suboptimal antenna selection \( sas \) schemes , depending whether source node global channel state information \( csi \) main link \( source destination \) wiretap link \( source eavesdropper \) moreover , traditional space time transmission \( stt \) studied benchmark authors evaluate secrecy performance stt , sas , oas schemes terms probability zero secrecy capacity furthermore , authors examine generalized secrecy diversity stt , sas , oas schemes asymptotic analysis probability zero secrecy capacity ratio average gains main wiretap channels tends infinity different conventional secrecy diversity assumes infinite signal noise ratio \( snr \) received destination condition eavesdropper finite received snr shown generalized secrecy diversity orders stt , sas , oas schemes product number antennas source destination additionally , numerical results show proposed oas scheme strictly outperforms stt sas schemes terms probability zero secrecy capacity
packet delivery heterogeneous broadcast networks paper , study problem packet delivery heterogeneous packet erasure broadcast networks technical challenge enable users receive packets different rates , quality individual channel present new analytical framework characterizing delivery rate delivery delay performance previously proposed non block based network coding scheme literature scheme studied homogeneous network settings show first time , via new theoretical analysis simulations actually achieve packet delivery using user , show user highest link capacity achieves maximum possible throughput also , non zero packet delivery rate possible users , delivery rate depends difference packet arrival rate sender link capacity user accuracy analytical framework confirmed comparing results simulations different settings packet arrival rate sender link
provable self play algorithms competitive reinforcement learning self play , algorithm learns playing without requiring direct supervision , become new modern reinforcement learning \( rl \) achieving performance practice however , majority theory reinforcement learning applies setting agent plays fixed environment remains largely open whether self play algorithms provably effective , especially necessary manage exploration exploitation tradeoff r n study self play competitive reinforcement learning setting markov games , generalization markov decision processes two player case introduce self play algorithm value iteration upper lower confidence bound \( \) , show achieves regret mathcal tilde \( sqrt \) playing steps game regret measured agent 's performance emph fully adversarial exploit agent 's strategy emph step also introduce explore exploit style algorithm , achieves slightly worse regret mathcal tilde \( 2 3 \) , guaranteed run polynomial time even worst case best knowledge , work presents first line provably sample efficient self play algorithms competitive reinforcement learning
e de twitter c c c c de 2018 contemporary world , significant number people use social networking services variety purposes , including , limited , communicating , messages searching information popular social network political twitter , service messages characters , called tweets , influential various countries often use medium spread ideas make public work , analysis made connections candidates year 2018 using analysis complex networks measure influence relevance , metric established able quantify importance users network part analysis , memory algorithm used detect communities , groups strongly connected vertices \( tweets \) users
fingerprinting capacity assumption address maximum rate fingerprinting codes assumption , studying lower upper bounds value rate various sizes attacker lower bounds obtained considering typical , represents new idea area fingerprinting enables us improve previously known lower bounds size two three upper bounds , fingerprinting problem modelled communications problem shown maximum code rate bounded capacity certain class channels , similar multiple access channel converse coding theorems proved paper provide new upper bounds fingerprinting capacity r n proved capacity fingerprinting size two three binary alphabet satisfies 0 25 leq c 2 , 2 leq 0 0 leq c 3 , 2 leq 0 respectively arbitrary fixed size , derive upper bound \( \) 1 fingerprinting capacity binary case finally , general , establish upper bounds fingerprinting capacity involving single letter mutual information quantities
generating function codeword lengths variable length lossy compression allowing positive distortion probability paper considers problem variable length lossy source coding performance criteria distortion probability generating function codeword lengths derive non asymptotic fundamental limit generating function codeword lengths allowing positive distortion probability shown achievability converse bounds characterized r entropy based quantity proof achievability result , explicit code construction provided , investigate asymptotic single letter characterization fundamental limit stationary memoryless source
computing group rational function let g k \( k \( x \) \) group degree one pure field extension k \( x \) k paper describe polynomial time algorithms computing field \( h \) fixed h g computing group g f rational function f k \( x \)
estimating prevalence deception online review communities purchase decisions increasingly influenced user generated online reviews accordingly , growing concern potential deceptive opinion spam reviews written sound , reader practice received considerable public attention concern , relatively little known actual prevalence , rate , deception online review communities , less still factors influence r n propose generative model deception , conjunction deception classifier , use explore prevalence deception six popular online review communities , com , , , , additionally propose theoretical model online reviews based economic signaling theory , consumer reviews inherent information consumers , acting signal product 's true , unknown quality find deceptive opinion spam growing problem overall , different growth rates across communities rates , argue , driven different signaling costs associated deception review community , e g , requirements measures taken increase signaling cost , e g , filtering reviews written first time , deception prevalence effectively reduced
influence dynamic social network type size group evolution discovery new technologies allow store vast amount data users interaction data social network created additionally , usually also time activities stored , dynamic network analyzed splitting many representing state network specific period time one interesting issue group evolution time track group evolution method used however , choice type length might great influence method results therefore , paper , influence type well length method results extensively analyzed
complexity propositional restricted sets boolean functions fundamental important form non monotonic reasoning given knowledge base explaining world aims finding explanation observed paper focus propositional , knowledge base represented propositional problem deciding whether exists explanation shown complete general consider variants obtained restricting allowed certain sets boolean functions give complete classification complexity considerable sets boolean functions way , identify easier cases , namely np complete polynomial cases highlight sources intractability , address problem counting explanations draw complete counting complexity
denoising deep neural networks based voice activity detection recently , deep belief networks \( \) based voice activity detection \( vad \) proposed powerful fusing advantages multiple features , achieves state art performance however , deep layers based vad show superiority layers paper , propose denoising deep neural network \( \) based vad address aforementioned problem specifically , pre train deep neural network special unsupervised denoising greedy layer wise mode , fine whole network supervised way common back propagation algorithm pre training phase , take noisy speech signals visible layer try extract new feature minimizes reconstruction cross entropy loss noisy speech signals corresponding clean speech signals experimental results show proposed based vad outperforms based vad also shows performance improvement deep layers layers
inverse multipath fingerprinting millimeter wave beam alignment efficient beam alignment crucial component millimeter wave systems analog beamforming , especially fast changing vehicular settings paper proposes position aided approach vehicle 's position \( e g , available via gps \) used query multipath fingerprint database , provides prior knowledge potential directions reliable beam alignment approach inverse fingerprinting localization , measured multipath compared fingerprint database retrieve likely position power loss probability introduced metric quantify accuracy used optimizing candidate beam selection two candidate beam selection methods developed , one heuristic minimizes probability proposed beam alignment evaluated using realistic channels generated commercial ray simulator using generated channels , extensive investigation provided , includes required measurement sample size build effective fingerprint , impact measurement noise , sensitivity changes traffic density , beam alignment overhead comparison ieee baseline using concept beam coherence time , duration two consecutive beam alignments , parameters ieee , overhead compared mobility context results show proposed approach provides increasing rates larger antenna arrays , ieee decreasing rates due larger beam training overhead large portion beam coherence time , becomes shorter increasing mobility
good mdps automata probabilistic analysis reinforcement learning characterize class omega automata used analysis finite markov decision processes \( mdps \) call automata \( \) show automata closed classic simulation well powerful simulation relations leverage properties optimal control strategies mdps closure enables us exploit state space reduction techniques , based direct delayed simulation , guarantee simulation equivalence demonstrate promise automata defining new class automata favorable properties b automata low branching degree obtained simple construction show going beyond limit deterministic automata may significantly benefit reinforcement learning
estimation fiber using neighborhood information abstract data diffusion magnetic imaging \( \) used reconstruct fiber , example , muscle white estimation fiber \( \) crucial step reconstruction process estimates noise paper , new method called fiber orientation reconstruction using neighborhood information \( \) described shown reduce effects noise improve fo estimation performance incorporating spatial consistency uses fixed tensor basis model diffusion weighted signals , advantage providing explicit relationship basis vectors fo spatial coherence using weighted l 1 norm regularization terms , contain interaction directional information neighbor data fidelity using squared error observed reconstructed diffusion weighted signals appropriate weighting competing objectives , resulting objective function minimized using block coordinate descent algorithm , straightforward strategy used speed processing experiments performed digital , data , n brain data qualitative quantitative evaluation results demonstrate improves quality fo estimation state art algorithms
urban dynamics modeling based guided cross modal embedding ongoing rapid takes place ever increasing speed , fully modeling urban dynamics becomes challenging , also necessity development challenging human activities constructions ubiquitous urban landscape life content change 's crucial due fact date urban dynamics enable optimize city planning strategy help individuals daily lives efficient way previous topic model based methods attempt solve problem suffer high computational cost memory consumption , limiting scalability city level applications also , strong prior assumptions make models fail capture certain patterns nature r n bridge gap , propose , guided embedding approach jointly model location , time text information given dataset geo social media , extract aggregate location time construct heterogeneous information network using aggregated space time based approach used construct vector representations times , locations frequent words co occurrence pairs nodes closer latent space vector representations used infer related time , locations keywords user query experiments done enormous datasets show model generate comparable better quality query results compared state art models outperform cutting edge models activity recovery classification
coding sets dna storage paper study error correcting codes storage data synthetic dna investigate storage model data set represented set sequences , length l errors within model losses whole sequences point errors inside sequences , insertions , propose code constructions correct errors storage system encoded decoded efficiently deriving upper bounds codes using sphere packing arguments , show many codes close optimal
scalar help vector source coding problem paper , consider scalar help vector source coding problem l 1 correlated gaussian memoryless sources deal case l encoders observe noisy linear combinations k correlated gaussian scalar sources work partial side information decoder , remaining one encoder vector gaussian source works primary source need reconstruct determine outer region case l sources independent vector source also show inner region special case vector source regard k scalar sources
algebraic hybrid satellite space time codes digital broadcasting , different methods broadcasting future digital tv single frequency network \( \) intensive study improve transmission also cover areas , hybrid scheme may used hybrid transmission , signal transmitted satellite site 2008 , et al proposed use double layer 3d space time \( st \) code hybrid 4 x 2 mimo transmission digital tv paper , alternative codes simpler structure proposed 4 x 2 hybrid system , new codes constructed 3 x 2 system performance proposed codes analyzed computer simulations , showing significant improvement simple repetition schemes proposed codes prove addition robust presence power imbalance two sites
cooperative tracking cyclists based smart devices infrastructure future traffic scenarios , vehicles traffic participants equipped various types sensors , allowing cooperation based data information exchange article presents approach cooperative tracking cyclists using smart devices infrastructure based sensors smart device carried cyclists intersection equipped wide angle stereo camera system two tracking models presented compared first model based stereo camera system detections , whereas second model combines camera based detections velocity rate data provided smart device aim overcome limitations tracking approaches based single data sources show numerical evaluations scenes cyclists starting turning right cooperation leads improvement ability keep track accuracy track particularly comes occlusions visual system , therefore , contribute safety vulnerable road users future traffic
wikipedia assessing gender online wikipedia community created contains information people different countries , disciplines aims document world 's knowledge neutral point view however , diversity wikipedia community potential introduce biases gender biases content wikipedia paper aim tackle sub problem larger challenge presenting applying computational method assessing gender bias wikipedia along multiple dimensions find women wikipedia covered well many wikipedia language , way women differs way hope work contributes increasing awareness gender biases online , particular attention different levels gender biases web
achievable rate optical channel finite memory fiber channel modeled variety ways simple additive white complex gaussian noise model , models incorporate memory channel , simple model good approximation optical fiber hence study fiber channel finite memory provide achievable bound channel capacity improves upon previously known bound
throughput optimizing localized link scheduling multihop wireless networks physical interference model study throughput optimum localized link scheduling wireless networks majority results link scheduling assume binary interference models simplify interference constraints actual wireless communication physical interference model reflects physical reality precisely , problem becomes notoriously harder physical interference model existing results link scheduling physical interference model , even fewer practical distributed localized scheduling paper , tackle challenges localized link scheduling posed complex physical interference constraints integrating partition shifting strategies compare scheme , present class localized scheduling algorithms provable throughput guarantee subject physical interference constraints algorithm oblivious power setting first localized algorithm achieves least constant fraction optimal capacity region subject physical interference constraints algorithm uniform power setting first localized algorithm logarithmic approximation ratio optimal solution extensive simulation results demonstrate performance efficiency algorithms
secure communications noma system subcarrier assignment power allocation secure communication promising technology wireless networks ensures secure transmission information paper , investigate joint subcarrier \( sc \) assignment power allocation problem non orthogonal multiple access \( noma \) forward two way relay wireless networks , presence exploiting cooperative \( \) enhance security communication link , aim maximize achievable secrecy energy efficiency jointly designing sc assignment , user pair scheduling power allocation assuming perfect knowledge channel state information \( csi \) relay station , propose low complexity subcarrier assignment scheme \( 1 \) , equivalent many many matching games , 2 formulated secrecy energy efficiency maximization problem secure power allocation problem modeled convex geometric programming problem , solved interior point methods simulation results demonstrate effectiveness proposed algorithms scenarios using using , respectively
geometric properties satisfying assignments random epsilon 1 k sat study geometric structure set solutions random epsilon 1 k sat problem l geq 1 , two satisfying assignments b l connected exists sequence satisfying assignments connecting changing l bits time r n first prove w h p two assignments random epsilon 1 k sat instance \( log n \) connected , conditional satisfying assignments also , exists epsilon 0 \( 0 , frac 1 k 2 \) w h p two satisfying assignments distance least epsilon 0 cdot n form set assignments believe true epsilon 0 , thus satisfying assignments random 1 k sat instance form single cluster
automatic synthesis switching controllers linear hybrid automata paper study problem automatically generating switching controllers class linear hybrid automata , respect safety objectives identify solve contained previous problem , providing sound complete symbolic procedure , based polyhedral abstractions state space also prove termination iteration procedure promising experimental results presented , based implementation procedure top tool
graph kernel proposed addition api ecosystem support modern cryptography security measures overview current progress presented , major advancement , including cryptography data transport , access control enforcing graph policies restrictions , finally process profiles using security modules node 's resource access making community aware , well proposed solutions provided , improve state security future robotics
enabling intelligent music systems present methodology aimed cross modal machine learning uses tools methods drawn broad range areas disciplines , including music , systematic , , motion capture , human computer interaction , computational audio signal processing main tasks include \( 1 \) adapting crowd approaches music performance create dataset music music covers variety emotions , \( 2 \) applying audio language informed machine learning techniques dataset identify automatically content music , \( 3 \) integrating motion capture data system performing music
learning actions roles decentralized robot teams teams robots complete task , communication often necessary like humans , robot implicitly communicate actions interpreting 's actions typically difficult , since given action may many different underlying reasons propose alternate approach instead able infer whether action due exploration , exploitation , communication , define separate roles agent role defines distinct reason acting \( e g , exploit , communicate \) , correctly interpret meaning behind 's actions results suggest leveraging alternating roles leads performance comparable teams explicitly exchange messages find images videos experimental http url
comparing deep neural networks humans object recognition signal gets weaker human visual object recognition typically rapid , well largely independent viewpoint object orientation recently , visual systems ones capable remarkable computational changed rise class computer vision algorithms called deep neural networks \( dnns \) achieve human level classification performance object recognition tasks furthermore , growing number studies report similarities way dnns human visual system process objects , suggesting current dnns may good models human visual object recognition yet clearly exist important architectural processing differences state art dnns visual system potential consequences differences well understood aim address issue comparing human dnn abilities towards image find human visual system robust image like contrast reduction , additive noise novel addition , find progressively classification error patterns humans dnns signal gets weaker , indicating may still marked differences way humans current dnns perform visual object recognition findings well carefully measured freely available datasets provide new useful benchmark computer vision community improve robustness dnns motivation search mechanisms brain could facilitate robustness
square root let q 0 denote rational numbers expanded 0 1 0 q 0 expanded total sign function sign rational number paper discuss extension q 0 \( , sqrt \) signed every number unique square root
wikipedia knowledge powered conversational agents open domain dialogue intelligent agents exhibit use knowledge , however demonstrations date popular sequence sequence models typically generate hope generic utterances weights model mapping input utterance \( \) output , rather employing knowledge context use knowledge far proved difficult , part lack supervised learning benchmark task exhibits open dialogue clear end collect release large dataset directly grounded knowledge retrieved wikipedia design architectures capable knowledge , reading conditioning , finally generating natural responses best performing dialogue models able conduct discussions open domain topics evaluated automatic metrics human evaluations , new benchmark allows measuring improvements important research direction
concave flow small depth directed networks small depth networks arise variety network related applications , often form maximum flow maximum weighted matching recent works generalized methods include costs arising concave functions paper give algorithm takes depth network strictly increasing concave weight functions flows edges computes \( 1 epsilon \) approximation maximum weight flow time epsilon 1 times overhead logarithmic various numerical parameters related gradients r n approach based extending scaling algorithm approximate maximum weighted matchings setting small depth networks , generalizing concave functions restricted setting linear weights range w min , w max , produces \( 1 epsilon \) approximation time \( epsilon 1 log \( w max w min \) \) algorithm combines variety tools provides unified approach towards several problems involving small depth networks
attention clusters purely attention based local feature integration video classification recently , substantial research effort focused apply cnns rnns better extract temporal patterns videos , improve accuracy video classification paper , however , show temporal information , especially longer term patterns , may necessary achieve competitive results common video classification datasets investigate potential purely attention based local feature integration characteristics features video classification , propose local feature integration framework based attention clusters , introduce shifting operation capture diverse signals carefully analyze compare effect different attention mechanisms , cluster sizes , use shifting operation , also investigate combination attention clusters multimodal integration demonstrate effectiveness framework three real world video classification datasets model achieves competitive results across particular , large scale dataset , framework obtains excellent single model accuracy 79 4 terms top 1 94 0 terms top 5 accuracy validation set attention clusters backbone winner solution challenge 2017 code models released soon
motion planning unlabeled optimality guarantees study problem path planning unlabeled \( indistinguishable \) unit robots planar environment obstacles introduce algorithm minimizes total path length , e , sum lengths individual paths algorithm guaranteed find solution one exists , report exists otherwise runs time tilde \( 4 2n 2 \) , number robots n total complexity workspace moreover , total length solution text opt , opt optimal solution cost best knowledge first algorithm problem guarantees algorithm implemented exact manner present experimental results efficiency
pseudo random graphs bit probe schemes one sided error study probabilistic bit probe schemes membership problem given set n elements size structure queries type x \? quickly h , p b , j , proposed bit probe scheme based scheme needs space \( n log \) bits , requires read one randomly chosen bit memory answer query answer correct high probability two sided errors paper show problem exists bit probe scheme one sided error needs space \( n log 2 poly \( log \) \) bits difference model , , , consider bit probe scheme auxiliary word means scheme memory split two parts different size main storage \( n log 2 \) bits short word log \( 1 \) bits pre computed stored set answer query x \? allow read whole word one bit main storage reasonable values parameters space bound better achieved scheme without data
free play methodology evaluation social robotics dataset social interactions evaluating human robot social interactions rigorous manner notoriously difficult studies either conducted constrained protocols allow robust measurements degree , cost validity wild , leads superior experimental , often limited expense rigorous interaction metrics r n introduce novel interaction paradigm , designed rich social interactions desirable scientific properties \( , clear metrics , possibility either autonomous robot \) paradigm focuses robot interactions , builds free play environment present design interaction paradigm , technical aspects \( including open source implementation software platform \) , well two large open datasets acquired paradigm , act experimental baselines future research
time series learning using monotonic logical properties propose new paradigm time series learning users implicitly specify families signal shapes choosing monotonic parameterized signal predicates families predicates \( also called specifications \) seen infinite boolean feature vectors , able leverage user 's domain expertise property parameter values increase , specification becomes easier satisfy presence multiple parameters , monotonic specifications admit trade curves parameter space , akin pareto multi objective optimization , separate specifications satisfied satisfied monotonic specifications \( trade curves \) features time series data , develop principled way distance measure signals lens monotonic specification unique feature approach , simple boolean based monotonic specification used explain two traces \( sets traces \) given distance given simple enough specification , enables relaying high level two signals certain distance kind signals lie conclude demonstrating technique two case studies illustrate simple monotonic specifications used desirable distance measures
target based hyperspectral via generalized robust localizing targets interest given hyperspectral \( \) image applications ranging remote sensing surveillance task target detection leverages fact material object characteristic spectral response , depending upon composition different materials often correlated , matched filtering based approaches may appropriate case work , present technique localize targets interest based spectral also present corresponding recovery guarantees , leveraging recent theoretical results end , model image superposition low rank component dictionary sparse component , wherein dictionary consists priori known characteristic spectral responses target localize finally , analyze performance proposed approach via experimental validation real data classification task , compare related techniques
exploiting partially annotated data temporal relation extraction temporal relations \( \) events described natural language known labor intensive , total number quadratic number events result , small number documents typically annotated , limiting coverage various lexical semantic phenomena order improve existing approaches , one possibility make use readily available , partially annotated data \( p partial \) cover documents however , missing annotations p known , rather help , existing systems work case study exploring various usages p extraction results show despite missing annotations , p still useful supervision signal task within constrained bootstrapping learning framework system described system publicly available
coordination complexity small information large populations initiate study quantity call coordination complexity distributed optimization problem , information defining problem instance distributed among n parties , need choose action , jointly form solution optimization problem coordination complexity represents minimal amount information centralized coordinator , full knowledge problem instance , needs broadcast order coordinate n parties play nearly optimal solution r n show upper bounds coordination complexity problem imply existence good jointly differentially private algorithms solving problem , turn known upper bound price anarchy certain games dynamically changing populations r n show several results fully characterize coordination complexity problem computing many one matching bipartite graph giving almost matching lower upper bounds upper bound fact extends much generally , problem solving linearly separable convex program also give different upper bound technique , use bound coordination complexity nash equilibrium routing game , computing stable matching
ad blocking study performance privacy counter measures many internet rely advertising revenue however , users presence ads websites visit , data size ads often comparable actual content impact time , also internet user cases absence procedure , many users ad blocking browser extensions work , study performance popular ad large set news websites moreover , investigate benefits ad user privacy well mechanisms used websites counter finally , explore traffic overhead due ad
understanding top k sparsification distributed deep learning distributed stochastic gradient descent \( sgd \) algorithms widely deployed training large scale deep learning models , communication overhead among workers becomes new system bottleneck recently proposed gradient sparsification techniques , especially top k sparsification error compensation \( topk sgd \) , significantly reduce communication traffic without obvious impact model accuracy theoretical studies carried analyze convergence property topk sgd however , existing studies details top k operator gradient sparsification use relaxed bounds \( e g , exact bound random k \) analysis hence derived results cannot well describe real convergence performance topk sgd end , first study gradient distributions topk sgd training process extensive experiments theoretically derive bound top k operator finally , exploit property gradient distribution propose approximate top k selection algorithm , computing efficient gpus , improve scaling efficiency topk sgd significantly reducing computing overhead codes available url https url
removing local paper consider , , error interval vertices particular , study problem removing many local \( minima maxima \) possible terrain show removing minima maxima done optimally \( n log n \) time , terrain n vertices interestingly , however , removing minima maxima simultaneously np hard , even hard approximate within factor \( log log n \) unless p np moreover , show even simplified version problem vertices two different already np hard , result obtain proving hardness special case 2 disjoint connected subgraphs , problem received considerable attention graph algorithms community
beyond vector spaces compact data differentiable weighted graphs learning useful representations key ingredient success modern machine learning currently , representation learning mostly relies embedding data euclidean space however , recent work shown data domains better modeled non euclidean metric spaces , geometry result performance paper , aim inductive bias imposed embedding space geometry namely , propose map data general non vector metric spaces weighted graph shortest path distance design , graphs model arbitrary geometry proper configuration edges weights main contribution method learns weighted graph representation data end end gradient descent greater generality fewer model assumptions make powerful existing embedding based approaches confirm superiority method via extensive experiments wide range tasks , including classification , compression , collaborative filtering
efficient algorithm diameter graphs generated trees problem practical theoretical interest determine estimate diameter various families networks previously known estimate diameter graphs generated trees upper bound given cited paper \( \) work , first assess performance upper bound show every n , exists tree n vertices , difference upper bound true diameter value least n 4 r n evaluating upper bound takes time omega \( n ! \) paper , provide algorithm obtains estimate diameter , requires time \( n 2 \) furthermore , value obtained algorithm less equal previously known diameter upper bound improvement polynomial time , still performing least well previous bound , possible algorithm works directly tree n vertices require examining also provide tree value computed algorithm necessarily unique , important result examples quite rare families trees investigated far , possible values computed algorithm also upper bound diameter
concatenation non binary random linear codes maximum distance separable codes novel coding scheme introduced scheme consists parallel concatenation mds block code code , constructed field , f q performance concatenated coding scheme analyzed derivation tight bounds probability decoding failure function overhead shown concatenated scheme performs well codes channels characterized high erasure probabilities , whereas provide failure probabilities lower several orders magnitude moderate low erasure probabilities
2006 commercial spreadsheet review management summary provides outline commercial spreadsheet review process aim process ensure enhancement work spreadsheet acceptable level risk introducing new errors
near optimal small depth lower bounds small distance connectivity show depth circuit determining whether n node graph path length k must size n omega \( k 1 \) previous best circuit size lower bounds problem n k \( \( \) \) \( due beame , , \) n omega \( \( log k \) \) \( following recent formula size lower bound \) lower bound quite close optimal , since simple construction gives depth circuits size n \( k 2 \) problem \( bound even n k omega \( 1 \) would require proving undirected connectivity mathsf nc 1 \) r n proof reduction new lower bound size small depth circuits computing skewed variant functions important role classical circuit lower bounds , , h key ingredient proof required lower bound like functions use emph random projections , extension random restrictions recently employed random projections allow us obtain quantitative bounds employing simpler arguments , , previous works , , ,
neural network models paraphrase identification semantic textual similarity natural language inference question answering paper , analyze several neural network designs \( variations \) sentence pair modeling compare performance extensively across eight datasets , including paraphrase identification , semantic textual similarity , natural language inference , question answering tasks although models claimed state art performance , original papers often reported one two selected datasets provide systematic study show \( \) encoding contextual information lstm inter sentence interactions critical , \( ii \) tree lstm help much previously claimed surprisingly improves performance twitter datasets , \( iii \) enhanced sequential inference model best far larger datasets , pairwise word interaction model achieves best performance less data available release implementations open source toolkit
efficient decoding algorithms compute forward strategy address paper decoding aspects compute forward \( cf \) physical layer network coding strategy known original decoder cf asymptotically optimal however , performance gap optimal decoders practical settings still known work , develop assess performance novel decoding algorithms cf operating multiple access channel fading channel , analyze ml decoder develop novel approximation based decoding algorithm showed numerically outperform original cf decoder gaussian channel , investigate maximum \( map \) decoder derive novel map decoding metric develop practical decoding algorithms proved numerically outperform original one
composition operators matrix representation finite section method theoretical framework maps shapes paper theoretical foundation method functional maps , first presented 2012 , , solomon , field theory maps shapes show analyze method looking application theories composition operators , matrix tion operators separable spaces , theory finite section method three well known topics functional analysis applied task modelling correspondences shapes three dimensional space , concepts lead directly functional maps associated functional matrices mathematically spoken , functional maps composition operators two dimensional manifolds , functional matrices infinite matrix representations maps present introduction notion theoretical foundation functional framework theory matrix , especially composition operators also discuss two numerical methods solving equations operators , namely , two variants finite section method one , well known , leads system linear equations , second one minimum norm solution system computed present main convergence results related methods
statistical model checking probabilistic paper , propose temporal logic hyperpctl extends hyperpctl reason probabilistic allows expressing probabilistic nested temporal probability operators show hyperpctl express important probabilistic information flow security policies furthermore , first time , investigate statistical model checking \( smc \) algorithms hyperpctl specifications discrete time markov chains \( \) end , first study smc hyperpctl specifications non nested probability operators desired confidence significance level unlike existing smc algorithms based sequential probability ratio tests \( \) , use confidence interval avoid need priori knowledge margin , extend proposed smc algorithms hyperpctl specifications multiple probability operators nested different ways finally , evaluate proposed algorithms two examples , probabilistic causation
teaching learning uncertainty investigate simple model social learning two agents , teacher student teacher 's goal student state world however , teacher certain state world needs simultaneously learn parameter student model teacher 's student 's uncertainties via noisy transmission channels , employ two simple decoding strategies student focus two teaching strategies low effort strategy simply information , high effort strategy communicating teacher 's current best estimate world time instant , based cumulative learning using tools large deviation theory , calculate exact learning rates strategies demonstrate regimes low effort strategy outperforms high effort strategy primary technical contribution detailed analysis large deviation properties sign transient markov random walk mathbb z
far side cube game semantic models usually start core model language , range combinatorial constraints shape plays constraint usually corresponds introduction new language operation , feature game semantics commonly known combinatorial constraints , resulting general game model , game models live set understand game semantics , serve , complex , game models literature might also interesting right , instance game semantic paradigm
strategy non constructive many combinatorial games , one prove first player best play using simple non constructive argument called strategy work complexity behind proofs hard actually find winning move game , know strategy one exists \? prove problem hard already minimum games symmetric maker maker games , simple classes games capture two main types strategy arguments current literature
students patterns interaction mathematics intelligent learning analytics application purpose purpose paper determine potential students academic success foundation mathematics course analyzing data logs intelligent design methodology approach cross study design used sample 58 records extracted data logs intelligent , data data collected surveys two step clustering , correlation regression analysis , square analysis paired sample tests applied address research questions findings data logs include information number topics number topics student prior knowledge derived attribute , ratio number topics number topics \( denoted variable top paper \) found predictors final foundation mathematics course 42 students report way selecting topics either sequential random results paired sample test demonstrated students selected topics sequential manner able retain learning assessment whereas students topics randomly able retain learning value research established three indicators academic success course foundation mathematics using intelligent monitor students progress detect students risk able attain desired learning guide choose correct sequence topics
one explanation fit promise interactive explanations machine learning transparency need transparency predictive systems based machine learning algorithms arises consequence ever increasing proliferation industry whenever black box algorithmic predictions influence human , inner algorithms decisions explained relevant , including system engineers , system 's operators individuals whose case variety interpretability explainability methods available , satisfy diverse expectations competing objectives might required parties involved address challenge paper promises interactive machine learning improved transparency black box systems using example explanations state art approach interpretable machine learning r n specifically , show explanations adjusting conditional extract additional explanations asking follow \? questions experience building , deploying presenting type system allowed us list desired properties well potential limitations , used guide development interactive medium interaction , e , user interface various communication channels , may give personalisation , argue adjusting explanation content important end , properties , scope , context , purpose target explanation considered , addition explicitly limitations
user profile based research paper recommendation design recommender system research papers based topic modeling users feedback results used make results relevant next time query user 's needs understood observing change user shows preference time