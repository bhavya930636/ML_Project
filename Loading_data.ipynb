{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba98790-a314-4ddf-ae36-cafb153492c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjain/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.08 GB: 100%|███████████████████████| 81/81 [08:05<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/arxiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 7570.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 808.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# !pip install ogb\n",
    "# !pip install torch torchvision torchaudio\n",
    "# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
    "\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "dataset = PygNodePropPredDataset(name = \"ogbn-arxiv\") \n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "graph = dataset[0] # pyg graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf14d9cc-552d-4b64-b305-6d020ee7dcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Indices: tensor([     0,      1,      2,  ..., 169145, 169148, 169251])\n",
      "Validation Indices: tensor([   349,    357,    366,  ..., 169185, 169261, 169296])\n",
      "Test Indices: tensor([   346,    398,    451,  ..., 169340, 169341, 169342])\n",
      "Graph Object: Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Indices:\", train_idx)\n",
    "print(\"Validation Indices:\", valid_idx)\n",
    "print(\"Test Indices:\", test_idx)\n",
    "print(\"Graph Object:\", graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9dd5e7-0b6f-4632-999f-8ae3f19835d5",
   "metadata": {},
   "source": [
    "# train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a5dc4f-633f-41ed-8839-27c1c12965e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        node_id label\n",
      "169333   169333  test\n",
      "169334   169334  test\n",
      "169335   169335  test\n",
      "169336   169336  test\n",
      "169337   169337  test\n",
      "169338   169338  test\n",
      "169339   169339  test\n",
      "169340   169340  test\n",
      "169341   169341  test\n",
      "169342   169342  test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Create a DataFrame with all node IDs\n",
    "node_ids = torch.arange(graph.num_nodes)\n",
    "\n",
    "# Create labels for train/valid/test\n",
    "labels = ['train' if i in train_idx else 'valid' if i in valid_idx else 'test' if i in test_idx else 'unlabeled' for i in node_ids]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_traintest = pd.DataFrame({'node_id': node_ids.tolist(), 'label': labels})\n",
    "\n",
    "# Show the first few rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e799347e-5ac2-4535-88b7-8ce711a76dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "train    90941\n",
      "test     48603\n",
      "valid    29799\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_values = df_traintest['label'].value_counts()\n",
    "\n",
    "# Print the unique values and their counts\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac939ccf-a7de-423b-8bcf-4c31216f40ec",
   "metadata": {},
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12400700-ede7-4812-9247-3b5582ab0cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   node_id label\n",
      "0        0   [4]\n",
      "1        1   [5]\n",
      "2        2  [28]\n",
      "3        3   [8]\n",
      "4        4  [27]\n",
      "label\n",
      "[16]    27321\n",
      "[24]    22187\n",
      "[28]    21406\n",
      "[30]    11814\n",
      "[10]     7869\n",
      "[34]     7867\n",
      "[8]      6232\n",
      "[4]      5862\n",
      "[5]      4958\n",
      "[2]      4839\n",
      "[27]     4801\n",
      "[26]     4605\n",
      "[36]     3524\n",
      "[19]     2877\n",
      "[23]     2834\n",
      "[31]     2828\n",
      "[9]      2820\n",
      "[37]     2369\n",
      "[13]     2358\n",
      "[3]      2080\n",
      "[20]     2076\n",
      "[39]     2029\n",
      "[22]     1903\n",
      "[6]      1618\n",
      "[38]     1507\n",
      "[33]     1271\n",
      "[25]     1257\n",
      "[11]      750\n",
      "[18]      749\n",
      "[1]       687\n",
      "[14]      597\n",
      "[7]       589\n",
      "[0]       565\n",
      "[17]      515\n",
      "[29]      416\n",
      "[32]      411\n",
      "[15]      403\n",
      "[21]      393\n",
      "[35]      127\n",
      "[12]       29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "node_labels = graph.y # squeeze to remove unnecessary dimensions\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_labels = pd.DataFrame({'node_id': node_ids.tolist(), 'label': node_labels.tolist()})\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(df_labels.head())\n",
    "unique_values = df_labels['label'].value_counts()\n",
    "\n",
    "# Print the unique values and their counts\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45da07bb-fc8d-4508-b46a-edbf8ef40abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 169343\n",
      "Number of edges: 1166243\n",
      "Edge index shape: torch.Size([2, 1166243])\n",
      "First 5 edges:\n",
      " tensor([[104447,  15858, 107156, 107156, 107156],\n",
      "        [ 13091,  47283,  69161, 136440, 107366]])\n"
     ]
    }
   ],
   "source": [
    "# Check the number of nodes and edges\n",
    "num_nodes = graph.num_nodes\n",
    "num_edges = graph.num_edges\n",
    "print(f\"Number of nodes: {num_nodes}\")\n",
    "print(f\"Number of edges: {num_edges}\")\n",
    "\n",
    "# node_features = graph.x  # 'x' typically contains the node features\n",
    "# print(\"Node features shape:\", node_features.shape)\n",
    "# print(\"First 5 node features:\\n\", node_features[:5])\n",
    "\n",
    "# Edge index\n",
    "edge_index = graph.edge_index  # 'edge_index' contains the edges\n",
    "print(\"Edge index shape:\", edge_index.shape)\n",
    "print(\"First 5 edges:\\n\", edge_index[:, :5])  # First 5 edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd58e94-d0e5-4160-8a6f-f68b5d942f67",
   "metadata": {},
   "source": [
    "# Title and abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "008540f6-d63f-4e1b-83aa-a049d15a38bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200971</td>\n",
       "      <td>ontology as a source for rule generation</td>\n",
       "      <td>This paper discloses the potential of OWL (Web...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549074</td>\n",
       "      <td>a novel methodology for thermal analysis a 3 d...</td>\n",
       "      <td>The semiconductor industry is reaching a fasci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>630234</td>\n",
       "      <td>spreadsheets on the move an evaluation of mobi...</td>\n",
       "      <td>The power of mobile devices has increased dram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>803423</td>\n",
       "      <td>multi view metric learning for multi view vide...</td>\n",
       "      <td>Traditional methods on video summarization are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1102481</td>\n",
       "      <td>big data analytics in future internet of things</td>\n",
       "      <td>Current research on Internet of Things (IoT) m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper id                                              title  \\\n",
       "0    200971           ontology as a source for rule generation   \n",
       "1    549074  a novel methodology for thermal analysis a 3 d...   \n",
       "2    630234  spreadsheets on the move an evaluation of mobi...   \n",
       "3    803423  multi view metric learning for multi view vide...   \n",
       "4   1102481    big data analytics in future internet of things   \n",
       "\n",
       "                                            abstract  \n",
       "0  This paper discloses the potential of OWL (Web...  \n",
       "1  The semiconductor industry is reaching a fasci...  \n",
       "2  The power of mobile devices has increased dram...  \n",
       "3  Traditional methods on video summarization are...  \n",
       "4  Current research on Internet of Things (IoT) m...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_node_mapping = pd.read_csv('dataset/ogbn_arxiv/mapping/nodeidx2paperid.csv')  # nodeid to paperid mapping\n",
    "df_paper_data = pd.read_csv('new_titles_abstracts.tsv', sep='\\t')\n",
    "df_paper_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb598ad7-7c46-46f1-94cc-dc37be533ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node idx</th>\n",
       "      <th>paper id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9657784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39886162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>116214155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>121432379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>231147053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node idx   paper id\n",
       "0         0    9657784\n",
       "1         1   39886162\n",
       "2         2  116214155\n",
       "3         3  121432379\n",
       "4         4  231147053"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_node_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0675369d-94eb-410f-b47a-18640e862240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   node_id                                              title  \\\n",
      "0        0  evasion attacks against machine learning at te...   \n",
      "\n",
      "                                            abstract  \n",
      "0  In security-sensitive applications, the succes...  \n",
      "        node_id                                              title  \\\n",
      "169342   169342  fauras a proxy based framework for ensuring th...   \n",
      "\n",
      "                                                 abstract  \n",
      "169342  HTTP/2 video streaming has caught a lot of att...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Merge the two dataframes on 'paper_id'\n",
    "df_titleabs = pd.merge(df_node_mapping, df_paper_data, on='paper id', how='inner')\n",
    "\n",
    "# Step 3: Rename columns for clarity (optional)\n",
    "df_titleabs = df_titleabs.rename(columns={'node idx': 'node_id', 'title': 'title', 'abstract': 'abstract'})\n",
    "\n",
    "# Step 4: Show the first few rows of the new dataframe\n",
    "print(df_titleabs[['node_id', 'title', 'abstract']].head(1))\n",
    "\n",
    "print(df_titleabs[['node_id', 'title', 'abstract']].tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe7505-3653-4b86-b7fc-c253b4a3f5d1",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48f74bee-eeab-4bc9-9df2-1aebd044a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    f\"{row['title']} {row['abstract']}\"\n",
    "    for index, row in df_titleabs.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81d3e4be-19a8-4196-ad03-66c854b5b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    str(row['label'][0])  # Assuming the label is in a list and you want the first element\n",
    "    for index, row in df_labels.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bba13297-cb78-408d-a09a-5d154d13d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define the percentages for train, test, and validation\n",
    "train_percentage = 0.70  # 70% of the data in the training set\n",
    "val_percentage = 0.15    # 15% of the data in the validation set\n",
    "test_percentage = 0.15   # 15% of the data in the test set\n",
    "\n",
    "# Ensure percentages sum to 1\n",
    "assert train_percentage + val_percentage + test_percentage == 1, \"Percentages must sum to 1\"\n",
    "\n",
    "# Get the total number of rows in the data\n",
    "num_rows = len(df_traintest)\n",
    "\n",
    "# Generate a random list of indices\n",
    "indices = list(range(num_rows))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Calculate the number of rows for each split\n",
    "num_train = int(train_percentage * num_rows)\n",
    "num_val = int(val_percentage * num_rows)\n",
    "num_test = num_rows - num_train - num_val  # Remaining rows go to test\n",
    "\n",
    "# Assign each row to train, validation, or test\n",
    "train_indices = indices[:num_train]\n",
    "val_indices = indices[num_train:num_train + num_val]\n",
    "test_indices = indices[num_train + num_val:]\n",
    "\n",
    "train_or_test_list = []\n",
    "for i in range(num_rows):\n",
    "    if i in train_indices:\n",
    "        train_or_test_list.append('train')\n",
    "    elif i in val_indices:\n",
    "        train_or_test_list.append('val')\n",
    "    else:\n",
    "        train_or_test_list.append('test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc3dddaf-015e-4284-940e-ab50a8eaea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"evasion attacks against machine learning at test time In security-sensitive applications, the success of machine learning depends on a thorough vetting of their resistance to adversarial data. In one pertinent, well-motivated attack scenario, an adversary may attempt to evade a deployed system at test time by carefully manipulating attack samples. In this work, we present a simple but effective gradient-based approach that can be exploited to systematically assess the security of several, widely-used classification algorithms against evasion attacks. Following a recently proposed framework for security evaluation, we simulate attack scenarios that exhibit different risk levels for the classifier by increasing the attacker's knowledge of the system and her ability to manipulate attack samples. This gives the classifier designer a better picture of the classifier performance under evasion attacks, and allows him to perform a more informed model selection (or parameter setting). We evaluate our approach on the relevant security task of malware detection in PDF files, and show that such systems can be easily evaded. We also sketch some countermeasures suggested by our analysis.\", 'automatic traceability maintenance via machine learning classification Previous studies have shown that software traceability, the ability to link together related artifacts from different sources within a project (e.g., source code, use cases, documentation, etc.), improves project outcomes by assisting developers and other stakeholders with common tasks such as impact analysis, concept location, etc. Establishing traceability links in a software system is an important and costly task, but only half the struggle. As the project undergoes maintenance and evolution, new artifacts are added and existing ones are changed, resulting in outdated traceability information. Therefore, specific steps need to be taken to make sure that traceability links are maintained in tandem with the rest of the project. In this paper we address this problem and propose a novel approach called TRAIL for maintaining traceability information in a system. The novelty of TRAIL stands in the fact that it leverages previously captured knowledge about project traceability to train a machine learning classifier which can then be used to derive new traceability links and update existing ones. We evaluated TRAIL on 11 commonly used traceability datasets from six software systems and compared it to seven popular information Retrieval (IR) techniques including the most common approaches used in previous work. The results indicate that TRAIL outperforms all IR approaches in terms of precision, recall, and F-score.', 'evolving neural networks to follow trajectories of arbitrary complexity Abstract   Many experiments have been performed that use evolutionary algorithms for learning the topology and connection weights of a neural network that controls a robot or virtual agent. These experiments are not only performed to better understand basic biological principles, but also with the hope that with further progress of the methods, they will become competitive for automatically creating robot behaviors of interest. However, current methods are limited with respect to the (Kolmogorov) complexity of evolved behavior. Using the evolution of robot trajectories as an example, we show that by adding four features, namely (1) freezing of previously evolved structure, (2) temporal scaffolding, (3) a homogeneous transfer function for output nodes, and (4) mutations that create new pathways to outputs, to standard methods for the evolution of neural networks, we can achieve an approximately linear growth of the complexity of behavior over thousands of generations. Overall, evolved complexity is up to two orders of magnitude over that achieved by standard methods in the experiments reported here, with the major limiting factor for further growth being the available run time. Thus, the set of methods proposed here promises to be a useful addition to various current neuroevolution methods.', 'discriminative nonlinear analysis operator learning when cosparse model meets image classification A linear synthesis model-based dictionary learning framework has achieved remarkable performances in image classification in the last decade. Behaved as a generative feature model, it, however, suffers from some intrinsic deficiencies. In this paper, we propose a novel parametric nonlinear analysis cosparse model (NACM) with which a unique feature vector will be much more efficiently extracted. Additionally, we derive a deep insight to demonstrate that NACM is capable of simultaneously learning the task-adapted feature transformation and regularization to encode our preferences, domain prior knowledge, and task-oriented supervised information into the features. The proposed NACM is devoted to the classification task as a discriminative feature model and yield a novel discriminative nonlinear analysis operator learning framework (DNAOL). The theoretical analysis and experimental performances clearly demonstrate that DNAOL will not only achieve the better or at least competitive classification accuracies than the state-of-the-art algorithms, but it can also dramatically reduce the time complexities in both training and testing phases.']\n",
      "['4', '23', '13', '16']\n",
      "['train', 'train', 'train', 'test']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[::50000])\n",
    "print(labels[::50000])\n",
    "print(train_or_test_list[::50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "489f766b-8851-4542-b24b-4239d27de1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "#     f\"{row['title']} {row['abstract']}\"\n",
    "#     for index, row in df_titleabs.iterrows()\n",
    "# ]\n",
    "\n",
    "# # Prepare labels based on the df_labels\n",
    "# labels = [\n",
    "#     str(row['label'][0])  # Assuming the label is in a list and you want the first element\n",
    "#     for index, row in df_labels.iterrows()\n",
    "# ]\n",
    "\n",
    "# # Prepare train/test list based on df_traintest\n",
    "# train_or_test_list = [\n",
    "#     'train' if row['node_id'] < 169338 else 'test'  # Change this logic as per your requirements\n",
    "#     for index, row in df_traintest.iterrows()\n",
    "# ]\n",
    "\n",
    "# Prepare meta data\n",
    "meta_data_list = []\n",
    "for i in range(len(sentences)):\n",
    "    meta = f\"{i}\\t{train_or_test_list[i]}\\t{labels[i]}\"\n",
    "    meta_data_list.append(meta)\n",
    "\n",
    "meta_data_str = '\\n'.join(meta_data_list)\n",
    "\n",
    "# Write meta data to file\n",
    "with open(f'data/all_labels.txt', 'w') as f:\n",
    "    f.write(meta_data_str)\n",
    "\n",
    "# Write sentences (corpus) to file\n",
    "corpus_str = '\\n'.join(sentences)\n",
    "with open(f'data/corpus/all_corpus.txt', 'w') as f:\n",
    "    f.write(corpus_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b45067d-ff30-4ac5-a434-8ade44e2d618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0\\ttrain\\t4', '50000\\ttrain\\t23', '100000\\ttrain\\t13', '150000\\ttest\\t16']\n"
     ]
    }
   ],
   "source": [
    "print(meta_data_list[::50000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9571a5-1342-4b3f-b09b-e6efcfce3571",
   "metadata": {},
   "source": [
    "# class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ea6db-dccd-4c81-bdd4-a8ed3526ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33dea0b4-dd78-4e7a-a818-d1233fba3133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label idx arxiv category\n",
      "0          0    arxiv cs na\n",
      "1          1    arxiv cs mm\n",
      "2          2    arxiv cs lo\n",
      "3          3    arxiv cs cy\n",
      "4          4    arxiv cs cr\n",
      "Index(['label idx', 'arxiv category'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV dataset (replace 'your_file.csv' with the actual file path)\n",
    "df = pd.read_csv('dataset/ogbn_arxiv/mapping/labelidx2arxivcategeory.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Print the column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf353036-5e02-4f10-82df-4d6968417d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
