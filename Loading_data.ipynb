{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba98790-a314-4ddf-ae36-cafb153492c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ogb in /home/sjain/anaconda3/lib/python3.11/site-packages (1.3.6)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from ogb) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from ogb) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from ogb) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from ogb) (1.2.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from ogb) (2.1.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from ogb) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from ogb) (2.0.7)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from ogb) (0.2.2)\n",
      "Requirement already satisfied: setuptools>=44 in /home/sjain/anaconda3/lib/python3.11/site-packages (from outdated>=0.2.0->ogb) (68.2.2)\n",
      "Requirement already satisfied: littleutils in /home/sjain/anaconda3/lib/python3.11/site-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
      "Requirement already satisfied: requests in /home/sjain/anaconda3/lib/python3.11/site-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sjain/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sjain/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.0->ogb) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sjain/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.0->ogb) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/sjain/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/sjain/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.20.0->ogb) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.20.0->ogb) (2.2.0)\n",
      "Requirement already satisfied: filelock in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (1.12)\n",
      "Requirement already satisfied: networkx in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/sjain/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->ogb) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sjain/anaconda3/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sjain/anaconda3/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sjain/anaconda3/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/sjain/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
      "Requirement already satisfied: torch in /home/sjain/anaconda3/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in /home/sjain/anaconda3/lib/python3.11/site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in /home/sjain/anaconda3/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/sjain/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: numpy in /home/sjain/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/sjain/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torch-scatter in /home/sjain/anaconda3/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: torch-sparse in /home/sjain/anaconda3/lib/python3.11/site-packages (0.6.18)\n",
      "Requirement already satisfied: torch-cluster in /home/sjain/anaconda3/lib/python3.11/site-packages (1.6.3)\n",
      "Requirement already satisfied: torch-spline-conv in /home/sjain/anaconda3/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: torch-geometric in /home/sjain/anaconda3/lib/python3.11/site-packages (2.6.1)\n",
      "Requirement already satisfied: scipy in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch-sparse) (1.11.4)\n",
      "Requirement already satisfied: aiohttp in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch-geometric) (3.9.3)\n",
      "Requirement already satisfied: fsspec in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch-geometric) (2023.10.0)\n",
      "Requirement already satisfied: jinja2 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/sjain/anaconda3/lib/python3.11/site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sjain/anaconda3/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sjain/anaconda3/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sjain/anaconda3/lib/python3.11/site-packages (from aiohttp->torch-geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.9.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sjain/anaconda3/lib/python3.11/site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sjain/anaconda3/lib/python3.11/site-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sjain/anaconda3/lib/python3.11/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sjain/anaconda3/lib/python3.11/site-packages (from requests->torch-geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sjain/anaconda3/lib/python3.11/site-packages (from requests->torch-geometric) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjain/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# !pip install ogb\n",
    "# !pip install torch torchvision torchaudio\n",
    "# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
    "\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "dataset = PygNodePropPredDataset(name = \"ogbn-arxiv\") \n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "graph = dataset[0] # pyg graph object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9dd5e7-0b6f-4632-999f-8ae3f19835d5",
   "metadata": {},
   "source": [
    "# train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a5dc4f-633f-41ed-8839-27c1c12965e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        node_id label\n",
      "169338   169338  test\n",
      "169339   169339  test\n",
      "169340   169340  test\n",
      "169341   169341  test\n",
      "169342   169342  test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Create a DataFrame with all node IDs\n",
    "node_ids = torch.arange(graph.num_nodes)\n",
    "\n",
    "# Create labels for train/valid/test\n",
    "labels = ['train' if i in train_idx else 'valid' if i in valid_idx else 'test' if i in test_idx else 'unlabeled' for i in node_ids]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_traintest = pd.DataFrame({'node_id': node_ids.tolist(), 'label': labels})\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(df_traintest.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac939ccf-a7de-423b-8bcf-4c31216f40ec",
   "metadata": {},
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12400700-ede7-4812-9247-3b5582ab0cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   node_id label\n",
      "0        0   [4]\n",
      "1        1   [5]\n",
      "2        2  [28]\n",
      "3        3   [8]\n",
      "4        4  [27]\n"
     ]
    }
   ],
   "source": [
    "node_labels = graph.y # squeeze to remove unnecessary dimensions\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_labels = pd.DataFrame({'node_id': node_ids.tolist(), 'label': node_labels.tolist()})\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(df_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45da07bb-fc8d-4508-b46a-edbf8ef40abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 169343\n",
      "Number of edges: 1166243\n",
      "Node labels shape: torch.Size([169343, 1])\n",
      "First 5 node labels:\n",
      " tensor([[ 4],\n",
      "        [ 5],\n",
      "        [28],\n",
      "        [ 8],\n",
      "        [27]])\n",
      "Edge index shape: torch.Size([2, 1166243])\n",
      "First 5 edges:\n",
      " tensor([[104447,  15858, 107156, 107156, 107156],\n",
      "        [ 13091,  47283,  69161, 136440, 107366]])\n"
     ]
    }
   ],
   "source": [
    "# Check the number of nodes and edges\n",
    "num_nodes = graph.num_nodes\n",
    "num_edges = graph.num_edges\n",
    "print(f\"Number of nodes: {num_nodes}\")\n",
    "print(f\"Number of edges: {num_edges}\")\n",
    "\n",
    "# node_features = graph.x  # 'x' typically contains the node features\n",
    "# print(\"Node features shape:\", node_features.shape)\n",
    "# print(\"First 5 node features:\\n\", node_features[:5])\n",
    "\n",
    "# Node labels\n",
    "node_labels = graph.y  # 'y' typically contains the node labels\n",
    "print(\"Node labels shape:\", node_labels.shape)\n",
    "print(\"First 5 node labels:\\n\", node_labels[:5])\n",
    "\n",
    "# Edge index\n",
    "edge_index = graph.edge_index  # 'edge_index' contains the edges\n",
    "print(\"Edge index shape:\", edge_index.shape)\n",
    "print(\"First 5 edges:\\n\", edge_index[:, :5])  # First 5 edges\n",
    "\n",
    "\n",
    "# Find all unique node labels\n",
    "# unique_labels = torch.unique(node_labels)\n",
    "\n",
    "# Print the unique labels\n",
    "# print(\"Unique node labels:\", unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd58e94-d0e5-4160-8a6f-f68b5d942f67",
   "metadata": {},
   "source": [
    "# Title and abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "008540f6-d63f-4e1b-83aa-a049d15a38bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200971</td>\n",
       "      <td>ontology as a source for rule generation</td>\n",
       "      <td>This paper discloses the potential of OWL (Web...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549074</td>\n",
       "      <td>a novel methodology for thermal analysis a 3 d...</td>\n",
       "      <td>The semiconductor industry is reaching a fasci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>630234</td>\n",
       "      <td>spreadsheets on the move an evaluation of mobi...</td>\n",
       "      <td>The power of mobile devices has increased dram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>803423</td>\n",
       "      <td>multi view metric learning for multi view vide...</td>\n",
       "      <td>Traditional methods on video summarization are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1102481</td>\n",
       "      <td>big data analytics in future internet of things</td>\n",
       "      <td>Current research on Internet of Things (IoT) m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper id                                              title  \\\n",
       "0    200971           ontology as a source for rule generation   \n",
       "1    549074  a novel methodology for thermal analysis a 3 d...   \n",
       "2    630234  spreadsheets on the move an evaluation of mobi...   \n",
       "3    803423  multi view metric learning for multi view vide...   \n",
       "4   1102481    big data analytics in future internet of things   \n",
       "\n",
       "                                            abstract  \n",
       "0  This paper discloses the potential of OWL (Web...  \n",
       "1  The semiconductor industry is reaching a fasci...  \n",
       "2  The power of mobile devices has increased dram...  \n",
       "3  Traditional methods on video summarization are...  \n",
       "4  Current research on Internet of Things (IoT) m...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_node_mapping = pd.read_csv('dataset/ogbn_arxiv/mapping/nodeidx2paperid.csv')  # nodeid to paperid mapping\n",
    "df_paper_data = pd.read_csv('new_titles_abstracts.tsv', sep='\\t')\n",
    "df_paper_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb598ad7-7c46-46f1-94cc-dc37be533ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node idx</th>\n",
       "      <th>paper id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9657784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39886162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>116214155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>121432379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>231147053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node idx   paper id\n",
       "0         0    9657784\n",
       "1         1   39886162\n",
       "2         2  116214155\n",
       "3         3  121432379\n",
       "4         4  231147053"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_node_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0675369d-94eb-410f-b47a-18640e862240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   node_id                                              title  \\\n",
      "0        0  evasion attacks against machine learning at te...   \n",
      "1        1  how hard is computing parity with noisy commun...   \n",
      "2        2  on the absence of the rip in real world applic...   \n",
      "3        3      a promise theory perspective on data networks   \n",
      "4        4  analysis of asymptotically optimal sampling ba...   \n",
      "\n",
      "                                            abstract  \n",
      "0  In security-sensitive applications, the succes...  \n",
      "1  We show a tight lower bound of $\\Omega(N \\log\\...  \n",
      "2  The purpose of this paper is twofold. The firs...  \n",
      "3  Networking is undergoing a transformation thro...  \n",
      "4  Over the last 20 years significant effort has ...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Merge the two dataframes on 'paper_id'\n",
    "df_titleabs = pd.merge(df_node_mapping, df_paper_data, on='paper id', how='inner')\n",
    "\n",
    "# Step 3: Rename columns for clarity (optional)\n",
    "df_titleabs = df_titleabs.rename(columns={'node idx': 'node_id', 'title': 'title', 'abstract': 'abstract'})\n",
    "\n",
    "# Step 4: Show the first few rows of the new dataframe\n",
    "print(df_titleabs[['node_id', 'title', 'abstract']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe7505-3653-4b86-b7fc-c253b4a3f5d1",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "489f766b-8851-4542-b24b-4239d27de1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    f\"{row['title']} {row['abstract']}\"\n",
    "    for index, row in df_titleabs.iterrows()\n",
    "]\n",
    "\n",
    "# Prepare labels based on the df_labels\n",
    "labels = [\n",
    "    str(row['label'][0])  # Assuming the label is in a list and you want the first element\n",
    "    for index, row in df_labels.iterrows()\n",
    "]\n",
    "\n",
    "# Prepare train/test list based on df_traintest\n",
    "train_or_test_list = [\n",
    "    'train' if row['node_id'] < 169338 else 'test'  # Change this logic as per your requirements\n",
    "    for index, row in df_traintest.iterrows()\n",
    "]\n",
    "\n",
    "# Prepare meta data\n",
    "meta_data_list = []\n",
    "for i in range(len(sentences)):\n",
    "    meta = f\"{i}\\t{train_or_test_list[i]}\\t{labels[i]}\"\n",
    "    meta_data_list.append(meta)\n",
    "\n",
    "meta_data_str = '\\n'.join(meta_data_list)\n",
    "\n",
    "# Write meta data to file\n",
    "with open(f'data/graph_node_labels.txt', 'w') as f:\n",
    "    f.write(meta_data_str)\n",
    "\n",
    "# Write sentences (corpus) to file\n",
    "corpus_str = '\\n'.join(sentences)\n",
    "with open(f'data/corpus/graph_node_corpus.txt', 'w') as f:\n",
    "    f.write(corpus_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b45067d-ff30-4ac5-a434-8ade44e2d618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0\\ttrain\\t4', '1\\ttrain\\t5', '2\\ttrain\\t28', '3\\ttrain\\t8', '4\\ttrain\\t27']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"evasion attacks against machine learning at test time In security-sensitive applications, the success of machine learning depends on a thorough vetting of their resistance to adversarial data. In one pertinent, well-motivated attack scenario, an adversary may attempt to evade a deployed system at test time by carefully manipulating attack samples. In this work, we present a simple but effective gradient-based approach that can be exploited to systematically assess the security of several, widely-used classification algorithms against evasion attacks. Following a recently proposed framework for security evaluation, we simulate attack scenarios that exhibit different risk levels for the classifier by increasing the attacker's knowledge of the system and her ability to manipulate attack samples. This gives the classifier designer a better picture of the classifier performance under evasion attacks, and allows him to perform a more informed model selection (or parameter setting). We evaluate our approach on the relevant security task of malware detection in PDF files, and show that such systems can be easily evaded. We also sketch some countermeasures suggested by our analysis.\",\n",
       " 'how hard is computing parity with noisy communications We show a tight lower bound of $\\\\Omega(N \\\\log\\\\log N)$ on the number of transmissions required to compute the parity of $N$ input bits with constant error in a noisy communication network of $N$ randomly placed sensors, each having one input bit and communicating with others using local transmissions with power near the connectivity threshold. This result settles the lower bound question left open by Ying, Srikant and Dullerud (WiOpt 06), who showed how the sum of all the $N$ bits can be computed using $O(N \\\\log\\\\log N)$ transmissions. The same lower bound has been shown to hold for a host of other functions including majority by Dutta and Radhakrishnan (FOCS 2008). #R##N#Most works on lower bounds for communication networks considered mostly the full broadcast model without using the fact that the communication in real networks is local, determined by the power of the transmitters. In fact, in full broadcast networks computing parity needs $\\\\theta(N)$ transmissions. To obtain our lower bound we employ techniques developed by Goyal, Kindler and Saks (FOCS 05), who showed lower bounds in the full broadcast model by reducing the problem to a model of noisy decision trees. However, in order to capture the limited range of transmissions in real sensor networks, we adapt their definition of noisy decision trees and allow each node of the tree access to only a limited part of the input. Our lower bound is obtained by exploiting special properties of parity computations in such noisy decision trees.',\n",
       " \"on the absence of the rip in real world applications of compressed sensing and the rip in levels The purpose of this paper is twofold. The first is to point out that the Restricted Isometry Property (RIP) does not hold in many applications where compressed sensing is successfully used. This includes fields like Magnetic Resonance Imaging (MRI), Computerized Tomography, Electron Microscopy, Radio Interferometry and Fluorescence Microscopy. We demonstrate that for natural compressed sensing matrices involving a level based reconstruction basis (e.g. wavelets), the number of measurements required to recover all $s$-sparse signals for reasonable $s$ is excessive. In particular, uniform recovery of all $s$-sparse signals is quite unrealistic. This realisation shows that the RIP is insufficient for explaining the success of compressed sensing in various practical applications. The second purpose of the paper is to introduce a new framework based on a generalised RIP-like definition that fits the applications where compressed sensing is used. We show that the shortcomings that show that uniform recovery is unreasonable no longer apply if we instead ask for structured recovery that is uniform only within each of the levels. To examine this phenomenon, a new tool, termed the 'Restricted Isometry Property in Levels' is described and analysed. Furthermore, we show that with certain conditions on the Restricted Isometry Property in Levels, a form of uniform recovery within each level is possible. Finally, we conclude the paper by providing examples that demonstrate the optimality of the results obtained.\",\n",
       " \"a promise theory perspective on data networks Networking is undergoing a transformation throughout our industry. The shift from hardware driven products with ad hoc control to Software Defined Networks is now well underway. In this paper, we adopt the perspective of the Promise Theory to examine the current state of networking technologies so that we might see beyond specific technologies to principles for building flexible and scalable networks. Today's applications are increasingly distributed planet-wide in cloud-like hosting environments. Promise Theory's bottom-up modelling has been applied to server management for many years and lends itself to principles of self-healing, scalability and robustness.\",\n",
       " \"analysis of asymptotically optimal sampling based motion planning algorithms for lipschitz continuous dynamical systems Over the last 20 years significant effort has been dedicated to the development of sampling-based motion planning algorithms such as the Rapidly-exploring Random Trees (RRT) and its asymptotically optimal version (e.g. RRT*). However, asymptotic optimality for RRT* only holds for linear and fully actuated systems or for a small number of non-linear systems (e.g. Dubin's car) for which a steering function is available. The purpose of this paper is to show that asymptotically optimal motion planning for dynamical systems with differential constraints can be achieved without the use of a steering function. We develop a novel analysis on sampling-based planning algorithms that sample the control space. This analysis demonstrated that asymptotically optimal path planning for any Lipschitz continuous dynamical system can be achieved by sampling the control space directly. We also determine theoretical bounds on the convergence rates for this class of algorithms. As the number of iterations increases, the trajectory generated by these algorithms, approaches the optimal control trajectory, with probability one. Simulation results are promising.\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(meta_data_list[:5])\n",
    "(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9571a5-1342-4b3f-b09b-e6efcfce3571",
   "metadata": {},
   "source": [
    "# class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ea6db-dccd-4c81-bdd4-a8ed3526ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33dea0b4-dd78-4e7a-a818-d1233fba3133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label idx arxiv category\n",
      "0          0    arxiv cs na\n",
      "1          1    arxiv cs mm\n",
      "2          2    arxiv cs lo\n",
      "3          3    arxiv cs cy\n",
      "4          4    arxiv cs cr\n",
      "Index(['label idx', 'arxiv category'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV dataset (replace 'your_file.csv' with the actual file path)\n",
    "df = pd.read_csv('dataset/ogbn_arxiv/mapping/labelidx2arxivcategeory.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Print the column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf353036-5e02-4f10-82df-4d6968417d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
