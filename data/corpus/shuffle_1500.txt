towards reliable automated general movement assessment screening infants using wearable \( ps \) serious condition , thus , often leads life long , particular \( cp \) clinical settings , 's general movement assessment \( \) used classify movements using approach , identifying infants high risk developing ps training maintenance assessment skills essential expensive correct use , yet many practitioners lack skills , preventing larger scale screening leading significant missing opportunities early detection intervention affected infants present automated approach , based body novel sensor data analysis method discriminative pattern discovery \( \) designed cope scenarios coarse annotations data available model training demonstrate effectiveness approach study 34 \( 21 typically developing infants 13 ps infants abnormal movements \) method able correctly trials abnormal movements least accuracy required newly trained human annotators \( 75 \) , encouraging towards goal automated ps screening system used population wide
performance visible light communications systems non orthogonal multiple access visible light communications \( vlc \) recently proposed promising efficient solution indoor ubiquitous connectivity paper , non orthogonal multiple access , recently proposed effective scheme fifth generation \( 5g \) wireless networks , considered context vlc systems , different channel uncertainty models end , first derive novel closed form expression bit error rate \( ber \) perfect channel state information \( csi \) , quantify effect noisy csi deriving simple approximated expression former tight upper bound latter offered results respective results extensive monte carlo simulations used provide useful insights effect imperfect csi knowledge system performance shown , noisy csi leads slight degradation ber performance , csi cause performance degradation order users' channel gains change result mobility
attention attention architectures visual question answering vqa visual question answering \( vqa \) increasingly popular topic deep learning research , requiring coordination natural language processing computer vision modules single architecture build upon model placed first vqa challenge developing new attention mechanisms introducing simplified classifier performed gpu hours extensive architecture searches able achieve evaluation score 64 , outperforming existing state art single model 's validation score 63 15
covert communication adversarially channels consider situation transmitter alice may wish communicate receiver bob adversarial channel active adversary communication binary symmetric channel \( \( q \) \) , may \( \) certain fraction p transmitted bits communication covert reliable requires adversary unable estimate whether alice communicating based noisy observations , reliability requires receiver bob able correctly recover alice 's message high probability unlike setting passive adversaries considered thus far literature , show reliable covert communication presence actively jamming adversaries requires alice bob shared key \( unknown \) optimal throughput depends size key 1 \) alice bob 's shared key less 0 \( n \) bits , communication simultaneously covert reliable possible , shared key larger \( n \) , optimal throughput scales \( sqrt n \) explicitly characterize even constant factor \( matching inner outer bounds \) wide range parameters interest 2 \) alice bob large amount \( omega \( sqrt n \) bits \) shared key , present tight covert capacity characterization parameters interest 3 \) size shared key moderate \( \( omega \( log \( n \) \) , \( sqrt n \) \) \) , show achievable coding scheme well outer bound information theoretically optimal throughput 4 \) alice bob 's shared key \( sqrt n log \( n \) \) bits , develop computationally efficient coding scheme alice bob whose throughput constant factor smaller information theoretically optimal
wireless communications symbol generation nano iot enables wide range ground breaking technologies , face implementation challenges due scale space restrictions pose severe power supply considerations , point packet transmissions sufficient state art turn , difficulties developing efficient protocols even basic operations , addressing routing present work proposes new network architecture address challenges generate packets , hence , need corresponding transmission power consumption instead , relies external symbol generator incoming symbols , intended messages appear symbol stream short \( 1 bit \) , low energy pulse neighboring nodes shown exhibit \( even battery less \) operation , ability operate without medium access control , completely applications moreover , operation event driven , allowing clock less implementations new evaluated simulated multi hop nano iot network shown offer nearly perfect packet delivery rates practically collisions , congestion level
secure integration vehicles power grid paper focuses secure integration distributed energy resources \( \) , especially vehicles \( \) , power grid consider vehicle grid \( \) system connected power grid paper , propose novel cyber physical anomaly detection engine system behavior anomalies almost detection engine ensures critical power grid component \( , \) remains secure monitoring \( \) cyber messages various state changes data constraints along \( b \) power data cyber network using power measurements sensors physical power distribution network since system time sensitive , anomaly detection engine also timing requirements protocol messages enhance safety best knowledge , first piece work combines \( \) protocols , \( b \) cyber network \( c \) power measurements physical network detect power grid system
social events time varying mobile phone graph large scale study human mobility significantly enhanced last decade massive use mobile phones urban populations studying activity mobile phones allows us , infer social networks individuals , also observe movements individuals space time work , investigate two related sources information integrated within context detecting analyzing large social events show large social events characterized anomalous increase activity antennas neighborhood event , also increase social relationships present event moreover , detected large social event via increased antenna activity , use network connections infer whether user present event precisely , address following three challenges \( \) automatically detecting large social events via increased antenna activity \( ii \) characterizing social detected event \( iii \) analyzing feasibility inferring whether users event
approach mitigating attacks based low power lossy networks routing protocol low power lossy networks \( \) existing routing protocol internet things \( iot \) proactive , lightweight , distance vector protocol offers security various forms routing attacks still , various attacks \( rank , version attacks many \) possible network due problem control frames , centralized root controller , devices many ways various solutions present literature every solution appropriate system framework completely solves issues , present approach mitigate attacks efficiently effectively use based system internal attacks mini removing external attacks based approach , use detection system multiple locations analyzing behaviour nodes final decision whether node attacker depends mainly three things trust nodes , local decision multiple sink nodes global decision root node also use blockchain features framework better internal security use threshold values rules mini removing external attacks paper , provide proposed approach theoretical analysis approach provide better protection attacks method
generative latent flow work , propose generative latent flow \( \) , algorithm generative modeling data distribution uses auto encoder \( ae \) learn latent representations data , flow map distribution latent variables simple noise contrast auto encoder based generative models , use various encourage encoded latent distribution match prior distribution , model explicitly constructs mapping two distributions , leading better density matching avoiding latent variables compare model several related techniques , show many relative advantages including fast convergence , single stage training minimal reconstruction trade also study relationship model stochastic counterpart , show model viewed vanishing noise limit flow prior quantitatively , standardized evaluations , method achieves state art sample quality among ae based models commonly used datasets , competitive benchmarks
exploiting parallelism opportunities deep learning frameworks state art machine learning frameworks support wide variety design features enable flexible machine learning programming interface programmability burden machine learning developers identifying using performance optimal setting feature rich frameworks , however , involves non trivial amount performance characterization domain specific knowledge paper takes deep analyzing performance impact key design features role parallelism observations insights simple set one use achieve much higher training inference speedup evaluation results show proposed performance tuning outperform intel settings 1 1 , respectively , across diverse set real world deep learning models
quantifying information overload social media impact social information overload become ubiquitous problem modern society social media users receive flow information , often rate far higher cognitive process information paper , conduct large scale quantitative study information overload evaluate impact information dissemination twitter social media site model social media users information processing systems queue incoming information according policies , process information queue unknown rates decide forward incoming information users show data tweets received users used uncover key properties policies estimate information processing rates limits understanding users' information processing behaviors allows us infer whether extent users suffer information overload r n analysis provides empirical evidence information processing limits social media users information active popular social media users often ones moreover , find rate users receive information impacts processing behavior , including information different sources , much information process , quickly process information finally , social media user social depends crucially rate receives information exposure piece information , idea , product , much less effective users receive information higher rates , meaning need adopt particular
sentiment analysis news recent years brought significant growth volume research sentiment analysis , mostly highly subjective text types \( movie product reviews \) main difference texts news articles target clearly defined unique across text following different annotation efforts analysis issues encountered , news opinion mining different text types identified three need addressed definition target separation good bad news content good bad sentiment expressed target analysis clearly marked opinion expressed explicitly , interpretation use world knowledge furthermore , distinguish three different possible views articles author , reader text , addressed differently time sentiment given definitions , present work mining entities english language news , \( \) test relative suitability various sentiment dictionaries \( b \) attempt separate positive negative opinion good bad news experiments described , tested whether subject domain defining vocabulary results showed idea appropriate context news opinion mining approaches taking consideration produce better performance
system interaction structure article introduces logical system , called , extends multiplicative linear logic self dual logical operator extension particularly challenging calculus , far , achieved becomes natural new formalism , called calculus structures , main contribution work structures formulas subject certain laws typical calculus structures obtained generalizing calculus way new top symmetry observed , employs inference rules inside structures depth properties , addition allowing design , yield modular proof cut elimination
bounded contention coding wireless networks high snr regime efficient communication wireless networks typically possibility interference among several transmitting nodes much important research decreasing number collisions order obtain faster algorithms communication networks r n paper proposes novel approach wireless communication , collisions rather avoiding , additive channel introduces coding technique called bounded contention coding \( bcc \) allows collisions successfully decoded nodes original transmissions whose complexity depends bound contention among transmitters r n bcc enables deterministic local broadcast network n nodes transmitters information l bits within \( log n al \) bits communication full duplex , \( \( log n al \) \( log n \) \) bits , high probability , half duplex combined random linear network coding , bcc gives global broadcast within \( \( log n \) \( log n l \) \) bits , high probability also holds dynamic networks change arbitrarily time worst case adversary bound contention given , shown estimate obtain global broadcast adaptive true contention network
precisely null space conditions compressed sensing algorithm paper , propose new efficient algorithms verify null space condition compressed sensing \( cs \) given \( n \) times n \( 0 \) cs matrix positive k , interested computing alpha k max z 0 , z 0 max k k leq k z k 1 z 1 , k represents subsets 1 , 2 , , n , k cardinality k particular , interested finding maximum k alpha k 1 2 however , computing alpha k known extremely challenging paper , first propose series new polynomial time algorithms compute upper bounds alpha k based new polynomial time algorithms , design new algorithm , compute emph exact alpha k greatly reduced complexity needed , new algorithm also achieves smooth tradeoff computational complexity result accuracy empirical results show performance improvements algorithm existing known methods algorithm outputs precise values alpha k , much lower complexity exhaustive search
denoising auto encoder deep directed generative model recent work \( et al , 2013 \) shown auto encoders \( \) become models density estimator however , practice , framework suffers mcmc sampling process method estimate test log likelihood consider directed model identity mapping \( simple corruption \) inference model model mod els , propose denoising auto encoders \( \) generate samples distribution tractable prior assumption probabilistic tion corrupted data approaches tractable level corruption increases work tries answer two questions hand , deep directed models success fully trained without intractable posterior infer difficult optimization deep networks inference generative mod els \? recent directed model like vae \( , 2014 \) trained complex dataset images hand , samples data distribution samples considered prior distribution far data fold \? called global denoising scheme results show positive responses work provide fairly generative models com dataset
dynamic power splitting policies af relay networks wireless energy harvesting wireless energy harvesting \( \) provides way supply energy relay nodes forward information source destination pairs paper , investigate problem relay node dynamically power splitting ratio information transmission \( \) energy harvesting \( eh \) order achieve optimal outage performance according knowledge channel state information \( csi \) relay , optimal dynamic power splitting policy full csi partial csi provided finally , simulations , proposed power splitting policies improve outage performances policy full csi achieves best performance also shown policy partial csi approach policy full csi closely incurs far less system overhead
unsupervised domain adaptation self supervision paper addresses unsupervised domain adaptation , setting labeled training data available source domain , goal good performance target domain unlabeled data like much previous work , seek align learned representations source target domains preserving way alignment learning perform auxiliary self supervised task \( \) domains simultaneously self supervised task brings two domains closer together along direction relevant task training jointly main task classifier source domain shown successfully generalize unlabeled target domain presented objective implement easy optimize achieve state art results four seven standard benchmarks , competitive results segmentation adaptation also demonstrate method well another popular pixel level adaptation method
layout end end layout recovery 360 images problem 3d layout recovery indoor scenes core research topic decade however , still several major challenges remain among relevant ones , major part state art methods make implicit explicit assumptions scenes e g box shaped also , current methods computationally expensive suitable real time applications like robot navigation work present \( layout \) , first end end model 3d layout recovery 360 images experimental results show outperform state art assumptions scene lower cost also show model generalizes better camera position variations conventional approaches using , type convolution applied directly sphere projection hence invariant distortions r n https url
learning boolean small weights membership queries consider problem proper learning boolean integer weights 0 , 1 , ldots , membership queries best known algorithm problem adaptive algorithm asks n \( 5 \) membership queries best lower bound number membership queries n learning threshold functions small weights using membership queries r n paper close gap give adaptive proper learning algorithm two rounds asks n \( \) membership queries also give non adaptive proper learning algorithm asks n \( 3 \) membership queries
using regular chains library build algebraic decompositions lifting algebraic decomposition \( cad \) important tool , quantifier elimination range applications traditionally , cad built process projection lifting move problem within euclidean spaces changing dimension recently , alternative approach first complex space using triangular decomposition real space introduced implemented within library describe freely available package within library build projection lifting detail projection lifting algorithms modified allow , discuss motivation survey functionality package
generative adversarial networks estimation distribution algorithms combinatorial optimization estimation distribution algorithms \( \) require flexible probability models efficiently learned sampled generative adversarial networks \( gan \) generative neural networks trained implicitly model probability distribution given data , possible sample distribution integrate gan evaluate performance system solving combinatorial optimization problems single objective use several standard benchmark problems compare results state art multivariate gan yield competitive results gan lacks ability quickly learn good approximation probability distribution key reason seems large amount noise present first generations
adaptive transmission scheme wireless sensor networks 4 abstract reduced energy consumption sensor nodes one major challenges wireless sensor networks \( wsns \) deployment regard , error control coding \( \) one techniques used energy optimization wsns similarly , critical distance another term used energy efficiency , used provides better results energy saving paper three different critical distance values used different coding gains energy saving distance lies critical distance values particular encoders selected respect particular coding gains coding gains used critical distances estimation encoders adaptive encoder transmit power selection scheme respect coding gain results significant energy saving wsns environment simulations provide better results energy saving achieved using adaptive scheme
extracting 3d structures images using convolutional recurrent networks known key biological significance , especially study cancer , considerable effort focused automated measurement analysis medical pre clinical images particular , networks may extremely irregular appearance individual may conform classical descriptions appearance typically , extracted either segmentation pipeline , direct tracking neither methods well suited images tumor order address propose method directly extract representation using convolutional neural networks show two dimensional extended 3d complex images using recently convolutional long short term memory units \( \) demonstrate effectiveness hybrid convolutional recurrent architecture 2d 3d convolutional
using tree structures approximate belief networks tree structures shown provide efficient framework propagating pearl , paper studies problem finding optimal approximating tree star decomposition scheme sets three binary variables , pearl , shown enhance class probability distributions support tree structures structures called tree structures scoring rule found appropriate optimality criterion evaluate different tree structures characteristics structures closest actual belief network identified using rule , greedy exact techniques developed find optimal approximation
flows novelty detection industrial time series data flow based deep generative models learn data distributions transforming simple base distribution complex distribution via set transformations due , models score unseen data samples computing exact likelihood learned distribution makes flow based models perfect tool novelty detection , anomaly detection technique unseen data samples classified normal abnormal scoring learned model normal data show flows used novelty detectors time series two flow based models , masked autoregressive flows free form dynamics restricted autoregressive made networks , tested synthetic data motor current data industrial machine achieve good results , outperforming conventional novelty detection method , local outlier factor
caching rental cost zapping emph file caching problem defined follows given cache size k \( positive integer \) , goal minimize total retrieval cost given sequence requests files file f size size \( f \) \( positive integer \) retrieval cost cost \( f \) \( non negative number \) file cache emph emph fault occurs requested file cache file cache paying retrieval cost , file may removed \( emph \) cache total size files cache exceed k r n study following variants online file caching problem emph caching rental cost \( emph rental caching \) rental cost lambda \( positive number \) file cache time unit goal minimize sum retrieval costs rental costs emph caching zapping file emph paying zapping cost n 1 file , future requests file n't incur cost goal minimize sum retrieval costs zapping costs r n study two variants also variant combines two \( rental caching zapping \) present deterministic lower upper bounds competitive analysis framework study extend online covering algorithm give deterministic online algorithms also present randomized lower upper bounds problems
lower bounds information complexity via zero communication protocols applications show almost known lower bound methods communication complexity also lower bounds information complexity particular , define relaxed version partition bound prove lower bounds information complexity function relaxed partition bound norm based methods \( e g \? 2 method \) based methods \( e g corruption bound , smooth bound , discrepancy bound \) , except partition bound result uses new connection zero communication protocols players either output value prove following compression lemma given protocol function f information complexity , one construct zero communication protocol non probability least 2 \( \) computes f correctly high probability conditioned , show zero communication protocol relaxed partition bound use main theorem resolve three open questions man first , show information complexity vector subspace problem \( n 1 3 \) , , turn , implies exists exponential separation quantum communication complexity classical information complexity moreover , provide \( n \) lower bound information complexity gap hamming distance problem
exploiting channel memory joint estimation scheduling downlink networks address problem opportunistic multiuser scheduling downlink networks markov modeled outage channels consider scenario scheduler full knowledge channel state information , instead estimates channel state information exploiting memory inherent markov channels along feedback scheduled users opportunistic scheduling optimized two stages \( 1 \) channel estimation rate adaptation maximize expected immediate rate scheduled user \( 2 \) user scheduling , based optimized immediate rate , maximize overall long term sum throughput downlink scheduling problem partially observable markov decision process classic vs trade difficult quantify therefore study problem framework multi armed bandit processes \( \) perform whittle 's analysis whittle 's traditionally known hard establish index policy derived based whittle 's known optimality properties various settings show problem downlink scheduling imperfect channel state information whittle derive whittle 's index policy closed form via extensive numerical experiments , show index policy near optimal performance r n work reveals , incomplete channel state information , exploiting channel memory opportunistic scheduling result significant performance gains almost gains realized using easy implement index policy
magic number problem language families investigate magic number problem , , question whether exists minimal n state nondeterministic finite automaton \( nfa \) whose equivalent minimal deterministic finite automaton \( \) alpha states , n alpha satisfying n less equal alpha less equal exp \( 2 , n \) number alpha satisfying condition called magic number \( n \) shown 11 magic numbers exist general regular languages , 5 trivial non trivial magic numbers unary regular languages identified obtain similar results automata languages like , example , languages , star free , prefix , suffix , closed languages , prefix , suffix , free languages , showing trivial magic numbers , exist finite languages obtain partial results showing certain numbers non magic
hierarchical attention model social contextual image recommendation image based social networks among popular social networking services recent years tremendous images everyday , understanding users' preferences user generated images making recommendations become need fact , many hybrid models proposed various kinds side information \( e g , image visual representation , social network \) user item historical behavior enhancing recommendation performance however , due unique characteristics user generated images social image platforms , previous studies capture complex aspects influence users' preferences unified framework moreover , hybrid models relied predefined weights combining different kinds information , usually resulted sub optimal recommendation performance end , paper , develop hierarchical attention model social contextual image recommendation addition basic latent user interest modeling popular matrix factorization based recommendation , identify three key aspects \( e , history , social influence , owner \) affect user 's latent preferences , aspect contextual factor complex relationships users images , design hierarchical attention network naturally hierarchical relationship \( elements aspects level , aspect level \) users' latent interests identified key aspects specifically , taking embeddings state art deep learning models tailored kind data , hierarchical attention network could learn differently less content finally , extensive experimental results real world datasets clearly show superiority proposed model
compressed sensing gaussian measurements via linear programming natural parameter space consider combining phase retrieval classical compressed sensing inspired recent novel formulation phase retrieval called , present analyze , linear program compressed sensing natural parameter space establish provided initialization arbitrary k sparse n vector , recovers vector global sign high probability \( k log frac n k \) magnitude measurements gaussian random vectors proof fact exploits connection 1 bit compressed sensing first result establish compressed sensing gaussian measurements optimal sample complexity
multi aspect analytical framework spatio temporal data using tensor decomposition shot selection process thought indicator identity player team characterization processes important player team comparisons , pre game etc typically , shot charts compared heuristic manner recently though automated ways appeared analytics literature aim identifying set prototype patterns used basis describing player team however , approaches almost focused spatial distribution however , multitude parameters affect shot selection player example , time remaining clock , score differential , etc contextual factors impact shot selection player work , propose framework based tensor decomposition obtaining set prototype patterns based spatiotemporal information contextual meta data , used describe overall shot selection process player team core framework 3d tensor x , whose element x \( , j , k \) equal number entity location j time k granularity time location defined depending application using decomposition decompose tensor several interpretable patterns , capture group entities , take similar locations similar times game using tensor components , express every entity combination components weights corresponding elements entity factor decomposition framework introduced paper applications analysis spatiotemporal data available optical player tracking showcase analyzing small dataset
epistemic strategy logic extended abstract paper presents extension temporal epistemic logic operators quantify strategies language also provides natural way represent agents would know aware strategies used agents examples presented motivate framework , relationships several variants alternating temporal epistemic logic discussed computational complexity model checking logic also characterized
linear vs nonlinear extreme learning machine spectral spatial classification hyperspectral images new machine learning approach , extreme learning machine \( elm \) received much attention due good performance however , directly applied hyperspectral image \( hsi \) classification , recognition rate low elm use spatial information , important hsi classification view , paper proposes new framework spectral spatial classification hsi combining elm belief propagation \( lbp \) original elm linear , nonlinear \( kernel \) improvement linear elm \( \) however , based experiments much analysis , found better choice nonlinear elm spectral spatial classification hsi furthermore , exploit marginal probability distribution uses whole information hsi learns distribution using lbp proposed method maintains fast speed elm , also greatly improves accuracy classification experimental results well known hsi data sets , , university , demonstrate good performance proposed method
noma vlc downlink transmission random receiver orientation visible light communications \( vlc \) emerging technology promise solution spectrum problem conventional radio frequency \( rf \) work , consider downlink multiuser vlc network users randomly change location vertical orientation order increase spectral efficiency , consider non orthogonal multiple access \( noma \) transmission serve multiple users simultaneously particular , propose individual group based user ordering techniques noma various user feedback schemes order reduce computational complexity link overhead , feedback channel quality proposed computed using mean value vertical angle \( instead exact value \) , well distance information addition , two bit feedback scheme proposed group based user scheduling , relies distance vertical angle , differs conventional one bit feedback distance outage probability sum rate expressions derived analytically , show good match simulation data numerical results verify practical feedback scheme mean vertical angle achieves near optimal sum rate performance , two bit feedback significantly outperforms one bit feedback
towards theory propose study notions behaviour type composition operator making first step towards definition formal framework studying behaviour composition setting sufficiently general provide insight component based systems modelled compared illustrate proposed notions classical examples \( traces , labelled transition systems \) finally , definition memoryless operators , takes us one step closer formal understanding separation concerns principle computational aspects system within components , whereas coordination layer responsible managing memoryless operators
training test set analysis et al recent paper claims classify brain processing subjects imagenet stimuli measured eeg use representation derived processing create novel object classifier paper , together series subsequent papers 8 , 15 , 17 , 20 , 21 , 30 , 35 , claims field achieving extremely successful results several computer vision tasks , including object classification , transfer learning , generation images human perception thought using brain derived representations measured eeg novel experiments analyses demonstrate results crucially depend block design use , stimuli given class presented together , fail rapid event design , stimuli different classes randomly block design leads classification arbitrary brain states based block level temporal correlations tend exist eeg data , rather related activity every trial test sets comes block many trials corresponding training sets , block design thus leads training test set subsequent analyses performed data multiple published papers calls question results show novel object classifier constructed random codebook performs well better novel object classifier constructed representation extracted eeg data , suggesting performance classifier constructed representation extracted eeg data benefit brain derived representation results underlying difficulty tasks involved overly , false , claims
truthful scheduling mechanisms mobile crowdsensing mobile crowdsensing leverages mobile devices \( e g , smart phones \) human mobility pervasive information exploration collection promising paradigm various research application domains unfortunately , mobile crowdsensing due lack incentive mechanisms human paper , study incentive mechanisms novel mobile crowdsensing scheduling \( mcs \) problem , mobile crowdsensing application owner set sensing tasks , human users \( mobile devices \) compete tasks based respective sensing costs available time periods , finally owner well users maximize sensing revenue certain budget prove mcs problem np hard propose polynomial time approximation mechanisms also show approximation mechanisms \( including offline online versions \) achieve desirable game theoretic properties , namely individual , well \( 1 \) performance ratios finally , conduct extensive simulations demonstrate correctness effectiveness approach
toward real world single image super resolution new benchmark new model existing learning based single image \( \) methods trained evaluated simulated datasets , low resolution \( lr \) images generated applying simple uniform degradation \( e , \) high resolution \( hr \) counterparts however , real world lr images far complicated consequence , models trained simulated data become less effective applied practical scenarios paper , build real world super resolution \( \) dataset paired lr hr images scene captured adjusting length digital camera image registration algorithm developed align image pairs different resolutions considering degradation kernels naturally non uniform dataset , present laplacian based kernel prediction network \( lp \) , efficiently learns per pixel kernels recover hr image extensive experiments demonstrate models trained dataset deliver better visual quality edges finer textures real world scenes trained simulated datasets though dataset built using two cameras \( \) , trained model generalizes well camera devices mobile phones
model inversion networks model based optimization work , aim solve data driven optimization problems , goal find input maximizes unknown score function given access dataset inputs corresponding scores inputs high dimensional valid inputs small subset space \( e g , valid sequences valid natural images \) , model based optimization problems become difficult , since optimizer must avoid distribution inputs propose address problem model inversion networks \( \) , learn inverse mapping scores inputs scale high dimensional input spaces leverage offline data contextual non contextual optimization problems also handle purely offline data sources active data collection evaluate tasks bayesian optimization literature , high dimensional model based optimization problems images designs , contextual bandit optimization data
fast human pose estimation existing human pose estimation approaches often consider improve model performance , putting significant efficiency problem leads development heavy models poor scalability cost effectiveness practical use work , investigate studied practically critical pose model efficiency problem end , present new fast pose distillation \( \) model learning strategy specifically , lightweight pose neural network architecture capable executing rapidly low computational cost achieved effectively transferring pose structure knowledge strong teacher network extensive evaluations demonstrate advantages method broad range state art pose estimation approaches terms model cost effectiveness two standard benchmark datasets , human pose pose
mutual information distribution ofdm based spatial multiplexing exact variance outage approximation communication considers distribution mutual information frequency selective spatially rayleigh fading multiple input multiple output \( mimo \) channels results presented orthogonal frequency division multiplexing \( ofdm \) based spatial multiplexing new exact closed form expressions derived variance mutual information contrast previous results , new expressions apply systems arbitrary numbers antennas arbitrary length channels simplified expressions also presented high low signal noise ratio \( snr \) regimes analytical variance results used provide accurate analytical approximations distribution mutual information , outage capacity
collecting swarm grid environment using shared global inputs paper investigates efficient techniques collect actuated particle swarm despite obstacles swarm particles critical importance health care targeted delivery , micro scale particles must goal location individual particles must small order navigate micro , decreasing size brings new challenges individual particles small contain power computation instead controlled global input , applied flow field r n make progress , paper considers swarm robots grid world position either free space obstacle paper provides algorithms collect robots one position compares algorithms basis efficiency implementation time
minimizing movement fixed parameter tractability study extensive class movement minimization problems arise many practical scenarios far little theoretical study general , problems involve planning coordinated motion collection agents \( representing robots , people , map labels , network messages , etc \) achieve global property network minimizing maximum average movement \( energy \) previous theoretical results class problems approximation , mainly negative many movement problems interest polynomial given number mobile agents typically much smaller complexity environment , turn fixed parameter tractability characterize boundary tractable intractable movement problems general set turns complexity problem fundamentally depends minimal configurations thus complexity particular problem determined answering purely combinatorial question using general tools , determine complexity several problems show many movement problems interest solved efficiently
estimating unseen develop differentially private methods estimating various distributional properties given sample discrete distribution p , functional f , accuracy privacy parameters alpha , goal estimate f \( p \) accuracy alpha , maintaining differential privacy sample r n prove almost tight bounds sample size required problem several interest , including support size , support coverage , entropy show cost privacy negligible variety settings , theoretically experimentally methods based sensitivity analysis several state art methods estimating properties sublinear sample complexities
privacy enhanced multimodal neural representations emotion recognition many mobile applications virtual conversational agents aim recognize adapt emotions enable , data transmitted users' devices stored central servers yet , data contain sensitive information could used mobile applications without user 's , , eavesdropping adversary work , show multimodal representations trained primary task , emotion recognition , demographic information , could selected opt user analyze leakage differs representations obtained textual , acoustic , multimodal data use adversarial learning paradigm private information present representation investigate effect varying strength adversarial component primary task privacy metric , defined attacker predict specific demographic information evaluate paradigm multiple datasets show improve privacy metric significantly performance primary task best knowledge , first work analyze privacy metric differs across modalities multiple privacy concerns still maintaining performance emotion recognition
doubly sparse sparse mixture sparse experts efficient softmax inference computations softmax function significantly expensive number output classes large paper , present novel softmax inference speedup method , doubly sparse softmax \( softmax \) , leverages sparse mixture sparse experts efficiently retrieve top k classes different existing methods require approximate fixed softmax , method learning based adapt softmax weights better approximation particular , method learns two level hierarchy entire output class space several partially overlapping experts expert sparse contains subset output classes find top k classes , sparse mixture enables us find expert quickly , sparse expert enables us search within small scale softmax empirically conduct evaluation several real world tasks \( including neural machine translation , language modeling image classification \) demonstrate significant computation reductions achieved without loss performance
packet routing 3d lightweight linear path scheme packet routing requires novel approaches , cope extreme limitations posed nano scale highly lossy wireless channels , extremely limited hardware capabilities non unique node among restrictions present work offers addressing routing solution static 3d find applications material monitoring property tuning addressing process relies virtual coordinates multiple , alternative point sets act offers different address granularity within network space , selection optimized packet node using novel heuristic regarding routing , node whether located linear segment connecting sender node deduction made using integer , node local information manner , minimizing computational storage overhead proposed scheme importantly , nodes width linear path , thus energy efficiency \( redundant transmissions \) increased path diversity enable future adaptive routing schemes extensive evaluation via simulations advantages novel scheme related approaches
learning robust bed making using deep imitation learning bed making universal home task challenging due reaching motions automating bed making multiple technical challenges perception unstructured environments , object manipulation , obstacle sequential decision making explore , algorithm learning robust policies , applied automating bed making without markers human support robot \( \) human demonstrations grasping failure detection , learn deep neural network policies leverage pre trained features automate task experiments 1 2 scale bed placed bed , suggest policies learned 50 demonstrations achieve 96 coverage , 200 better detector baseline using contour detection
refined particle swarm intelligence method abrupt motion tracking conventional tracking solutions able deal abrupt motion based smooth motion assumption accurate motion model abrupt motion subject motion continuity smoothness address problem tracking optimisation problem propose novel abrupt motion tracker based swarm intelligence unlike existing swarm based filtering methods , first introduce swarm based sampling strategy tradeoff exploration exploitation state space search optimal proposal distribution secondly , propose dynamic acceleration parameters \( \) allow fly tuning best mean variance distribution sampling combining two strategies within particle swarm optimisation framework represents novel method address abrupt motion best knowledge , never done , introduce new dataset abrupt motion \( \) dataset consists 12 videos finally , experimental quantitative qualitative results shown effectiveness proposed method terms dataset unbiased , object size invariant fast recovery tracking abrupt motions
computational models spreadsheet development basis approaches among multiple causes high error rates spreadsheets , lack proper training deep understanding computational model upon spreadsheet computations rest might least issue paper addresses problem presenting model cell interaction , thus cell computations approach motivated investigation different spreadsheet systems handle certain computational issues moving cells , copy operations , recursion
byzantine convex consensus preliminary version much past work asynchronous approximate byzantine consensus assumed scalar inputs nodes 3 , 7 recent work approximate byzantine consensus algorithms case input node dimensional vector , nodes must reach consensus vector convex input vectors fault free nodes 8 , 12 dimensional vectors viewed points dimensional euclidean space thus , algorithms 8 , 12 require fault free nodes decide point dimensional space r n paper , generalize problem allow decision convex polytope dimensional space , polytope within convex input vectors fault free nodes name problem byzantine convex consensus \( bcc \) , present asynchronous approximate bcc algorithm optimal fault tolerance , goal convex polytope large possible claim algorithm satisfies goal , show bound output convex polytope chosen algorithm
channel estimation barrier massive mimo communication systems new wave wireless services , including virtual reality , autonomous driving internet things , driving design new generations wireless systems deliver ultra high data rates , massive number connected devices ultra low latency massive multiple input multiple output \( mimo \) one critical underlying technologies allow future wireless networks meet service needs article discusses application deep learning \( dl \) massive mimo channel estimation wireless networks integrating underlying characteristics channels future high speed cellular deployment develop important insights derived physical radio frequency \( rf \) channel properties present comprehensive overview application dl accurately estimating channel state information \( csi \) low overhead provide examples successful dl application csi estimation massive mimo wireless systems highlight several promising directions future research
discrete time maximum principle matrix lie groups article derive maximum principle \( \) discrete time optimal control problems matrix lie groups provides first order necessary conditions optimality necessary conditions typically yield two point boundary value problems , boundary value problems solved extract optimal control trajectories constrained optimal control problems mechanical systems , general , solved numerically , motivates need derive discrete time models accurate preserve non manifold structures underlying continuous time controlled systems discrete time systems evolving euclidean spaces readily applicable discrete time models evolving non manifolds article bridge establish discrete time matrix lie groups discrete time models derived via discrete mechanics , \( structure preserving discretization scheme , \) leading preservation underlying manifold time , thereby resulting greater numerical accuracy technique class constrained optimal control problems includes point wise state control action constraints , encompasses large class control problems arise various field engineering applied sciences
softnull many antenna full duplex wireless via digital beamforming paper , present study digital controlled method , called softnull , enable full duplex many antenna systems unlike designs rely analog self interference , softnull relies digital transmit beamforming reduce self interference softnull attempt perfectly null self interference , instead seeks reduce self interference sufficiently prevent receiver dynamic range residual self interference receiver evaluate performance softnull using measurements element antenna array indoor outdoor environments find softnull significantly outperform half duplex small cells operating many antenna regime , number antennas many number users served simultaneously
optimal placement autonomous vehicles visibility based robot networks communication environments , line \( los \) communication \( e g free space optical communication using visible light \) becomes one reliable efficient ways send information scattered mobile units paper , consider problem planning optimal locations trajectories group autonomous vehicles see set units environment obstacles contributions paper following 1 \) propose centralized distributed algorithms verify vehicles units form connected network los 2 \) present algorithm maintain visibility based connectivity , possible , single vehicle 3 \) study computational
approximate nearest neighbor search high dimensions nearest neighbor problem defined follows given set p n points metric space \( x , \) , build data structure , given point q , returns point p closest q \( nearest neighbor p \) data structure stores additional information set p , used find nearest neighbor without computing distances q p problem wide range applications machine learning , computer vision , databases fields r n reduce time needed find nearest neighbors amount memory used data structure , one formulate em approximate nearest neighbor problem , goal return point p distance q c cdot min p p \( q , p \) , c geq 1 last two decades , many efficient solutions problem developed article survey developments , well connections questions geometric functional analysis combinatorial geometry
partial order reduction security protocols security protocols concurrent processes communicate using cryptography aim achieving various security properties recent work formal verification brought procedures tools deciding trace equivalence properties \( e g , anonymity , , secrecy \) bounded number however , procedures based naive symbolic exploration traces considered processes , , greatly limits scalability practical impact verification tools r n paper , overcome difficulty developing partial order reduction techniques verification security protocols provide reduced transition systems optimally redundant traces , adequate model checking trace equivalence properties protocols means symbolic execution implemented reductions tool , demonstrated achieves expected speedup various protocols
policy optimization second order advantage information policy optimization high dimensional continuous control tasks exhibits difficulty caused large variance policy gradient estimators present action subspace dependent gradient \( \) estimator incorporates theorem \( \) control \( \) unified framework reduce variance , proposed algorithm \( \) learns underlying factorization structure among action space based second order advantage information captures quadratic information explicitly efficiently utilizing wide deep architecture empirical studies show proposed approach demonstrates performance improvements high dimensional synthetic settings 's continuous control tasks
free global optimization algorithms population based methods random search approaches paper , provide introduction free optimization algorithms potentially applied train deep learning models existing deep learning model training mostly based back propagation algorithm , updates model variables layers layers gradient descent algorithm variants however , objective functions deep learning models optimized usually non convex gradient descent algorithms based first order get local easily resolve problem , various local global optimization algorithms proposed , help improve training deep learning models greatly representative examples include bayesian methods , algorithm , direct , , mcs , ga , , de , , , , simulated annealing , etc follow paper 18 , introduce population based optimization algorithms , e g , ga , , de , , , random search algorithms , e g , simulated annealing , paper introduction free optimization algorithms , refer 18 information
methods interpreting understanding deep neural networks abstract paper provides entry point problem interpreting deep neural network model explaining predictions based tutorial given 2017 tutorial paper , set methods exhaustive , sufficiently representative discuss number questions interpretability , technical challenges , possible applications second part tutorial focuses recently proposed layer wise relevance propagation \( \) technique , provide theory , recommendations , , make efficient use real data
graph model selection via random walks paper , present novel approach based random walk process finding meaningful representations graph model approach leverages behavior many short random walks novel initialization mechanisms generate model discriminative features features able capture comprehensive structural signature underlying graph model resulting representation invariant node permutation size graph , allowing direct comparison large classes graphs test approach two challenging model selection problems discrimination sparse regime model stochastic block model clique problem representation approach achieves performance closely matches known theoretical limits addition computationally simple scalable large graphs
sink mobility trajectory clustering routing protocols wsns energy efficient routing protocols consistently efficient solutions wireless sensor networks \( wsns \) routing area wsns one emerging fast growing fields brought low cost , low power multi functional sensor nodes paper , examine protocols related homogeneous heterogeneous networks evaluate efficiency different clustering schemes , compare five clustering routing protocols low energy adaptive clustering hierarchy \( \) , threshold sensitive energy efficient sensor network \( \) , distributed energy efficient clustering \( \) two variants clustering multi hop protocol threshold sensitive energy efficient sensor network \( \) hierarchical threshold sensitive energy efficient sensor network \( h \) contribution paper introduce sink mobility increase network life time routing protocols two scenarios discussed compare performances routing protocols first scenario static sink later one mobile sink used perform analytical simulations matlab using different performance metrics , number nodes , number nodes throughput index terms wireless sensor networks , base station , cluster head
statistical validity consistency big data analytics general framework technological generation huge volume data complexity management analysis big data analytics practice revealing hidden aspects data making although storage , retrieval management big data possible efficient algorithm system development , concern statistical consistency remains addressed view specific characteristics since big data conform standard analytics , need proper modification existing statistical theory tools propose , , general statistical framework algorithmic principle big data analytics ensure statistical accuracy conclusions proposed framework potential forward big data analytics right direction partition approach proposed broad enough practical data analytic problems
laplacian networks bounding indicator function smoothness neural networks robustness past years , deep neural network \( dnn \) robustness become question importance matter fact , sensitive settings lead consequences likely occur facing adversarial attacks , hardware failures limitations , imperfect signal acquisition address question , authors proposed different approaches aiming increasing robustness dnns , adding training using noisy examples paper propose new regularizer built upon laplacian similarity graphs obtained representation training data layer dnn architecture regularizer large changes \( across consecutive layers architecture \) distance examples different classes , smooth variations class boundaries since agnostic type expected predicting dnn , proposed regularizer combined existing ad hoc methods provide theoretical justification regularizer demonstrate effectiveness improve robustness dnns classical supervised learning vision datasets
efficient checking individual rewards properties markov population models recent years fluid approaches analysis markov populations models demonstrated great value initially developed estimate behaviour system terms expected values population counts , fluid approach subsequently extended sophisticated models embedding within model checking procedures paper extend recent work checking properties individual agents within markovian population model , consider checking properties incorporate rewards
content reuse interest sharing tagging communities tagging communities represent subclass class user generated content sharing online communities communities users introduce tag content later use although recent studies attempt social knowledge context exploiting collaboration among users , little research done quantify current level user collaboration communities paper introduces two metrics quantify level collaboration content reuse shared interest using two metrics , paper shows current level collaboration consistently low , significantly limits potential social knowledge communities study also discusses implications findings context recommendation systems
pin exploiting ambient light sensor mobile devices paper , propose new type side channel based ambient light sensor employed today 's mobile devices pervasive usage mobile devices , e , smartphones computers vast amount sensors represent side channels serious threat user 's privacy security recent advances area research focused employed motion sensors camera well sound , investigate less obvious source information leakage , namely ambient light successfully demonstrate minor turns mobile devices cause variations ambient light sensor information thus , first show sensor sensitive information furthermore , demonstrate variations enough information infer user 's personal identification number \( pin \) input based set known results show able determine correct pin set 50 random within first ten 80 time contrast , chance finding right pin randomly ten would 20 since data required perform attack without specific , presented side channel security privacy mobile device
general framework derivation regular expressions aim paper design theoretical framework allows us perform computation regular expression space generic structures thanks formalism , main properties regular expression derivation , set , need proved one time , top level moreover , shown construct alternating automaton associated derivation regular expression general framework finally , derivation derivation turn particular case general scheme shown construct , nfa
interpreting communities based evolution dynamic attributed network many methods proposed detect communities , plain , also attributed , , even dynamic complex networks modeling point view , utility , com structure must characterized relatively properties studied system however , existing works focus detection communities , try tackle interpretation problem moreover , existing approaches limited either type data handle nature results output work , see interpretation problem independent detection process , consisting identifying characteristic features communities give formal definition problem propose method solve aim , first define sequence based representation networks , com temporal information , community structure , logical measures , attributes describe identify emerging sequential patterns dataset use characterize communities study performance method artificially generated dynamic attributed networks also em validate framework real world systems network scientific , network social interactions
weight hierarchies family linear codes associated degenerate quadratic forms restrict degenerate quadratic forms finite field subspaces quotient spaces related results subspaces quotient spaces obtained based , solve weight hierarchies family linear codes degenerate quadratic forms
semi supervised localization bidirectional image retrieval framework introduce novel deep neural network architecture links visual regions corresponding textual segments including words task , architecture makes use rich semantic information available joint embedding space multi modal data joint embedding space , extract associative localization maps develop naturally , without explicitly providing supervision training localization task joint space learned using bidirectional ranking objective optimized using n pair loss formulation training mechanism demonstrates idea localization information learned inherently optimizing bidirectional retrieval objective model 's retrieval localization performance evaluated entities datasets architecture outperforms state art results semi supervised localization setting
conjunctive regular path queries string variables introduce class conjunctive path queries , obtained conjunctive regular path queries \( \) adding string variables \( also called \) found practical implementations regular expressions considered user friendly , since combine two concepts well established practice pattern based graph queries regular expressions due string variables , express inter path dependencies , evaluation complexity , restricted , hard data complexity identify three natural acceptable evaluation complexity data complexity nl , combined complexity varies , np terms expressive power , compare unions , extended conjunctive regular path queries \( \) unions
detailed analysis algorithms experimental mathematics study several variants single pivot multi pivot algorithms consider discrete probability problems experimental mathematics , explicit expressions expectations , even higher moments numbers comparisons obtained variants , monte carlo experiments performed , numerical results demonstrated scaled limiting distribution also discussed
single letter upper bound feedback capacity finite state channels upper bound feedback capacity finite state channels \( \) derived new technique , called q contexts , based construction directed graph used recursively receiver 's output sequences finite set contexts choice q graph , feedback capacity bounded single letter expression , c text leq \( x , q \) , p x , q distribution \( , q \) stationary distribution shown bound tight feedback capacity known channels state function outputs , channel , channels , consecutive ones input constrained erasure channel memoryless channel efficiency also demonstrated deriving new capacity result erasure channel \( dec \) upper bound obtained directly expression general sufficient condition optimality upper bound sufficient condition based fixed point principle equation , indeed , formulated simple lower bound feedback capacity arbitrary q graphs upper bound indicates single letter expression might exist capacity finite state channels without feedback based construction auxiliary random variable specified structure , q graph , distribution upper bound also serves non trivial bound capacity channels without feedback , problem still open
channel based beam tracking millimeter wave communications beamforming structures fixed beam provide solutions millimeter wave \( \) communications due low hardware cost however , training overhead search optimal beamforming configuration proportional codebook size improve efficiency beam tracking , propose beam tracking scheme based channel database , comprises mappings statistical beamforming gains user locations scheme tracks user movement utilizing trained beam configurations estimating gains beam configurations trained simulations show proposed scheme achieves significant beamforming performance gains existing beam tracking schemes
demand based scheduling mixed criticality tasks one processor strategies artificially high criticality task low criticality behaviors successfully employed scheduling mixed criticality systems although efficient scheduling algorithms developed implicit task systems , true general tasks paper develop new demand based test general mixed criticality task systems , bound low high criticality demand tasks show new test strictly known demand based test systems also propose new strategy based test , show simulations strategy significantly outperforms known scheduling algorithms variety task systems
block cyclic stochastic coordinate descent deep neural networks present stochastic first order optimization algorithm , named , adds cyclic constraint stochastic block coordinate descent uses different subsets data update different subsets parameters , thus limiting effect outliers training set empirical tests benchmark datasets show algorithm outperforms state art optimization methods accuracy well convergence speed improvements consistent across different architectures , combined training techniques regularization methods
mining difficulty adjustment miner proof work must implement difficulty adjustment algorithm \( \) order maintain consistent inter arrival time blocks conventional essentially feedback controllers , , inherently reactive approach manipulation often causes either correct present mining , proactive works collecting hash rate miners difficulty set directly used miners devise statistical test capable detecting hash rate deviations utilizing blockchain data test sensitive enough detect variety deviations , almost never honest miners demonstrate simulation , reasonable assumptions , mining effective maintaining target block time , one dynamic currently deployed preliminary work , hash rate miner approach supports 1 total directly consider two types fundamental attacks future work address limitations
distributed function computation confidentiality set terminals observe correlated data seek compute functions data using interactive public communication time , required value private function data remains eavesdropper observing communication general , private function functions computed nodes different show class functions computable conditional entropy data given value private function greater least rate interactive communication required related source coding task single letter formula provided rate special cases
control agents coupled shared unit demand resources consider control problem involving several agents coupled multiple unit demand resources resources , agent 's consumption modeled random variable controlling number agents probabilistic manner , subject capacity constraints , ubiquitous smart cities instance , agents humans feedback loop price signal , automated decision support systems toward system level goals paper , consider single feedback loop corresponding single resource multiple coupled feedback loops corresponding multiple resources population agents example , network devices allocates resources deliver several services , services coupled capacity constraints resources propose new algorithm fundamental guarantees convergence optimality , well present example performance
mimicking networks parameterized connectivity given graph g \( v , e \) , capacities w \( e \) edges , subset terminals mathcal subseteq v mathcal k , mimicking network \( g , mathcal \) graph \( h , \) contains copies mathcal preserves value minimum cuts separating subset , b subseteq mathcal terminals mimicking networks size 2 2 k known exist constructed , best known lower bound 2 omega \( k \) therefore , exponential size required one aims preserving cuts exactly r n paper , study mimicking networks preserve connectivity graph exactly value c , c parameter notion mimicking network sufficient applications , elaborate first show mimicking size 3 c cdot k exists , , preserve cuts small capacity using network size linear k next , show algorithm finds mimicking network time 2 \( c 2 \) operatorname poly \( \)
co directions sketching approximate matrix introduce co occurring directions sketching , deterministic algorithm approximate matrix product \( \) , streaming model show co directions achieves better error bound randomized deterministic approaches co occurring directions gives 1 epsilon approximation optimal low rank approximation matrix product empirically algorithm outperforms competing methods , small sketch size validate empirically theoretical findings algorithms
potential work analyses potential , quite successful algorithm k sat , estimating runtime distributions random 3 sat instances close phase transition estimate optimal time empirical data , reaching potential speedup factor 1 39 calculating times probability distributions reduces factor maximum 1 30 spin result distribution approximates runtime distribution 93 used instances well machine learning pipeline presented compute time fixed strategy exploit potential main components pipeline random forest determining distribution type neural network distribution 's parameters performs statistically significantly better 's strategy policy without using presented approach structure particularly hard problems
first come first served online slot allocation huffman coding one choose good huffman code fly , without knowing underlying distribution \? online slot allocation \( \) models similar problems n slots , known cost n items requests items drawn fixed hidden probability distribution p request , item , , previously requested , algorithm \( knowing slot costs requests far , p \) must place item slot j \( \) goal minimize sum , items , probability item times cost assigned slot r n optimal offline algorithm trivial put item slot , second item second slot , etc optimal online algorithm first come first served \( \) put first requested item slot , second \( distinct \) requested item second slot , etc optimal competitive ratios online algorithm 1 h \( n 1 \) n general costs 2 concave costs logarithmic costs , ratio , asymptotically , 1 gives cost opt \( log opt \) r n huffman coding , yields online algorithm \( one allocates codewords demand , without knowing underlying probability distribution \) guarantees asymptotically optimal cost opt 2 log \( 1 opt \) 2
long term feature detailed video understanding understand world , humans need relate present past , put events context paper , enable existing video models propose long term feature information extracted entire video augment state art video models otherwise would view short 2 5 seconds experiments demonstrate augmenting 3d convolutional networks long term feature yields state art results three challenging video datasets , ,
social media mobility landscape spatial patterns urban human mobility multi source data paper , present three step framework , including location identification , bias modification , sample validation , human mobility analysis social media data specifically , propose ways identifying personal activity specific places commuting patterns , , based \( 's twitter \) check records , well modifying sample bias check data population synthesis technique independent travel logistic survey used benchmark results obvious differences users' survey activity mobility patterns , large variation population data two sources bias modification , similarity coefficient commuting distance distributions data survey observations increases substantially 23 63 synthetic data proves satisfactory cost effective alternative source mobility information proposed framework inform many applications related human mobility , ranging transportation , urban planning modelling
sprites state channels payment networks go faster , ethereum blockchain based , deployed today , cannot scale wide spread use leading approach scaling smart contract mechanism called payment channel enables two mutually parties efficiently \( requires single blockchain set \) payment channels linked together form payment network , payments two parties \( usually \) network along path crucially , parties without along route r n paper , propose novel variant payment channels , called sprites , reduces worst case collateral cost hop along route may incur benefits sprites two fold 1 \) network , payment across path ell channels requires collateral theta \( ell delta \) time , delta time commit chain sprites reduces cost \( ell delta \) 2 \) unlike prior work , sprites supports partial , channel continue operate without r n evaluating sprites make several additional contributions first , simulation based security model first formalism model timing guarantees payment channels construction also modular , making use generic abstraction , called state channel , first formalize also provide simulation framework payment network protocols , use confirm sprites construction throughput reducing attacks
biologically plausible learning rule deep learning brain proposed deep learning , providing important progress wide range high complexity tasks , might new insights learning brain however , methods used deep learning artificial neural networks biologically would need replaced biologically realistic counterparts previous biologically plausible reinforcement learning rules , like augment , showed promising results focused shallow networks three layers learning rules also generalize networks layers handle tasks higher complexity \? , demonstrate learning schemes indeed generalize deep networks , include attention network propagates information selected action lower network levels resulting learning rule , called q , equivalent particular form error backpropagation one output unit one time demonstrate utility learning scheme larger problems , trained networks two hidden layers mnist dataset , standard interesting machine learning task results demonstrate capability q comparable error backpropagation , although learning rate 1 5 2 times network learn trial error updates action value one output unit time results provide new insights deep learning implemented brain
smart motion action recognition attack adversarial attack inspired great interest computer vision , showing classification based solutions prone imperceptible attack many tasks paper , propose method , smart , attack action rely 3d motions method involves innovative perceptual loss ensures attack empirical studies demonstrate smart effective white box black box scenarios variety action datasets shown different strategies proven extensive perceptual studies finally , smart shows adversarial attack 3d motion , one type time series data , significantly different traditional adversarial attack problems
deep edge implementation digital cameras use sensors color filter array \( \) capture channel components every pixel location , resulting image contain pixel values channels current research missing channels , also known , introduces many artifacts , zipper effect false color many deep learning techniques outperform classical techniques reducing impact artifacts however , models tend consequently , edge implementation state art deep learning based algorithms low end edge devices major challenge provide exhaustive search deep neural network architectures obtain pareto front color peak signal noise ratio \( \) performance criterion versus number parameters model complexity state art architectures pareto front used choose best architecture variety resource constraints simple architecture search methods exhaustive search grid search require conditions loss function converge optimum conditions brief theoretical study
compositional memory visual question answering visual question answering \( vqa \) one topics computer vision recently many state art methods use holistic visual features language features long short term memory \( lstm \) module , sophisticated interaction coarse modeling also blocks possibilities exploring finer grained local features contribute question answering dynamically time r n paper addresses fundamental problem directly modeling temporal dynamics language possible local image patches question words , end end approach explicitly features associated words ones available multiple local patches attention mechanism , combines fused information generate dynamic messages , call standard question answering module together contextual visual information linguistic information motivated recent practices deep learning , use auxiliary loss functions training improve performance experiments two latest public datasets suggest method superior performance notably , dataset advanced state art 6 , also evaluated approach recent vqa dataset
suffix tree approach email filtering present approach email filtering based suffix tr ee data structure method scoring using suffix tree developed number scoring score functions tested results show character level represent classes suffix tree significantly classification accuracy compared currently popular methods , naive bayes believe method extended tion documents domains
robust non linear feature selection image fusion theory human visual perception system strong robustness image fusion robustness based human visual perception system 's characteristics feature selection non linear fusion different features order simulate human visual perception mechanism image fusion tasks , propose multi source image fusion framework combines factors attention mechanisms framework effectively combines traditional image features modern deep learning features first , perform multi scale decomposition multi source images , visual saliency map deep feature map combined fusion factor perform high low frequency nonlinear fusion secondly , characteristics high low frequency fusion selected channel attention network obtain final fusion map nonlinear characteristics selection characteristics human visual perception system image fusion , fused image line human visual perception mechanism finally , validate fusion framework public datasets visible images , medical images multi focus images experimental results demonstrate superiority fusion framework state arts visual quality , objective fusion metrics robustness
confidence near optimal anytime adaptive algorithm configuration algorithm configuration methods optimize performance parameterized heuristic algorithm given distribution problem instances recent work introduced algorithm configuration procedure \( \) provably achieves near optimal performance high probability nearly minimal runtime worst case also offers emph anytime property optimality guarantees longer run unfortunately , structured emph adaptive characteristics parameterized algorithm treats every input like worst case follow work \( \) achieves away anytime property paper introduces new algorithm , , preserves near optimality anytime properties structured adding particular , new algorithm perform dramatically faster settings many algorithm configurations perform poorly show empirically settings arise frequently practice anytime property useful finding good configurations quickly
support analysts know customers study prediction support ticket escalations large software organizations understanding keeping customer central requirements engineering strategies , analyze , requirements complemented efforts manage customer input products deployed latter , support tickets key allowing customers issues , bug reports , feature requests whenever insufficient attention given support issues , however , management time consuming expensive , especially large organizations managing hundreds customers thousands support tickets work provides step towards job support analysts , particularly predicting risk support tickets field study large industrial partner , ibm , used design science methodology characterize support process data available ibm analysts managing escalations iterative cycles design evaluation , translated understanding support expert knowledge customers features support ticket model implemented machine learning model predict support ticket escalations trained evaluated machine learning model 2 5 million support tickets 10 , 000 escalations , obtaining recall 79 9 80 8 reduction workload support analysts looking identify support tickets risk site evaluations , prototype tool developed implement machine learning techniques practice , showed efficient support ticket management features developed support ticket model designed serve starting place organizations interested implementing model predict support ticket escalations , future researchers build advance research prediction
predicting device device channels cellular channel measurements learning approach device device \( d2d \) communication , enables direct connection users cellular channels base stations \( \) , promising way traffic conventional cellular networks d2d communication , one problem , order optimally allocate resources across d2d cellular users , knowledge d2d channel gains needed however , knowledge hard obtain reasonable signaling costs paper , show problem information provided estimation cellular channels users surrounding estimation done normal operation network cellular d2d channel gains exhibit independent fast fading behavior , show average gains cellular d2d channels share non explicit correlation structure , network topology , terrain , setup propose machine \( deep \) learning approach capable predicting d2d channel gains independent cellular channels results show high degree convergence true predicted d2d channel gains predicted gains allow reach near optimal communication capacity many radio resource management algorithms
handling 0 state trajectory constraints temporal landmarks temporal landmarks proved helpful mechanism deal temporal planning problems , specifically improve planners performance handle problems constraints paper , show strength using temporal landmarks handle state trajectory constraints 0 analyze formalism , temporal planner particularly solving planning problems , present detailed study exploits underlying temporal landmark based mechanism representing reasoning trajectory constraints
reasoning knowledge strategies epistemic strategy logic paper introduce epistemic strategy logic \( \) , extension strategy logic modal operators individual knowledge enhanced framework allows us represent explicitly reason knowledge agents agents' strategies provide semantics terms epistemic concurrent game models , consider corresponding model checking problem show complexity model checking worse \( non epistemic \) strategy logic
graph filter distributed implementation paper , consider graph filter \( nsgfbs \) process data graph distributed manner given analysis filter small bandwidth , propose algebraic optimization methods constructing synthesis filter corresponding nsgfbs provide perfect signal reconstruction noiseless setting moreover , prove proposed nsgfbs control resonance effect presence bounded noise limit influence shot noise primarily small neighborhood location graph graph large size , distributed implementation significant advantage , since data processing communication demands agent vertex depend mainly neighboring topology paper , propose iterative distributed algorithm implement proposed nsgfbs based nsgfbs , also develop distributed denoising technique demonstrated satisfactory performance noise suppression
codes group algebras classify , terms structure finite group g , group algebras right right principal left means language coding theory classify code group algebras considered far groups g optimality codes asymptotic results discussed
discrete signal processing graphs frequency analysis signals datasets arise physical engineering applications , well social , , , many domains , becoming increasingly larger complex contrast traditional time image signals , data domains supported arbitrary graphs signal processing graphs extends concepts techniques traditional signal processing data indexed generic graphs paper studies concepts low high graphs , low , high , band pass graph filters traditional signal processing , concepts easily defined natural frequency ordering physical interpretation signals graphs , general , obvious frequency ordering propose definition total variation graph signals naturally leads frequency ordering graphs defines low , high , band pass graph signals filters study design graph filters specified frequency response , illustrate approach applications sensor detection data classification
synthesis fast multiplication algorithms arbitrary tensors method fast linear transform algorithm synthesis arbitrary tensor , matrix , vector proposed method based factorization tensor using factors building computational structures performing fast tensor vector multiplication computer dedicated hardware platform
multi instance multi label learning paper , propose miml \( multi instance multi label learning \) framework example described multiple instances associated multiple class labels compared traditional learning frameworks , miml framework convenient natural representing complicated objects multiple semantic meanings learn miml examples , propose algorithms based simple strategy , experiments show solving problems involving complicated objects multiple semantic meanings miml framework lead good performance considering process may information , propose algorithm miml problems directly regularization framework moreover , show even access real objects thus cannot capture information real objects using miml representation , miml still useful propose algorithms works transforming single instances miml representation learning , works transforming single label examples miml representation learning experiments show tasks able achieve better performance learning single instances single label examples directly
generation learning unsupervised gans memory networks propose approach address two issues commonly occur training unsupervised gans first , since gans use continuous latent distribution embed multiple classes clusters data , often correctly handle structural disparate classes latent space second , gans easily past generated samples generators , adversarial training argue two problems unsupervised gan training largely learnable memory network generators access generators effectively learn representation training samples understand underlying cluster distributions data , structure problem time , better clusters previously generated samples , mitigate forgetting problem propose novel end end gan model named , involves memory network trainable many existing gan models evaluations multiple datasets fashion mnist , , cifar10 , , show model interpretable , generates realistic image samples high visual fidelity also achieves state art scores unsupervised gan models cifar10 dataset , without optimization
deep reinforcement learning user identity linkage user identity linkage task recognizing identities user across different social networks \( sn \) previous works tackle problem via estimating pairwise similarity identities different sn , predicting label identity pairs selecting relevant identity pair based similarity scores however , methods ignore results previously matched identities , could contribute linkage following matching steps address problem , user identity linkage sequence decision problem propose reinforcement learning model optimize linkage strategy global perspective method makes full use social network structure history matched identities , long term influence current matching subsequent decisions conduct experiments different types datasets , results show method achieves better performance state art methods
3d surface reconstruction based lidar data achieve fully autonomous navigation , vehicles need compute accurate model direct surrounding paper , 3d surface reconstruction algorithm heterogeneous density 3d data presented proposed method based based representation , adaptive neighborhood kernel sourced gaussian confidence evaluation introduced enables keep good trade density reconstructed mesh accuracy experimental evaluations carried synthetic \( \) real \( kitti \) 3d data show good performance compared state art method used surface reconstruction
optimality properties distributed strategies measurement based evaluation coordinated multicell ofdma transmission throughput multicell systems inherently limited interference available communication resources coordinated resource allocation key efficient performance , demand signaling computational resources grows rapidly number cells , terminals , handle , propose novel multicell framework dynamic cooperation clusters terminal jointly served small set base stations base station coordinates interference neighboring terminals , thus limiting making framework scalable framework describe interference channels ideal joint multicell transmission resource allocation \( e , precoding scheduling \) formulated optimization problem \( \) performance described arbitrary functions signal interference noise ratios \( \) arbitrary linear power constraints although \( \) nonconvex difficult solve optimally , able prove 1 \) optimality single stream beamforming 2 \) conditions full power usage 3 \) precoding based parameters zero one optimality properties used propose low complexity strategies centralized scheme distributed version requires local channel knowledge processing evaluate performance measured multicell channels observe proposed strategies achieve close optimal performance among centralized distributed solutions , respectively addition , show multicell interference coordination give substantial improvements sum performance , joint transmission sensitive synchronization errors terminals experience performance
feature fusion online mutual knowledge distillation propose learning framework named feature fusion learning \( \) efficiently powerful classifier fusion module combines feature maps generated parallel neural networks specifically , train number parallel neural networks sub networks , combine feature maps sub network using fusion module create meaningful feature map fused feature map fused classifier overall classification unlike existing feature fusion methods , framework , ensemble sub network classifiers transfers knowledge fused classifier fused classifier knowledge back sub network , mutually teaching one another online knowledge distillation manner mutually teaching system improves performance fused classifier also obtains performance gain sub network moreover , model beneficial different types network used sub network performed variety experiments multiple datasets cifar 10 , cifar 100 imagenet proved method effective alternative methods terms performance sub networks fused classifier
gated attention text comprehension paper study problem answering style questions documents model , gated attention \( ga \) reader , integrates multi hop architecture novel attention mechanism , based multiplicative interactions query embedding intermediate states recurrent neural network document reader enables reader build query specific representations document accurate answer selection ga reader obtains state art results three benchmarks task cnn daily mail news dataset effectiveness multiplicative interaction demonstrated ablation study , comparing alternative compositional operators implementing gated attention code available https url
local block coordinate descent algorithm convolutional sparse coding model convolutional sparse coding \( csc \) model recently gained considerable signal image processing communities providing global , yet tractable , model whole image , csc shown overcome several limitations patch based sparse model achieving superior performance various applications methods pursuit learning csc dictionary often rely alternating direction method multipliers \( \) fourier domain computational convolutions , ignoring local characterizations image recent work et al suggested algorithm csc , operating locally image patches demonstrates better performance compared fourier based methods , still relying work maintain localized strategy , proposing new much simpler approach based block coordinate descent algorithm method termed local block coordinate descent \( \) furthermore , introduce novel stochastic gradient descent version training convolutional filters stochastic leverages benefits online learning , applicable single training image demonstrate advantages proposed algorithms image multi focus image fusion , achieving state art results
cross lingual models word embeddings empirical comparison despite interest using cross lingual knowledge learn word embeddings various tasks , systematic comparison possible approaches literature perform extensive evaluation four popular approaches cross lingual embeddings , requiring different form supervision , four different language pairs evaluation setup four different tasks , including intrinsic evaluation lingual cross lingual similarity , extrinsic evaluation downstream semantic syntactic applications show models require expensive cross lingual knowledge almost always perform better , supervised models often prove competitive certain tasks
geometric approach upper bound theorem sums convex polytopes derive tight expressions maximum number k faces , 0 le k le 1 , sum , p 1 p r , r convex polytopes p 1 , , p r mathbb r , 2 r , \( recursively defined \) function number vertices polytopes r n results coincide recently proved 2 contrast 's approach , uses tools combinatorial algebra , approach purely geometric uses basic notions f h vector calculus , generalizes methodology used 15 14 proving upper bounds f vector sum two three convex polytopes , respectively r n key idea behind approach express sum p 1 p r section polytope mathcal c bounding k faces p 1 p r reduces bounding subset \( k r 1 \) faces mathcal c contain vertices r polytopes r n end paper sketch explicit construction upper bounds
learning adaptive exposure via constrained two level reinforcement learning online advertising e commerce , traditional problem assign right ad right user fixed ad slots paper , investigate problem advertising adaptive exposure , number ad slots locations dynamically change time based relative scores recommendation products order maintain user long term revenue , two types constraints need met exposure query level day level constraints model problem constrained markov decision process per state constraint \( \) propose constrained two level reinforcement learning original advertising exposure optimization problem two relatively independent sub optimization problems also propose constrained experience mechanism accelerate policy training process experimental results show method improve advertising revenue satisfying different levels constraints real world datasets besides , proposal constrained experience mechanism significantly improve training speed stability policy performance
robustness via closed loop robotic manipulation self supervised learning prediction appealing objective self supervised learning behavioral skills , particularly autonomous robots however , effectively utilizing predictive models control , especially raw image inputs , poses number major challenges predictions used \? \? paper , tackle questions proposing method learning robotic skills raw image observations , using autonomously collected experience show even imperfect model complete complex tasks continuously , requires model track objective \( e g , object interest \) enable robot continuously task , devise self supervised algorithm learning image registration , keep track objects interest duration trial demonstrate idea combined video prediction based controller enable complex behaviors learned scratch using raw visual inputs , including grasping , objects , non manipulation real world experiments demonstrate model trained robot hours autonomously collected , unlabeled data able successfully perform complex manipulation tasks wide range objects seen training
nesterov accelerated gradient scale adversarial attacks deep learning models vulnerable adversarial examples crafted applying human imperceptible perturbations benign inputs however , black box setting , existing adversaries often poor transferability attack defense models work , perspective regarding adversarial example generation optimization process , propose two new methods improve transferability adversarial examples , namely nesterov iterative fast gradient sign method \( ni fgsm \) scale invariant attack method \( sim \) ni fgsm aims adapt nesterov accelerated gradient iterative attacks effectively look improve transferability adversarial examples sim based discovery scale invariant property deep learning models , leverage optimize adversarial perturbations scale copies input images avoid overfitting white box model generate adversarial examples ni fgsm sim naturally integrated build robust gradient based attack generate adversarial examples defense models empirical results imagenet dataset demonstrate attack methods exhibit higher transferability achieve higher attack success rates state art gradient based attacks
joint link scheduling control vlc based indoor access networks demands wireless access services expected spectrum capacity near term spectrum deploying additional address challenge cost inefficient , due challenge system maintenance according report , mobile internet access traffic indoor leveraging power line communication available indoor infrastructure , visible light communication \( vlc \) utilized small one time cost vlc also facilitates great advantage able jointly perform illumination communications , little extra power beyond illumination required communications , thus rendering wireless access small power consumption study , investigate problem minimizing total power consumption general multi user vlc indoor network satisfying users' traffic demands maintaining acceptable level illumination utilize column generation method obtain epsilon bounded solution several practical implementation issues integrated proposed algorithm , including different configurations light source ways interference among vlc links extensive simulations , show approach reduces power consumption state art vlc based scheduling algorithms 60 maintaining required illumination
transmit antenna correlation spatial multiplexing systems letter present transmit antenna correlation spatial multiplexing systems channel state information transmitter \( csit \) multiple input multiple output \( mimo \) correlated channel indeed , high correlation system capacity performance related work thus far considered statistical channel model model approximate form transmitter receiver side correlation measuring power spectral \( \) , channel capacity well studied assumption correlation matrix actual configuration mimo systems linear structure uniform linear array \( \) therefore , propose optimal assumption novel transmit correlation matrix letter significantly reduce arithmetic complexity spectral norms use result maximize ergodic capacity minimize average bit error rate \( ber \) spatial multiplexing \( sm \) systems zero forcing \( \) linear receiver simulation results show proposed method achieve significant performance enhancement versus conventional equal power transmission
capacity two hop relay channel wireless energy transfer relay source energy transmission cost paper , investigate communication system energy harvesting \( eh \) source radio frequency \( rf \) energy band full duplex relay node exploits energy transmit data destination node via relay node assume two scenarios battery eh source first scenario , assume eh source equipped battery thereby cannot store energy result , rf energy harvested one symbol interval used following symbol interval second scenario , assume eh source equipped battery storage capacity store harvested rf energy result , rf energy harvested one symbol interval used following symbol system models , derive channel capacity subject average power constraint relay additional energy transmission cost eh source compare derived capacities achievable rates several benchmark schemes results show using optimal input distributions eh source relay essential high performance moreover , demonstrate energy transmission cost source result severe achievable performance
distorted lattices protection measure far triangulation degenerate short paper study protection properties quality measures family lattices obtained integer grid mathbb r show quality measures family maximized certain distortion parameter , parameter , lattice lattice , well known object discrete geometry
learning general principles hundreds software projects one project , call bellwether , offers best advice used offer advice many projects used make quality predictions new projects , even much experience new projects existing methods bellwether transfer slow applied projects studied , 60 days cpu find hence , propose general novel bellwether detection algorithm based hierarchical clustering level within tree clusters , one bellwether computed projects , tree hierarchical method scalable approach learning effective models large data sets example , nearly projects , prediction models generated general 's bellwether good found via standard methods
neural cache bit cache acceleration deep neural networks paper presents neural cache architecture , purposes cache structures transform massively parallel compute units capable running deep neural networks techniques arithmetic arrays , create efficient data mapping reducing data movement proposed neural cache architecture capable fully executing convolutional , fully connected , pooling layers cache proposed architecture also supports quantization cache experimental results show proposed architecture improve inference latency 18 state art multi core cpu \( \) , 7 server class gpu \( \) , model neural cache improves inference throughput 12 cpu \( 2 gpu \) , reducing power consumption 50 cpu \( gpu \)
specification construction using equivalences smt solvers propose method write check specification including quantifiers using behaviors , e , input output pairs method requires following input user \( 1 \) answers finite number queries , presents behavior user , whether behavior correct \( 2 \) equivalence theory \( set formulae \) , represents users opinion pairs behaviors equivalent respect specification \( 3 \) vocabulary , e , set formulae provide basic building blocks specification written , user specify type theory simple relational grammar , method generate vocabulary equivalence theories method automatically generates behaviors using satisfiability modulo theory solver since writing specification consists formalizing ideas initially , must , definition , least one initial step notion formalized user ad hoc manner step equivalence theory vocabulary call primitive formalization step considerably easier write equivalence theory vocabulary write full formal specification scratch , provide experimental evidence claim also show constructed , specification one level providing vocabulary material next level
lstm network real time odometry estimation use 2d attractive autonomous driving industry accuracy , light weight low cost however , since 2d slice surrounding environment detected scan , challenge execute important tasks localization vehicle paper present novel framework use deep recurrent convolutional neural networks \( rcnn \) odometry estimation using 2d application provides tools extract features data using convolutional neural networks \( cnns \) , addition models possible connections among consecutive scans using long short term memory \( lstm \) recurrent neural network results real road dataset show method run real time without using gpu acceleration competitive performance compared methods , interesting approach could complement traditional localization systems
multi view photometric stereo robust solution benchmark dataset spatially varying isotropic materials present method capture 3d shape spatially varying reflectance multi view photometric stereo \( \) technique works general isotropic materials algorithm suitable perspective cameras nearby point light sources data capture setup simple , consists digital camera , led , automatic single viewpoint , use set photometric stereo images identify surface points distance camera collect information multiple viewpoints combine structure motion obtain precise reconstruction complete 3d shape spatially varying isotropic bidirectional reflectance distribution function \( \) captured simultaneously inferring set basis mixing weights surface point experiments , demonstrate algorithm two different setups setup highest precision setup best according experiments , setting , captured shapes accurate 0 5 captured reflectance relative root mean square error \( \) 9 also quantitatively evaluate state art newly collected benchmark dataset , publicly available future research
semi supervised video object segmentation using capsule routing work propose capsule based approach semi supervised video object segmentation current video object segmentation methods frame based often require optical flow capture temporal consistency across frames difficult compute end , propose video based capsule network , , segment several frames conditioned reference frame segmentation mask conditioning performed novel routing algorithm attention based efficient capsule selection address two challenging issues video object segmentation 1 \) segmentation small objects 2 \) occlusion objects across time issue segmenting small objects addressed module allows network process small spatial regions video , framework utilizes novel memory module based recurrent networks helps tracking objects move frame occluded network trained end end demonstrate effectiveness two benchmark video object segmentation datasets outperforms current offline approaches dataset run time almost fast competing methods code publicly available https url
compositional languages neural learning model principle compositionality , enables natural language represent complex concepts via structured combination simpler ones , allows us open set messages using limited vocabulary compositionality indeed natural property language , may expect appear communication protocols created neural agents language games paper , propose effective neural learning \( \) algorithm , applied interacting neural agents , facilitates emergence structured type language indeed , languages provide learning speed advantages neural agents training , via provide probabilistic model explanation advantage compositional language exist experiments confirm analysis , also demonstrate emerged languages largely improve generalizing power neural agent communication
learning cooperative visual dialog agents deep reinforcement learning introduce first goal driven training visual question answering dialog agents specifically , pose cooperative game two agents communicate natural language dialog select unseen image images use deep reinforcement learning \( rl \) learn policies agents end end pixels multi agent multi round dialog game reward r n demonstrate two experimental results r n first , demonstration pure rl \( scratch \) , show results synthetic world , agents communicate vocabulary , e , symbols pre specified meanings \( x , , z \) find two bots communication protocol start using certain symbols ask answer certain visual attributes \( shape color style \) thus , demonstrate emergence language communication among dialog agents human supervision r n second , conduct large scale real image experiments dataset , supervised dialog data show rl agents significantly outperform agents interestingly , rl learns ask questions good , ultimately resulting informative dialog better team
capacity dna data embedding substitution number methods proposed last decade encoding information using \( dna \) , giving rise emerging area dna data embedding since dna sequence equivalent sequence symbols \( bases \) , dna data embedding \( called dna dna steganography \) seen digital communications problem channel errors analogous dna bases depending use coding dna host sequences , , respectively , denote dna segments cannot translated , dna data embedding essentially problem communications without side information encoder paper , shannon capacity dna data embedding obtained case dna sequences subject substitution modeled using model molecular evolution studies also drawn respect biological implications results presented
optimal power control multiuser channels paper , define power region set power allocations k users meets minimum signal interference ratio \( \) modeled multiuser system fixed linear receiver signature sequences show power region convex linear logarithmic scale furthermore minimal element power constraints included intersection set power r n framework , aim minimizing total power minimizing monotone functional feasible power region , minimum otherwise , solution balance conflicting interests , suggest projection minimum point power region onto set power settings finally , appropriate utility function , problem minimizing total power seen finding nash solution , sheds light power assignment game theoretic point view essential result
user guidance interactive camera calibration building augmented reality \( \) pipeline , crucial step camera calibration overall quality heavily depends turn camera calibration influenced choice camera pattern poses yet currently little research user specific pose build upon novel camera calibration framework capable generate calibration poses real time present user study evaluating different visualization methods guide user target pose using presented method even novel users capable perform precise camera calibration 2 minutes
interleaver design polar codes slow fading channels consider problem using polar codes slow fading wireless channels design , focus parallel slow fading channel 2 blocks , polar codes rate 1 2 motivated 's systematic polar code construction , propose interleaver design general polar code interleaver comprises using bit order bit channels interleaver called diversity interleaver addition diversity interleaver , diversity polar code proposed increase diversity gain r n proposed designs evaluated via link simulations awgn fading channels simulation results show performance close outage probability \( within 2 db \) significant gains using random interleaver
k median k center approximation algorithms ordered k median consider generalization k median k center , called em ordered k median problem problem , given metric space \( mathcal , c \) n mathcal points , non increasing weight vector w mathbb r n , goal open k centers assign point point j mathcal center minimize w 1 cdot text \( largest assignment cost \) w 2 cdot text \( second largest assignment cost \) ldots w n cdot text \( n th largest assignment cost \) give \( 18 epsilon \) approximation algorithm problem algorithms utilize relaxation primal dual , combined procedure special case 0 , 1 weights , models problem minimizing ell largest assignment costs interesting , provide novel reduction \( standard \) k median problem showing lp relative guarantees k median guarantees ordered k median problem yields nice clean \( 8 5 epsilon \) approximation algorithm 0 , 1 weights
optimal active social network de anonymization using information paper , de internet users actively querying group social networks considered problem , anonymous attacker 's website , attacker uses 's history query social media activity purpose de anonymization using minimum number queries stochastic model problem considered attacker partial prior knowledge group membership graph receives noisy responses real time queries 's identity assumed chosen randomly based given distribution models users' risk malicious website de anonymization algorithm proposed based information performance finite asymptotically large social network regimes analyzed furthermore , converse result provided proves optimality proposed attack strategy
lattice reduction aided mmse last years , novel low complexity approaches mimo channels gained much attention thereby , methods based lattice basis reduction special interest , achieve optimum diversity order paper , tutorial overview optimized according mmse criterion given proven applying zero forcing algorithm suitably augmented channel matrix \( inverse square root correlation matrix data symbols times noise variance forms lower part \) results optimum solution fact already widely used lacks formal proof turns important take correlations data correctly account type lattice reduction actually used
relationships average channel capacity average bit error rate outage probability outage capacity additive white gaussian noise channels wireless communications , average performance measures \( apms \) average channel capacity \( acc \) , average bit error rate \( \) outage probability capacity \( op \) widely utilized performance gains different environments various scenarios quantify factors design implementation influence system performance best knowledge , yet discovered apms related article , inspired work et al 1 , propose one calculated using apms without snr characterization particularly , using 's transformation \( \) , identify relationships among apms relationships irrespective snr distribution thereby , propose tractable approach , call based analysis , establish relationship two given apms , introduce novel relationships among acc , op performances additive white gaussian noise channels fading environments demonstrate obtain exact acc using performance , discover op performances obtained using exact acc performance consider numerical examples simulations validate newly derived relationships
massive mimo communications case studies future directions aerial vehicles \( \) , also known drones , applications , surveillance , management , , place high requirements communication drones terms throughput , reliability , latency existing wireless technologies , notably , currently used connectivity limited short ranges low mobility situations new , scalable technology needed meet future demands long connectivity ranges , support fast moving drones , possibility simultaneously communicate entire swarms drones massive multiple input multiple output \( mimo \) , main technology component emerging 5g , potential meet requirements
integrated nfv sdn architectures systematic literature review network functions virtualization \( nfv \) software defined networking \( sdn \) new paradigms move towards open software network hardware nfv aims network functions deploy general purpose hardware , sdn makes networks separating control data nfv sdn complementary technologies capable providing one network solution sdn provide connectivity virtual network functions \( \) flexible automated way , whereas nfv use sdn part service function chain many studies designing nfv sdn architectures different environments researchers trying address reliability , performance , scalability problems using different architectural designs systematic literature review \( \) focuses integrated nfv sdn architectures , following goals \) investigate provide depth review state art nfv sdn architectures , ii \) synthesize architectural designs , iii \) identify areas improvements broadly , encourage researchers advance current stage development \( e , state practice \) integrated nfv sdn architectures , shed light future research efforts challenges faced
review tree edit distance problem related path decomposition algorithms ordered labeled tree tree nodes labeled left right order among relevant edit distance two ordered labeled trees minimum cost changing one tree sequence edit steps literature , class algorithms based different yet closely related path decomposition schemes article reviews principles algorithms , studies concepts related algorithmic complexities consequence decomposition schemes
place apps fog state art open challenges fog computing aims extending cloud towards iot achieve improved qos latency sensitive bandwidth applications fog calls novel models algorithms multi component applications way data processing occurs best placed , based functional non functional requirements r n survey reviews existing methodologies solve application placement problem fog , three main objectives first , offers comprehensive overview currently employed algorithms , availability open source , size test use cases second , literature based application fog infrastructure characteristics captured available models , focus considered constraints metrics finally , identifies open challenges application placement fog
exploiting multi layer graph factorization multi attributed graph matching multi attributed graph matching problem finding correspondences two sets data considering complex properties described multiple attributes however , information multiple attributes likely process makes integrated attribute , matching accuracy reason , multi layer graph structure based algorithm proposed recently effectively avoid problem separating attributes multiple layers , several remaining issues scalability problem caused huge matrix describe multi layer structure back projection problem caused continuous relaxation quadratic assignment problem work , propose novel multi attributed graph matching algorithm based multi layer graph factorization reformulate problem solved several small matrices obtained multi layer structure , solve problem using convex concave relaxation procedure multi layer structure proposed algorithm exhibits better performance state art algorithms based single layer structure
dual approach object tracking based optical flow swarm intelligence computer vision , object tracking complex problem though several existing algorithms object tracking , still several challenges remain solved instance , variation illumination light , noise , occlusion , start stop moving object , etc , make object tracking complex problem dynamic background also static background paper propose dual approach object tracking based optical flow swarm intelligence optical flow based \( \) tracker , tracks dominant points target object first frame last frame video sequence whereas swarm intelligence based \( particle swarm optimization \) tracker simultaneously tracks boundary information target object second frame last frame video sequence dual function tracking makes much robust respect problems flexibility approach successfully applicable variable background well static background compare performance proposed dual tracking algorithm several benchmark datasets obtain competitive results general cases obtained superior results using dual tracking algorithm also compare performance proposed dual tracker existing based algorithms tracking achieved better results
detection man made environments automatic detection human areas important security road safety applications paper attempts solve problem using deep learning techniques variety computer vision fields including object detection , tracking , segmentation edge detection several interesting insights transfer learning adapting models trained benchmark datasets real world deployment empirical evidence presented demonstrate detectors generalize training images natural deployment scenarios man made environments solution also proposed using semi automated synthetic data generation domain specific training code data used experiments made available facilitate work domain
comprehensive review audio steganalysis methods recently , merging signal processing techniques information security services drawn lot attention steganography steganalysis among trends like counterparts , steganography steganalysis constant steganography methods try presence covert messages looking data , whereas steganalysis methods try break steganography algorithms reveal existence hidden messages streaming nature audio signals , popularity , wide spread usage make good candidates steganography led rich literature steganography steganalysis audio signals study conduct comprehensive review audio steganalysis methods near 15 years end , compressed compressed methods reviewed , important details presented different tables furthermore , recent audio steganalysis methods \( non compressed compressed ones \) implemented comparative analyses performances conducted finally , study provides possible directions future research studies audio steganalysis
promise human evaluation model interpretability , user trust , human comprehension popular interpretable machine learning support goals , researchers evaluate model explanation performance using humans real world applications presents challenge many areas artificial intelligence position paper , propose explanations discuss reasoning suggesting functional interpretability may correlated cognitive function user preferences indeed case , evaluation optimization using functional metrics could implicit cognitive bias explanations finally , propose two potential research directions cognitive function explanation models , control tradeoff accuracy interpretability
landmark detection low resolution faces semi supervised learning landmark detection algorithms trained high resolution images perform poorly datasets containing low resolution images performance algorithms relying quality landmarks , example , face recognition best knowledge , exist dataset consisting low resolution face images along annotated landmarks , making supervised training paper , present semi supervised approach predict landmarks low resolution images learning labeled high resolution images objective work show predicting landmarks directly low resolution images effective current practice aligning images two step process , proposed approach first learns generate low resolution images modeling distribution target low resolution images second stage , generated images real low resolution images model learns predict landmarks real low resolution images generated low resolution images extensive , study impact design choices also show prediction landmarks directly low resolution images improves performance important tasks face recognition low resolution images
interactive discovery coordinated relationship chains maximum entropy models modern visual analytic tools human loop analysis limited ability direct user toward interesting promising directions study problem especially acute analysis task nature , e g , discovery potentially coordinated relationships massive text datasets tasks common domains like intelligence analysis security forensics goal uncover surprising bridging multiple types relations introduce new maximum entropy models discover surprising chains relationships leveraging count data entity occurrences documents models embedded visual analytic system called treats relationship first class objects user toward promising lines demonstrate user input direct analysis toward valid conclusions whereas purely algorithmic approach could led experimental results synthetic real datasets intelligence community presented
use pairwise distance learning brain signal classification limited observations increasing access brain signal data using creates new opportunities study brain activity perform diseases work proposes pairwise distance learning approach classification relying spectral properties signal given limited number observations \( e case control individuals \) clinical trials , propose siamese neural network architecture learn discriminative feature space pairwise combinations observations per channel way , multivariate order signal used form data augmentation , supporting network generalization ability convolutional layers parameters learned loss proposed explore spectral images derived brain signal results case control population show features extracted using proposed neural network lead improved diagnosis \( accuracy sensitivity \) spectral features , thus suggesting existence non trivial , discriminative brain patterns
training neural networks based competitive algorithm predicting earthquake intensity study determined neural network weights biases competitive algorithm \( \) order train network predicting earthquake intensity reason , used dependent parameters like earthquake occurrence time , 's latitude degree , depth , center distance earthquake center provided data base studied neural network two hidden layer first layer 16 neurons second layer 24 neurons using algorithm , average error testing data 0 variance equal 0 earthquake prediction error mse criteria algorithm 0 , using ga , mse value 0
decentralized connectivity preserving deployment large scale robot swarms present decentralized scalable approach deployment robot swarm approach scenarios swarm must reach multiple spatially distributed targets , enforce constraint robot network cannot split basic idea behind work construct logical tree topology physical network formed robots logical tree acts backbone used robots enforce connectivity constraints study compare two algorithms form logical tree algorithms differ order robots join tree algorithm starts tree root grows towards targets , algorithm manner algorithms perform , prevent suboptimal topologies growth tree contributions \( \) formulation two algorithms \( ii \) comparison algorithms extensive physics based simulations \( iii \) validation findings real robot experiments
cross layer design wireless multihop networks stochastic channels time varying statistics network utility maximization often applied cross layer design wireless networks considering known wireless channels however , realistic wireless channel capacities stochastic time varying statistics , solution problems capture effects based theory develop framework scheduling , routing , congestion control power control wireless multihop networks considers stochastic long short term fading wireless channels specifically , wireless channel modeled via stochastic differential equations several assumptions exist state art channel modeling within framework finite number states consideration wireless channel modeling leads problem formulation non convex time varying utilities consider cases non orthogonal orthogonal access users medium first case , scheduling performed via power control , latter scheduling power control role power control increase users' optimal utility exploiting random reductions stochastic channel power loss also considering energy efficiency finally , numerical results evaluate performance operation proposed approach study impact several involved parameters convergence
soft goals compiled away soft goals extend classical model planning simple model preferences best plans ones least cost ones maximum utility , utility plan sum utilities soft goals achieved plan cost finding plans high utility appears involve two linked problems choosing subset soft goals achieve finding low cost plan achieve new search algorithms heuristics developed planning soft goals , new track introduced international planning competition \( ipc \) test performance note , show however extensions needed soft goals increase expressive power basic model planning action costs , easily compiled away apply problems net benefit track recent ipc , show optimal cost based planners better compiled problems optimal planners original problems explicit soft goals furthermore , show , negative preferences conditions avoid , also compiled away using similar idea
3d slicer study , present using free open source medical image computing platform biomedical research \( 3d \) slicer volumetric changes like critical factor treatment decisions general volume acquired manually therefore , manual slice slice segmentations magnetic resonance imaging \( mri \) data , obtained regular , performed contrast manual time consuming slice slice segmentation process slicer alternative significantly faster less user intensive contribution , compare pure manual segmentations ten semi automatic segmentations slicer thus , boundaries completely manually slice slice basis performed slicer enhanced segmentation using competitive region growing based module slicer named results showed time user effort required based segmentations average less pure manual segmentations furthermore , calculated dice similarity coefficient \( \) manual slicer based segmentations proof two comparable yielding average 97 3 39
neural architecture based fuzzy perceptual representation online multilingual recognition due mobile devices , online handwritten become important input smartphones devices increase online recognition performance , deeper neural networks extensively used context , paper handles problem online handwritten script recognition based extraction features system deep approach system sequences classification many solutions appeared order facilitate recognition accordingly , used method combined new classifiers order get flexible system good results achieved compared online characters words recognition system latin performance two proposed systems assessed using five databases indeed , recognition rate exceeds 98
acute triangulation cube shown exists acute triangulation three dimensional cube method constructing acute triangulation described , triangulation discussed
provable online dictionary learning sparse coding consider dictionary learning problem , aim model given data linear combination matrix known dictionary , sparse weights linear combination known coefficients since dictionary coefficients , linear model unknown , corresponding optimization inherently non convex major challenge recently , provable algorithms dictionary learning proposed yet , provide guarantees recovery dictionary , without explicit recovery guarantees coefficients moreover , estimation error dictionary impacts ability successfully localize estimate coefficients potentially limits utility existing provable dictionary learning methods applications coefficient recovery interest end , develop simple plausible alternating optimization based online dictionary learning algorithm , recovers dictionary coefficients exactly geometric rate , appropriately algorithm , , also scalable large scale distributed implementations neural architectures , mean involves simple linear non linear operations finally , theoretical results via experimental evaluation proposed algorithm current state art techniques
model based algorithm efficient storage format parallel hss structured matrix approximations present , novel model based algorithm implementation semi separable \( hss \) matrix computations parallel architectures uses novel storage format improve data locality scalability hss matrix matrix shared memory processors build performance model hss matrix matrix based performance model , mixed rank heuristic introduced find optimal hss tree depth faster hss matrix evaluation uniform sampling used improve performance hss compression outperforms state art hss matrix multiplication codes , , average 2 8x 6 respectively target processors
deep reinforcement learning autonomous internet things model applications challenges internet things \( iot \) extends internet connectivity iot devices around world , iot devices collect share information reflect status physical world autonomous control system \( \) , hand , performs control functions physical systems without external intervention extended period time integration iot results new concept autonomous iot \( \) sensors collect information system status , based intelligent agents iot devices well edge fog cloud servers make control decisions order achieve , promising method intelligent agents leverage techniques field artificial intelligence , especially reinforcement learning \( rl \) deep reinforcement learning \( drl \) decision making paper , first provide comprehensive survey state art research , propose general model applications rl drl finally , challenges open issues future research identified
trajectory optimization curvature bounded non vehicles application autonomous driving paper , propose trajectory optimization computing smooth collision free trajectories curvature bounded vehicles among static dynamic obstacles one key formulation optimization routine space angular linear velocities , optimization two layer structure wherein angular optimized keeping linear velocities fixed vehicle obstacles modeled velocity optimization layer shown computationally efficient difference convex structure commonly observed linear systems leads less conservative approximation compared obtained approximating polygon individually hand , leads optimization problem less number constraints compared obtained approximating polygons multiple overlapping use proposed trajectory optimization basis constructing model predictive control framework navigating autonomous car complex scenarios like , lane changing merging moreover , also highlight advantages provided alternating optimization routine specifically , show produces trajectories comparable lengths smoothness compared produced joint simultaneous optimization space angular linear velocities however , importantly , alternating optimization provides gain computational time
self multi label learning diversity major challenge learning multi label data size label space makes problem np hard problem gradually involving easy hard tags learning process besides , utilization diversity maintenance approach overfitting subset easy labels paper , propose self multi label learning diversity \( \) aims cover diverse labels respect learning addition , proposed framework applied efficient correlation based multi label method non convex objective function optimized extension block coordinate descent algorithm empirical evaluations real world datasets different dimensions features labels effectiveness proposed predictive model
incremental computation pseudo inverse laplacian theory applications based approach computing pseudo inverse combinatorial laplacian matrix \( l \) simple , undirected graph proposed nature underlying sub problems studied detail means elegant interplay l effective distance \( \) closed forms provided novel two stage process helps compute pseudo inverse analogous scalar forms obtained converse case , structural , breaking graph disjoint components successive edge deletions scalar forms cases , show absolute element wise independence stages , thus suggesting potential analytical experimental results presented dynamic \( time evolving \) graphs well large graphs general \( representing real world networks \) order magnitude reduction computational time achieved dynamic graphs general case , approach performs better practice standard methods , even though worst case theoretical complexities may remain important contribution consequences study online social networks
cake without two dimensional cake , pairwise disjoint required cut cake b pieces , entirely contained unique piece , total number pieces \( b , \) minimal number naturally depends geometric constraints cake pieces paper presents tight bounds number pieces must connected , convex rectangular
improving robustness heterogeneous serverless computing systems via probabilistic task pruning cloud based serverless computing increasingly popular computing paradigm paradigm , different services diverse computing requirements deploying heterogeneous computing \( hc \) system efficiently process hc system , task needed given service , potentially exhibits different execution times type machine ideal resource allocation system must aware uncertainties execution times robust , quality service \( qos \) requirements users met research aims maximize robustness hc system utilized offer serverless computing system , particularly system strategy maximize robustness develop task pruning mechanism added existing task mapping heuristics without pruning tasks low probability improves likelihood tasks , thereby increasing system robustness overall qos evaluate impact pruning mechanism , examine various configurations heterogeneous homogeneous computing systems evaluation results indicate considerable improvement \( 35 \) system robustness
knowledge base completion baselines back many papers published knowledge base completion task past years introduce novel architectures relation learning evaluated standard datasets fb15k paper shows accuracy almost models published fb15k outperformed appropriately tuned baseline model findings claim performance improvements recent models due architectural changes opposed hyper parameter tuning different training objectives future research consider performance models evaluated reported
double explore commit asymptotic optimality beyond study two armed bandit problem rewards explore commit \( etc \) strategy , consists exploration phase followed exploitation phase , one widely used algorithms variety online decision applications nevertheless , shown et al \( 2016 \) etc suboptimal asymptotic sense horizon grows , thus , worse fully sequential strategies upper confidence bound \( \) paper , argue variant etc algorithm actually achieve asymptotically optimal regret bounds multi armed bandit problems type algorithms specifically , propose double explore commit \( detc \) algorithm two exploration exploitation prove detc achieves asymptotically optimal regret bound time horizon goes infinity knowledge , detc first non fully sequential algorithm achieves asymptotic optimality addition , extend detc batched bandit problems , \( \) exploration process split small number \( ii \) round complexity central interest prove batched version detc achieve asymptotic optimality constant round complexity first batched bandit algorithm attain asymptotic optimality terms regret round complexity
graph power nonlinearity graph based semi supervised learning \( \) algorithms predict labels nodes based provided labels small set seed nodes classic methods capture graph structure underlying diffusion process propagates graph edges spectral diffusion , includes personalized page rank label propagation , propagates random walks social diffusion propagates shortest paths common ground em linearity , distinguish contributions strong relations many weak relations r n recently , non linear methods node embeddings graph convolutional networks \( gcn \) demonstrated large gain quality tasks methods introduce multiple components greatly vary graph structure , seed label information , features used r n aim study contribution non linearity , ingredient , performance gain , place classic linear graph self training framework surprisingly , observe using resulting em significantly improves respective non baselines also outperform state art non linear methods moreover , since self training scalability base method , obtain higher quality better scalability
step probabilistic programming cognitive architectures probabilistic programming considered framework , basic components cognitive architectures represented unified elegant fashion time , adopting component cognitive architectures extending capabilities probabilistic programming languages particular , implicit specification generative models via concepts links proposed , usefulness declarative knowledge achieving efficient inference briefly
multiple attribute text style transfer dominant approach unsupervised style transfer text based idea learning latent representation , independent attributes style paper , show condition necessary always met practice , even domain adversarial training explicitly aims learning disentangled representations thus propose new model controls several factors variation textual data condition disentanglement replaced simpler mechanism based back translation method allows control multiple attributes , like gender , sentiment , product type , etc , fine grained control trade content preservation change style pooling operator latent space experiments demonstrate fully model produces better generations , even tested new challenging benchmarks comprising reviews multiple sentences multiple attributes
hybrid monte carlo sampling smoother four dimensional data assimilation paper constructs ensemble based sampling smoother four dimensional data assimilation using hybrid monte carlo approach smoother samples efficiently posterior probability density solution initial time unlike well known ensemble kalman smoother , optimal linear gaussian case , proposed methodology naturally non gaussian errors non linear model dynamics observation operators unlike four dimensional variational met , finds mode posterior distribution , smoother provides estimate posterior uncertainty one use ensemble mean minimum variance estimate state , use ensemble conjunction variational approach estimate background errors subsequent assimilation numerical results demonstrate advantages proposed method compared traditional variational ensemble based smoothing methods
dynamic teaching sequential decision making environments describe theoretical bounds practical algorithm teaching model demonstration sequential decision making environment unlike previous efforts optimized learners teacher demonstrate static policy , focus teacher decision dynamically choose different policies different parts environment develop several teaching frameworks based previously defined supervised protocols , teaching dimension , extending handle noise sequences inputs encountered mdp provide theoretical bounds several important model classes setting suggest practical algorithm dynamic teaching
towards semantic perceptual image metric present full reference , perceptual image metric based vgg 16 , artificial neural network trained object classification fit metric new database based unique images annotated ground truth human received minimal instruction resulting metric shows competitive performance 2013 , database widely used assess image quality methods interestingly , shows strong responses objects potentially semantic relevance faces text , demonstrate using visualization technique ablation experiments effect , metric appears model higher influence semantic context judgments , observe particularly vast majority users image processing systems image quality assessment \( iqa \) tasks , findings may significant impact real world applications perceptual metrics
localization discrete event systems based state tree structures recently developed localization , top approach distributed control discrete event systems control framework decomposition \( global \) control action local control strategies individual agents paper , establish counterpart localization theory framework state tree structures , known efficient control design large systems new framework , introduce new concepts local state tracker , local control function , state based local global control equivalence , prove collective localized control behavior identical optimal \( e \) controlled behavior addition , propose new efficient localization algorithm exploits computation finally demonstrate localization approach model complex manufacturing system
stable camera motion estimation using convex programming study inverse problem estimating n locations 1 , , n \( global scale , translation negation \) r noisy measurements subset \( \) pairwise lines connect , , noisy measurements pm \( j \) j pairs \( , j \) \( signs unknown \) problem core structure motion \( \) problem computer vision , 's represent camera locations r 3 noiseless version problem , exact line measurements , considered previously general parallel rigidity theory , mainly order characterize conditions unique realization locations noisy pairwise line measurements , current methods tend produce spurious solutions clustered around locations sensitivity location estimates well known problem , especially large , irregular collections images r n paper introduce semidefinite programming \( \) formulation , tailored overcome clustering phenomenon identify implications parallel rigidity theory location estimation problem well posed , prove exact \( noiseless case \) stable location recovery results also formulate alternating direction method solve resulting semidefinite program , provide distributed version formulation large numbers locations specifically camera location estimation problem , formulate pairwise line estimation method based robust camera orientation subspace estimation lastly , demonstrate utility algorithm experiments real images
fusion framework moving foreground detection wavelet domain detecting moving foreground objects known difficult due similarity foreground objects background conventional methods cannot distinguish foreground background due small differences thus suffer detection foreground objects paper , present fusion framework address problem wavelet domain first show small differences image domain certain wavelet likelihood wavelet coefficient foreground estimated formulating foreground background models wavelet band proposed framework effectively aggregates different wavelet based characteristics wavelet transform experimental results demonstrated proposed method significantly outperformed existing methods detecting foreground objects specifically , average f measure proposed algorithm 0 compared 0 0 8 state art methods
analyzing classifiers code mixed factors sentiment identification multilingual often languages express social communication platforms sometimes , original script language preserved , using common script languages quite popular well due , multiple languages mixed different rules grammar , using script makes challenging task natural language processing even case accurate sentiment identification paper , report results various experiments carried movie reviews dataset code mixing property two languages like english , script tested various machine learning algorithms trained english features code mixed data achieved maximum accuracy using na bayes \( \) model also tested various models trained code mixed data , well english features highest accuracy 50 obtained using support vector machine \( svm \) model finally , analyzed snippets discussed challenges needed resolved better accuracy
nesterov accelerated gradient scale improving transferability adversarial examples recent evidence suggests deep neural networks \( dnns \) vulnerable adversarial examples , crafted adding human imperceptible perturbations legitimate examples however , existing adversarial attacks generate adversarial examples weak transferability , making difficult evaluate robustness dnns challenging black box setting address issue , propose two methods nesterov iterative fast gradient sign method \( n mi fgsm \) scale invariant attack method \( sim \) , improve transferability adversarial examples n mi fgsm tries better optimizer applying idea nesterov accelerated gradient gradient based attack method sim leverages scale invariant property dnns generated adversarial example set scaled images inputs , two methods naturally combined form strong attack enhance existing gradient attack methods empirical results imagenet 2017 adversarial competition show proposed methods generate adversarial examples higher transferability existing competing baselines
results weighted independent weighted independent np hard graph problem , remains computationally intractable many restricted graph classes particular , problem np hard classes sat graphs chordal graphs results showing problem np hard proper subclass intersection sat graphs chordal graphs hand , identify two new classes graphs problem admits polynomial time solutions
unpaired multi domain image generation via regularized conditional gans paper , study problem multi domain image generation , goal generate pairs corresponding images different domains recent development generative models , image generation achieved great progress applied various computer vision tasks however , multi domain image generation may achieve desired performance due difficulty learning correspondence different domain images , especially information paired samples given tackle problem , propose regularized conditional gan \( \) capable learning generate corresponding images absence paired training data based conditional gan , introduce two guide model learn corresponding semantics different domains evaluate proposed model several tasks paired training data given , including generation edges , generation faces different attributes , etc experimental results show model successfully generate corresponding images tasks , outperforms baseline methods also introduce approach applying unsupervised domain adaptation
upper bound number transpositions sort permutation consider problem upper bounding number transpositions needed sort permutation well known permutation using n \( n 1 \) 2 adjacent transpositions show , allow adjacent transpositions , well element position 1 element last position , number transpositions needed n 2 4 answers open question posed , \( 2010 \)
equivalent relaxations optimal power flow several convex relaxations optimal power flow \( \) problem recently developed using bus models branch flow models paper , prove relations among three convex relaxations semidefinite relaxation computes full matrix , chordal relaxation based chordal extension network graph , second order cone relaxation computes smallest partial matrix prove feasible sets bus model branch flow model , establishing equivalence two models second order cone relaxations results , networks , relaxations equivalent one always solve second order cone relaxation mesh networks , semidefinite relaxation tighter second order cone relaxation requires computational effort , chordal relaxation good balance simulations used illustrate results
greedy algorithm stochastic matching 2 approximation motivated applications online exchange , stochastic matching problem introduced , , , \( 2009 \) proven 4 approximation simple greedy strategy , fact 2 approximation paper confirm hypothesis
approximation algorithms max problem limited supply consider max problem limited supply , n items , c copies item , bidders every b v item goal find pricing p allocation items bidders maximizes , every item allocated c bidders , every receives one item b receives item p leq v presented 2 approximation problem et al presented 4 approximation price variant pricing must non increasing \( , p 1 geq p 2 geq geq p n \) present e \( e 1 \) approximation max problem limited supply , every 0 , \( 2 \) approximation price variant
implementation dynamic distributed dimensional data model new language writing data analysis programs easy implement run high performance similarly , dynamic distributed dimensional data model \( \) aims data analysis operations strong performance goals , unified data model associative arrays work , present implementation describe enables facilitates data analysis several experiments showcase scalable performance new version compared original matlab implementation
black box complexity binary value function binary value function , , appeared several studies theory evolutionary computation one extreme examples linear pseudo boolean functions unbiased black box complexity previously shown , n problem size augment upper bound n 2 \( 1 \) , precise roughly half values n also present lower bound n 1 \( 1 \) provide algorithm compute exact black box complexity given n
instance output optimal parallel algorithms acyclic joins massively parallel join algorithms received much attention recent years , prior work focused worst optimal algorithms however , worst case optimality join algorithms relies hard instances large output sizes , rarely appear practice stronger notion optimality em output optimal , requires algorithm optimal within class instances sharing input output size even stronger optimality em instance optimal , e , algorithm optimal every single instance , may always achievable r n traditional ram model computation , classical algorithm instance optimal acyclic join massively parallel computation \( mpc \) model , situation becomes much complicated first show class r hierarchical joins , instance optimality still achieved mpc model , give new mpc algorithm arbitrary acyclic join load \( p sqrt cdot p \) , , input output sizes join , p number servers mpc model improves mpc version algorithm \( sqrt \) factor furthermore , show output optimal \( p cdot \) , every acyclic non r hierarchical join finally , give first output sensitive lower bound triangle join mpc model , showing inherently difficult acyclic joins
inverse graphics gan learning generate 3d shapes unstructured 2d data recent work shown ability learn generative models 3d shapes unstructured 2d images however , training models requires step rendering process , therefore past work focused developing rendering models smooth non differentiable process various ways models thus unable take advantage photo realistic , fully , industrial built graphics industry paper introduce first scalable training technique 3d generative models 2d data utilizes non differentiable renderer account non , introduce proxy neural renderer match output non differentiable renderer propose discriminator output matching ensure neural renderer learns smooth appropriately evaluate model images generated 3d shapes , show model consistently learn generate better shapes existing models trained unstructured 2d images
meta modeling game deriving theory consistent based separation laws via deep reinforcement learning abstract paper presents new meta modeling framework employs deep reinforcement learning \( drl \) generate mechanical constitutive models interfaces constitutive models information flow directed graphs process writing constitutive models simplified sequence graph edges goal maximizing model score \( function accuracy , robustness forward prediction quality \) thus meta modeling formulated markov decision process well defined states , actions , rules , objective functions rewards using neural networks estimate policies state values , computer agent able efficiently self improve constitutive model generated self playing , way zero \( algorithm world game go \) improves numerical examples show automated meta modeling framework produces models outperform existing cohesive models benchmark separation data , also capable detecting hidden mechanisms among micro structural features incorporating constitutive models improve forward prediction accuracy , difficult tasks manually
biologically motivated deep learning method using hierarchical competitive learning study proposes novel biologically motivated learning method deep convolutional neural networks \( cnns \) combination cnns back propagation \( \) learning powerful method recent machine learning regimes however , requires large labeled data training , requirement become barrier real world applications address problem utilize unlabeled data , propose introduce unsupervised competitive learning requires forward propagating signals pre training method cnns method evaluated image discrimination tasks using mnist , cifar 10 , imagenet datasets , achieved state art performance biologically motivated method imagenet experiment results suggested method enables higher level learning representations solely forward propagating signals without backward error signal learning convolutional layers proposed method could useful variety poorly labeled data , example , time series medical data
run time parameter sensitivity analysis optimizations efficient execution parameter sensitivity analysis \( sa \) critical allow use image processing application investigated work processes high resolution whole cancer tissue images large datasets characterize classify disease however , application parameterized changes parameter values may significantly affect results thus , understanding impact parameters output using sa important draw reliable scientific conclusions execution application rather compute intensive , sa requires process input data multiple times parameter values systematically optimizing process important allow sa large datasets work , employ distributed computing system novel computation reuse optimizations accelerate sa new computation reuse strategy maximize reuse even limited memory availability previous approaches would able fully take advantage reuse proposed solution evaluated environment nodes \( cpu cores \) parallel efficiency 92 , improving previous reuse strategies 2 8x
crowd counting via weighted dense attribute feature maps crowd counting important task computer vision , many applications video surveillance although regression based framework achieved great improvements crowd counting , improve discriminative power image representation still open problem conventional holistic features used crowd counting often fail capture semantic attributes spatial cues image paper , propose integrating semantic information learning locality aware feature sets accurate crowd counting first , help convolutional neural network \( cnn \) , original pixel space mapped onto dense attribute feature map , dimension pixel wise feature indicates probabilistic strength certain semantic class , locality aware features \( \) built idea spatial neighboring patches proposed explore spatial context local information finally , traditional encoding method extended generalized form diverse coefficient weights taken consideration experimental results validate effectiveness presented method
performance analysis enhancement ofdm communications paper , analyze frequency orthogonal frequency division multiplexing \( ofdm \) system known ofdm high rate wireless personal area networks \( \) based ultra \( \) transmission besides considering standard , also propose study system performance application turbo \( ra \) codes , well ofdm bit methodology consists \( \) study channel model developed 15 frequency domain perspective suited ofdm transmission , \( b \) development quantification appropriate information theoretic performance measures , \( c \) comparison measures simulation results ofdm standard proposal well proposed extensions , \( \) consideration influence practical , imperfect channel estimation performance find current ofdm standard sufficiently exploits frequency channel , system performs channel rate turbo codes reduced complexity clustered bit algorithm improve system power efficiency 6 db data rate
modeling empathy conversations abstract empathy , defined behavioral sciences , ability human recognize , understand emotions , others paper , address two related problems automatic affective behavior analysis design annotation protocol automatic recognition empathy human human conversations propose evaluate annotation scheme empathy inspired modal model emotions annotation scheme evaluated corpus real life , conversations context behavioral analysis , designed automatic segmentation classification system empathy given different speech language levels representation empathy may , investigated features derived lexical acoustic spaces feature development process designed support fusion automatic selection relevant features high dimensional space automatic classification system evaluated call center conversations showed significantly better performance baseline
feedback capacity first order moving average gaussian channel feedback capacity stationary gaussian additive noise channel open , except case noise white find feedback capacity stationary first order moving average additive gaussian noise channel closed form specifically , channel given x z , 1 , 2 , , input x satisfies power constraint noise z first order moving average gaussian process defined z alpha u 1 u , alpha le 1 , white gaussian u , 0 , 1 , r n show feedback capacity channel log x 0 , x 0 unique positive root equation rho x 2 \( 1 x 2 \) \( 1 alpha x \) 2 , rho ratio average input power per transmission variance noise innovation u optimal coding scheme simple linear scheme additive white gaussian noise channel transmitter real valued information signal beginning communication subsequently receiver 's error processing feedback noise signal linear stationary first order autoregressive filter resulting error probability maximum likelihood decoding doubly exponentially duration communication feedback capacity first order moving average gaussian channel similar form best known achievable rate first order emph autoregressive gaussian noise channel studied , , , although optimality latter yet established
explaining black box decisions shapley cohort refinement introduce variable importance measure explain importance individual variables decision made black box function measure based shapley value cooperative game theory measures variable importance usually work changing value one variables others held fixed function interest approach create combinations predictors never appear practice never present prediction function created cohort refinement shapley approach measures variable importance without using data points actually observed
massively multilingual document alignment cross lingual sentence distance cross lingual document alignment aims identify pairs documents two distinct languages comparable content aligned data used variety nlp tasks training cross lingual representations mining parallel machine translation training paper develop unsupervised scoring function leverages cross lingual sentence embeddings compute semantic distance documents different languages semantic distances used guide document alignment algorithm properly pair cross lingual web documents across variety low , , high resource language pairs recognizing proposed scoring function state art methods computationally intractable long web documents , utilize tractable greedy algorithm performs experimentally demonstrate distance metric performs better alignment current baselines outperforming 7 high resource language pairs , 15 resource language pairs , 22 low resource language pairs
note clustering aggregation consider clustering aggregation problem given set want find clustering minimizes sum input binary case \( clustering \) problem known np hard turing reduction result providing polynomial time many one reduction result also implies 2 \( n \) cdot \( 1 \) time algorithm exists clustering instance n elements , unless exponential time hypothesis fails positive side , show problem fixed parameter tractable respect number input
deep transfer learning single channel automatic sleep channel mismatch many sleep studies suffer problem insufficient data fully utilize deep neural networks different use different set , leading need training automated algorithms rather small databases , whereas large annotated databases around cannot directly included studies data due channel mismatch work presents deep transfer learning approach overcome channel mismatch problem transfer knowledge large dataset small cohort study automatic sleep single channel input employ state art train network source domain , e large dataset , pretrained network target domain , e small cohort , complete knowledge transfer study two transfer learning scenarios slight heavy channel mismatch source target domains also investigate whether , , finetuning entirely partially pretrained network would affect performance sleep target domain using sleep studies \( mass \) database consisting 200 subjects source domain sleep database consisting 20 subjects target domain study , experimental results show significant performance improvement sleep achieved proposed deep transfer learning approach furthermore , results also reveal essential finetuning feature learning parts pretrained network able channel mismatch problem
syntax aware aspect level sentiment classification graph attention networks aspect level sentiment classification aims identify sentiment expressed towards aspect given context sentence previous neural network based methods largely ignore syntax structure one sentence paper , propose novel target dependent graph attention network \( \) aspect level sentiment classification , explicitly utilizes dependency relationship among words using dependency graph , propagates sentiment features directly syntactic context aspect target experiments , show method outperforms multiple baselines embeddings also demonstrate using bert representations substantially performance
fundamental limits caching heterogeneous networks work fundamental limits coded caching heterogeneous networks multiple \( n 0 \) senders antennas , serve different users associated \( linked \) shared , cache helps arbitrary number users assumption cache placement , work exact optimal worst case delay dof , broad range user cache association profiles profile describes many users cache achieved presenting information theoretic converse based index coding captures impact user cache association , well presenting coded caching scheme optimally association profile exploiting benefits encoding across users share cache work reveals powerful interplay shared multiple senders antennas , draw conclusion , long cache serves least n 0 users , adding single degree cache redundancy yield dof increase equal n 0 , time irrespective profile going 1 n 0 antennas reduces delivery time factor n 0 finally conclusions also drawn related problem coded caching multiple file requests
exploring use 5g points presence paper presents early exploration preliminary results use \( \) 5g points presence use 5g would enable cost effective deployment functions mobile nodes could integrated demand unified 5g infrastructure , enhancing capacity network adapt particular service requirements area first step , evaluate feasibility cost , terms energy consumption , using techniques resource constrained aerial vehicle platforms , fundamental software technology evolution towards 5g complement evaluation presenting proof concept considers use platforms enable real time 5g communications cases
massively parallel lossless data decompression today 's exponentially increasing data high cost storage make compression essential big data industry although research efficient compression , fast decompression critical analytics queries read compressed data decompression somewhat assigning data block different process , break speed require exploiting massive parallelism modern multi core processors gpus data decompression within block propose two new techniques increase degree parallelism decompression first technique exploits massive parallelism gpu simd architectures second compression efficiency data dependencies limit parallelism decompression evaluate techniques scheme , called , based compression huffman encoding achieve speed head head comparison several multi core cpu based libraries , achieving 17 energy saving comparable compression ratios
survey application machine learning techniques optical networks today , amount data communications networks extremely high diverse \( e g , data regarding users behavior , traffic traces , network , signal quality indicators , etc \) advanced mathematical tools required extract useful information large set network data particular , machine learning \( ml \) regarded promising area perform network data analysis enable , e g , network self configuration fault management survey classify describe relevant studies dealing applications ml optical communications networking optical networks system facing growth terms complexity due introduction huge number parameters \( routing configurations , modulation format , symbol rate , coding schemes , etc \) , mainly due , among others , coherent transmission technology , advanced digital signal processing presence nonlinear effects optical systems although good number research papers appeared last years , application ml optical networks still early stage survey provide reference researchers practitioners interested field work area , conclude paper proposing new possible research directions
detecting smart social network topic model approach detection social network challenging problem rigid anti rules resulted emergence smart legitimate users difficult identify paper , present novel classification approach based latent allocation \( \) , topic model approach local global information topic distribution patterns , capture tested one benchmark dataset one self collected dataset , proposed method outperforms art methods terms
secrecy via sources channels alice bob want share secret key communicate independent message , secret eavesdropper eve problem secret communication secret key generation two resources available correlated sources alice , bob , eve , noisy broadcast channel alice bob eve independent sources studied goal characterize fundamental tradeoff rates secret message secret key achievable solution proof optimality parallel channels sources case source component satisfies degradation order \( either legitimate receiver eavesdropper \) presented includes case jointly gaussian sources additive gaussian channel , secrecy region evaluated
model based outdoor performance capture propose new model based method accurately reconstruct human performances captured multi camera setup starting template actor model , introduce new unified implicit representation , skeleton tracking surface shape refinement method fits template video frames two stages first , coarse pose estimated , subsequently non rigid surface shape body pose jointly refined particularly surface shape refinement propose new combination 3d gaussians designed align model likely without explicit segmentation edge detection obtain much higher quality outdoor settings existing methods , show state art methods indoor scenes designed
solving inverse problems splitting networks propose new method uses deep learning techniques solve inverse problems inverse problem form learning end end mapping observed data ground truth inspired splitting strategy widely used regularized iterative algorithm tackle inverse problems , mapping decomposed two networks , one handling inversion physical forward model associated data term one handling denoising output former network , e , inverted version , associated prior regularization term two networks trained jointly learn end end mapping , getting two step training training annealing intermediate variable two networks gap input \( degraded version output \) output approaches ground truth proposed network , referred , flexible sense existing end end network structure first network existing denoising network structure used second one extensive experiments synthetic data real datasets tasks , motion deblurring , super resolution , colorization , demonstrate efficiency accuracy proposed method compared image processing algorithms
note measure new entropy like measure well new measure total uncertainty theory introduced measures better justified previously proposed candidates
model checking data flows concurrent network updates full version present model checking approach verification data flow correctness networks concurrent updates network configuration verification problem great importance software defined networking \( sdn \) , errors lead packet loss , black holes , security approach based specification temporal properties individual data flows , requirement flow free cycles check whether properties simultaneously satisfied active data flows network configuration updated represent behavior concurrent network controllers resulting configurations , introduce extension petri nets relation , characterizes data flow caused transition petri net safe petri nets , reduce verification temporal flow properties circuit model checking problem solved effective verification techniques like , interpolation , bounded model checking report encouraging experiments prototype implementation based hardware model
results permutation properties kind finite fields permutation polynomials many applications finite fields theory , coding theory , cryptography , combinatorial design , communication theory , permutation form x r \( x q 1 \) mathbb f q 2 studied , k , l x proved permutation polynomials r 1 q 1 1 paper , consider , finite fields mathbb f q 3 mathbb f q e two different kinds methods employed , partial results obtained
verification validation agent based simulations using virtual overlay multi agent system approach agent based models popular number different areas example , used range domains ranging modeling tumor growth , systems , models social networks , computer mobile self networks one reason success similarity human however , power abstraction , easily applicable wide number domains , hard validate agent based models addition , building valid simulations challenging task also crucial ensure modeling , level abstraction , model conceptual system system mind paper , address important area validation agent based models presenting novel technique broad applicability applied kinds agent based models present framework , virtual overlay multi agent system used validate simulation models addition , since agent based models typically growing , parallel , multiple domains , , present new single validation technique applicable agent based models technique , allows validation agent based simulations uses virtual overlay multi agent system overlay multi agent system comprise various types agents , form overlay top agent based simulation model needs validated able log , agents contains clearly defined constraints , , , real time demonstrate effectiveness , show broad applicability wide variety simulation models ranging social sciences computer networks spatial non spatial conceptual models
deterministic sketching streaming sparse recovery norm estimation study classic streaming sparse recovery problems using deterministic linear , including l1 l1 l1 sparse recovery problems \( latter also known l1 heavy hitters \) , norm estimation , approximate inner product focus fixed matrix r x n deterministic recovery estimation procedure work possible input vectors simultaneously results improve upon existing work , following main contributions r n proof l1 sparse recovery inner product estimation equivalent , matrices used solve problems upper bound number measurements \( eps 2 min log n , \( log n log \( 1 eps \) \) 2 \) also obtain fast sketching recovery algorithms making use fast transform running times number measurements improve upon previous work also obtain better error guarantees previous work terms smaller tail input vector r n new lower bound number linear measurements required solve l1 l1 sparse recovery show omega \( k eps 2 \( n k \) eps \) measurements required recover x 1 \( 1 eps \) x tail \( k \) 1 , x tail \( k \) x onto largest k coordinates magnitude r n tight bound theta \( eps 2 log \( eps 2 n \) \) number measurements required solve deterministic norm estimation , e , recover x 2 eps x 1 r n problems study , tight bounds already known randomized complexity previous work , except case l1 l1 sparse recovery , nearly tight bound known work thus aims study deterministic complexities problems
scheme maximal resource utilization peer peer live streaming peer peer streaming technology become one major internet applications offers opportunity high quality video content large number peers low costs widely efficient utilization peers server 's capacities , peers enjoy high bit rate video minimal end end delay paper , present practical scheduling algorithm works challenging condition capacity available , e , utilizes resources maximum streaming rate peer small number overlay network autonomously sub streams according budget model way number peers exactly one sub stream maximized hop count delay also taken account construct short depth trees finally , show simulation peers dynamically converge efficient overlay structure short hop count delay moreover , proposed scheme gives nice features homogeneous case simulated scenarios
algebraic decoding q ary reed muller product reed solomon codes consider list decoding algorithm recently proposed 8 q ary reed muller codes r q \( l , , n \) length n q simple easily accessible correctness proof given shows algorithm achieves relative error correction radius \( 1 1 n \) improvement proof using one point algebraic geometric codes given 8 described algorithm adapted decode product reed solomon codes propose new low complexity recursive algebraic decoding algorithm reed muller product reed solomon codes algorithm achieves relative error correction radius tau 1 \( 1 q \) technique proved outperform method complexity error correction radius wide range code rates
resource light method cross lingual semantic textual similarity recognizing semantically similar sentences across languages beneficial many tasks , ranging cross lingual information retrieval detection machine translation recently proposed methods predicting cross lingual semantic similarity short texts , however , make use tools resources \( e g , machine translation systems , syntactic named entity recognition \) many languages \( language pairs \) exist contrast , propose unsupervised resource light approach measuring semantic similarity texts different languages operate bilingual \( multilingual \) space , project continuous word vectors \( e , word embeddings \) one language vector space language via linear translation model align words according similarity vectors bilingual embedding space investigate different unsupervised measures semantic similarity exploiting bilingual embeddings word requiring limited size set word translation pairs languages , proposed approach applicable virtually pair languages exists sufficiently large corpus , required learn monolingual word embeddings experimental results three different datasets measuring semantic textual similarity show simple resource light approach reaches performance close supervised resource intensive methods , stability across different language pairs furthermore , evaluate proposed method two extrinsic tasks , namely extraction parallel sentences comparable corpora cross lingual detection , show yields performance comparable complex resource intensive state art models respective tasks
parallel chain protocol based logical clock emerging parallel chain protocols represent address scalability blockchain multiple parallel chain instances , whole throughput approach network capacity coordinate different blocks construct global ordering critical performance parallel chain protocol however , solutions use either global synchronization clock single chain bottleneck pre defined ordering sequences distortion causality order blocks addition , prior ordering methods rely honest participants follow ordering protocol , remain ordering \( \) attack r n hand , conflicting transactions included global block sequence make simple payment verification \( \) difficult clients usually need store full record transactions distinguish whether transactions however , requirement full record greatly application , especially mobile scenarios r n technical report , propose , leverages logical clock fine grained realize simple , efficient , secure parallel chain protocol observing characteristics parallel chain , find blocks ordering issue parallel chain many similarities event ordering distributed system thus adopts virtual logical clock , optimized minimum protocol overhead runs distributed way addition , combines mining incentive block ordering , providing incentive compatibility attack 's , fine grained well solve conflicting transactions parallel chain shown friendly
spectral regularization mode collapse gans despite excellent progress recent years , mode collapse remains major problem generative adversarial networks \( gans \) paper , present spectral regularization gans \( sr gans \) , new robust method mode collapse problem gans theoretical analysis shows optimal solution discriminator strong relationship spectral distributions weight matrix therefore , monitor spectral distribution discriminator spectral normalized gans \( sn gans \) , discover phenomenon refer spectral collapse , large number singular values weight matrices dramatically mode collapse occurs show strong evidence linking mode collapse spectral collapse based link , set tackle spectral collapse surrogate mode collapse developed spectral regularization method compensate spectral distributions weight matrices prevent , turn successfully prevents mode collapse gans provide theoretical explanations sr gans stable provide better performances sn gans also present extensive experimental results analysis show sr gans always outperform sn gans also always mode collapse sn gans fail code available https url
adaptive input representations neural language modeling introduce adaptive input representations neural language modeling extend adaptive softmax et al \( 2017 \) input representations variable capacity several choices input output layers , whether model words , characters sub word units perform systematic comparison popular choices self attentional architecture experiments show models equipped adaptive embeddings fast train popular character input cnn lower number parameters benchmark achieve 18 7 , improvement 10 5 compared previously best published result billion word benchmark , achieve 23
connecting dots document level neural relation extraction edge oriented graphs document level relation extraction complex human process requires logical inference extract relationships named entities text existing approaches use graph based neural models words nodes edges relations , encode relations across sentences models node based , e , form pair representations based solely two target node representations however , entity relations better expressed unique edge representations formed paths nodes thus propose edge oriented graph neural model document level relation extraction model different types nodes edges create document level graph inference mechanism graph edges enables learn intra inter sentence relations using multi instance learning internally experiments two document level biomedical datasets chemical disease disease show usefulness proposed edge oriented approach
benchmark breast image segmentation breast \( bus \) image segmentation challenging critical bus computer aided diagnosis \( cad \) systems many bus segmentation approaches proposed last two decades , performances approaches assessed using relatively small private datasets differ quantitative metrics , result discrepancy performance comparison therefore , need building benchmark compare existing methods using public dataset , determine performance best breast tumor segmentation algorithm available today investigate segmentation strategies valuable clinical practice theoretical study work , b mode bus image segmentation benchmark \( \) images compare performance five state art bus segmentation methods quantitatively
visually aware fashion recommendation design generative image models building effective recommender systems domains like fashion challenging due high level semantic complexity features involved \( e , fashion styles \) recent work shown approaches recommendation \( e g , art , etc \) made accurate incorporating visual signals directly recommendation objective , using feature representations derived deep networks , seek extend contribution showing recommendation performance significantly improved learning image representations directly , e , training image representation \( pixel level \) recommender system jointly contribution related recent work using siamese cnns , though able show improvements state art recommendation techniques variants make use pre trained visual features furthermore , show model used emph , e , given user product category , generate new images \( e , items \) consistent personal represents first step towards building systems go beyond existing items product corpus , used suggest styles aid design new products
extended finite automata decision problems matrix make connection membership identity problems matrix groups extended finite automata provide alternative proof decidability membership problem 2 times 2 integer matrices show problem extended finite automata 4 times 4 integer matrix prove decidability problem extended finite automata sufficient condition decidability membership identity problems
linear upper bound weisfeiler dimension graphs bounded weisfeiler \( wl \) dimension graph measure inherent complexity graph originally derived combinatorial graph isomorphism test called weisfeiler algorithm , wl dimension also terms number variables required describe graph isomorphism first order logic counting quantifiers r n known wl dimension upper bounded graphs exclude fixed graph minor \( , 2012 \) however , bounds derived general result recently , proved wl dimension planar graphs 3 \( , , , 2017 \) r n paper , prove wl dimension graphs surface g 3 wl dimension graphs surface g , approach yields upper bound 3
effective sampling fast segmentation using robust geometric model fitting identifying underlying models set data points noise outliers leads highly complex multi model fitting problem problem posed clustering problem projection higher order data points graph , clustered using spectral clustering calculating possible higher order computationally expensive hence , cases , subset used paper , propose effective sampling method obtaining highly accurate approximation full graph , required solve multi structural model fitting problems computer vision proposed method based observation usefulness graph segmentation improves distribution hypotheses used build graph approaches distribution actual parameters given data paper , approximate actual parameter distribution using k th order statistics based cost function , samples generated using greedy algorithm coupled data sub sampling strategy experimental analysis shows proposed method accurate computationally efficient compared state art robust multi model fitting techniques implementation method publicly available https github com model fitting
cooperation visual dialog models work propose intervention method visual dialog models , aim contribution individual linguistic visual components , conduct structured randomized aim individual component model , observe changes task performance state art visual dialog model demonstrate methodology yields surprising insights , namely dialog image information minimal contributions task performance intervention method presented applied check strength robustness component visual dialog systems
pgd adversarial training necessary alternative training via soft quantization network noisy natural samples recent work adversarial attack defense suggests pgd universal l infty first order attack , pgd adversarial training significantly improve network robustness wide range first order l infty bounded attacks , represented state art defense method however , obvious pgd adversarial training highly computational cost generating adversarial samples , making computationally large high resolution real datasets imagenet dataset addition , recent work also suggested simple close form solution robust model mnist therefore , natural question pgd adversarial training really necessary robust defense \? paper , give negative answer proposing training paradigm comparable pgd adversarial training several standard datasets , using noisy natural samples specifically , reformulate min max objective pgd adversarial training problem minimize original network loss plus l 1 norms gradients w r inputs l 1 norm loss , propose computationally feasible solution embedding differentiable soft quantization layer network input layer show formally soft quantization layer trained noisy natural samples alternative approach minimizing l 1 gradient norms pgd adversarial training extensive empirical evaluations standard datasets show proposed models comparable pgd adversarially trained models pgd attacks remarkably , method achieves speed mnist maintaining comparable ability , first time fine robust imagenet model within two days code provided url https url
actor critic linearly solvable continuous mdp partially known dynamics many robotic applications , aspects system dynamics modeled accurately others difficult obtain model present novel reinforcement learning \( rl \) method continuous state action spaces learns partial knowledge system without active exploration solves linearly solvable markov decision processes \( l mdps \) , well suited continuous state action spaces , based actor critic architecture compared previous rl methods l mdps path integral methods model based , actor critic learning need model dynamics , importantly , transition noise levels however , requires knowing control dynamics problem evaluate method two synthetic test problems , one real world problem simulation using real traffic data experiments demonstrate improved learning policy performance
linear programming decoding linear codes framework linear programming \( lp \) decoding linear codes developed framework facilitates linear programming based coded modulation systems use direct modulation mapping coded symbols proved resulting lp decoder likelihood property also shown decoder output cost equivalence linear program graph covers proved also proved channel combination satisfies particular symmetry condition , codeword error rate performance independent transmitted codeword two alternative polytopes use linear programming decoding studied , shown many classes codes polytopes yield complexity advantage decoding polytope representations lead polynomial time decoders wide variety classical linear codes lp decoding performance illustrated 11 , 6 ternary code ternary psk modulation awgn , case shown performance lp decoder comparable codeword error rate optimum hard decision based decoding lp decoding also simulated medium length ternary ldpc codes corresponding psk awgn
deterministic approximate counting degree 2 polynomial threshold functions let g 1 , 1 k 1 , 1 boolean function q 1 , dots , q k degree 2 polynomials 1 , 1 n give emph deterministic algorithm , given input explicit descriptions g , q 1 , dots , q k accuracy parameter eps 0 , approximates pr x sim 1 , 1 n g \( sign \( q 1 \( x \) \) , dots , sign \( q k \( x \) \) \) 1 within additive pm eps constant eps 0 k geq 1 running time algorithm fixed polynomial n first fixed polynomial time algorithm approximately count satisfying natural class depth 3 boolean r n algorithm extends recent result cite deterministic approximate counting algorithm single degree 2 polynomial threshold function sign \( q \( x \) \) , corresponding k 1 case result r n algorithm analysis requires several novel technical go significantly beyond tools required handle k 1 case cite one new multidimensional central limit theorem degree 2 polynomials gaussian random variables builds recent calculus based results probability theory use basis new decomposition technique k tuples degree 2 gaussian polynomials thus obtain efficient deterministic approximate counting algorithm gaussian distribution finally , third new ingredient lemma emph k tuples degree polynomial threshold functions generalizes cite 10 , lemma et al cite new lemma lets us extend deterministic approximate counting results gaussian boolean domain
large scale noma massive machine type communication investigate large scale deployment non orthogonal multiple access \( noma \) improved spectral power efficiency cellular networks provide massive wireless connectivity \( e g machine type communication \) first , describe single antenna noma technology extension co located multiple antenna noma well coordinated transmission \( \) enabled noma technologies discuss practical challenges large scale deployment noma inter noma interference \( \) , inter cell interference , hardware implementation complexity end , present one key enabling technique overcome challenges large scale deployment noma generally speaking , feasible large scale noma implementation , sophisticated diversity enhancing techniques used compensate degradation coding gain decrease complexity resulting increased level required successive interference cancellation \( \) furthermore , massively extend noma network coverage area , noma transmitters cooperate generalized manner serve nearby users simultaneously
comments bit interleaved coded modulation , presented detailed analysis bit interleaved coded modulation , simple popular technique used improve system performance , especially context fading channels derived upper bound probability error , called bound correspondence , proof bound shown new upper bound also derived known whether original bound valid important special case square qam labeling , new bound close , slightly tighter , original bound numerical example
achievable degrees freedom k user broadcast channel alternating csit via interference creation channel state information transmitter affects degrees freedom wireless networks paper , analyze dof k user multiple input single output \( \) broadcast channel \( bc \) alternating channel state information transmitter \( csit \) specifically , csit user three states , namely , perfect csit \( p \) , csit \( \) csit \( n \) among different time slots k user bc , show total achievable degrees freedom \( dof \) given k 2 2k 1 utilizing benefits csit patterns compare achievable dof results reported previously literature case csit hybrid csit models
multi criteria service selection algorithm business process requirements selection appropriate web services realize business tasks still remain open issue propose multi criteria algorithm efficient service selection web services qos values stored web service ontology \( \) business processes modeled 0 specifications algorithm performs instance based ontology matching business process ontology business context , functional properties qos values web services considered algorithm computes variation qos values times strategy allows better accurate web services ranking relevant user 's request
thanks predicting zero valued activations lightweight convolutional neural networks convolutional neural networks \( cnns \) introduce state art results various tasks price high computational demands inspired observation spatial correlation exists cnn output feature maps \( \) , propose method dynamically predict whether activations zero valued according neighboring activation values , thereby avoiding zero valued activations reducing number convolution operations implement zero activation predictor \( \) lightweight cnn , imposes negligible easy deploy train furthermore , tuned many different operating points along accuracy savings trade curve example , using vgg 16 2012 dataset , different operating points achieve reduction 23 5 32 3 \( mac \) operations top 1 top 5 accuracy degradation 0 3 0 1 1 0 5 without fine tuning , respectively considering one fine tuning , 7 mac operations may reduced 1 1 0 accuracy degradation
data driven segmentation post mortem iris images paper presents method segmenting iris images obtained subjects , training deep convolutional neural network \( dcnn \) designed purpose semantic segmentation post mortem iris recognition recently emerged alternative , additional , method useful analysis time poses many new challenges technological , one image segmentation stage , proven difficult reliably conventional iris recognition methods approach based architecture , fine tuned 1 , manually segmented post mortem iris images taken post mortem iris v1 0 database experiments presented paper show data driven solution able learn specific present post mortem samples , missing , offers considerable improvement state art , conventional segmentation algorithm \( \) intersection union \( \) metric improved 6 \( \) \( dcnn based presented paper \) subject disjoint , multiple data train test subsets paper offers first known us method automatic processing post mortem iris images offer source codes trained dcnn perform end end segmentation post mortem iris images , described paper also , offer binary masks corresponding manual segmentation samples post mortem iris v1 0 database facilitate development alternative methods post mortem iris segmentation
cross domain collaborative filtering via translation based learning proliferation social media platforms e commerce sites , several cross domain collaborative filtering strategies recently introduced transfer knowledge user preferences across domains main challenge cross domain recommendation learn users' different behaviors multiple domains paper , propose cross domain collaborative filtering model following translation based strategy , namely model , learn embedding space translation vectors capture high order feature interactions users' multiple preferences across domains , efficiently compute feature latent embeddings , feature pairs high interaction weights latent space , feature embeddings observed interactions across domains closely related well formulate objective function ranking problem factorization machines learn model 's parameters via gradient descent addition , better capture non linearity user preferences across domains extend proposed model using deep learning strategy , namely experiments six publicly available cross domain tasks demonstrate effectiveness proposed models , outperforming state art cross domain strategies
unsupervised deep multi focus image fusion convolutional neural networks recently used multi focus image fusion however , due lack labeled data supervised training networks , existing methods adding gaussian blur focused images simulate generate synthetic training data ground truth supervised learning moreover , classify pixels focused leverage results construct fusion weight maps series post processing steps paper , present unsupervised end end learning directly predicting fully focused output image multi focus input image pairs proposed approach uses novel cnn architecture trained perform fusion without need ground truth fused images exploits image structural similarity \( \) calculate loss metric widely fused image quality evaluation consequently , able utilize em real benchmark datasets , instead simulated ones , train network model forward , fully convolutional neural network process images variable sizes test time extensive evaluations benchmark datasets show method outperforms existing state art terms visual quality objective evaluations
university neural systems paper describes university 's shared news translation biomedical translation tasks 12 translation directions news , translating english , german , , , chinese biomedical task submitted systems english , german , systems neural machine translation systems trained , attentional encoder decoder follow setup last year build based models parallel back translated monolingual training data year include use deep architectures , layer normalization , compact models due weight improvements segmentations perform extensive experiments , reporting layer normalization , deep architectures , different techniques
two attacks rank metric code based schemes identity based encryption scheme code based signature scheme proposed nist competition quantum safe cryptography , moreover , fundamental building block new identity based encryption \( \) signature scheme based rank metric enjoys remarkably small key sizes , intended level security bits unfortunately show parameters proposed scheme algebraic attack exploits fact augmented codes used scheme low weight codewords therefore , without cannot time second contribution show problem deeper finding new signature rank based cryptography , also found attack generic problem upon security reduction relies however , scheme , seems parameters scheme could chosen order avoid attack finally , also shown one rank metric scheme hamming metric , attack found
spectral concentration greedy k clustering popular graph clustering method consider embedding input graph r k induced first k laplacian , partition graph via geometric manipulations resulting metric space despite practical success methodology , limited understanding several heuristics follow framework provide theoretical justification one natural computationally efficient variant r n result follows partition graph called strong cluster small external , large internal present simple greedy spectral clustering algorithm returns partition provably close suitably strong partition , provided partition exists recent result shows strong partitions exist graphs sufficiently large spectral gap k th \( k 1 \) th eigenvalues taking together main theorem gives spectral algorithm finds partition close strong one graphs large enough spectral gap also show simple greedy algorithm implemented near linear time fixed k error guarantee finally , evaluate algorithm real world synthetic inputs
fog computing based framework resources information infrastructure management spatial data infrastructure \( \) important concept sharing spatial data across web cumulative techniques spatial cloud computing fog computing , greater potential emerged tool processing , analysis transmission spatial data fog computing paradigm fog devices help increase throughput reduce latency edge client respect cloud computing environment paper proposed developed fog computing based framework mining analytics spatial big data resources management built prototype using pi , embedded validated taking suitable case study resources management preliminary analysis including overlay analysis results showed fog computing hold great promise analysis spatial data used open source e reducing transmission cloud fog node
complexity control behaviors k peaked elections variant approval voting single peaked elections much attention recently many np hard voting problems become polynomial time solvable restricted single peaked elections natural generalization single peaked elections k peaked elections , k allowed election paper , mainly aim establishing complexity dichotomy controlling behaviors variant strategy preference based approval voting k peaked elections different values k turns np hardness results general case also hold k peaked elections , even k 2 , 3 hand , derive polynomial time algorithms certain strategy preference based approval voting control problems k 2 addition , also study strategy preference based approval control problems viewpoint parameterized complexity prove fpt w hardness results
capacity results noisy channel motivated dna based storage , study noisy channel , seen concatenation standard noisy channel \( \) channel , breaks data block small pieces channel models dna storage system , capturing two key aspects \( 1 \) data written onto many short dna stored way \( 2 \) corrupted noise synthesis , , storage channel characterize capacity exactly \( large set parameters \) , show simple index based coding scheme optimal
real root finding rank linear hankel matrices let h 0 , , h n times matrices entries hankel structure , e constant consider linear hankel matrix h \( \) h 0 x 1 x n problem computing sample points connected component real algebraic set defined rank constraint sf rank \( h \( \) \) leq r , given integer r leq 1 computing sample points real algebraic sets defined rank linear matrices general problem finds applications many areas control theory , computational geometry , optimization , etc moreover , hankel matrices appear many areas engineering sciences also , since hankel matrices symmetric , algorithmic development problem seen first step towards dedicated exact algorithm solving semi definite programming problems , e linear matrix assumptions input \( smoothness variety \) , design probabilistic algorithm tackling problem adaptation called critical point method takes advantage special structure problem complexity essentially quadratic specific degree bounds variety report practical experiments analyze algorithm takes advantage special structure first implementation outperforms existing implementations computing sample points general real algebraic sets examples reach state art
energy harvesting framework network simulator 3 ns 3 problem designing optimal communication protocols energy harvesting wireless networks recently received considerable attention , thus requiring accurate modeling energy harvesting process simulation framework include current ns 3 energy framework allows definition new energy sources incorporate contribution energy harvester , integrating energy harvester component existing energy source using existing energy framework paper , propose extension ns 3 20 energy framework order explicitly introduce concept energy harvester starting definition general energy harvester , provide implementation two simple models energy harvester addition , introduce concept energy predictor , information energy source harvester uses information predict amount energy available future finally , extend current energy framework include model energy source device energy model energy consumption sensor example simulation results show benefit contributions ns 3 energy framework
real time approximate bayesian computation scene understanding consider scene understanding problems predicting person reaching , inferring pose 3d objects depth images , inferring street pedestrians busy intersection paper shows solve problems using approximate bayesian computation underlying generative models built realistic simulation software , bayesian error model gap simulation outputs real data simulators drawn computer graphics , video game , traffic simulation code paper introduces two techniques inference used separately combination first train neural simulators , using simple form domain randomization make robust gap simulation reality second adaptively latent variables using tree approach adapted computer graphics paper also shows performance accuracy measurements real world problems , establishing feasible solve problems real time
using backpropagation speech texture generation voice conversion inspired recent work neural network image generation rely backpropagation towards network inputs , present proof concept system speech texture synthesis voice conversion based two mechanisms approximate inversion representation learned speech recognition neural network , matching statistics activations different source target similar image texture synthesis neural style transfer , system works optimizing cost function respect input samples end use differentiable feature extraction pipeline train convolutional ctc speech recognition network system able extract speaker characteristics limited amounts target speaker data , little seconds , used generate realistic speech reconstruct utterance different voice
auto encoder matching model learning utterance level semantic dependency dialogue generation generating semantically coherent responses still major challenge dialogue generation different conventional text generation tasks , mapping inputs responses conversations complicated , highly demands understanding utterance level semantic dependency , relation whole meanings inputs outputs address problem , propose auto encoder matching \( \) model learn dependency model contains two auto encoders one mapping module auto encoders learn semantic representations inputs responses , mapping module learns connect utterance level representations experimental results automatic human evaluations demonstrate model capable generating responses high coherence compared baseline models code available https url
inferring networks complementary products modern recommender system , important understand products relate example , user looking mobile phones , might make sense phones , phone , might instead want , cases , two types recommendations referred products instead , products addition r n develop method infer networks complementary products formulate supervised link prediction task , learn semantics data associated products primary source data use text product reviews , though method also makes use features ratings , specifications , , , build topic models trained automatically discover topics text successful predicting explaining relationships experimentally , evaluate system product , large dataset consisting 9 million products , million links , million reviews
covariance correlation kernels graph generalized paths formalism work closed form expressions computing expectation co number co nodes paths sampled network according general path weights \( paths \) underlying idea two nodes considered similar appear together \( short \) paths network results obtained regular paths serve basis computing new covariance correlation measures nodes experiments semi supervised classification show introduced similarity measures provide competitive performances compared state art distances similarities
virtual accurate definition mobile robot workspace using rgb google address problem controlling workspace mobile robot ensure human aware navigation especially relevance non expert users human robot shared spaces , e g home environments , since want keep control mobile robots , robots therefore , introduce virtual robot performing tasks purpose , employ rgb google human robot interface specify virtual environment evaluated system concerning correctness , accuracy teaching effort , compared results baseline methods method features equally high accuracy reducing teaching effort factor 3 1 compared baseline
motion guided attention video salient object detection video salient object detection aims discovering visually distinctive objects video effectively take object motion consideration video salient object detection critical issue existing state art methods either explicitly model motion cues ignore spatial contexts within optical flow images paper , develop multi task motion guided video salient object detection network , learns two sub tasks using two sub networks , one sub network salient object detection still images motion saliency detection optical flow images introduce series novel motion guided attention modules , utilize motion saliency sub network enhance sub network still images two sub networks learn adapt end end training experimental results demonstrate proposed method significantly outperforms existing state art algorithms wide range benchmarks hope simple effective approach serve solid baseline help future research video salient object detection code models made available
beyond trace reconstruction population recovery deletion channel emph population recovery problem learning unknown distribution unknown set n bit strings , given access independent distribution independently corrupted according noise channel recent work studied problems bit erasure noise channels r n study population recovery emph deletion channel , bit independently emph deleted fixed probability bits concatenated transmitted far challenging noise model bit noise erasure noise indeed , even case population size 1 \( corresponding trivial distribution supported single string \) corresponds emph trace reconstruction problem , challenging problem received much recent attention \( see e g cite , , , , \) r n give algorithms lower bounds population recovery deletion channel population size ell 1 main sample complexity upper bound , show ell \( log n log log n \) , population ell strings 0 , 1 n learned deletion channel noise using 2 n 1 2 \( 1 \) samples lower bound side , show n omega \( ell \) samples required perform population recovery deletion channel , ell leq n 1 2 epsilon r n upper bounds obtained via robust multivariate generalization polynomial based analysis , due cite , k bit string identifies string different approach recent algorithms trace reconstruction \( ell 1 case \) lower bounds build moment matching results cite cite
kernel based training generative networks generative adversarial networks \( gans \) designed help min max optimization problems solved stochastic gradient type algorithms known non robust work revisit non adversarial method based kernels relies pure minimization problem propose simple stochastic gradient algorithm computation solution using simplified tools stochastic approximation theory demonstrate batch versions algorithm smoothing gradient improve convergence observations allow development training algorithm enjoys reduced computational complexity increased robustness exhibiting similar synthesis characteristics classical gans
1 adversarial robustness based adversarial robustness research contains various implementations attacks , defenses robust training methods built \( et al , 2017 \) , leverages advantages dynamic computational graph provide efficient reference implementations code license open sourced https url
conditional transfer dense residual attention traffic signs street view imagery object detection classification traffic signs street view imagery essential element asset management , map making autonomous driving however , traffic signs occur rarely consequently , difficult recognize automatically improve detection classification rates , propose generate images traffic signs , used train detector classifier research , present end end framework generates realistic image traffic sign given image traffic sign target class propose residual attention mechanism dense concatenation called dense residual attention , preserves background information transferring object information also propose utilize multi scale , smaller scales output guide higher resolution output performed detection classification tests across large number traffic sign classes , training detector using combination real generated data newly trained model reduces number false positives 1 2 1 5 99 recall detection tests absolute improvement 4 \( top 1 accuracy \) classification tests
reconstruction simulation based physical field reconstruction neural network method variety modeling techniques developed past decade reduce computational expense improve accuracy modeling study , new framework modeling suggested compared popular methods , distinctive characteristic image based model analysis based model \( e g , , \) framework , reconstruction neural network \( reconnn \) model designed simulation based physical field 's reconstruction proposed reconnn contains two convolutional neural network \( cnn \) generative adversarial net work \( gan \) cnn employed construct mapping contour images physical field objective function subsequently , gan utilized generate images similar existing contour images finally , polynomial applied complete reconstruction however , existing cnn models commonly applied classification tasks , difficult handle regression tasks images meanwhile , existing gan architectures insufficient generate high accuracy pseudo contour images therefore , reconnn model based convolution convolution \( \) convolutional autoencoder based generative adversarial network \( cae \) suggested evaluate performance proposed model , classical topology optimization procedure considered reconnn utilized reconstruction heat transfer process pin heat sink demonstrates proposed reconnn model proved potential capability reconstruct physical field , structural optimization
curriculum deepsdf learning sketch , start simple flexible shapes , gradually complex accurate ones subsequent training paper , design shape curriculum learning continuous signed distance function \( \) shapes , namely curriculum deepsdf inspired humans learn , curriculum deepsdf learning task order difficulty according following two criteria surface accuracy sample difficulty former considers ground truth , latter weights hard training samples near complex geometry fine structure specifically , curriculum deepsdf learns reconstruct coarse shapes first , gradually increases accuracy focuses complex local details experimental results show carefully designed curriculum leads significantly better shape training data , training network architecture deepsdf believe application shape benefit training process wide variety 3d shape representation learning methods
probabilistic view neighborhood based recommendation methods probabilistic graphic model elegant framework present complex real world observations modeling uncertainty logical flow \( independent factors \) paper , present probabilistic framework neighborhood based recommendation methods \( \) similarity regarded factor thus , leads estimation user preference maximizing posterior similarity introduce novel multi layer similarity models learns joint influence various features , name new framework empirical results real world datasets show allows accurate estimation user preferences
adaptive task allocation heterogeneous multi robot teams evolving unknown robot capabilities multi robot teams heterogeneous capabilities , typical task allocation methods assign tasks robots based suitability robots perform certain tasks well requirements task however , real world robot teams , suitability robot might unknown prior deployment , might vary due changing environmental conditions paper presents adaptive task allocation task execution framework allows individual robots among tasks explicitly taking account efficacy performing tasks parameters might unknown deployment might vary time emph parameter encoding effectiveness given robot towards task updated fly , allowing algorithm tasks among robots aim executing developed framework requires explicit model changing environment unknown robot capabilities takes account progress made robots completing tasks simulations experiments demonstrate efficacy proposed approach variations environmental conditions robot capabilities unknown deployment
causal inference via kernel measures discovering causal structure among set variables fundamental problem many areas science paper , propose kernel conditional causal inference \( \) fully nonparametric causal discovery method based purely data novel interpretation notion cause effect , derive corresponding measure using framework kernel hilbert spaces based , propose three decision rules causal discovery demonstrate wide applicability method across range diverse synthetic datasets furthermore , test method real world time series data real world benchmark dataset cause effect pairs outperform existing state art methods
first women second gender bias wikipedia contributing writing history never easy today access web able play part wikipedia , open free , one primary sources knowledge web paper , study gender bias wikipedia terms women characterized , analyze content three aspects meta data , language , network structure results show , indeed , differences characterization structure differences line world wikipedia , differences attributed gender bias wikipedia content differences social theory discuss implications wikipedia policy
distributed non stochastic experts consider online distributed non stochastic experts problem , distributed system consists one node connected k sites , sites required communicate via time step , one k site nodes expert set 1 , , n , site receives information experts round goal distributed system minimize regret time horizon , simultaneously keeping communication minimum r n two extreme solutions problem \( \) full communication essentially non distributed setting obtain optimal \( sqrt log \( n \) \) regret bound cost communication \( ii \) communication site runs independent copy regret \( sqrt log \( n \) \) communication 0 paper shows difficulty simultaneously achieving regret asymptotically better sqrt communication better give novel algorithm oblivious adversary achieves non trivial trade regret \( sqrt k 5 \( 1 epsilon \) 6 \) communication \( k epsilon \) , value epsilon \( 0 , 1 5 \) also consider variant model , expert model , show label efficient et al \( 2005 \) already gives us strategy near optimal regret vs communication trade
modular description comprehensive semantics model uml version 2 0 document , introduce system model semantic domain unified modeling language \( uml \) , system model form possible core foundation uml semantics definition purpose , definitions document targeted towards uml means central concepts uml formalized theories system model document structured follows rest chapter 1 , discuss general approach highlight main decisions chapter important understand rest document chapter 2 contains definition structural part system model 3 4 contain control communication related definition definitions form basis describe state system chapter 5 two variants state transitions systems introduced define object behavior 6 \( event based \) 7 \( timed \) chapter 8 document document second version system model result major effort define structure , behavior interaction object oriented , possibly distributed systems abstract enough general value , also sufficient detail semantic foundation uml first version system model found , ,
multiple source shortest paths embedded graphs let g directed graph n vertices non negative weights directed edges , embedded surface g , let f arbitrary face g describe randomized algorithm graph \( log n \) time high probability , shortest path distance vertex boundary f vertex g \( log n \) time result directly generalizes \( n log n \) time algorithm soda 2005 multiple source shortest paths planar graphs intuitively , preprocessing algorithm maintains shortest path tree source point continuously around boundary f application algorithm , describe algorithms compute shortest non non separating cycle embedded , undirected graphs \( g 2 n log n \) time high probability high probability time bounds hold worst case generic edge weights , additional \( log n \) factor arbitrary edge weights
incorporating expressive graphical models variational approximations chain graphs hidden variables global variational approximation methods graphical models allow efficient approximate inference complex posterior distributions using simpler model choice approximating model determines tradeoff complexity approximation procedure quality approximation paper , consider variational approximations based two classes models standard bayesian networks , markov networks mixture models , classes allow find better tradeoffs spectrum approximations first class models chain graphs , capture distributions partially directed second class models directed graphs \( bayesian networks \) additional latent variables classes allow representation multi variable dependencies cannot easily represented within bayesian network
braid group cryptography last decade , number public key cryptosystems based com group theoretic problems braid groups proposed survey cryptosystems known attacks r n survey includes basic facts braid groups normal form elements , known algorithms solving word problem braid group , major public key cryptosystems based braid group , known attacks cryptosystems conclude discussion future directions \( includes also description cryptosystems based non groups \)
lsm generated binary functions material note arxiv r n et al 1 defined operation \( efficient \) omega order study computational complexity certain approximate counting problems asked whether log functions defined binary unary functions sense give negative answer question
video super resolution using 3d convolutional neural networks video super resolution , spatio temporal coherence , among frames must exploited appropriately accurate prediction high resolution frames although 2d convolutional neural networks \( cnns \) powerful modelling images , 3d cnns suitable spatio temporal feature extraction preserve temporal information end , propose effective 3d cnn video super resolution , called require motion alignment preprocessing maintains temporal depth spatio temporal feature maps capture temporally nonlinear characteristics low high resolution frames , adopts residual learning conjunction sub pixel outputs outperforms state art method average 0 45 0 db higher scales 3 4 , respectively , benchmark first deals performance due scene change , important practice previously considered
formal definition ai definition artificial intelligence proposed 1 definition formal least word human used paper formalize definition 1 problem definition level intelligence ai compared intelligence human order change introduce parameters ai depend one parameters level intelligence define one ai level intelligence assume level intelligence respective ai intelligent human nevertheless , cannot say level cannot calculate exact value
efficient optimization loops limits randomized sums consider optimization problems objective requires inner loop many steps limit sequence increasingly costly approximations meta learning , training recurrent neural networks , optimization solutions differential equations examples optimization problems character problems , expensive compute objective function value gradient , loop using less accurate approximations induce biases damage overall solution propose randomized \( rt \) gradient estimators , represent objective sum series sample linear combinations terms provide unbiased gradient estimates identify conditions rt estimators achieve optimization convergence rates independent length loop required accuracy approximation also derive method tuning rt estimators online maximize lower bound expected decrease loss per unit computation evaluate adaptive rt estimators range applications including meta optimization learning rates , variational inference parameters , training lstm model long sequences
joint uplink downlink opportunistic scheduling scheme infrastructure propose combined uplink downlink scheduling algorithm infrastructure presence uplink downlink flows , infrastructure suffers uplink downlink problem decreases throughput access point \( ap \) resolve maintaining separate queue associated mobile station \( \) ap also increase system throughput making time function channel gains reduces collision probability also theoretically analyze performance system symmetric statistics users validate analysis extensive simulations simulation results show increase system throughput 40 compared 11 mac index terms , opportunistic scheduling
identify locate separate audio visual object extraction large video collections using weak supervision tackle problem scene analysis weakly labeled data end , build upon previous representation learning framework perform object classification noisy acoustic environments integrate audio source enhancement capability made possible novel use non negative matrix factorization audio modality approach multiple instance learning paradigm effectiveness established experiments challenging dataset music performance videos also show encouraging visual object localization results
scalable hierarchical clustering tree introduce grinch , new algorithm large scale , non greedy hierarchical clustering general linkage functions compute arbitrary similarity two point sets key components grinch efficiently hierarchy new points , supporting discovery clusters complex structure grinch motivated new notion separability clustering linkage functions prove linkage function consistent ground truth clustering , grinch guaranteed produce cluster tree containing ground truth , independent data arrival order empirical results benchmark author coreference datasets \( standard learned linkage functions \) show grinch accurate scalable methods , orders magnitude faster hierarchical clustering
formal availability analysis using theorem proving availability analysis used assess possible failures restoration process given system analysis involves steady state individual system components usage information along commonly used availability modeling techniques , availability block diagrams \( \) fault trees \( \) determine system level availability traditionally , availability analyses conducted using paper methods simulation tools cannot absolute correctness due limitations complementary approach , propose use higher order logic theorem conduct availability analysis safety critical systems purpose , present higher order logic formalization steady state availability , configurations generic purposes , utilized conduct formal availability analysis satellite array , used main source power 3 \( 3 \) satellite
screenernet learning self curriculum deep neural networks propose learn curriculum supervised learning deep reinforcement learning deep neural networks deep neural network , called screenernet specifically , learn weight sample jointly training screenernet main network end end self fashion screenernet neither sampling bias requires past learning history show networks augmented screenernet achieve early convergence better accuracy state art learning methods extensive experiments using three popular vision datasets mnist , cifar10 pascal , task using deep q learning moreover , screenernet extend curriculum learning methods prioritized experience \( per \) accuracy improvement
universal phase transition community stochastic block model prove existence asymptotic phase transition threshold community spectral modularity method e j , e , \( 2006 \) sciences , \( 2006 \) stochastic block model phase transition community occurs inter community edge connection probability p grows phase transition sub critical regime small p , modularity based community detection successfully identifies communities , super critical regime large p successful community detection impossible show , community sizes become large , asymptotic phase transition threshold p equal sqrt p 1 cdot p 2 , p \( 1 , 2 \) within community edge connection probability thus phase transition threshold universal sense depend ratio community sizes universal phase transition phenomenon validated simulations sized communities using derived expression phase transition threshold propose empirical method estimating threshold real world data
tree structured multi stage principal component analysis tmpca theory applications pca based sequence vector \( \) dimension reduction method text classification problem , called tree structured multi stage principal component analysis \( tmpca \) presented paper theoretical analysis applicability tmpca demonstrated extension previous work \( su , \) unlike conventional word vector embedding methods , tmpca method dimension reduction sequence level without labeled training data furthermore , preserve sequential structure input sequences show tmpca computationally efficient able facilitate sequence based text classification tasks preserving strong mutual information input output mathematically also demonstrated experimental results dense \( fully connected \) network trained tmpca data achieves better performance state art neural network based solutions
deep fog failure resilient dnn inference edge cloud partitioning deep neural networks \( dnns \) physical nodes edge , fog , cloud nodes , could enhance sensor fusion , reduce bandwidth inference latency however , dnn distributed physical nodes , failure physical nodes causes failure dnn units placed nodes performance inference task , likely , poor , distributed dnn specifically designed properly trained failures motivated , introduce , dnn architecture augmentation scheme making distributed dnn inference task failure resilient , introduce elements model distributed dnn inference inspired concept residual connections dnns , introduce distributed dnns , basis 's design provide next , extensive experiments using two existing datasets sensing vision applications confirm ability provide distributed dnns edge cloud networks
regularization advantages multilingual neural language models low resource domains neural language modeling \( lm \) led significant improvements several applications , including automatic speech recognition however , typically require large amounts training data , available many domains languages study , propose multilingual neural language model architecture , trained jointly domain specific data several low resource languages proposed multilingual lm consists language specific word embeddings encoder decoder , one language specific lstm layer , plus two lstm layers shared parameters across languages multilingual lm model facilitates transfer learning across languages , extra regularizer low resource scenarios integrate proposed multilingual approach state art highly regularized neural lm , evaluate conversational data domain four languages range training data sizes compared monolingual , results show significant improvements proposed multilingual lm amount available training data limited , indicating advantages cross lingual parameter sharing low resource language modeling
deep convolutional neural networks action recognition using depth map sequences recently , deep learning approach achieved promising results various fields computer vision paper , new framework called hierarchical depth motion maps \( \) 3 channel deep convolutional neural networks \( \) proposed human action recognition using depth map sequences firstly , original depth data 3d mimic rotation cameras , algorithms handle view variant cases secondly , order effectively extract body shape motion information , generate weighted depth motion maps \( \) several temporal scales , referred hierarchical depth motion maps \( \) , three channels trained three orthogonal separately proposed algorithms evaluated , , action datasets respectively also combine last three datasets larger one \( called combined dataset \) test proposed method results show approach achieve state art results individual datasets without performance degradation combined dataset
integer programming approach student project allocation problem preferences projects student project allocation problem preferences projects \( p \) involves sets , projects , preferences projects context , typically seek stable matching projects \( \) however , stable matchings different sizes , problem finding maximum stable matching \( max p \) np hard two known approximation algorithms max p , performance guarantees 2 3 2 paper , describe integer programming \( ip \) model enable max p solved optimally following , present results arising empirical analysis investigates solution produced approximation algorithms compares optimal solution obtained ip model , respect size stable matchings constructed , instances randomly generated derived real datasets main finding 3 2 approximation algorithm finds stable matchings close maximum cardinality
h girth conjecture hybrid stretch spanners \( alpha , beta \) n vertex graph g \( v , e \) subgraph h g satisfying \( u , v , h \) leq alpha cdot \( u , v , g \) beta every pair \( u , v \) v times v , \( u , v , \) distance u v subseteq g known every integer k geq 1 , every graph g polynomially \( 2k 1 , 0 \) size \( n 1 1 k \) size stretch bound essentially optimal girth conjecture therefore ask one conjecture multiplicative stretch 2k 1 emph neighboring vertex pairs , maintaining strictly emph better multiplicative stretch rest pairs answer question introduce notion emph k hybrid spanners , non neighboring vertex pairs enjoy emph multiplicative k stretch neighboring vertex pairs enjoy emph multiplicative \( 2k 1 \) stretch \( hence , tight conjecture \) show every unweighted n vertex graph g edges , \( polynomially \) k hybrid \( k 2 cdot n 1 1 k \) edges alternative natural approach girth conjecture allow take care subset pairs times v given subset vertices subseteq v referred emph sources spanners distances times v bounded referred emph spanners several constructions variant provided \( e g , multiplicative spanners , additive spanners \)
dataset five years public activity scratch online community scratch programming environment online community people create , share , learn , communicate collaboration scratch team , created dataset public activity scratch online community first five years \( 2012 \) dataset comprises 32 tables information 1 million scratch users , nearly 2 million scratch projects , 10 million comments , 30 million scratch projects , help researchers understand dataset , establish validity data , also include source code every version software website , well software used generate dataset believe largest comprehensive dataset programming artifacts communication n n n n n n n n machine accessible metadata file describing reported data \( format \)
capacity 2 user gaussian mac link multiple access channel point point channel sharing medium communications considered obtain outer bound capacity region setup , show outer bound achievable cases cases mainly interference strong strong sum capacity upper bound also obtained , nearly tight interference power receivers low case , using gaussian codes treating interference noise achieves sum rate close upper bound
co embedding deep variational auto encoder conditional variational generation problems predicting new field \( \) image \( x \) many distinct solutions good representing ambiguity requires building conditional model p \( x \) prediction , conditioned image model difficult train , usually training data containing many different image result , need different training examples share data produce good models presents call code space collapse training procedure produces model good loss score , represents conditional distribution poorly demonstrate improved method building conditional models exploiting metric constraint training data prevents code space collapse demonstrate model two example tasks using real data image saturation adjustment , image describe quantitative metrics evaluate generation results results quantitatively outperform different strong baselines
global local explanations black box models decision making process many state art machine learning models inherently extent impossible human interpret model directly black box models led call research explaining black box models , two main approaches global explanations aim explain model 's decision making process general , local explanations aim explain single prediction since remains challenging establish fidelity black box models globally interpretable approximations , much attention put local explanations however , whether local explanations able reliably represent black box model provide useful insights remains open question present global local explanations \( \) objective provide insights model 's global decision making process overall , results reveal choice aggregation find global importance introduced local interpretable model agnostic explanations \( \) reliably represent model 's global behavior proposed better able represent features affect model 's predictions , provide global insights identifying distinguishing features
epistemic inequality diffusion scientific ideas spread ideas scientific community often viewed competition , good ideas spread greater intrinsic , citation counts correlate importance impact however , relatively little known structural factors influence spread ideas , specifically idea might influence , investigate role faculty hiring networks , set transitions faculty institutions , shaping spread ideas computer science , importance network idea consider comprehensive data hiring events faculty departments computer science u , timing 200 , associated analyzing five popular research topics , show empirically faculty hiring facilitate spread ideas science established mechanism , analyze potential consequences using epidemic models simulate generic spread research ideas quantify impact idea diffusion across network find research institutions quickly completely work similar quality less institutions analyses establish theoretical trade offs university quality ideas necessary efficient results establish faculty hiring underlying mechanism persistent epistemic advantage observed institutions , provide theoretical lower bound impact structural inequality shaping spread ideas science
numbers theory based game theoretic framework adversarial decision making fuzzy environment adversarial decision making particular type decision making problem gain decision obtains result decisions affected actions taken others representation evaluations methods find optimal alternative two important aspects adversarial decision making aim study develop general framework solving adversarial decision making issue uncertain environment combining fuzzy set theory , game theory numbers theory \( \) , based game theoretic framework adversarial decision making fuzzy environment presented within proposed framework model , fuzzy set theory used model uncertain evaluations decision alternatives , non among fuzzy evaluations taken consideration using , interests among decision considered two person non constant sum game theory perspective application given demonstrate effectiveness proposed model work , one hand , developed effective framework adversarial decision making fuzzy environment one hand , improved basis generalization theory uncertainty reasoning
channel estimation systematic polar codes study polar codes fading channels great importance applying polar codes wireless communications channel estimation fundamental step communication possible fading channels systematic non systematic polar codes , construction based information set known bits efficient implementation systematic non systematic polar codes exists comes channel estimation channel tracking , additional pilot symbols codeword traditionally paper , improve performance polar codes finite domain , pilot symbols selected coded symbols order keep existing efficient structure polar code encoding , pilot selection critical since reuse existing structure paper , two pilot denoted uneven pilot selection \( \) even pilot selection \( eps \) proposed , change efficient polar encoding structure proposed eps proven satisfy efficient construction condition performance eps shown paper outperform traditional pilot insertion scheme simulation results provided verify performance proposed pilot selection schemes
focused quantization sparse cnns deep convolutional neural networks \( cnns \) powerful tools wide range vision tasks , enormous amount memory compute resources required cnns pose challenge deploying constrained devices existing compression techniques , reducing model sizes , computationally friendly paper , statistical properties sparse cnns present focused quantization , novel quantization strategy based power two values , exploits weight distributions fine grained pruning proposed method dynamically effective numerical representation weights layers varying , significantly reducing model sizes cnns replaced much cheaper bit shift operations efficient inference coupled lossless encoding , built compression pipeline provides cnns high compression ratios \( cr \) , low computation cost minimal loss accuracy resnet 50 , achieved 18 cr 0 24 loss top 5 accuracy , outperforming existing compression methods fully compressed resnet 18 found higher cr top 5 accuracy , also hardware efficient requires fewer logic implement compared state art quantization methods assuming throughput
orthogonal show several problems orthogonal graph use minimum number rows , area , length edge total edge length cannot approximated better within polynomial factor optimal polynomial time unless p np also provide fixed parameter tractable algorithm testing whether drawing small number rows
discriminative distance based network indices application link prediction large networks , using length shortest paths distance measure well studied shortcoming extending graphs directed graphs second shortcoming huge number vertices may exactly score third shortcoming many applications , distance two vertices depends length shortest paths , also number shortest paths paper , first develop new distance measure vertices graph yields discriminative distance based centrality indices measure proportional length shortest paths proportional number shortest paths present algorithms exact computation proposed discriminative indices second , develop randomized algorithms precisely estimate average discriminative path length average discriminative show give \( epsilon , delta \) approximations indices third , perform extensive experiments several real world networks different domains experiments , first show compared traditional indices , discriminative indices usually much , show randomized algorithms precisely estimate average discriminative path length average discriminative , using samples , show real world networks usually average discriminative path length , bounded constant \( e g , 2 \) fourth , order better motivate usefulness proposed distance measure , present novel link prediction method , uses discriminative distance decide vertices likely form link future , show superior performance compared well known existing measures
software engineering practices machine learning last years enormous increase machine learning \( ml \) applications program functions longer written code , huge amount data samples using ml algorithm however , often complexity managing resulting ml models well real production system software engineering , decades developing tools methodologies create , manage complex software modules present overview current techniques manage complex software , applies ml models
inputs approximated nonlinear functions inference homomorphic encryption deep neural networks homomorphic encryption \( lhe \) offers potential solution could allow sensitive data utilize cloud deploy models remote inference deep neural networks \( dnn \) however , application faces several obstacles due limitations lhe one main problems commonly used nonlinear functions dnn operations supported lhe , e addition multiplication common lhe approaches , train model nonlinear function , replace low degree polynomial approximation inference time private data typically leads approximation errors loss prediction accuracy , propose method reduces loss small values entirely , depending simple hyper parameters achieved introduction novel simple min max normalization scheme , scales inputs nonlinear functions ranges low approximation error intuitive concept trivial implement , empirically show offers stable effective approximation solution nonlinear functions dnn return , enable deeper networks lhe , facilitate development security privacy aware analytics applications
column oriented storage techniques mapreduce users mapreduce often run performance problems scale workloads many problems overcome applying techniques learned three decades research parallel however , translating techniques mapreduce implementation hadoop presents unique challenges lead new design choices paper describes column oriented storage techniques incorporated hadoop way preserves popular programming apis r n show simply using binary storage formats hadoop provide performance boost naive use text files introduce column oriented storage format compatible replication scheduling constraints hadoop show speed mapreduce real workloads order magnitude also show dealing complex column types arrays , maps , nested records , common mapreduce , incur significant cpu overhead finally , introduce novel list column format record construction strategy records provide additional 1 5x performance boost experiments real used show column oriented storage techniques improve performance map phase hadoop much two orders magnitude
maximized posteriori attributes selection facial salient landmarks face recognition paper presents robust dynamic face recognition technique based extraction matching devised probabilistic graphs drawn features related independent face areas face matching strategy based matching individual salient facial graph characterized features connected facial landmarks order reduce face matching errors , decision theory applied individual matching scores obtained pair salient facial features proposed algorithm evaluated face databases experimental results demonstrate effectiveness potential proposed face recognition technique also case partially occluded faces
graph planarity testing hierarchical embedding constraints hierarchical embedding constraints define set allowed cyclic orders edges vertices graph constraints expressed terms fpq trees fpq trees variant trees includes f nodes addition p q nodes f node represents permutation fixed , e , cannot let g graph every vertex g equipped set fpq trees encoding hierarchical embedding constraints edges study problem testing whether g admits planar embedding , vertex v g , cyclic order edges v described least one fpq trees associated v prove problem np complete even number fpq trees associated vertex bounded constant however g bounded , problem solved polynomial time besides interesting right , study planarity testing hierarchical embedding constraints used address planarity testing problems modeled set fpq trees vertices input graph proof concept , apply techniques study planarity testing clustered graphs show planarity testing fixed fixed parameter tractable parameterized size clusters tree width multi graph obtained clusters single vertices
critical note evaluation clustering algorithms experimental evaluation major research methodology investigating clustering algorithms purpose , number benchmark datasets widely used literature quality plays important role value research work however , existing studies , little attention paid specific properties datasets often regarded black box problems work , help advanced visualization dimension reduction techniques , show potential issues popular benchmark datasets used evaluate clustering algorithms may compromise research quality even may produce completely results suggest significant efforts need devoted improving current practice experimental evaluation clustering algorithms principled analysis benchmark dataset interest
simultaneous task allocation planning uncertainty propose novel techniques task allocation planning multi robot systems operating uncertain environments task allocation performed simultaneously planning , provides detailed information individual robot behaviour , also exploits independence tasks efficiently use markov decision processes model robot behaviour linear temporal logic specify tasks safety constraints building upon techniques tools formal verification , show generate sequence multi robot policies , iteratively tasks individual robots fail , providing probabilistic guarantees performance \( safe operation \) team robots resulting policy implement approach evaluate benchmark multi robot example
second order statistics analysis comparison arithmetic geometric average fusion application multi sensor target tracking abstract two fundamental approaches information averaging based linear logarithmic combination , yielding arithmetic average \( aa \) geometric average \( ga \) fusing data , respectively context multi sensor target tracking , two common formats data fused random variables probability density functions , namely v fusion f fusion , respectively work , analyze compare second order statistics \( including variance mean square error \) aa ga terms v fusion f fusion case weighted gaussian mixtures representing presence false \( whose weight sums necessarily unit \) also considered , result turns significantly different single target addition exact derivation , analyses also provided
semantically guided representation learning self supervised monocular depth self supervised learning showing great promise monocular depth estimation , using geometry source supervision depth networks indeed capable learning representations relate visual appearance 3d properties implicitly leveraging category level patterns work investigate leverage directly semantic structure guide geometric representation learning , remaining self supervised regime instead using semantic labels proxy losses multi task approach , propose new architecture leveraging fixed pretrained semantic segmentation networks guide self supervised representation learning via pixel adaptive convolutions furthermore , propose two stage training process overcome common semantic bias dynamic objects via method improves upon state art self supervised monocular depth prediction pixels , fine grained details , per semantic categories
external sources answer set programs programs extension answer set programs \( asp \) external sources end , external atoms provide bidirectional interface program external source traditional evaluation algorithm programs based truth values external atoms explicit calls external source approach optimized techniques reduce number necessary verification calls speed , remaining external calls still expensive paper present alternative evaluation approach based external atoms , motivated existing less general approaches specialized formalisms dl programs external atoms compiled away verification calls necessary approach implemented experiments show significant performance gain besides performance improvements , exploit extending previous \( semantic \) characterizations program equivalence asp programs , including strong equivalence , uniform equivalence h , b equivalence finally , based equivalence criteria , characterize also inconsistency programs extensions since well known asp extensions \( constraint asp \) special cases , results interesting beyond particular formalism consideration theory practice logic programming \( \)
deep learning anomaly detection survey anomaly detection important problem well studied within diverse research areas application domains aim survey two fold , firstly present structured comprehensive overview research methods deep learning based anomaly detection furthermore , review methods anomaly across various application domains assess effectiveness state art research techniques different categories based underlying assumptions approach adopted within category outline basic anomaly detection technique , along variants present key assumptions , normal anomalous behavior category , present also present advantages limitations discuss computational complexity techniques real application domains finally , outline open issues research challenges faced adopting techniques
low delay multi party solution paper , attempt revisit problem multi party practical perspective , design space involved problem believe emphasis low end end delays two parties must , source rate session adapt bandwidth availability congestion present , multi party solution specifically designed achieve objectives entirely peer peer \( \) , eliminating cost maintaining servers designed deliver video low end end delays , quality levels available network resources arbitrary network topologies network contrast commonly assumed scenarios bandwidth edge network highlight design distributed adaptive rate control protocol , discover adapt arbitrary topologies network conditions quickly , converging efficient link rate allocations allowed underlying network adaptive link rate control , source video encoding rates also dynamically controlled optimize video quality arbitrary network conditions implemented prototype system , demonstrate superior performance existing solutions local experimental internet
fine grained static detection obfuscation transforms using ensemble learning semantic reasoning ability efficiently detect software used prime facilitate selection application adequate techniques present novel approach combines semantic reasoning techniques ensemble learning classification purpose providing static detection framework obfuscation transformations contrast existing work , provide methodology detect multiple layers obfuscation , without depending knowledge underlying functionality training set used also extend work detect constructions obfuscation transformations , thus providing fine grained methodology end , provide several studies best practices use machine learning techniques scalable efficient model according experimental results evaluations , models accuracy state art obfuscation transformations overall accuracies constructions 100
higher dimension tensor completion via low rank tensor ring decomposition problem incomplete data common signal processing machine learning tensor completion algorithms aim recover incomplete data partially observed entries paper , taking advantages high flexibility recently proposed tensor ring \( tr \) decomposition , propose new tensor completion approach named tensor ring weighted optimization \( tr \) finds latent factors incomplete tensor gradient descent algorithm , latent factors employed predict missing entries tensor conduct various tensor completion experiments synthetic data real world data simulation results show tr performs well various high dimension tensors furthermore , image completion results show proposed algorithm outperforms state art algorithms many situations especially missing rate test images high \( e g , 0 9 \) , performance tr significantly better compared algorithms
partial proof nash theorem via equilibria document consists two parts second part submitted earlier new proof nash 's theorem , first part note explaining problem found proof careful study led simultaneous discovery error far error fixed , many results techniques paper remain valid , continue make available online r n abstract original paper r n give novel proof existence nash equilibria finite games without using fixed point theorems path following arguments approach relies new notion intermediate nash correlated equilibria called equilibria , correlated equilibria certain symmetry factorization properties prove exist duality argument , using 's proof correlated equilibrium existence first step r n appropriate limit equilibria converge convex nash equilibria , proving exist well equilibria defined terms game , method automatically proves stronger symmetric game symmetric nash equilibrium case without follows argument
neural learning generate using motivated recent machine learning based models learn styles , paper focus problem generation challenging task machine capture linguistic features strongly characterize certain , well semantics 's production , influenced personal experiences background since constructed using , form structure , propose based neural language model , describe generation mechanism designed around style , automatically selecting representative generations work target author usually enough successfully train modern deep neural networks , propose multi stage procedure exploits non works author , also publicly available huge corpora learn syntax grammar target language focus , widely quantitative qualitative experimental analysis generated reported , included expert strong background studies generated frequently considered real generic population , relative difference respect ones really , expert perceived 's style generated text
unpaired image image translation using adversarial consistency loss unpaired image image translation class vision problems whose goal find mapping different image domains using unpaired training data cycle consistency loss widely used constraint problems however , due strict pixel level constraint , cannot perform geometric changes , remove large objects , ignore texture paper , propose novel adversarial consistency loss image image translation loss require translated image translated back specific source image encourage translated images important features source images overcome drawbacks cycle consistency loss method achieves state art results three challenging tasks glasses removal , translation , translation
interactive debugging asp programs broad application answer set programming \( asp \) declarative problem solving requires development tools supporting coding process program debugging one crucial activities within process recently suggested asp debugging approaches allow efficient computation possible explanations fault however , even small program debugger might return large number possible explanations selection correct one must done manually paper present interactive query based asp debugging method extends previous approaches finds explanation means observations system queries whether set ground atoms must true \( \) \( \) answer sets program since queries informative others , discuss query selection strategies , given user 's preferences explanation , find best query , query answer reduces overall number queries required identification explanation
prioritized sweeping better episodic control episodic control proposed third approach reinforcement learning , besides model free model based control , three types human memory e episodic , procedural semantic memory theoretical properties episodic control well investigated show deterministic tree markov decision processes , episodic control equivalent form prioritized sweeping terms sample efficiency well memory computation demands general deterministic stochastic environments , prioritized sweeping performs better even memory computation demands restricted equal episodic control results suggest generalizations prioritized sweeping partially observable environments , combined use function approximation search possible implementations prioritized sweeping
deep learning eeg manifold categorization active speech related brain computer interfaces \( bci \) aim primarily finding alternative communication people speaking step towards full decoding speech active , present bci system subject independent classification categories exploiting novel deep learning based hierarchical feature extraction scheme better capture complex representation high dimensional \( eeg \) data , compute joint variability eeg channel cross covariance matrix extract spatio temporal information encoded within matrix using mixed deep neural network strategy model framework composed convolutional neural network \( cnn \) , long short term network \( lstm \) , deep autoencoder train individual networks , combined outputs final gradient boosting classification step best models achieve average accuracy 77 9 across five different binary classification tasks , providing significant 22 5 improvement previous methods also show visually , work demonstrates speech imagery eeg significant discriminative information intended movements responsible natural speech synthesis
video representation learning dense predictive coding objective paper self supervised learning spatio temporal embeddings video , suitable human action recognition make three contributions first , introduce dense predictive coding \( \) framework self supervised representation learning videos learns dense encoding spatio temporal blocks predicting future representations second , propose curriculum training scheme predict future less temporal context model encode varying spatial temporal signals , therefore leading semantic representations third , evaluate approach first training model kinetics dataset self supervised learning , finetuning representation downstream task , e action recognition single stream \( rgb \) , pretrained representations achieve state art self supervised performance \( 75 7 acc \) \( 35 7 acc \) , outperforming previous learning methods significant margin , approaching performance baseline pre trained imagenet
weighted linear matroid parity algorithm matroid parity \( matroid matching \) problem , introduced common generalization matching matroid intersection problems , general requires exponential number oracle calls nevertheless , \( \) showed problem admits min max formula polynomial algorithm linearly represented matroids since efficient algorithms developed linear matroid parity problem paper , present combinatorial , deterministic , polynomial time algorithm weighted linear matroid parity problem algorithm builds polynomial matrix formulation using adopts primal dual approach based augmenting path algorithm \( \) unweighted problem
recommendation subgraphs web discovery recommendations central utility many including , well popular e commerce stores sites typically contain set recommendations every product page enables easily navigate website choosing appropriate set recommendations page one key features engines deployed several e commerce sites r n specifically , engine consisting several independent components analyzes paper focuses structure optimizer component improves website navigation experience enables discovery novel content r n begin formalizing concept recommendations used discovery formulate natural graph optimization problem case , reduces bipartite matching problem practice , solving matching problems requires time scalable also , implementing simple algorithms critical practice significantly easier maintain production motivated us analyze three methods solving problem increasing order sampling algorithm , greedy algorithm involved partitioning based algorithm r n first theoretically analyze performance three methods random graph models characterizing method yield solution sufficient quality parameter ranges needed complement providing empirical analysis algorithms simulated real world production data results confirm always necessary implement complicated algorithms real world good practical results obtained using heuristics confidence theoretical guarantees
spatio temporal analysis topic popularity twitter present first comprehensive characterization diffusion ideas twitter , studying topics include popular less popular topics data set containing approximately 10 million users comprehensive tweets posted users 2009 2009 \( approximately 200 million tweets \) , perform rigorous temporal spatial analysis , investigating time evolving properties subgraphs formed users topic focus two different notions spatial network topology formed following links twitter , location users investigate effect popularity topics find users high number strong impact popularity topics become popular disjoint clusters users begin merge form one component grows cover significant fraction network analysis shows highly popular topics cross regional boundaries
online human activity recognition using low power wearable devices human activity recognition \( har \) significant research interest due applications health monitoring patient recent research har focuses using smartphones due widespread use however , leads use , limited choice sensors inefficient use resources , since smartphones designed har paper presents first har framework perform online training inference proposed framework starts novel technique generates features using fast fourier discrete wavelet transforms based stretch sensor data using features , design neural network classifier trained online using policy gradient algorithm experiments low power iot device \( \) nine users show 97 7 accuracy identifying six activities transitions less 12 5 power consumption
strength replacement weak arithmetic replacement \( collection choice \) scheme bounded quantifier exchange prove independence scheme various weak theories arithmetic , sometimes complexity assumption
mosden scalable mobile collaborative platform opportunistic sensing applications mobile smartphones along embedded sensors become efficient various mobile applications including opportunistic sensing advances smartphones world possibilities paper proposes mobile collaborative platform called mosden enables supports opportunistic sensing run time mosden captures sensor data across multiple apps , smartphones users mosden supports emerging trend separating sensors application specific processing , storing sharing mosden reuse sensor data hence reducing efforts developing novel opportunistic sensing applications mosden implemented android based smartphones experimental evaluations validate scalability energy efficiency mosden suitability towards real world applications results evaluation lessons learned presented discussed paper
full rate full diversity achieving mimo precoding partial csit paper , consider n times n r multiple input multiple output \( mimo \) channel block fading reliability \( terms achieved diversity order \) rate \( number symbols transmitted per channel use \) interest channels propose new precoding scheme achieves full diversity \( n r th order diversity \) well full rate \( n symbols per channel use \) using partial channel state information transmitter \( csit \) , applicable mimo systems including n r n mimo proposed scheme achieves full diversity improved coding gain optimization choice constellation sets optimization maximizes min 2 precoding scheme subject energy constraint scheme requires feedback n 1 angle parameter values , compared r real coefficients case full csit error rate performance results 3 times 1 , 3 times 2 , 4 times 1 , 8 times 1 mimo systems \( n 3 , 3 , 4 , 8 symbols per channel use , respectively \) show proposed precoding achieves , , order , respectively performances shown better precoding schemes literature better performance due choice signal sets feedback proposed scheme
multimodal twitter datasets natural natural man made , people use social media platforms twitter post textual content report updates people , infrastructure damage , missing found people among information types studies revealed line information , processed timely effectively , useful organizations gain awareness plan operations addition analysis textual content , recent studies shown imagery content social media boost response significantly despite extensive research mainly focuses textual content extract useful information , limited work focused use imagery content combination content types one reasons lack labeled imagery data domain therefore , paper , aim tackle limitation large multi modal dataset collected twitter different natural provide three types annotations , useful address number response management tasks different organizations
finding highly connected spanning subgraphs network design problem \( sndp \) , input edge weighted \( \) graph g integer r every pair vertices u , v v \( g \) objective construct subgraph h minimum weight contains r edge disjoint \( node disjoint \) u v paths fundamental problem combinatorial optimization captures numerous well studied problems graph theory graph algorithms paper , consider version problem given lambda edge connected \( \) graph g non negative weight function w edges integer k , objective find minimum weight spanning subgraph h also lambda edge connected , least k fewer edges g words , asked compute maximum weight subset edges , cardinality k , may safely deleted g motivated question , investigate connectivity properties lambda edge connected \( \) graphs obtain significant structural results demonstrate importance structural results presenting algorithm running time 2 \( k log k \) v \( g \) \( 1 \) lambda , thus proving fixed parameter tractability follow result obtain em first polynomial compression lambda unweighted graphs consequence , also obtain first fixed parameter tractable algorithm , polynomial kernel parameterized version classic equivalent graph problem believe structural results independent interest play crucial role design algorithms connectivity constrained problems general sndp problem particular
self supervised multi level face model learning monocular reconstruction reconstruction dense 3d models face geometry appearance single image highly challenging ill posed constrain problem , many approaches rely strong priors , parametric face models learned limited 3d scan data however , prior models restrict generalization true diversity facial geometry , reflectance illumination alleviate problem , present first approach jointly learns 1 \) face shape , expression , reflectance illumination basis 2 \) learned parametric face model multi level face model combines advantage 3d models regularization space generalization learned space train end end wild images without dense annotations fusing convolutional encoder differentiable expert designed renderer self supervised training loss , defined multiple detail levels approach compares state art terms reconstruction quality , better generalizes real world faces , runs
data science using emotional arcs movies drive business model innovation much business literature addresses issues consumer centric design businesses design customized services products accurately reflect consumer preferences \? paper uses data science natural language processing methodology explore whether extent emotions shape consumer preferences media content using unique dataset 6 , movie , generate mapping content capture emotional trajectory motion picture combine obtained mappings clusters represent consumer emotional clusters used predict overall success parameters movies including box , satisfaction levels \( captured ratings \) , , well number reviews find like movie 6 basic shapes highest box associated man shape characterized emotional fall followed emotional rise shape results successful movies irrespective production budget yet , man produces movies generates movies interestingly , carefully chosen combination production budget may produce successful movie emotional shape implications analysis generating demand content driving business model innovation discussed
time static type checking dynamic languages dynamic languages , python , many benefits , lack static types means errors remain latent code long time many researchers developed various systems bring benefits static types dynamic languages , prior approaches dealing , generates code program paper , propose hummingbird , new system uses novel technique , time static type checking , type check code even presence hummingbird , method type dynamically run time , methods created method called , hummingbird type checks method body current type thus , hummingbird provides thorough static checks per method basis , also allowing arbitrarily complex performance , hummingbird static type checking pass , checks necessary formalize hummingbird using core , like language prove sound evaluate hummingbird , applied six apps , including three use , powerful framework relies heavily found apps successfully using hummingbird , hummingbird performance overhead reasonable applied hummingbird earlier versions one app found several type errors introduced fixed lastly , demonstrate using hummingbird development mode app live updates applied
lightweight mcmc probabilistic programs using caching lightweight , source source transformation approaches implementing mcmc probabilistic programming languages popular simplicity , support existing deterministic code , ability execute existing fast however , also slow , requiring complete execution program every proposal present new extension lightweight approach , , enables efficient , execution proposals based two core ideas transforming probabilistic programs passing style \( \) , caching results function calls show several common models , reduces proposal runtime 20 , cases reducing runtime complexity linear model size constant also demonstrate nearly order magnitude speedup complex inverse procedural modeling application
monocular human motion capture using cnn coupled geometric prior recovering 3d full body human pose challenging problem many applications successfully addressed motion capture systems body markers multiple cameras paper , address challenging case using single camera also leveraging markers going directly 2d appearance 3d geometry deep learning approaches shown remarkable learn 2d appearance features missing piece integrate 2d , 3d temporal information recover 3d geometry account uncertainties arising discriminative model introduce novel approach treats 2d joint locations latent variables whose uncertainty distributions given deep fully convolutional neural network unknown 3d poses modeled sparse representation 3d parameter estimates realized via expectation maximization algorithm , shown 2d joint location uncertainties inference extensive evaluation benchmark datasets shows proposed approach achieves greater accuracy state art baselines notably , proposed approach require synchronized 2d 3d data training applicable wild images , demonstrated dataset
truth envy allocation games study auctions additive agents limit number items may receive refer setting allocation games seek truthful envy free mechanisms maximize social welfare e , agents incentive lie agent seeks exchange outcomes another , showed pivot payments \( known truthful , individually rational , positive transfers \) , also envy free mechanism special case n items n unit capacity agents elaborate upon problem show pivot payments envy free agent capacities equal agent capacities identical , show truthful envy free mechanism maximizes social welfare one positive transfers case two agents \( arbitrary capacities \) show mechanism truthful , envy free , individually rational , positive transfers conclude host open problems arise work
survey based texture synthesis based texture synthesis process generating , input sample , new texture images arbitrary size perceptually equivalent sample two main approaches statistics based methods patch arrangement methods first class , texture characterized statistical signature , random sampling conditioned signature produces different texture images second class copy procedure , together large regions sample hybrid methods try combine ideas approaches avoid recent approaches using convolutional neural networks fit classification , statistical others performing patch arrangement feature space produce impressive synthesis various kinds textures nevertheless , found real textures organized multiple scales , global structures revealed coarse scales highly varying details finer ones thus , large natural images textures results state art methods degrade rapidly , problem modeling remains wide open
acute improved dialogue evaluation optimized questions multi turn comparisons dialogue remains important end goal natural language research , difficulty evaluation reason remains make real progress towards solution evaluation difficulties actually two fold automatic metrics correlate well human judgments , also human judgments fact difficult measure two used human tests , single turn pairwise evaluation multi turn scores , serious discuss work r n instead provide novel procedure involving comparing two full , human asked attention one speaker within , make pairwise questions optimized maximize robustness judgments across different annotators , resulting better tests also show tests work self play model setups , resulting faster , cheaper tests hope tests become de facto standard , release open source code end
double auction mechanism mobile crowd sensing data reuse mobile crowd sensing \( mcs \) new paradigm sensing , achieve flexible scalable sensing coverage low deployment cost , employing mobile users devices perform sensing tasks work , propose novel mcs framework data reuse , multiple tasks common data requirement share \( reuse \) common data mcs platform study optimal assignment mobile users tasks \( data reuse \) systematically , information symmetry , depending whether user cost task public information former case , formulate assignment problem generalized knapsack problem solve problem using classic algorithms latter case , propose truthful optimal double auction mechanism , built upon knapsack assignment problem , private information users tasks meanwhile achieve optimal assignment information symmetry simulation results show allowing data reuse among tasks , social welfare increased 100 , comparing without data reuse show proposed double auction budget balance , mainly due data reuse among tasks end , introduce price double auction \( data item \) achieve desired tradeoff budget balance social efficiency
smart finite state devices modeling framework demand response technologies introduce analyze markov decision process \( mdp \) machines model individual devices expected future demand response markets distribution grids devices following four types \( \) shed , e g light \( b \) , e g \( c \) controllable , e g controlled , whose task maintain auxiliary characteristic \( temperature \) within pre defined \( \) storage devices alternate generating analysis devices seeks find optimal price taking control strategy given stochastic model distribution market
alternating updates algorithm solving imperfect information games variant popular algorithm , faster empirical performance range problems introduced theoretical upper bound solution error , subsequent work showed error one step proof provide updated proofs recover original bound
adversarial task allocation problem tasks long fundamental importance examples include classical problem assigning computing tasks nodes distributed computing environment , well recent problem broad array tasks human extensive research problem generally addresses important issues uncertainty , , however , problem adversarial tampering task allocation process received much attention particular adversarial setting task allocation attacker may target specific worker order prevent tasks assigned worker consider two attack models one adversary allocation policy \( may randomized \) , second attacker actual allocation decision case tasks homogeneous , provide polynomial time algorithms settings tasks heterogeneous , however , show adversarial allocation problem np hard , present algorithms solving defender restricted assign single worker per task experiments show , surprisingly , difference two attack models minimal deterministic allocation achieve nearly much utility randomized
quasi cyclic ldpc codes high girth study class quasi cyclic ldpc codes provide precise conditions guaranteeing high girth graph experimentally , codes propose perform worse random ldpc codes parameters , significant algebraic codes
ad fortran part 1 design propose extensions fortran integrate forward reverse automatic differentiation \( ad \) directly programming model irrespective implementation technology , embedding ad constructs directly language extends reach ad allowing abstraction concepts interest scientific computing practice , root finding , optimization , finding equilibria continuous games multiple different tasks share common interfaces , whether use ad internally maximize function f library , \( f , \) , internally constructs f ad , without learn use particular ad tool illustrate utility extensions example programs become much closer traditional mathematical notation paper describes extensions implemented program generates input existing fortran based ad tools
technical report generalized matching pursuit approach graph structured sparsity sparsity constrained optimization important challenging problem wide applicability data mining , machine learning , statistics paper , focus sparsity constrained optimization cases cost function general nonlinear function , particular , sparsity constraint defined graph structured sparsity model existing methods explore problem context sparse estimation linear models best knowledge , first work present efficient approximation algorithm , namely , graph structured matching pursuit \( graph mp \) , optimize general nonlinear function subject graph structured constraints prove algorithm enjoys strong guarantees analogous designed linear models terms convergence rate approximation accuracy case study , specialize graph mp optimize number well known graph scan models connected subgraph detection task , empirical evidence demonstrates general algorithm performs superior state art methods designed specifically task connected subgraph detection
multi ranking news articles using post read actions personalized article recommendation important improve user news sites existing work primarily click rates argue quality recommendations improved incorporating different types post read signals like sharing , commenting , e article links specifically , propose multi ranking problem news articles corresponds ranking problem maximize actions post read action type key technical challenge estimate rates post read action types mitigating impact enormous data sparsity , several variations factor models exploit correlations among post read action types also introduce novel variant called locally augmented tensor \( lat \) model data obtained major news site us , show factor models significantly outperform baseline models lat model significantly outperforms several variations factor models findings show possible incorporate post read signals commonly available online news sites improve quality recommendations
position aware convolutional networks traffic prediction forecasting future traffic flow distribution area important issue traffic management intelligent transportation system key challenge traffic prediction capture spatial temporal relations future traffic flows historical traffic due highly dynamical patterns human activities existing methods explore relations fusing spatial temporal features extracted multi source data however , position information helps distinguish patterns different positions paper , propose position aware neural network integrates data features position information approach employs backbone network capture rich features traffic distribution whole area novelty lies backbone network , apply position embedding technique used neural language processing represent position information embedding vectors learned training embedding vectors , design position aware convolution allows different kernels process features different positions extensive experiments two real world datasets show approach outperforms previous methods even fewer data sources
hybrid blind robust image technique based transform paper , robust blind image method proposed protection digital images hybrid method relies combining two well known transforms discrete fourier transform \( \) discrete transform \( \) motivation behind combination enhance robustness requirement achieved using coefficients robustness improvement applying coefficients magnitude embedded modifying coefficients band using secret key security proposed method enhanced applying transform \( \) embedding experiments conducted natural images results show , compared state art methods , proposed method robust wide range attacks preserving high
seeking principles software engineering like engineering , software engineering also principles guide construction computer applications properties include \) scalability , b \) maximal reproducibility , c \) energy efficiency practice , expect scientific application written execute many times multiple different processing platforms different scales optimized performance energy efficiency two decades , explicit parallel programming processing paradigms focused performance practices showed rigid program data dynamic runtime resource optimization fault , making difficult applications scale paper reports practice experiences search first principles software engineering compute data intensive applications specifically , report practice experiences using implicit parallel programming processing paradigms
rapidhare computationally method real time human activity recognition wearable sensors recent human activity recognition \( har \) methods , based body inertial sensors , achieved increasing performance however , expense longer cpu greater energy consumption therefore , complex models might suitable real time prediction mobile systems , e g , care support long term health monitoring systems , present new method called rapidhare real time human activity recognition based modeling distribution raw data half second context window using dynamic bayesian networks method employ dynamic programming based algorithms , notoriously slow inference , employ feature extraction selection methods comparative tests , show rapidhare extremely fast predictor , one half times faster artificial neural networks \( \) methods , eight times faster recurrent neural networks \( rnns \) hidden markov models \( \) moreover , performance , rapidhare achieves f1 score 94 27 accuracy 98 94 , compared , rnn , , reduces f1 score error rate 45 , , 63 accuracy error rate , , , respectively therefore , rapidhare suitable real time recognition mobile devices
distributed synthesis acyclic architectures distributed synthesis problem constructing distributed systems , e , systems satisfy given specification consider slightly general problem distributed control , goal restrict behavior given distributed system order satisfy specification systems finite state machines communicate via \( automata \) show decidability synthesis problem omega regular local specifications , communication graph system acyclic result extends previous decidability result restricted form local reachability specifications
deep convolutional autoencoder based lossy image compression image compression investigated fundamental research topic many decades recently , deep learning achieved great success many computer vision tasks , gradually used image compression paper , present lossy image compression architecture , utilizes advantages convolutional autoencoder \( cae \) achieve high coding efficiency first , design novel cae architecture replace conventional transforms train cae using rate distortion loss function second , generate energy compact representation , utilize principal components analysis \( pca \) feature maps produced cae , apply quantization entropy generate codes experimental results demonstrate method outperforms traditional image coding algorithms , achieving 13 7 rate database images compared besides , method maintains moderate complexity similar
interference alignment via improved subspace conditioning k user , single input single output \( \) , frequency selective interference channel , new low complexity transmit beamforming design improves achievable sum rate presented jointly employing interference alignment \( \) scheme presented 1 linear minimum mean square error \( mmse \) decoding transmitters receivers , respectively , new precoding design improves average sum rate preserving achievable degrees freedom scheme , k 2
exploring strategy uniqueness pareto optimality stable matching problem stable matching problem \( smp c \) ubiquitous real world extension stable matching problem \( smp \) involving although smp solved polynomial time , smp c np complete hence , clear , , theoretical results surrounding canonical smp problem apply setting paper , use recently developed sat encoding solve smp c exactly allows us stable matchings given instance smp c tool , empirically evaluate properties hold smp c r n take particular interest investigating , size market grows , percentage instances unique stable matchings also grows find trend among random problem instances sampled , find percentage instances optimal matching seems closely follow trends predicted previous also define investigate pareto optimal stable matchings , finding , even though important style algorithms previously designed solve smp c , always find one r n also investigate strategy smp c , showing even one stable matching exists , still incentive preferences however , problem optimal stable matching , show cannot via
buzz programming language self heterogeneous robot swarms present buzz , novel programming language heterogeneous robot swarms buzz compositional approach , offering primitives define swarm behaviors perspective single robot overall swarm single robot primitives include robot specific instructions manipulation neighborhood data swarm based primitives allow dynamic management robot teams , sharing information globally across swarm self organization stems completely decentralized mechanisms upon buzz run time platform based language extended add new primitives \( thus supporting heterogeneous robot swarms \) , run time platform designed top frameworks , robot operating system showcase capabilities buzz providing code examples , analyze scalability robustness run time platform realistic simulated experiments representative swarm algorithms
general based framework inconsistency tolerant query answering propose general framework inconsistency tolerant query answering within existential rule setting framework main semantics proposed state art introduces new ones based cardinality majority principles relies two key notions inference strategies inconsistency tolerant semantics seen composite plus inference strategy compare obtained semantics productivity point view
cognitive graph multi hop reading comprehension scale propose new framework multi hop question answering web scale documents inspired dual process theory cognitive science , framework gradually builds textit cognitive graph iterative process coordinating implicit extraction module \( system 1 \) explicit reasoning module \( system 2 \) giving accurate answers , framework provides reasoning paths specifically , implementation based bert graph neural network efficiently handles millions documents multi hop reasoning questions dataset , achieving joint f 1 score 34 9 , compared 23 6 best
body backscatter exploiting propagation vision battery free communication made backscatter technology body wearable devices recent advances communication backscatter tags body smart devices studies focused communication dimension , security dimension remains vulnerable demonstrated wireless connectivity exploited send fake messages result device key challenge attacks stems design backscatter thus , paper , explore feasibility body backscatter tag without modifying signal protocol present , physical layer solution security backscatter body smart device end , profile body propagation paths backscatter links , construct highly sensitive propagation identify body backscatter links implement design software radio evaluate different backscatter tags work 2 4 results show system identify body devices 93 23 average true positive rate 3 18 average false positive rate
adversarial contract design private data proliferation data collection machine learning techniques created opportunity private data data paper , study data problem using contract theoretic approach proposed adversarial contract design framework accounts honest demands data , well presence adversarial may purchase data compromise privacy propose notion price adversary \( \) quantify effects adversarial users data 's revenue , provide bounds various classes adversary utility also provide fast approximate technique compute presence adversaries
strategies development distributed framework computational sciences paper discusses generic approach developing grid based framework enabling workflows comprising existing software computational sciences areas highlight main requirements addressed developing framework strategies enabling convenient computation software grid environment shown uml based instruments graphical description workflows developing system suggested
extreme regression dynamic search advertising paper introduces new learning paradigm called extreme regression \( xr \) whose objective accurately predict numerical degrees relevance extremely large number labels data point xr provide elegant solutions many large scale ranking recommendation applications including dynamic search advertising \( \) xr learn accurate models recently popular extreme classifiers assume strictly binary valued label traditional regression metrics sum errors labels xr problems since could give extremely bounds label ranking quality also , existing regression algorithms n't efficiently scale millions labels paper addresses limitations \( 1 \) new evaluation metrics xr sum k largest regression errors \( 2 \) new algorithm called xreg xr task hierarchy much smaller regression problems thus leading highly efficient training prediction paper also introduces \( 3 \) new prediction algorithm xreg useful recommendation tasks experiments benchmark datasets demonstrated xreg outperform state art extreme classifiers well large scale 50 reduction new xr error metric , 2 2 4 improvements terms precision metric used extreme classification click rate metric used respectively deployment xreg resulted relative gain 27 query coverage xreg 's source code http url
framework model computing indicators non local influence journals via data acquisition algorithms defining measuring internationality function influence diffusion scientific journals open problem exists metric rank journals based extent scale internationality measuring internationality qualitative , , open interpretation limited interests tremendous increase number journals various fields across international journals , become absolute evaluate , rank categorize journals based internationality authors , current work defined internationality measure influence across boundaries concerns authors practices process journal scholarly influence select artificially boosted , primarily counter impact , authors come new method defines measures internationality eliminating local effects computing influence journals new metric , non local influence quotient \( \) proposed one parameter internationality computation along another novel metric , citation quotient complement ratio self citation total citation addition , international collaboration ratio used two parameters
machine learning early prediction failure intensive care unit intensive care presented large quantities patient information measurements multitude monitoring systems limited ability humans process complex information readily recognize act early signs patient used machine learning develop early system failure based high resolution database patient years data automatic system predicts 0 failure events \( 3 1 \) , 8 identified two hours advance , resulting area receiver operating characteristic curve 94 0 area precision recall curve 63 0 model validated large independent patient cohort
effectiveness type based control flow integrity control flow integrity \( cfi \) received significant attention community combat control attacks presence memory corruption vulnerabilities challenges creating practical cfi resulted development new type cfi based runtime type checking \( rtc \) rtc based cfi implemented number recent practical efforts reuse attack \( \) cfi number previous efforts studied limitations types cfi techniques , little done evaluate rtc based cfi work , study effectiveness rtc security aspects security perspective , observe type collisions abundant sufficiently large code bases exploiting build functional attack show attacker successfully rtc techniques using variant attacks respect type checking \( called \) also built two proof concept exploits , one web server mail server also discuss practical challenges implementing rtc findings suggest rtc practical applying cfi large code bases , policy strong enough facing motivated attacker
generating deep generative models imitation interactive tasks coordinate actions interaction partner requires constant exchange signals humans skills early mostly imitation learning active partner require ability predict adapt one 's partner interaction work want explore ideas human robot interaction setting robot required learn interactive tasks combination learning end , propose deep learning framework consisting number components \( 1 \) human robot motion embedding , \( 2 \) motion prediction human partner \( 3 \) generation robot joint trajectories matching human motion test ideas , collect human human interaction data human robot interaction data four interactive tasks hand , hand wave , demonstrate experimentally importance predictive adaptive components well low level abstractions successfully learn human behavior interactive social tasks
wave like decoding tail spatially coupled ldpc codes iterative finite coupling lengths , spatially coupled low density parity check \( ldpc \) codes show non negligible rate loss paper , investigate rate loss tail ldpc codes conjunction iterative higher order modulation formats therefore , examine threshold different coupled ensembles comparison decoding approximated charts density evolution results coupled ensemble given investigate effect potential different set using per bit curves , method 16 qam system , e g , using set partitioning hybrid mapping proposed , different sub blocks use different order optimize decoding tail codes , computational complexity overhead iterative remains small
optimality approximation schemes classical scheduling problem consider classical scheduling problem parallel identical machines minimize , achieve following results exponential time hypothesis \( eth \) r n 1 scheduling problem constant number identical machines , denoted pm c max , known admit fully polynomial time approximation scheme \( \) running time \( n \) \( 1 epsilon \) \( \) \( indeed , algorithm works even general problem machines \) prove algorithm essentially best possible sense \( 1 epsilon \) \( 1 delta \) n \( 1 \) time delta 0 implies eth fails r n 2 scheduling problem arbitrary number identical machines , denoted p c max , known admit polynomial time approximation scheme \( ptas \) running time 2 \( 1 epsilon 2 log 3 \( 1 epsilon \) \) n \( 1 \) prove algorithm nearly optimal sense 2 \( \( 1 epsilon \) 1 delta \) n \( 1 \) time ptas delta 0 implies eth fails , small room improvement r n obtain results provide two new reductions , one pm c max another p c max indeed , new reductions explore structure scheduling problems also lead interesting results example , using framework reduction p c max , et al \( arxiv \) able prove hardness scheduling problem matrix job processing times p \( p \) times n rank 3 , solving open problem mentioned et al \( soda 2013 \)
formal presentation mongodb extended version significant number database architectures data models proposed last decade new systems gained popularity , formal semantics generally still missing paper , consider case mongodb , widely adopted document database , roughly speaking relational tables correspond collections , tuples documents provide formalization based data model adopted mongodb , core fragment mongodb aggregation query language , , includes match , , project , group , operators study expressiveness defining relational view mongodb databases developing translation relational algebra notably , show fragment already least expressive full relational algebra \( relational view \) single collection , particular able express arbitrary joins investigate computational complexity significant
fully convolutional network ensembles white matter segmentation images abstract white matter \( \) commonly found individuals associated various paper , present study using deep fully convolutional network ensemble models automatically detect using fluid attenuation inversion recovery \( \) magnetic resonance \( \) scans algorithm evaluated ranked segmentation challenge 2017 evaluation stage , implementation algorithm submitted challenge , independently tested hidden set cases 5 dice score , precision robust distance obtained held test datasets 80 , 6 30 mm respectively highest achieved challenge , suggesting proposed method state art detailed descriptions quantitative analysis key components system provided furthermore , study cross evaluation presented discuss combination modalities affect generalization capability system system different protocols also investigated quantitative study presented show effect ensemble size effectiveness ensemble model additionally , software models method made publicly available effectiveness generalization capability proposed system show potential real world clinical practice
gossip based signaling dissemination extension next steps signaling paper , propose new gossip based signaling dissemination method next steps signaling protocol family detail , propose extend general internet signaling \( \) protocol , leverage new dissemination capabilities signaling layer protocol applications using capabilities extension consists two main procedures procedure , new enabled nodes discover , dissemination procedure , used effectively signaling messages within autonomous system aim , defined three dissemination models , , , , requirements different network service management scenarios experimental campaign carried shows effectiveness proposed solution
improved anomaly detection scenes via cell based analysis foreground speed size texture robust efficient anomaly detection technique proposed , capable dealing scenes traditional tracking based approaches tend fail initial foreground segmentation input frames analysis foreground objects effectively background dynamics input frames split non overlapping cells , followed extracting features based motion , size texture cell feature type independently presence anomaly unlike methods , refined estimate object motion achieved computing optical flow foreground pixels motion size features modelled approximated version kernel density estimation , computationally efficient even large training datasets texture features modelled adaptively grown code book , number entries codebook selected online fashion experiments recently published anomaly detection dataset show proposed method obtains considerably better results three recent approaches , social force , mixture dynamic textures \( \) proposed method also several orders magnitude faster , next best performing method
learning object attribute subspace unpaired data object object image another object second image example perform tasks like putting exactly eyeglasses image person image b usage images allows precise specification desired modifications improves diversity conditional image generation however , previous methods rely feature space operations , require paired data appearance models training objects background work , propose model learn object two unpaired sets images one set containing images kind object , set , mild constraint objects located approximately place example , training data one set reference face images eyeglasses , another set images , spatially aligned face landmarks despite weak 0 1 labels , model learn eyeglasses subspace contain multiple different types glasses consequently , perform fine grained control generated images , like glasses two images components eyeglasses subspace , create novel images people eyeglasses r n overall , deterministic generative model learns disentangled attribute subspaces weakly labeled data adversarial training experiments multi datasets validate effectiveness proposed model real world data , generating images specified eyeglasses , , styles , lighting conditions etc code available online
inside closed world evaluating autoencoder based detection ddos cloud machine learning based anomaly detection \( ml based ad \) successful detecting ddos events however published evaluations ml based ad limited data provided insight works address limited evaluation real world data , apply autoencoder , existing ml ad model , 57 ddos attack events captured 5 cloud major cloud provider improve understanding ml based ad works works , interpret data feature attribution counterfactual explanation show version autoencoders work well overall models capture nearly malicious flows 2 4 cloud attacks \( least 99 99 \) generate false \( 5 9 \) remaining 2 show models maintain near zero false positives benign flows 5 interpretation results shows models identify almost malicious flows non \( non wl \) destination \( 99 92 \) learning full list benign destination training data \( normality \) interpretation shows although models learn incomplete normality protocols source , still identify malicious flows non wl protocols \( \) source \( 100 0 97 5 \) risk false positives interpretation also shows models detect malicious flows packet sizes \( 8 5 \) inferring sizes normal based incomplete normality learned find models still detect flows \( 24 7 \) abnormal contents even see combining anomalies multiple flow features lastly , implications learn applying autoencoder based ad production
dpp net device aware progressive search pareto optimal neural architectures recent neural architectural search \( nas \) achieved state art performances applications image classification language modeling however , techniques typically ignore device related objectives inference time , memory usage , power consumption optimizing neural architecture device related objectives crucial deploying deep networks devices limited computing resources propose dpp net device aware progressive search pareto optimal neural architectures , optimizing device related \( e g , inference time memory usage \) device agnostic \( e g , accuracy model size \) objectives dpp net employs compact search space inspired current state art mobile cnns , improves search efficiency adopting progressive search \( et al 2017 \) experimental results cifar 10 demonstrate effectiveness pareto optimal networks found dpp net , three different devices \( 1 \) x gpu , \( 2 \) nvidia embedded system , \( 3 \) mobile phone arm cortex compared \( mobile \) , dpp net achieves better performances higher accuracy inference time various devices additional experimental results show models found dpp net also achieve considerably good performance imagenet well
online pricing price constraint personal data markets society 's personal data driving data markets , allowing data consumers launch customized queries datasets collected data broker data paper , study data broker maximize cumulative revenue reasonable sequential queries thus propose contextual dynamic pricing mechanism price constraint , features properties efficient online optimization , support linear non linear market value models uncertainty particular , low uncertainty , pricing mechanism provides worst case regret logarithmic number queries extend similar application scenarios , including service , online advertising , application , extensively evaluate three pricing instances noisy linear query , rental , dataset , u major cities , mobile ad click dataset , respectively analysis evaluation results reveal proposed pricing mechanism incurs low practical regret , online latency , memory overhead , also demonstrate existence price mitigate start problem posted price mechanism , thus reduce cumulative regret
towards theoretical understanding hashing based neural nets parameter reduction important topic deep learning due ever increasing size deep neural network models need train run resource limited machines despite many efforts area , rigorous theoretical guarantees existing neural net compression methods work paper , provide provable guarantees hashing based parameter reduction methods neural nets first , introduce neural net compression scheme based random linear sketching \( usually implemented efficiently via hashing \) , show \( smaller \) network able approximate original network input data smooth well conditioned low dimensional manifold network also trained directly via back propagation next , study previously proposed architecture show optimization landscape one hidden layer local strong property similar normal fully connected neural network complement theoretical results empirical
presence patterns segmenting user locations cell phone data dynamic monitoring commuting flows crucial improving systems fast developing cities around world however , existing methodology infer commuting destinations either rely large scale survey data , inherently expensive implement , call detail records based ad hoc heuristic assignment rules based frequency appearance given locations paper , proposed novel method accurately infer point origin destinations commuting flows based individual 's spatial temporal patterns call detail records project significantly improves accuracies upon heuristic assignment rules adopted literature starting historical data geo temporal travel pattern individuals , create , person location , vector probability distribution capturing likelihood person appear location given time day stacked way , matrix historical geo temporal data enables us apply decomposition use unsupervised machine learning techniques extract across locations different group , ultimately allows us make create labels , home work , specific locations testing methodology real world data known location labels shows method identifies home significant accuracy , improving upon commonly used methods literature 79 34 , respectively importantly , methodology significant computation burden easily scalable easily real world data historical tracking
semantic code repair using symbolic transformation networks study problem semantic code repair , broadly defined automatically non syntactic bugs source code majority past work semantic code repair assumed access unit tests candidate could validated contrast , goal develop strong statistical model accurately predict bug locations exact without access information intended correct behavior program achieving goal requires robust contextual repair model , train large corpus real world source code augmented bugs framework adopts two stage approach first large set repair candidates generated rule based processors , candidates statistical model using novel neural network architecture refer share , specialize , compete specifically , architecture \( 1 \) generates shared encoding source code using rnn abstract syntax tree , \( 2 \) scores candidate repair using specialized network modules , \( 3 \) scores together compete one another comparable probability space evaluate model real world test set github containing four common categories bugs model able predict exact correct repair time single , compared 13 accuracy attentional sequence sequence model
efficient multi point local decoding reed muller codes via interleaved codex reed muller codes among important classes locally correctable codes currently local decoding reed muller codes based decoding lines quadratic curves recover one single coordinate recover multiple coordinates simultaneously , naive way local decoding recovery single coordinate decoding algorithm might expensive , e , require higher query complexity paper , focus reed muller codes usual parameter regime , namely , total degree evaluation polynomials theta \( q \) , q code alphabet size \( fact , big q 4 setting \) introducing novel variation codex , e , interleaved codex \( concept codex used arithmetic secret sharing cite , \) , able locally recover arbitrarily large number k coordinates reed muller code simultaneously cost querying \( q 2k \) coordinates turns local decoding reed muller codes shows \( surprisingly \) accessing k locations fact cheaper procedure accessing single location k times precisely speaking , get success probability local decoding recovery single coordinate , one query \( 2 \) coordinates thus , query complexity local decoding smaller k omega \( q \) addition , local decoding decoding efficient , e , decoding complexity poly \( k , q \) construction interleaved codex based concatenation codex multiplication friendly pair , main tool realize codex based algebraic function fields \( precisely , algebraic geometry codes \)
low latency command dissemination vehicles vehicular , lead vehicle responsible managing 's moving directions velocity control following vehicles based vehicle vehicle communications however , reducing command dissemination latency multiple vehicles ensuring successful message delivery tail vehicle challenging propose new linear dynamic programming algorithm using backward arguments minimize dissemination latency vehicles furthermore , closed form dissemination latency vehicular obtained utilizing markov chain 1 model simulation results confirm proposed dynamic programming algorithm improves dissemination rate least 50 9 , compared similar algorithms literature moreover , also approximates best performance maximum gap 0 2 second terms latency
based 3d scene understanding partial point sets deep learning within context point clouds gained much research interest recent years mostly due promising results achieved number challenging benchmarks , 3d shape recognition scene semantic segmentation many realistic settings however , environment often taken single view , contains partial set scene due field view commodity cameras 3d scene semantic understanding partial point clouds considered challenging task work , propose processing approach 3d point cloud data based representation existing 360 point clouds fusing original 360 point clouds corresponding 3d representations input data , neural network able recognize partial point sets improving general performance complete point sets , resulting overall increase 9 4 3 segmentation accuracy partial complete scene semantic understanding , respectively method also applied 3d recognition context 3d part segmentation
spin detection robotic table table , rotation \( spin \) ball plays crucial role table match feature variety generates different amounts types spin develop robot compete human player , robot needs detect spin , plan appropriate return paper compare three methods estimate spin first two approaches use high speed camera captures ball flight frame rate camera allows movement ball seen first approach uses background difference determine position second alternative , train cnn predict orientation third method trajectory ball rotation effect force method gives highest accuracy used demonstration robot successfully different spin types real table human
evolutionary approach identification cellular automata based partial observations paper consider identification problem cellular automata \( \) problem defined solved context partial observations time gaps unknown length , e pre , partial configurations system certain , unknown time steps solution method based modified variant genetic algorithm \( ga \) proposed illustrated brief experimental results
regret minimization partially observable linear quadratic control study problem regret minimization partially observable linear quadratic control systems model dynamics unknown priori propose , explore commit algorithm learns model markov parameters follows principle face uncertainty design controller propose novel way decompose regret provide end end sublinear regret upper bound partially observable linear quadratic control finally , provide stability guarantees establish regret upper bound tilde mathcal \( 2 3 \) , time horizon problem
width independence beyond linear objectives distributed fair packing covering algorithms fair allocation resources deep early philosophy , broadly studied political science , economic theory , operations research , networking past decades , approach fair resource allocation led general class alpha fair utility functions single inequality parameter alpha 0 , infty theoretical computer science , well studied examples linear utilities \( alpha 0 \) , fair nash utilities \( alpha 1 \) , max min fair utilities \( alpha rightarrow infty \) r n work , consider general alpha fair resource allocation problems , defined maximization alpha fair utility functions packing constraints give improved distributed algorithms constructing epsilon approximate solutions problems algorithms width independent , , running times depend poly largest entry constraint matrix , closely match state art guarantees distributed algorithms packing linear programs case alpha 0 previously known width independent algorithms alpha fair resource allocation convergence times much worse dependence epsilon alpha analysis leverages approximate duality gap framework obtain better algorithms analysis r n finally , introduce natural counterpart alpha fairness minimization problems motivate usage context fair task allocation generalization yields alpha fair covering problems , provide first width independent nearly linear time approximate solvers reducing analysis alpha 1 case alpha fair packing problem
compositional generalization deep model separating syntax semantics standard methods deep learning natural language processing fail capture compositional structure human language allows systematic generalization outside training distribution however , human learners readily generalize way , e g applying known grammatical rules novel words inspired work neuroscience suggesting separate brain systems syntactic semantic processing , implement modification standard approaches neural machine translation , imposing analogous separation novel model , call syntactic attention , substantially outperforms standard methods deep learning scan dataset , compositional generalization task , without hand features additional supervision work suggests separating syntactic semantic learning may useful heuristic capturing compositional structure
learning item interaction embeddings user recommendations industry scale recommendation systems become e commerce shopping experience , online 50 million items , users come rely personalized recommendations surface relevant items massive one 's shopping experience multitude ways user interact item interested view , , add collection , add , purchase , etc different ways user item indicates different kinds consequently , user 's recommendations based item past activity , also way item paper , propose novel method learning interaction based item embeddings encode co occurrence patterns item , also interaction type learned embeddings give us convenient way approximating likelihood one item interaction pair would co occur another way simple inner product computational efficiency , model naturally candidate set selection method , evaluate industry scale recommendation system serves live traffic com experiments reveal taking interaction type account shows promising results improving accuracy modeling user shopping behavior
robust low rank representation fast face identification occlusions paper , propose iterative method address face identification problem block occlusions approach utilizes robust representation based two characteristics order model errors \( e g , block occlusion \) effectively first fits errors distribution described tailored loss function second describes error image specific structure \( resulting low rank comparison image size \) show joint characterization effective describing errors spatial continuity approach computationally efficient due utilization alternating direction method multipliers special case fast iterative algorithm leads robust representation method , used handle non errors \( e g , pixel corruption \) extensive results representative face databases \( constrained environments \) document effectiveness method existing robust representation methods respect identification rates computational time
darkmention deployed system predict enterprise targeted external recent data call organizations identify cyber attacks systems \( \) provide environments discuss existing vulnerabilities malicious software exploit vulnerabilities platforms offer security practitioners threat intelligence environment allows patterns related organization targeted cyber attacks paper , describe system \( called darkmention \) learns association rules indicators attacks real world cyber using learned rules , darkmention generates security operations center \( soc \) prior attacks goal design system automatically generates enterprise targeted timely , , accurate , show darkmention meets goal particular , show outperforms baseline systems attempt generate cyber attacks related two enterprises average increase f1 score 45 57 additionally , darkmention deployed part larger system built contract cyber attack automated sensor environment \( cause \) program actively attacks average 3 days
local search large neighborhoods parallel machines total problem present computational results heuristic algorithm parallel machines total weighted problem algorithm combines generalized pairwise neighborhoods , optimization new machine based neighborhood whose size non polynomial number machines computational results significantly improve current state art problem
lstm networks perform dynamic counting paper , systematically assess ability standard recurrent networks perform dynamic counting encode hierarchical representations neural models experiments designed small sized networks prevent training sets visualize interpret behaviour test time results demonstrate long short term memory \( lstm \) networks learn recognize well balanced language \( 1 \) multiple 1 languages , defined different pairs , simple real time k counter machines best knowledge , work first study introduce languages analyze computational power neural networks also show single layer lstm one hidden unit practically sufficient recognizing 1 language however , none recurrent networks able yield good performance 2 language learning task , requires model stack like mechanism recognition
locally codes meet regenerating codes locally codes \( \) designed distributed storage codes \( usually small \) bounded number helper nodes participating repair since existing assume exact repair allow full exchange stored data \( beta alpha \) , viewed generalization traditional erasure codes \( \) much desired feature local repair however , also means lack features functional repair partial information exchange \( beta alpha \) original regenerating codes \( \) motivated significant bandwidth \( bw \) reduction , existing works et al studied locally regenerating codes \( \) simultaneously admit three features local repair , partial information exchange , functional repair significant bw reduction observed r n one important issue local repair schemes \( including \) sometimes helper nodes may , result multiple failures , degraded , network dynamics setting node , work studies impact different helper selection methods proves , first time literature , node , existing methods helper selection , including used , strictly repair bw suboptimal scenarios , necessary combine new helper selection method , termed dynamic helper selection , achieve optimal bw work also compares performance different helper selection methods answers following fundamental question whether one method helper selection better \? various different scenarios
learning hyperspectral feature extraction classification network hyperspectral image \( hsi \) classification standard remote sensing task , image pixel given label indicating physical cover 's surface image semantic segmentation deep learning approaches ordinary images accelerated research hyperspectral image classification moreover , utilization spectral spatial cues hyperspectral images shown improved classification accuracy hyperspectral image classification use 3d convolutional neural networks \( 3d cnn \) extract spatial spectral cues hyperspectral images results parameters hence high computational cost propose network architecture called utilizes 3d convolutions modeling spectral spatial information early layers architecture 2d convolutions top layers deal semantic abstraction constrain architecture block performance simplicity model drastically reduced number parameters achieved comparable classification performance state art methods \( ip \) scene dataset , university scene \( \) dataset , \( sa \) scene dataset , \( bw \) dataset
distributed mean estimation limited communication motivated need distributed learning optimization algorithms low communication cost , study communication efficient algorithms distributed mean estimation unlike previous works , make probabilistic assumptions data first show dimensional data n clients , naive stochastic binary rounding approach yields mean squared error \( mse \) theta \( n \) uses constant number bits per dimension per client extend naive algorithm two ways show applying structured random rotation quantization reduces error mathcal \( \( log \) n \) better coding strategy reduces error mathcal \( 1 n \) uses constant number bits per dimension per client also show latter coding strategy optimal constant sense e , achieves best mse given communication cost finally demonstrate algorithms applying distributed 's algorithm k means power iteration pca
clp fd library modular clp extension prolog present new free library constraint logic programming finite domains , included prolog system library entirely written prolog , leveraging 's module system code transformation capabilities order achieve highly modular design without performance describe interface , implementation , design modular component r n library meets several design goals high level modularity , allowing individual components replaced different versions high efficiency , competitive fd implementations box approach , user specify new constraints different levels prolog implementation , order integration 's code analysis components r n core built upon two small libraries implement integer ranges top , finite domain variable defined , taking care constraint depending range changes three libraries form call fd kernel library r n fd kernel used turn implement several higher level finite domain constraints , specified using together labeling module layer forms name emph fd solver final level integrates clp \( fd \) paradigm fd solver achieved using attributed variables clp \( fd \) language set constraints provided solver r n user library work levels seen convenient writing new range module set fd constraints writing new
identifying influential time matter recently become one services web many users maintain blog write posts express opinion , experience knowledge product , event every subject general specific interest users read posts impact upon one nine , cite therefore , significant issue identify influential problem new relevant literature lacks sophisticated solutions , importantly solutions taken account temporal aspects identifying influential , even though time critical aspect article investigates issue identifying influential proposing two easily computed ranking methods , incorporate temporal aspects activity method based specific metric score 's posts first metric , termed , takes consideration number blog post 's comments , along date post second metric , , used score blog post according number age blog post 's comments methods evaluated state art influential identification method utilizing data collected real world community blog site obtained results new methods able better identify significant temporal patterns behaviour
study entanglement categorical framework natural language quantum mechanics corpus based vector spaces , notion entanglement provides means various communicate paper examine number implementations categorical framework et al 4 natural language , entanglement perspective specifically , goal better understand way level entanglement relational tensors \( lack \) affects compositional structures practical situations findings reveal number proposals construction lead almost separable tensors , fact considerably interactions words examine fact , show hat use algebras potential problems great extent finally , briefly examine machine learning method creates tensors exhibiting sufficient el entanglement
algorithms ell p low rank approximation consider problem approximating given matrix low rank matrix minimize ell p approximation error , p geq 1 case p 2 classical problem obtain first provably good approximation algorithms version low rank approximation work every value p geq 1 , including p infty algorithms simple , easy implement , work well practice , illustrate interesting tradeoffs approximation quality , running time , rank approximating matrix
learn augment joint data augmentation network optimization text recognition handwritten text scene text suffer various shapes distorted patterns thus training robust recognition model requires large amount data cover diversity much possible contrast data collection annotation , data augmentation low cost way paper , propose new method text image augmentation different traditional augmentation methods rotation , scaling perspective transformation , proposed augmentation method designed learn proper efficient data augmentation effective specific training robust using set points , proposed augmentation method flexible controllable furthermore , bridge gap processes data augmentation network optimization joint learning agent network learns output recognition network controls points generate proper training samples recognition network extensive experiments various benchmarks , including regular scene text , irregular scene text handwritten text , show proposed augmentation joint learning methods significantly boost performance recognition networks general toolkit geometric augmentation available
throughput analysis massive mimo uplink low resolution adcs investigate uplink throughput achievable multiple user \( mu \) massive multiple input multiple output \( mimo \) system , base station equipped large number low resolution analog digital \( adcs \) focus case neither transmitter receiver priori channel state information implies fading learned pilot transmission followed channel estimation receiver , based observations propose novel channel estimator , based decomposition , novel approximation rate achievable finite resolution adcs , case finite cardinality gaussian inputs , accurate broad range system parameters numerical results , illustrate , 1 bit case , pilot based channel estimation together maximal ratio , zero forcing detection enables reliable multi user communication high order , severe nonlinearity introduced adcs furthermore , show rate achievable infinite resolution \( quantization \) case using adcs bits resolution finally investigate robustness low resolution mu mimo uplink receive power different users , caused example imperfect power control
iterative partial rounding vertex cover hard capacities provide simple novel algorithmic design technique , call iterative partial rounding , gives tight rounding based approximation vertex cover hard capacities \( hc \) particular , obtain f approximation hc hypergraphs , improving previous results et al \( soda 2014 \) tight extent also gap approximation since posted \( \) believe rounding technique independence interests hard constraints considered r n main technical tool establishing approximation guarantee separation lemma existence strong partition solutions basic feasible extended version natural lp
trainable multiplication layer auto correlation co occurrence extraction paper , propose trainable multiplication layer \( tml \) neural network used calculate multiplication input features taking image input , tml raises pixel value power weight , thereby extracting higher order local auto correlation input image tml also used extract co occurrence feature map convolutional network training tml formulated based backpropagation constraints weights , enabling us learn discriminative multiplication patterns end end manner experiments , characteristics tml investigated learned kernels corresponding output features applicability tml classification neural network interpretation also evaluated using public datasets
new techniques algorithm design present evaluate new techniques designing algorithm view , problem scheduling aspect machine learning aspect prior work largely addressed one two aspects building recent work scheduling aspect problem , present technique addresses aspects simultaneously attractive theoretical guarantees experimentally , show technique used improve performance state art algorithms boolean satisfiability , zero one integer programming , planning
internet path diversity connectivity internet autonomous system level influenced network operator policies implemented turn impose direction address , consequently , paths used reach back destinations propose use directed graphs properly represent destinations internet number disjoint paths quantify network \? path diversity moreover , order understand effects policies connectivity internet , numerical analyses resulting directed graphs conducted results demonstrate , even policies applied , still path diversity border protocol cannot currently exploit
graph neural networks review methods applications learning tasks require dealing graph data contains rich relation information among elements modeling physics system , learning molecular , predicting interface , classifying diseases require model learn graph inputs domains learning non structural data like texts images , reasoning extracted structures , like dependency tree sentences scene graph images , important research topic also needs graph reasoning models graph neural networks \( \) models capture dependence graphs via message passing nodes graphs unlike standard neural networks , graph neural networks state represent information neighborhood arbitrary depth although primitive found difficult train fixed point , recent advances network architectures , optimization techniques , parallel computation enabled successful learning recent years , systems based variants graph neural networks graph convolutional network \( gcn \) , graph attention network \( \) , gated graph neural network \( \) demonstrated ground breaking performance many tasks mentioned survey , provide detailed review existing graph neural network models , systematically categorize applications , propose four open problems future research
polynomial depth e study relations notions , logical depth setting complexity theory introduce new notion polynomial depth based time bounded complexity show polynomial depth notion satisfies basic logical depth properties , namely neither sets p sets random exp polynomial deep , polynomial deep sets polynomially turing compute polynomial deep set prove exp complete sets poly deep , assumption np p measure zero , np contains polynomial deep set show every high set e contains polynomial deep set polynomial turing degree , exists low e polynomial deep sets
computation tree logic synchronization properties present logic extends ctl \( computation tree logic \) operators express synchronization properties property synchronized system holds paths certain length new logic obtained using path quantifiers temporal operators ctl , allowing different order quantifiers small syntactic variation logic express non regular properties known extensions equality path length show variant ctl decidable problem 3 p np , hard class problems solvable polynomial time using parallel access np oracle consider quantifier exchange extensions ctl , present operators defined using basic operators ctl express occurrence many synchronization points show model checking problem remains 3 distinguishing power ctl new logic coincide next operator allowed logics , thus classical quotient used state space reduction model checking
leveraging program analysis reduce user perceived latency mobile applications reducing network latency mobile applications effective way improving mobile user experience economic benefits paper presents , novel client centric technique reducing network latency http requests android apps work leverages string analysis control flow analysis automatically apps using 's rigorous formulation scenarios address shown incur significant runtime savings \( several per http request \) , applied evaluation benchmark developed real applications
control high performance bipedal robot using cooled paper describes control , evaluation new human scaled biped robot cooled \( \) based lessons learned previous work team 1 , present new system design force sensing series elastic \( \) force sensing series elastic \( \) designs reducing size weight robot 's system advantages designs energy efficiency , density , impact position force system design takes consideration human inspired range motion \( \) , relying placement balance terms control , perform stability analysis observer \( \) designed force control evaluate various position control algorithms time frequency domains low level baseline established , first perform controller evaluation using operational space control \( \) 2 finally , move evaluating full bipedal robot dynamic means algorithms appear 3
cluster computing white paper cluster computing new area computing , however , growing interest usage areas applications traditionally used parallel distributed computing platforms growing interest part availability powerful high speed networks commodity components well part rapidly software components available support high performance high availability applications r n white paper , put together industrial researchers experts fields time effort put together white paper status paper stage presence making request comments \( \)
volumetric srp refinement step sound source localization letter proposes efficient method based response power \( srp \) technique sound source localization using arrays refined volumetric srp \( srp \) deploying volumetric grid , srp achieves significant reduction computational complexity without sacrificing accuracy location estimates addition , refinement step improves compromise complexity accuracy experiments conducted simulated real data scenarios show srp outperforms state art methods accuracy lower computational cost
learning adapt stereo real world applications stereo depth estimation require models robust dynamic variations environment even though deep learning based stereo methods successful , often fail generalize unseen variations environment , making less suitable practical applications autonomous driving work , introduce learning adapt framework enables deep stereo methods continuously adapt new target domains unsupervised manner specifically , approach incorporates adaptation procedure learning objective obtain base set parameters better suited unsupervised online adaptation improve quality adaptation , learn confidence measure effectively masks errors introduced unsupervised adaptation evaluate method synthetic real world stereo datasets experiments evidence learning adapt , indeed beneficial online adaptation different domains
sparse neural knowledge based models prediction prediction future yet taken important help process course selection well designing personalized degree plans modifying based performance one successful approaches accurately predicting student 's grades future cumulative knowledge based regression models \( \) learns shallow linear models predict student 's grades similarity knowledge state target course student 's knowledge state built linearly learned provided knowledge components taken past , weighted grades however , prior contribute equally target course paper , propose novel neural knowledge based model \( \) learns importance historical course predicting target course compared competing approaches , experiments large real world dataset consisting sim 1 5 grades show effectiveness proposed model accurately predicting grades moreover , attention weights learned model helpful better designing degree plans
net mesh modeling assist segmentation volumetric data cnn based volumetric methods label individual field biomedical segmentation paper , show simultaneously performing segmentation recovering 3d mesh models surface boost performance r n end , propose end end trainable two stream encoder decoder architecture comprises single encoder two decoders , one labels outputs mesh key success two decoders communicate help learn goes beyond well known fact training deep network perform two different tasks improves performance r n demonstrate substantial performance increases two different challenging datasets
topic modeling based multi modal detection major common affects almost 7 u population 2017 audio visual emotion challenge \( \) asks participants build model predict levels based audio , video , text ranging 7 minutes since averaging features entire temporal information , discover , capture , preserve useful temporal details long significant challenges therefore , propose novel topic modeling based approach perform context aware analysis experiments show proposed approach outperforms context methods challenge baselines metrics
structured pruning neural networks budget aware regularization pruning methods shown effective reducing size deep neural networks keeping accuracy almost among effective methods network training sparsity prior loss learnable dropout parameters shortcoming approaches however neither size inference speed network controlled directly yet key feature targeting deployment cnns low power hardware overcome , introduce regularized pruning framework deep convolutional neural networks approach naturally fits traditional neural network training consists learnable layer , novel budget aware objective function , use knowledge distillation also provide insights residual network lead new architectures experimental results reveal cnns method accurate less compute state art methods also , approach effective preventing accuracy collapse case severe pruning allows us attain pruning factors without significantly affecting accuracy
accelerated randomized coordinate descent algorithms stochastic optimization online learning propose accelerated randomized coordinate descent algorithms stochastic optimization online learning algorithms significantly less per iteration complexity known accelerated gradient algorithms proposed algorithms online learning better regret performance known randomized online coordinate descent algorithms furthermore , proposed algorithms stochastic optimization exhibit good convergence rates best known randomized coordinate descent algorithms also show simulation results demonstrate performance proposed algorithms
secure deep learning algorithms side channel based reverse engineering deep learning algorithms recently become de facto paradigm various prediction problems , include many privacy preserving applications like online medical image analysis , privacy data deep learning system serious concern several efforts analyze exploit information deep learning architectures compromise data privacy paper , however , attempt provide evaluation strategy information deep neural network architectures considering case study convolutional neural network \( cnn \) based image classifier approach takes aid low level hardware information , provided hardware performance \( \) , execution cnn classifier simple hypothesis testing order produce exists information leakage actual input
decidability timed communicating automata study reachability problem networks timed communicating processes process timed automaton communicating processes messages channels messages carry clocks time transmission suitable timing constraints automaton access set local clocks message clocks sent received messages time dense clocks evolve rate main contribution complete decidable communication topologies previous work technical point view , use quantifier elimination reduction counter automata
filter modern processors filter well established quantum quantum physics compute eigenvalues large sparse matrices choosing block vector implementation , investigate optimization opportunities new class high performance compute devices high bandwidth low bandwidth memory focus access full address space supported architectures consideration intel phi nvidia pascal thorough performance analysis single device implementations using model propose two optimizations \( 1 \) subspace applied improved performance data access efficiency also show allows handling problems much larger high bandwidth memory without significant performance \( 2 \) communication computation successive subspaces implemented communication costs without extra memory traffic application scenario perform filter studies topological quantum matter performance numbers nodes presented , achieving beyond 500 computing \( 10 2 \) inner eigenvalues sparse matrices dimension \( 4 cdot 10 9 \)
sample efficient policy search optimal domains arising naturally many fields , optimal problems consider question deciding stop observation generating process examine problem simultaneously learning planning domains , data collected directly environment propose , simple flexible model free policy search method data sample efficiency leveraging problem structure bound sample complexity approach guarantee uniform convergence policy value estimates , existing pac bounds achieve logarithmic dependence horizon length setting also examine benefit method model based model free approaches 3 domains taken diverse fields
nonconvex low rank symmetric tensor completion noisy data study noisy symmetric tensor completion problem broad practical interest , namely , reconstruction low rank symmetric tensor highly incomplete randomly corrupted observations entries variety prior work dedicated problem , prior algorithms either computationally expensive large scale applications , come sub optimal statistical guarantees focusing well conditioned tensors constant cp rank , propose two stage nonconvex algorithm \( \) gradient descent following initialization achieves best specifically , proposed nonconvex algorithm tensor individual tensor factors within nearly linear time , time near optimal statistical guarantees \( e minimal sample complexity optimal estimation accuracy \) estimation errors spread across entries , thus achieving optimal ell infty statistical accuracy insight analysis nonconvex optimization might implications tensor estimation problems
recognizing using behavioural traces predict quality social interactions online games online social interactions games positive however , methods easily assess interaction quality games use behavioural traces predict , social interactions online setting collected audio , video , game , self report data 23 dyads , extracted 75 features , trained random forest support vector machine models , evaluated performance predicting binary \( high low \) well continuous toward partner models predict binary continuous 79 1 accuracy \( f1 \) 20 1 explained variance \( \) unseen data , features based communication demonstrating highest potential findings inform design games game communities , guide development systems mitigating behaviour online games
optimal scalar linear codes classes two sender index coding problem two sender index coding problem \( tgicp \) consists set receivers , messages set receivers distributed among two senders senders possibly set messages common message one receiver receiver subset messages \( known side information \) demands message objective design scalar linear codes senders minimum aggregate code length receivers able decode demands , leveraging knowledge side information receivers work , optimal scalar linear codes three sub problems \( considered single sender index coding problems \( \) \) tgicp used construct optimal scalar linear codes classes tgicp introduce notion joint extensions finite number , generalizes notion extensions single introduced prior work mathcal e joint extension finite number disjoint sub problems mathcal e identify class joint extensions , optimal scalar linear codes joint extensions constructed using sub problems construct scalar linear codes classes tgicp , one sub problems tgicp belong identified class joint extensions , provide necessary conditions optimality construction
successive point interest recommendation local differential privacy point interest \( poi \) recommendation system plays important role location based services \( \) help people explore new locations launch target users poi recommendation methods need users' raw check data , location privacy even worse , several privacy preserving recommendation systems could utilize transition pattern human movement address problems , propose successive point interest recommendation local differential privacy \( \) framework employs two types sources users' check history transition pattern two counts propose novel objective function learning user poi poi poi relationships simultaneously propose two privacy preserving mechanisms train recommendation system experiments using two public datasets demonstrate achieves better poi recommendation quality preserving stronger privacy check history
timing attacks massive parallelism resource sharing today 's cloud business model security challenge timing channels , also defenses based resource partitioning paper proposes timing control timing channels cloud environments approach reference clocks internal cloud imposing deterministic view time code , uses timing rate limit potential information leakage external prototype implementation first system mitigate timing channel leakage across full scale existing operating systems applications written arbitrary languages incurs varying performance cost , depending workload leakage limiting parameters , cost may justified security critical cloud applications data
deployment interactive multi application hpc workflows running scientific workflows task scientific domain workflow management solutions \( \) standard method reducing complexity application deployment high performance computing \( hpc \) infrastructure introduce design system extends combines functionality existing solutions order create high level , user centric operation deployment model design addresses requirements several use cases life sciences , focus neuroscience focus two use cases 1 \) three coupled simulators \( three different space time scales \) visualization 2 \) closed loop workflow optimized machine learning , coupling robot neural network simulation provide detailed overview application integrated monitoring relationship hpc job present novel usage model large scale interactive multi application workflows running hpc systems aims reducing complexity deployment execution , thus enabling new science
mean understand neural network define neural network learn recognize objects less 100 lines code however , training , characterized millions weights contain knowledge many object types across visual scenes networks thus dramatically easier understand terms code makes resulting properties , tuning connections , conjecture rules development learning may far easier understand resulting properties suggests neuroscience would benefit focus learning development
start bias yelp ratings yelp ratings often viewed metric local businesses paper study yelp ratings evolve time main finding average first ratings businesses receive particular , first review business receives dataset 4 1 , review 3 significant start bias may attributed limited exposure business first steps may mask analysis performed ratings therefore , study techniques identify correct bias , perform case study explore effect deal 's subsequent ratings show previous research 's effect average ratings number reviews received analysis points importance identifying removing biases yelp reviews
evaluation measures hierarchical classification unified view novel approaches hierarchical classification addresses problem classifying items hierarchy classes important issue hierarchical classification evaluation different classification algorithms , issue complicated hierarchical relations among classes several evaluation measures proposed hierarchical classification using hierarchy different ways without however providing unified view problem paper studies problem evaluation hierarchical classification key components existing performance measures also proposes two alternative generic views hierarchical evaluation introduces two corresponding novel measures proposed measures , along state art ones , empirically tested three large datasets domain text classification empirical results illustrate behaviour existing approaches proposed methods overcome problems across range cases
path planning driven point search many domains cells conditioned path taken often case video games , character may need certain object \( e , key \) able specific locations \( e g , high \) order non player characters handle scenarios present , driven approach based highly successful grid based point search \( \) algorithm show , formally experimentally , preserves 's optimality guarantees symmetry breaking advantages based variants game maps
game theoretical approach qos heterogeneous networks proliferation mobile phone users , interference management big concern years cope problem along ensuring better quality service \( qos \) , plays heterogeneous networks \( \) characteristics paper , propose game theoretic algorithm along dynamic channel allocation hybrid access mechanism self power control scheme view prioritized access issue , concept primary secondary users applied existence pure strategy nash equilibrium \( \) investigated come proposed scheme adopted increasing capacity increasing revenue operators considering optimal price consumers
improved lower bound sparse reconstruction matrices give short argument yields new lower bound number rows bounded , matrix necessary form matrix restricted property show matrix formed uniformly rows n times n matrix contains k sparse vector kernel , unless number rows omega \( k log k log \( n k \) \) lower bound applies whenever min \( k , n k \) log c n containing sparse vector kernel restricted property , generally application matrices uniform sparse recovery
new fuzzy lbp features face recognition many local texture features way implement algorithm trying improve performance attempt made paper represent theoretically simple computationally effective approach face recognition implementation face image sub regions features extracted using local binary pattern \( lbp \) window , fuzzy membership function central pixel lbp features possess texture discriminative property computational cost low information lbp , membership function , central pixel , limitations traditional lbp database like databases used evaluation proposed features svm classifier proposed approach k fold curves obtained results compared
object impact complexity packing dimensions packing classical problem one given set subsets euclidean space called objects , goal find maximum size subset objects pairwise non problem also known independent set problem intersection graph defined objects although problem np complete , several algorithms literature one key assumptions algorithms objects , two dimensions example , packing problem set polygons plane surprisingly admits algorithm paper give tight running time bounds packing similarly sized non objects higher dimensions r n propose alternative weak measure called number , show packing problem euclidean space constant dimension geq 3 family similarly sized objects number alpha solved 2 \( n 1 1 alpha \) time prove even case parallel boxes fixed shape , 2 \( n 1 1 alpha \) algorithm eth result whole range constant objects one extreme \( alpha 1 \) algorithm usual running time , objects extreme \( alpha n 1 \) , cannot hope improve upon force running time 2 \( n \) , thereby characterizes impact complexity packing case similarly sized objects also study problem parameterized solution size k , give n \( k 1 1 alpha \) algorithm , almost matching lower bound
convolutional 2d knowledge graph embeddings link prediction knowledge graphs task predicting missing relationships entities previous work link prediction focused shallow , fast models scale large knowledge graphs however , models learn less expressive features deep , multi layer models potentially limits performance work , introduce , multi layer convolutional network model link prediction , report state art results several established datasets also show model highly parameter efficient , yielding performance r gcn 8x fewer parameters analysis model suggests particularly effective modelling nodes high common highly connected , complex knowledge graphs addition , fb15k datasets suffer test set leakage , due inverse relations training set present test set however , extent issue far find problem severe simple rule based model achieve state art results fb15k ensure models evaluated datasets simply exploiting inverse relations cannot yield competitive results , investigate validate several commonly used datasets deriving robust variants necessary perform experiments robust datasets several previously proposed models find achieves state art mean rank across datasets
compliance incomplete event logs capability store data business processes execution called event logs brought diffusion tools analysis process assessment process model , tools often rigid dealing event logs include incomplete information process execution thus , ability handling incomplete event data one challenges mentioned process mining , evaluation compliance execution trace still requires end end complete trace performed r n paper exploits power provide flexible , yet computationally effective , framework deal different forms event log moreover proposes refinement classical notion compliance strong conditional compliance take account incomplete logs finally , performances evaluation experimental setting shows feasibility presented approach
legal document retrieval using document vector embeddings deep learning domain specific information retrieval process prominent research field natural language processing many researchers incorporated different techniques overcome technical domain provide model various domains interest main bottleneck studies heavy coupling domain experts , makes entire process time consuming study , developed three novel models compared standard generated via line repositories provided , specifically legal domain three different models incorporated vector space representations legal domain , document vector generation done two different mechanisms ensemble two study contains research carried process representing legal case documents different vector spaces , whilst incorporating semantic word measures natural language processing techniques ensemble model built study , shows significantly higher accuracy level , indeed proves need domain specific semantic similarity measures information retrieval process study also shows , impact varying distribution word similarity measures , varying document vector dimensions , lead improvements process legal information retrieval
parameter free network data reduction minimal algorithmic information loss study large complex datasets , big data , organized networks emerged one central challenges areas science technology cellular molecular networks one prime examples , number techniques data dimensionality reduction , especially context networks , developed yet , current techniques require predefined metric upon minimize data size introduce family parameter free algorithms based \( algorithmic \) information theory designed minimize loss \( computable \) property contributing object 's algorithmic content thus important preserve process data dimension reduction forcing algorithm first least important features independent particular criterion , universal fundamental mathematical sense using suboptimal approximations efficient \( polynomial \) demonstrate preserve network properties outperforming \( leading \) algorithms network dimension reduction method preserves graph theoretic indices measured , ranging degree distribution , clustering coefficient , edge , degree conclude demonstrate numerically parameter free , minimal information loss \( \) method robust , potential maximize preservation recursively features data networks , achieves equal significantly better results data reduction network methods
super resolution algorithms real data past decades , various super resolution \( sr \) techniques developed enhance spatial resolution digital images despite great number contributions , still lack comparative sr practical conditions , capturing real ground truth data challenging task therefore , current studies either evaluated 1 \) simulated data 2 \) real data without pixel wise ground truth r n facilitate comprehensive studies , paper introduces publicly available super resolution \( super \) database includes real low resolution images along high resolution ground truth data database comprises image sequences images captured 14 scenes various types motions photometric conditions datasets cover four spatial resolution levels using camera hardware database , benchmark 15 single image multi frame sr algorithms experiments quantitatively analyze sr accuracy robustness realistic conditions including independent object camera motion photometric variations
dynamic control coding delay tolerant networks delay tolerant networks \( \) leverage mobility relay nodes compensate lack connectivity thus enable communication nodes range decrease message delivery delay , information transmitted replicated network study replication mechanisms include reed solomon type codes well network coding order improve probability successful delivery within given time limit propose analytical approach allows us compute probability successful delivery study effect coding performance network optimizing parameters routing
aggressive quadrotor flight narrow gaps onboard sensing computing paper , address one main challenges towards autonomous quadrotor flight complex environments , flight narrow gaps present method allows quadrotor autonomously safely pass narrow , gap using onboard visual inertial sensors computer previous works addressed quadrotor flight gaps using external motion capture systems state estimation instead , estimate state fusing gap detection single onboard camera method generates trajectory considers geometric , dynamic , perception constraints approach , quadrotor always faces gap allow state estimation , vehicle dynamics gap , distance quadrotor edges gap maximized furthermore , trajectory execution cope varying uncertainty state estimate successfully evaluate demonstrate proposed approach many real experiments , achieving success rate 80 gap 45 best knowledge , first work addresses successfully reports aggressive flight narrow gaps using onboard sensing computing
large scale evaluation extraction models extraction models usually evaluated different , directly comparable , experimental setups result , remains well proposed models actually perform , compare work , address issue presenting systematic large scale analysis state art extraction models involving multiple benchmark datasets various sources domains main results reveal state art models fact still simple baselines datasets also present new insights impact using author reader assigned proxy gold standard , give recommendations strong baselines reliable benchmark datasets
implicit sensor based authentication smartphone users smartphones frequently used end users cloud based services , smartphones easily co attacker beyond initial log mechanism , highly desirable end users access security critical services data , whether cloud smartphone gained access smartphone incentive , must done automatic , non way hence , paper proposes novel authentication system , , implicit , continuous authentication end user based behavioral characteristics , leveraging sensors already built smartphones design system gives accurate authentication using machine learning sensor data multiple mobile devices system achieve 92 1 authentication accuracy negligible system overhead less 2 battery consumption
estimation shapley value ergodic sampling idea approximating shapley value n person game random sampling introduced et al \( 2009 \) improved et al \( 2013 \) et al \( 2017 \) using contrast independent sampling method , paper , develop algorithm uses pair negatively correlated samples reduce variance estimation examine eight games different characteristics test performance proposed algorithm show cases \( seven eight \) method least low variance independent sample , instances \( five eight \) , dramatically \( almost 60 average \) improves quality estimation analyzing results , conclude method works best case games high variability marginal contributions
computation offloading incentive mechanism delay cost constraints 5g satellite ground architecture 5g internet vehicles become new paradigm growing popularity variety computation intensive applications high requirements computational resources analysis capabilities existing network architectures resource management mechanisms may sufficiently guarantee satisfactory quality experience network efficiency , mainly coverage limitation road side units , insufficient resources , computational capabilities onboard equipment , frequently changing network topology , resource management schemes meet demands applications , article , first propose novel architecture integrating satellite network 5g cloud enabled internet vehicles efficiently support coverage global resource management incentive mechanism based joint optimization problem opportunistic computation offloading delay cost constraints established framework , vehicular user either significantly reduce application completion time offloading workloads several nearby vehicles opportunistic vehicle vehicle channels effectively controlling cost protect providing computing service optimization problem non convex np hard , simulated annealing based markov chain monte carlo well algorithm applied solve optimization problem , obtain high quality cost effective approximations global optimal solutions effectiveness proposed mechanism simulation results
breiman dilemma neural networks phase transitions margin dynamics margin training data important strategy since machine learning purpose boosting robustness classifiers toward good generalization ability yet breiman shows dilemma \( breiman , \) uniform improvement margin distribution emph necessarily reduces generalization errors paper , revisit breiman 's dilemma deep neural networks recently proposed normalized novel perspective provided explain breiman 's dilemma based phase transitions dynamics normalized margin distributions , trade expressive power models complexity data data complexity comparable model expressiveness sense training test data share similar phase transitions normalized margin dynamics , two efficient ways derived predict trend generalization test error via classic margin based generalization bounds restricted complexities hand , expressive models exhibit uniform improvements training , distinct phase transition test margin dynamics , may prediction power fail prevent overfitting experiments conducted show validity proposed method basic convolutional networks , , vgg 16 , resnet 18 , several datasets including cifar10 100 mini imagenet
covariance action recognition paper aim increasing power covariance matrix , limited capturing linear mutual dependencies variables present rigorous principled mathematical pipeline recover kernel computing covariance matrix , enhancing model complex , non linear relationships raw data end , propose , generalizes original covariance representation without efficiency computation experiments , validate proposed framework many previous approaches literature , scoring superior respect state art benchmark datasets 3d action recognition
throughput cognitive radio network congestion constraints network level study paper analyze cognitive radio network one primary one secondary transmitter , primary transmitter secondary node assumed \( e always packet transmitted \) secondary node cognitive way performance primary node assume receivers \( \) capabilities secondary node take advantage capability transmitting simultaneously primary certain conditions obtain analytical expressions stationary distribution primary node queue also provide conditions stability finally , provide expressions aggregate throughput network well throughput secondary node
proxies linear regression models machine learning model may exhibit discrimination used make decisions involving people one potential cause outcomes model uses statistical proxy protected demographic attribute paper formulate definition proxy use setting linear regression present algorithms detecting proxies definition follows recent work proxies classification models , characterizes model 's behavior 1 \) closely protected random variable , 2 \) influential overall behavior model show proxies linear regression models efficiently identified solving second order cone program , extend result account situations use certain input variable justified finally , present empirical results two law datasets exhibit varying degrees disparity prediction outcomes , demonstrating proxies shed useful light causes behavior models
directional analysis stochastic gradient descent via von fisher distributions deep learning although stochastic gradient descent \( sgd \) driving force behind recent success deep learning , understanding dynamics high dimensional parameter space limited recent years , researchers used stochasticity minibatch gradients , signal noise ratio , better characterize learning dynamics sgd inspired work , analyze sgd perspective stochasticity norms directions minibatch gradients propose model directional concentration minibatch gradients von fisher \( \) distribution , show directional uniformity minibatch gradients increases course sgd empirically verify result using deep convolutional networks observe higher correlation gradient stochasticity proposed directional uniformity gradient norm stochasticity , suggesting directional statistics minibatch gradients major factor behind sgd
deep multi camera people detection paper addresses problem multi view people map estimation existing solutions problem either operate per view , rely background pre processing approaches detection performance scenes become former exploit joint information , whereas latter deals input due foreground becoming number targets increases r n although deep learning algorithms proven remarkably numerous computer vision tasks , method applied yet problem large part due lack large scale multi camera data set r n core method architecture makes use monocular pedestrian data set , available larger scale multi view ones , applies parallel processing multiple video streams , jointly end end deep learning method outperforms existing methods large commonly used 2009 data set furthermore , make publicly available new three camera data set source code trained models made available open source license
hierarchical block sparse neural networks sparse deep neural networks \( dnns \) efficient memory compute compared dense dnns due computation sparse dnns , much lower dense dnns regular parallel hardware leads poor performance benefits sparse dnns performance issue sparse dnns structure sparsity leveraging improving runtime efficiency structural constraints often lead suboptimal accuracies work , jointly address accuracy performance sparse dnns using proposed class sparse neural networks called \( hierarchical block sparse neural networks \) given sparsity , models achieve better runtime performance unstructured sparse models better accuracy highly structured sparse models
information dynamic graphs present general approach study time \( measure fast information \) dynamic graphs \( graphs whose topology changes time according random process \) r n consider arbitrary converging markovian dynamic graph process , , processes topology graph time depends topology time 1 unique stationary distribution well studied models dynamic graphs markovian converging r n general conditions , bound time terms mixing time dynamic graph process recover , special cases result , bounds time emph random model emph random path models previous analysis techniques provided bounds restricted settings models result also provides first bound emph random model \( tight certain ranges parameters \) whose analysis important open question
dialogue act classification context aware self attention recent work dialogue act classification treated task sequence labeling problem using hierarchical deep neural networks build prior work leveraging effectiveness context aware self attention mechanism coupled hierarchical recurrent neural network conduct extensive evaluations standard dialogue act classification datasets show significant improvement state art results dialogue act \( \) corpus also investigate impact different utterance level representation learning methods show method effective capturing utterance level semantic text representations maintaining high accuracy
parameterized algorithms 3 path vertex cover 3 path vertex cover graph vertex subset c every path three vertices contains least one vertex c parameterized 3 path vertex cover problem asks whether graph 3 path vertex cover size k paper , give kernel vertices \( 1 k \) time polynomial space algorithm problem , new results improve previous known bounds
random beamforming heterogeneous users selective feedback individual sum rate individual scaling laws paper investigates three open problems random beamforming based communication systems scheduling policy heterogeneous users , closed form sum rate , randomness multiuser diversity selective feedback employing cumulative distribution function based scheduling policy , guarantee fairness among users well obtain multiuser diversity gain heterogeneous scenario scheduling framework , individual sum rate , namely average rate given user number users , interest analyzed different feedback schemes firstly , full feedback scheme , derive closed form individual sum rate employing decomposition probability density function selected user 's signal interference plus noise ratio technique employed obtain closed form rate approximation selective feedback spatial dimension analysis also extended random beamforming ofdma system additional selective feedback spectral dimension wherein best best l resource blocks fed back utilize extreme value theory examine randomness multiuser diversity selective feedback finally , leveraging tail equivalence method , multiplicative effect selective feedback random observations observed establish individual rate scaling
cluster interactive visual cluster analysis biologists biologists often perform clustering analysis derive meaningful patterns , relationships , structures data instances attributes though clustering plays role data exploration , takes non trivial efforts biologists find best grouping data using existing tools visual cluster analysis currently performed either many tools , require parameter several steps trial error paper , introduce cluster , novel visual analysis tool designed support cluster analysis biologists formal data science training cluster enables biologists apply domain clustering results visually demonstrating expected clustering outputs look like small sample data instances system predicts users' generates potential clustering results study follows design study protocol derive tasks requirements , design system , evaluate system experts dataset results study six biologists provide initial evidence cluster enables biologists create , refine , evaluate clustering results effectively analyze data gain data driven insights end , discuss lessons learned implications study
k epsilon anonymity k anonymity epsilon differential privacy volume variety data offers enormous potential research commercial use increased availability personal data particular interest enabling highly services tuned individual needs preserving privacy individuals attacks fast moving poses significant challenges one size fits approach r n paper present \( k , epsilon \) , approach combines k epsilon differential privacy models single coherent framework , providing privacy guarantees least strong offered individual models linking less 5 observed experimental results , even modest values k epsilon r n approach shown address well known limitations k anonymity epsilon differential privacy validated extensive experimental campaign using available datasets
scalar linear solvability networks associated representable matroids study networks introduced et al , showed network scalar linearly solvable finite field , network network associated representable matroid finite field paper , prove converse follows network scalar linearly solvable network network associated representable matroid finite field determining scalar linear solvability network equivalent finding representable matroid finite field valid network matroid mapping consequence , obtain correspondence scalar linearly solvable networks representable matroids finite fields note result , combined construction method due et al , generate potentially new scalar linearly solvable networks
business case technology analysis 5g low latency applications large number new consumer industrial applications likely change classic operator 's business models provide wide range new markets article analyses relevant 5g use cases require ultra low latency , technical business perspectives low latency services pose challenging requirements network , operators need costly changes network sense , clear whether going new business models light , specific applications requirements described potential market benefits operators conclusions show operators clear opportunities add value position strongly increasing number services provided 5g
eeg based drowsiness estimation driving safety using deep q learning factor road one driving drowsiness paper , propose using deep q learning analyze \( eeg \) dataset captured simulated driving test measuring correlation drowsiness driving performance , experiment represents important brain computer interface \( bci \) paradigm especially application perspective adapt driving test fit reinforcement learning framework , thus formulate drowsiness estimation problem optimization q learning task referring latest deep q learning technologies characteristics eeg data , deep q network action estimate drowsiness results show trained model trace variations mind state satisfactory way testing eeg data , demonstrates feasibility new computation paradigm also show method outperforms supervised learning counterpart superior real applications best knowledge , first introduce deep reinforcement learning method bci scenario , method potentially generalized bci cases
sms database performance measures baseline multi channel source separation recognition present multi channel database overlapping speech training , evaluation , detailed analysis source separation extraction algorithms sms multi speaker street journal consists artificially mixed speech taken database , unlike earlier databases consider 1 take care strictly separating speaker sets present training , validation test sets data ensure high degree randomness w r room size , array center rotation , well speaker position furthermore , paper offers critical assessment recently proposed measures source separation performance code generate database provide source separation baseline competitive word error rates provide common ground evaluation
data collaboration analysis distributed datasets paper , propose data collaboration analysis method distributed datasets proposed method centralized machine learning training datasets models remain distributed institutions recently , data large distributed decreasing costs data collection distributed datasets analyse one dataset , expect obtain novel insight achieve higher prediction performance compared individual analyses distributed dataset however , generally difficult original datasets due huge data size regarding privacy preserving problem avoid difficulties , propose data collaboration analysis method distributed datasets without sharing original datasets proposed method intermediate representation constructed individually instead original dataset
6 dof tracking small objects virtual augmented reality technologies seen significant growth past years key component systems ability track pose head controllers 3d space tackle problem efficient 6 dof tracking controller camera perspectives collected controller dataset consist , 000 stereo image pairs labelled full 6 dof pose controller proposed af model achieves mean average error 5 3d keypoint prediction used conjunction sensor controller enable 6 dof tracking also present results approaches model based full 6 dof tracking models operate strict constraints real time mobile cpu inference
parameterised counting classes tail versus reductions \( 2013 \) defined operators parameterised space complexity classes allowing bounded multiple read read access , respectively using operators , complexity many natural problems graphs article , study counting versions operators introduce variants based tail , 1 parabetatail , setting parameterised logarithmic space initially , examine properties classes central reductions well arithmetic operations prove class parabetatail l parameterised reductions l identify natural path counting problems complete newly introduced classes l l study complexity counting variants model checking problems specific classes fo formulas , find complete versions parabetatail l 1 l furthermore , present counting variant parameterised problem , input structure path , complete class l , show complexity parameterised variant function parabetatail l hard written difference two functions parabetatail l 0 1 matrices also , new complexity classes terms branching programs
survey hybrid testing techniques involving symbolic execution fuzzing recent efforts practical symbolic execution successfully path problem extent search based heuristics compositional approaches similarly , due increase performance multi core commodity computers , fuzzing method random based testing also seen promise however , possibility combining symbolic execution fuzzing , thereby providing opportunity mitigate drawbacks , sufficiently explored fuzzing could , example , path exploration symbolic execution , symbolic execution could make seed input generation fuzzing efficient , view , hybrid solution proposals symbolic execution fuzzing analyzing 77 relevant systematically selected papers , \( 1 \) present overview hybrid solution proposals symbolic execution fuzzing , \( 2 \) perform gap analysis research hybrid techniques improve , plain symbolic execution fuzzing , \( 3 \) propose new ideas hybrid test case generation techniques
study precoding strategies physical layer security wireless networks paper , propose novel non linear precoders downlink multi user mimo system existence multiple proposed non linear precoders designed improve physical layer secrecy rate specifically , combine non linear successive optimization precoding \( \) generalized matrix inversion \( \) technique maximize physical layer secrecy rate purpose comparison , examine different traditional precoders proposed algorithm terms secrecy rate well ber performance also investigate simplified generalized matrix inversion \( \) lattice reduction \( lr \) techniques order efficiently compute parameters precoders conduct computational complexity secrecy rate analysis proposed existing algorithms addition , scenario without knowledge channel state information \( csi \) , strategy artificial noise \( \) prior transmission employed enhance physical layer secrecy rate simulation results show proposed non linear precoders outperform existing precoders terms ber secrecy rate performance
scalable algorithm minimal core extraction propose new algorithm minimal core extraction , based deeper exploration resolution properties provide experimental results formal verification benchmarks algorithm finds smaller cores suboptimal algorithms runs faster algorithms guarantee core
filter early match late improving network based visual place recognition cnns performing place recognition time , particularly neural network optimized localization current environmental conditions paper investigate concept feature map filtering , , rather using activations within convolutional tensor , useful activations used since specific feature maps encode different visual features , objective remove feature maps ability recognize location across appearance changes key innovation filter feature maps early convolutional layer , continue run network extract feature vector using later layer network filtering early visual features extracting feature vector higher , viewpoint invariant later layer , demonstrate improved condition viewpoint approach requires image pairs training deployment environment , show state art performance achieved little single training image pair exhaustive experimental analysis performed determine full scope causality early layer filtering late layer extraction validity , use three datasets , , point , achieving overall superior performance work provides number new exploring cnn optimizations , without full training
beyond bs regular languages regular expressions counter check automata last years , various extensions omega regular languages proposed literature , including omega b regular \( omega regular languages extended \) , omega regular \( omega regular languages extended strict \) , omega bs regular languages \( combination omega b omega regular ones \) first two classes satisfy generalized property , namely , complement omega b regular \( resp , omega regular \) language omega regular \( resp , omega b regular \) one , last class closed existence non omega bs regular languages omega bs regular ones express fairly natural properties reactive systems motivates search well classes extended omega regular languages paper , introduce class omega regular languages , includes meaningful languages omega bs regular first define terms omega regular expressions , introduce new class automata \( counter check automata \) prove \( \) problem decidable ptime \( ii \) expressive enough capture omega regular languages \( whether omega regular languages complete respect counter check automata still open problem \) finally , provide encoding omega regular expressions u
linear model predictive safety learning based control shown learning based controllers provide superior performance , often lack safety guarantees paper aims addressing problem introducing model predictive safety \( \) scheme linear systems additive scheme safety proposed learning based input little necessary order keep system within given set constraints safety thereby related existence model predictive controller \( mpc \) providing feasible trajectory towards safe target set robust mpc formulation accounts fact model generally uncertain context learning , allows proving constraint satisfaction times proposed strategy scheme used order expand potentially conservative set safe states learning prove iterative technique safe set finally , practical data based design procedure proposed using scenario optimization
comprehensive survey potential game approaches wireless networks potential games form class non cooperative games improvement dynamics guaranteed converge many practical cases potential game approach applied wide range wireless network problems , particularly variety channel assignment problems paper , properties potential games introduced , games wireless networks proven potential games discussed
semi blind inference topologies dynamical processes dynamic graphs task major practical importance network science inferring graph structure noisy observations subset nodes available methods topology inference typically assume process network observed nodes however , application specific constraints may prevent network wide observations limited flexibility existing approaches , work structural models graph processes novel algorithms joint inference network topology processes partial observations structural equation models \( \) structural vector autoregressive models \( \) well identifying even directed topologies complex graphs capture causal dependencies among nodes , account time batch solver proposed inferring directed graphs best fit sequence observations , estimating network processes reduced computational complexity leveraging tools related kalman smoothing accommodate delay sensitive applications , online joint inference approach put even tracks time evolving topologies furthermore , specify novel conditions identifying network topology given partial observations prove required number observations unique identification reduces significantly network structure sparse numerical tests synthetic well real datasets effectiveness proposed approach
comparative analysis distributed parallel file systems internal techniques file system optimization common task file system field usually , seen key file system problem moreover , possible state optimization dominant commercial development problem new file system architecture development arises frequently academia end user treat file system performance key problem file system evolving technology understanding arises common treatment persistent memory slow result , problem improving performance data processing treats problem file system performance optimization however , evolution physical technologies persistent data storage requires significant changing concepts approaches file internal techniques generally speaking , trying improve file system efficiency cannot resolve issue file systems technological direction moreover , evolution file system technology whole impossible satisfy end user 's expectations means file systems optimization new persistent storage technologies question file systems whole without new file system 's approaches however , file system contains paradigm information important end user human needs distinguish two classes tasks \( 1 \) optimization task \( 2 \) task new architecture vision paradigm , frequently , project goal optimization task really new paradigm end user expectations complex set requirements optimization tasks cannot resolve current needs end user file system field end user 's expectations require tasks new architecture vision paradigm
person identification semantic region representation topology constraint person identification popular research topic aims matching specific person multi camera network automatically feature representation metric learning two important issues person identification paper , propose novel person identification method , consists reliable representation called semantic region representation \( \) , effective metric learning mapping space topology constraint \( \) integrates semantic representations achieve effective similarity comparison corresponding regions via parsing body multiple parts , focuses foreground context background interference learn metric , proposed consider topological relationship among samples feature space considers two fold constraints distribution positive pairs compact average distribution negative pairs regard probe , average distance different classes larger classes two aspects cooperate maintain compactness intra class well sparsity inter class extensive experiments conducted five challenging person identification datasets , , , grid , , market , show proposed method achieves competitive performance state art approaches
successive integer forcing sum rate optimality integer forcing receivers generalize traditional linear receivers multiple input multiple output channel decoding integer linear combinations transmitted streams , rather streams previous works shown additional degree freedom choosing integer coefficients enables receiver approach performance maximum likelihood decoding various scenarios , even optimal choice integer coefficients , additive noise 's output still correlated work study variant integer forcing , termed successive integer forcing , exploits noise correlations improve performance scheme integer forcing counterpart successive interference cancellation traditional linear receivers similarly latter , show successive integer forcing capacity achieving possible optimize rate allocation different streams comparison standard successive interference cancellation receivers , successive integer forcing receiver offers possibilities capacity achieving rate tuples , particular , ones balanced
cross modal learning multi modal video categorization multi modal machine learning \( ml \) models process data multiple modalities \( e g , video , audio , text \) useful video content analysis variety problems \( e g , object detection , scene understanding , activity recognition \) paper , focus problem video categorization using multi modal ml technique particular , developed novel multi modal ml approach call cross modal learning , one modality another correlation modalities , first train correlation main multi modal video categorization model show cross modal principle applied different types models \( e g , rnn , transformer , \) , demonstrate experiments proposed multi modal video categorization models cross modal learning perform strong state art baseline models
hard robust mean estimation robust mean estimation problem estimating mean mu mathbb r dimensional distribution list independent samples , epsilon fraction arbitrarily corrupted malicious adversary recent algorithmic progress resulted first polynomial time algorithms achieve emph dimension independent rates error instance , covariance , polynomial time one may find hat mu mu hat mu leq \( sqrt epsilon \) however , error rates achieved current polynomial time algorithms , dimension independent , sub optimal many natural settings , sub gaussian , bounded 4 th moments r n work give worst case complexity theoretic evidence improving error rates current polynomial time algorithms robust mean estimation may computationally intractable natural settings show several natural approaches improving error rates current polynomial time robust mean estimation algorithms would efficient algorithms small set expansion problem , 's small set expansion hypothesis \( long p np \) also give first direct reduction robust mean estimation problem , starting plausible variant small set expansion problem
high degree vertices eigenvalues diameter random networks work analyze basic properties random networks cite , , popular stochastic model generates planar graphs power law properties specifically , let k constant delta 1 geq delta 2 geq geq delta k degrees k highest degree vertices prove time , function f f \( \) rightarrow infty rightarrow infty , frac 1 2 f \( \) leq delta 1 leq f \( \) 1 2 2 , , k \( 1 \) , frac 1 2 f \( \) leq delta leq delta 1 frac 1 2 f \( \) high probability \( \) , show k largest eigenvalues adjacency matrix graph satisfy lambda k \( 1 pm \( 1 \) \) delta k 1 2 furthermore , prove refined upper bound asymptotic growth diameter , e , diameter \( g \) time satisfies \( g \) leq rho log frac 1 rho unique solution greater 1 equation 1 log log 3 finally , investigate properties model
trial offer markets trial offer markets , customers sample product deciding whether , ubiquitous online experience static dynamic properties often studied assuming consumers follow model try exactly one product paper , study generalize existing results realistic setting consumers try multiple products show model reduced standard model different product examine consequences reduction performance predictability market , role social influence , ranking policies
stair actions video dataset everyday home actions new large scale video dataset human action recognition , called stair actions introduced stair actions contains 100 categories action labels representing fine grained everyday home actions applied research various home tasks , , security stair actions , video single action label moreover , action category , around 1 , 000 videos obtained produced duration video mostly five six seconds total number videos , explain constructed stair actions show characteristics stair actions compared existing datasets human action recognition experiments three major models action recognition show stair actions train large models achieve good performance stair actions http url
general e 2 equivariant cnns big empirical success group equivariant networks led recent years great variety equivariant network architectures particular focus thereby rotation equivariant cnns planar images give general description e \( 2 \) equivariant convolutions framework cnns theory cnns thereby yields constraints convolution kernels depend group representations describing transformation laws feature spaces show constraints arbitrary group representations reduced constraints irreducible representations general solution kernel space constraint given arbitrary representations euclidean group e \( 2 \) implement wide range previously proposed entirely new equivariant network architectures extensively compare performances e \( 2 \) convolutions shown yield remarkable gains cifar 10 , cifar 100 10 used replacement non equivariant convolutions
exploiting gan internal capacity high quality reconstruction natural images generative adversarial networks \( gan \) demonstrated impressive results modeling distribution natural images , learning latent representations capture semantic variations unsupervised basis beyond generation novel samples , special interest exploit ability gan generator model natural image manifold hence generate changes manipulating images however , line work conditioned quality reconstruction , inversion latent space considered , propose exploit representation intermediate layers generator , show leads increased capacity particular , observe representation first dense layer , present state art gan models , expressive enough represent natural images high visual fidelity possible around images obtaining sequence new plausible synthetic images cannot generated latent space finally , example potential applications arise inversion mechanism , show preliminary results exploiting learned representation attention map generator obtain unsupervised segmentation natural images
behavior q composite random key graphs applications networked control random key graphs received considerable attention used various applications including secure sensor networks , social networks , study , , recommender systems paper , investigate q composite random key graph , whose construction n nodes follows node independently selects set k n different keys uniformly random pool p n distinct keys , two nodes establish undirected edge share least q key \( \) graph denoted g q \( n , k n , p n \) models secure sensor network employing well known q composite key g q \( n , k n , p n \) , analyze probabilities g q \( n , k n , p n \) k connectivity , k robustness , cycle perfect matching , respectively studies four properties motivated detailed discussion applications networked control results reveal g q \( n , k n , p n \) exhibits sharp transition property k n increases , probability g q \( n , k n , p n \) property increases 0 1 results provide fundamental design secure sensor networks different control related applications distributed network parameter estimation , fault tolerant consensus , resilient data
delay sensitive distributed power transmission threshold control aloha network finite state markov fading channels paper , consider delay sensitive power transmission threshold control design aloha network fading channels random access system consists access point k competing users , access local channel state information \( csi \) queue state information \( \) well common feedback \( collision \) access point seek derive delay optimal control policy \( composed threshold power control \) optimization problem memoryless policy k agent infinite horizon decentralized markov decision process \( dec mdp \) , finding optimal policy shown computationally intractable obtain feasible low complexity solution , optimization problem two subproblems , namely power control threshold control problem given threshold control policy , power control problem decomposed reduced state mdp single user overall complexity \( \) , n j size cardinality csi states threshold control problem , exploit special structure collision channel common feedback information derive low complexity solution delay performance proposed design shown substantial gain relative conventional throughput optimal approaches aloha
cross modal health state estimation individuals create diverse data today time history sources data include wearable devices , images , social media , geo spatial information tremendous opportunity within cross modal data analysis leverages existing domain knowledge methods understand guide human health especially diseases , current medical practice uses combination sparse based biological metrics \( tests , expensive imaging , etc \) understand evolving health status individual future health systems must integrate data created individual level better understand health status , especially framework work multiple user created open source data streams along established biomedical domain knowledge give two types quantitative state estimates health first , use wearable devices calculate \( crf \) , known quantitative leading predictor heart disease collected clinical settings second , estimate inherent genetic , environmental , , biological metrics diverse dataset experimental results 24 subjects demonstrate multi modal data provide personalized health insight understanding dynamic nature health status way better health based recommendation engines , better clinical decision making positive changes
almost envy freeness welfare efficiency fair division goods bads consider two models fair division items one goods one bads goods , study two generalized envy freeness proxies \( efx goods \) three common welfare \( , nash \) efficiency notions bads , study two generalized envy freeness proxies \( goods \) two less common \( nash \) efficiency notions existing algorithms goods work bads thus propose several new algorithms model bads new algorithms exhibit many nice properties example , additive identical , allocation maximizes nash finally , also give simple tractable cases envy freeness proxies welfare efficiency combination \( e g binary , allocations \)
snap ml hierarchical framework machine learning describe new software framework fast training generalized linear models framework , named snap machine learning \( snap ml \) , combines recent advances machine learning systems algorithms nested manner reflect hierarchical architecture modern computing systems prove theoretically hierarchical system accelerate training distributed environments intra node communication cheaper inter node communication additionally , provide review implementation snap ml terms gpu acceleration , , communication patterns software architecture , highlighting aspects critical achieving high performance evaluate performance snap ml single node multi node environments , quantifying benefit hierarchical scheme data streaming functionality , comparing widely used machine learning software frameworks finally , present logistic regression benchmark click logs dataset show snap ml achieves test loss order magnitude faster previously reported results , including obtained using learn
submodular optimization submodular cover submodular knapsack constraints investigate two new optimization problems minimizing submodular function subject submodular lower bound constraint \( submodular cover \) maximizing submodular function subject submodular upper bound constraint \( submodular knapsack \) motivated number real world applications machine learning including sensor placement data subset selection , require maximizing certain submodular function \( like coverage diversity \) simultaneously minimizing another \( like cooperative cost \) problems often posed minimizing difference submodular functions 14 , 35 worst case show , however , problems constrained optimization , natural many applications , achieve number bounded approximation guarantees also show problems closely related approximation algorithm solving one used obtain approximation guarantee provide hardness results problems thus showing approximation factors tight log factors finally , empirically demonstrate performance good scalability properties algorithms
dictionary testing problem dictionary learning \( sparse coding \) problem plays important role signal processing , neuroscience , statistics machine learning given collection vectors , goal learn basis respect given vectors sparse representation work , study testing problem r n roughly speaking , dictionary testing problem decide whether given collection vectors approximately transformed sparse vectors precisely , given input vectors 1 , ldots , p r , want distinguish following two cases \( choice parameters \) r n \( \) yes case exist matrix r times satisfying k sparse unit vectors x 1 , ldots , x p r x r n \( ii \) case exist sparse unit vectors x 1 , ldots , x p r r times satisfying \( x 1 , ldots , x p \) close \( 1 , ldots , p \) r n note unlike known results provable dictionary learning , assumption distribution x 1 , dots , x p yes case goal design efficient algorithm distinguish two cases using linear queries , e , inner products input vectors vectors choice r n simple efficient outputs yes gaussian width input sufficiently small analysis test viewed giving robust characterization gaussian width terms sparsity number linear queries made independent dimension
propositional independence formula variable independence forgetting independence study relevant given problem reasoning received increasing attention ai community paper , consider two basic forms independence , namely , syntactic one semantic one show features drawbacks particular , syntactic form independence computationally easy check , cases things intuitively relevant recognized also consider problem forgetting , e , knowledge base part relevant set queries constructed subset alphabet process computationally hard , allows subsequent reasoning , thus viewed form relevant part knowledge base extracted , reasoning tasks performed simplified
connecting gaze scene attention generalized attention estimation via joint modeling gaze scene saliency paper addresses challenging problem estimating general visual attention people images proposed method designed work across multiple social scenarios provides full picture subject 's attention gaze contrast , earlier works gaze attention estimation focused constrained problems specific contexts particular , model explicitly represents gaze direction handles frame gaze targets leverage three different datasets using multi task learning approach evaluate method widely used benchmarks single tasks gaze angle estimation attention within image , well new challenging task generalized visual attention prediction addition , created extended annotations datasets used experiments , publicly release
new multi edge metric constrained peg algorithm designing binary ldpc code improved cycle structure progressive edge growth \( peg \) algorithm constructs edge stage maximize variable node \( \) interest local girth real time thus , local , one edge added current graph \( \) setting , may maximized relative setting address problem , define multi edge local girth edge trial , based definitions , propose new multi edge metric constrained peg algorithm \( mm pega \) improve design mm pega constructs edge stage , relative current setting , potentially maximize interest local girth certain number \( edge trial \) edges added setting first analyze properties multi edge local girth , propose algorithm calculating multi edge local girth also propose method mm pega moreover , generalize mm pega improving different peg like designs according theoretical analysis , increasing edge trial mm pega expected affect cycle structure error performance resulting low density parity check \( ldpc \) code expectation verified simulations
ftos verify analysis verification non functional properties fault tolerant systems focus tool ftos alleviate burden offering code generation non functional aspects including fault tolerance mechanisms one crucial aspect context ensure user selected mechanisms system model sufficient specified underlying fault hypothesis paper , formal approaches verification proposed assist claim first precision ftos pure mathematical constructs , formulate deterministic assumption , necessary extension like systems \( e g , ftos \) fault tolerance show local properties system deterministic assumption preserved modified synchronous system used verification model enables use techniques known hardware verification implementation , develop prototype tool called ftos verify , deploy add ftos , conduct several case studies
parameterized complexity view description logic reasoning description logics knowledge representation languages designed balance computational tractability many different description logics developed , numerous computational problems logics studied computational complexity however , essentially complexity analyses reasoning problems description logics use one dimensional framework classical complexity theory multi dimensional framework parameterized complexity theory able provide much detailed image complexity reasoning problems r n paper argue framework parameterized complexity lot offer complexity analysis description logic reasoning problems one takes progressive forward looking view parameterized complexity tools argument means three case studies first case study problem concept satisfiability logic respect nearly acyclic second case study concerns concept satisfiability concepts parameterized number occurrences union operators number occurrences full existential quantification third case study offers critical look data complexity results parameterized complexity point view three case studies representative wide range uses parameterized complexity methods description logic problems
system deduction based formal verification workflow oriented software models abstract work concerns formal verification workflow oriented software models using approach formal correctness model 's behaviour considered manually building logical specifications , regarded set temporal logic formulas , seems significant obstacle user applying approach system , along architecture , deduction based verification workflow oriented models proposed process inference based semantic method , advantages compared traditional deduction strategies algorithm automatic generation logical specifications proposed generation procedure based predefined workflow patterns , standard dominant notation modeling business processes main idea behind approach consider patterns , defined terms temporal logic , kind logical primitives enable transformation models temporal logic formulas logical specification automation generation process crucial bridging gap reasoning difficulty practical application logical specifications built manually approach way towards supporting , enhancing , understanding deduction based formal verification workflow oriented models
difficulties implementation quantum computers paper reviews various engineering facing field quantum computing specifically , problems related , state preparation , error correction , considered
enabling efficient rdma based synchronous mirroring persistent memory transactions synchronous mirroring \( sm \) standard approach building highly available fault tolerant enterprise storage systems sm ensures strong data consistency maintaining multiple exact data propagating every update strong consistency provides fault tolerance guarantees simple programming model enterprise system designers current storage devices , sm comes modest performance performing local remote updates simultaneously performing local updates , due relatively slow performance storage today 's systems however , emerging persistent memory ultra low latency network technologies careful evaluation existing sm techniques , technologies present fundamentally different latency characteristics compared traditional counterparts addition , existing low latency network technologies , remote direct memory access \( rdma \) , provide limited ordering guarantees provide guarantees necessary sm evaluate performance implications rdma based sm , develop rigorous testing framework based persistent memory testing framework makes use two different tools \( \) \( ii \) modified version benchmark suite , comprises set common cloud applications using framework , find recently proposed rdma primitives , remote commit , provide correctness guarantees , take full advantage asynchronous nature rdma hardware end , propose new primitives enabling efficient correct sm rdma , use primitives develop two new techniques high performance sm persistent
exploiting physical layer security multiuser computation offloading letter considers mobile edge computing \( \) system one access point \( ap \) multiple users channel , presence malicious eavesdropper system , user execute respective computation tasks partitioning two parts , computed locally ap , respectively exploit physical layer security secure multiuser computation offloading eavesdropper setup , minimize weighted sum energy consumption users , subject newly secrecy offloading rate constraints computation latency constraints , jointly optimizing computation communication resource allocations propose efficient algorithm solve problem
energy efficient communication gaussian interference networks processing energy cost work considers communication gaussian interference networks processing energy cost , explicitly takes account energy processing transmitters presence processing energy cost , transmitting time conventional cost case longer optimal two user gaussian interference channel processing energy cost , assuming states transmitters utilized signaling , several transmission schemes varying complexities proposed sum rates compared interference free upper bound moreover , strong interference regime , interference incur rate penalty , identified shown larger case processing energy cost also , extensions three user cascade gaussian z interference channel processing energy cost provided , scheduling user transmissions based interference geometry investigated
termination analysis probabilistic programs consider nondeterministic probabilistic programs basic property termination present efficient methods termination analysis nondeterministic probabilistic programs polynomial approach synthesis polynomial ranking , one hand significantly generalizes linear ranking hand counterpart polynomial ranking functions proving termination programs approach polynomial ranking 's , yielding efficient method sound , also semi complete large subclass programs show experimental results demonstrate approach handle several classical programs complex polynomial , synthesize efficient quadratic ranking linear one exist even simple affine programs
nlvr2 visual bias analysis nlvr2 \( et al , 2019 \) designed robust language bias data collection process resulted natural language sentence true false labels process provide similar measure control visual bias technical report analyzes potential visual bias nlvr2 show amount visual bias likely exists finally , identify subset test data allows test model performance way robust potential biases show performance existing models \( et al , 2019 2019 \) relatively robust potential bias propose add evaluation subset data nlvr2 evaluation protocol , update release include including implementation code used analysis available http url
word class embeddings multiclass text classification pre trained word embeddings encode general word semantics lexical natural language , proven useful across many nlp tasks , including word sense , machine translation , sentiment analysis , name supervised tasks multiclass text classification \( focus article \) seems appealing enhance word representations ad hoc embeddings encode task specific information propose \( supervised \) word class embeddings \( \) , show , concatenated \( unsupervised \) pre trained word embeddings , substantially facilitate training deep learning models multiclass classification topic show empirical evidence yield consistent improvement multiclass classification accuracy , using four popular neural architectures six widely used publicly available datasets multiclass text classification code publicly available https url
generic method automatic ground truth generation camera captured documents contribution paper first contribution novel , generic method automatic ground truth generation camera captured document images \( , , articles , , etc \) enables us build large scale \( e , millions images \) labeled camera captured scanned documents datasets , without human intervention method generic , language independent used generation labeled documents datasets \( scanned \) non language , e g , english , , , , etc assess effectiveness presented method , two different datasets english generated using presented method evaluation samples two datasets shows 99 98 images correctly labeled second contribution large dataset \( called \) camera captured characters words images , comprising 1 million word images \( 10 million character images \) , captured real camera based acquisition dataset used training well testing character recognition systems camera captured documents third contribution novel method recognition document images proposed method based long short term memory outperforms state art methods camera based fourth contribution , various benchmark tests performed uncover behavior commercial \( \) , open source \( \) , presented camera based using presented dataset evaluation results reveal existing , already get high accuracies scanned documents , limited performance camera captured document images accuracy 75 , accuracy 50 22 , presented character recognition system accuracy 95 10
state constraints list decoding list decoding arbitrarily varying channels \( \) state constraints investigated shown rates within epsilon randomized coding capacity input dependent state achieved maximal error list decoding using lists size \( 1 epsilon \) average error achievable rate region converse bound given lists size l bounds based two different notions coincide general example given shows list size l capacity may positive strictly smaller randomized coding capacity behavior different situation without state constraints
constant approximation algorithms highly connected multi dominating sets unit disk graphs given undirected graph node set v positive k , k connected dominating set \( \( k , \) cds \) defined subset v node v least neighbors , k connected subgraph induced weighted \( k , \) cds problem find minimum weight \( k , \) cds given node weighted graph problem called unweighted \( k , \) cds problem objective minimize cardinality \( k , \) cds problems actively studied unit disk graphs , motivated application constructing virtual backbone wireless ad hoc network however , constant approximation algorithms known k leq 3 unweighted \( k , \) cds problem , \( k , \) \( 1 , 1 \) weighted \( k , \) cds problem paper , consider case geq k , present simple \( 5 k k \) approximation algorithm unweighted \( k , \) cds problem , primal dual \( k 2 log k \) approximation algorithm weighted \( k , \) cds problem algorithms achieve constant approximation factors k fixed constant
estimation channel non reciprocity massive mimo time division duplex \( \) based massive mimo systems rely reciprocity wireless propagation channels calculating downlink precoders based uplink however , effective uplink downlink channels incorporating analog radio front base station \( bs \) user \( ues \) exhibit non reciprocity due non identical behavior individual transmit receive chains downlink aware channel non reciprocity \( nrc \) , system performance significantly degraded due nrc induced interference terms paper , consider general based massive mimo system frequency response bs ues , well mutual coupling bs large antenna system induce channel nrc based nrc signal models , first propose novel iterative estimation method bs ue side nrc matrices also propose efficient nrc aware downlink design utilizes obtained estimates furthermore , efficient pilot signaling scheme bs ues introduced order facilitate executing proposed estimation method nrc aware precoding technique practical systems comprehensive numerical results indicate substantially improved spectral efficiency performance proposed nrc estimation nrc aware precoding methods adopted , compared existing state art methods
drawing arrangement graphs small grids play planarity describe linear time algorithm finds planar drawing every graph simple line arrangement within grid area \( n 7 6 \) known input causes algorithm use area omega \( n 1 epsilon \) epsilon 0 finding input would represent significant progress k set problem discrete geometry drawing line arrangement graphs main task planarity
gradient augmented information retrieval autoencoders semantic hashing paper explore use autoencoders semantic hashing context information retrieval paper efficiently train autoencoder order create meaningful low dimensional encodings data paper demonstrate computing storing closest encodings input query help speed search time improve quality search results novel contributions paper involve using representation data learned auto encoder order augment search query various ways present evaluate new gradient search augmentation \( \) approach , well well known pseudo relevance feedback \( \) adjustment find helps improve performance based information retrieval system , combined works best overall systems compared paper
artificial neural networks propose genetic algorithm \( ga \) optimization artificial neural networks includes well parameters \( e , weights biases \) hyperparameters \( e g , learning rate , weight decay , dropout \) produced three two contributing hyperparameters one contributing parameters version population based training \( \) combines traditional gradient based approaches stochastic gradient descent \( sgd \) ga optimize parameters hyperparameters across sgd improvements traditional provide increased speed adaptation greater ability shed population methods improve final accuracy well time fixed accuracy wide range deep neural network architectures including convolutional neural networks , recurrent neural networks , dense neural networks , capsule networks
performance analysis training based multi pair two way full duplex relaying massive antennas paper considers multi pair two way amplify forward relaying system , multiple pairs full duplex users served via full duplex relay massive antennas , relay adopts maximum ratio combining maximum ratio transmission \( \) processing orthogonal pilot scheme least square method firstly exploited estimate channel state information \( csi \) number relay antennas finite , derive approximate sum rate expression shown good predictor ergodic sum rate , especially large number antennas corresponding achievable rate expression obtained adopting another pilot scheme estimates composite csi user pair reduce pilot overhead channel estimation analyze achievable rates two pilot schemes show relative two methods furthermore , power allocation strategies users relay proposed based sum rate maximization max min fairness criterion , respectively finally , numerical results verify accuracy analytical results show performance gains achieved proposed power allocation
efficient influence maximization weighted independent cascade model influence maximization \( \) problem find seed set social network achieves maximal influence spread problem plays important role numerous models proposed solve problem however , none considers attributes nodes paying attention structure network causes applying models real word applications r n motivated , present weighted independent cascade \( wic \) model , novel cascade model extends applicability independent cascade \( \) model attributes nodes problem wic model maximize value nodes influenced problem np hard solve problem , present basic greedy algorithm weight \( \) algorithm moreover , propose bounded weight \( bwr \) algorithm make effort improve efficiency bounding diffusion node influence prove bwr fully polynomial time approximation scheme \( \) experimentally , show additional node attribute , solution achieved wic model outperforms model nearly experimental results show bwr achieve excellent approximation faster greedy algorithm three orders magnitude little accuracy especially , bwr handle large networks millions nodes several seconds keeping rather high accuracy result demonstrates bwr solve problem effectively efficiently
bangla word clustering based gram 4 gram 5 gram language model paper , describe research method generates bangla word clusters basis meaning language contextual similarity importance word clustering parts speech \( \) tagging , word sense , text classification , recommender system , , grammar , knowledge discover many others natural language processing \( nlp \) applications history word clustering , english languages already implemented methods word clustering efficiently due lack resources , word clustering bangla still implemented efficiently , implementation beginning stage research word clustering english based preceding next five words key word found efficient result , trying implement gram , 4 gram 5 gram model word clustering bangla observe one best among started research quite large corpus approximate 1 bangla words using machine learning technique research generate word clusters analyze clusters testing different threshold values
location enhanced authenticated key exchange introduce \( location enhanced authenticated key exchange \) , generic protocol location , user attributes , access policy desired services multi factor authentication , allowing two peers establish secure , session perform mutual authentication pre shared keys , authentication factors contributes \( 1 \) forward secrecy session keys \( 2 \) security zero knowledge proofs \( \) , learned exchange \( 3 \) ability use location , also multiple authentication factors user service \( 4 \) providing two privacy authentication scheme , user may authenticated either based attributes \( unique identification \) , full individual authentication \( 5 \) employing expressiveness flexibility decentralized multi policy attribute based encryption , allowing multiple service providers control respective key generation attributes
optimal algorithms continuous non monotone submodular submodular maximization paper study fundamental problems maximizing continuous non monotone submodular function , without coordinate wise family optimization problems several applications machine learning , , communication systems main result first frac 1 2 approximation algorithm continuous submodular function maximization approximation factor frac 1 2 best possible algorithms query objective function polynomially many points special case submodular maximization , e submodular functions also coordinate wise concave along coordinates , provide different frac 1 2 approximation algorithm runs time results improve upon prior work et al , 2017 , , 2017 r n first algorithm uses novel ideas reducing guaranteed approximation problem analyzing zero sum game coordinate , incorporates geometry zero sum game value coordinate second algorithm exploits coordinate wise identify monotone equilibrium condition sufficient getting required approximation guarantee , equilibrium point using binary search run experiments verify performance proposed algorithms related machine learning applications
tight upper lower bounds information rate phase noise channel numerical upper lower bounds information rate additive white gaussian noise channel affected discrete time multiplicative autoregressive moving average \( \) phase noise proposed paper state space model multidimensional , problem cannot conventional based methods assume first order model phase noise quantization phase space , number state would enormous proposed lower upper bounds based particle filtering kalman filtering simulation results show upper lower bounds close claim numerically computed actual information rate multiplicative phase noise channel , least cases studied paper moreover , lower bound , virtually capacity achieving , obtained incoming signal based kalman filter aided past data thus claim found virtually optimal multiplicative phase noise channel , least cases considered paper
exploration regret minimization discrete continuous markov decision processes introduce analyse two algorithms exploration exploitation discrete continuous markov decision processes \( mdps \) based exploration scal variant scal \( et al , 2018 \) performs efficient exploration exploitation unknown weakly communicating mdp upper bound c optimal bias function known mdp states , actions gamma leq possible next states , prove scal achieves theoretical guarantees scal \( e , high probability regret bound \( c sqrt gamma sat \) \) , much smaller computational complexity similarly , c scal exploits exploration achieve sublinear regret mdp continuous state space show c scal achieves regret bound \( , 2012 \) first algorithm regret guarantees setting algorithms , scal maintain high confidence set plausible mdps around true unknown mdp , scal c scal leverage exploration directly plan empirically estimated mdp , thus computationally efficient
modified diversity class probability estimation co training hyperspectral image classification due limited amount imbalanced classes labeled training data , conventional supervised learning ensure discrimination learned feature hyperspectral image \( hsi \) classification paper , propose modified diversity class probability estimation \( \) two deep neural networks learn spectral spatial feature hsi classification co training phase , recurrent neural network \( rnn \) convolutional neural network \( cnn \) utilized two learners extract features labeled unlabeled data based extracted features , selects samples update initial labeled data combining k means clustering traditional diversity class probability estimation \( \) co training way , keep new labeled data class balanced extract discriminative features minority majority classes testing process , classification results acquired co decision two learners experimental results demonstrate proposed semi supervised co training method make full use unlabeled information enhance learners achieve favorable accuracies three widely used data sets , university center
capacity mimo interference channels capacity region multiple input multiple output interference channel \( mimo \) channel matrices square studied capacity region strong interference established definition strong interference scalar channels moreover , sum rate capacity z interference , noisy interference , mixed interference established results generalize known results scalar gaussian
automatic differentiation look tensor operational calculus paper take look automatic differentiation tensor operational calculus work best material learning tensor operational calculus already automatic differentiation purpose , provide simple implementation automatic differentiation , steps taken explained language tensor operational calculus
testing synchronization consider first problem appears application automata , namely , problem deciding whether letter automaton first general results \( 4 \) , \( 5 \) case strongly connected partial automata specifically show automaton probability 1 \( 1 \) present algorithm linear n expected time , best known algorithm quadratic instance interesting due applications synchronization finite state information sources next consider synchronization partial automata application systems theory computational case prove problem testing given automaton synchronization np complete
diagnosis using deep learning images critical review abstract overview applications deep learning diagnosis using images presented describe various image datasets used deep learning purposes applications deep learning segmentation disk , , well detection reviewed recent deep learning models classification diseases age related , also discussed important critical insights future research directions given
impact data preparation fairness software systems machine learning models widely adopted scenarios directly affect people development software systems based models raises legal concerns , decisions may lead treatment individuals based attributes like gender data preparation key machine learning pipeline , effect fairness yet studied detail paper , evaluate fairness effectiveness learned models affected removal sensitive attribute , encoding categorical attributes , instance selection methods \( including cross random \) used german data datasets , widely studied known fairness concerns applied data preparation technique individually analyse difference predictive performance fairness , using statistical parity difference , disparate impact , index results show fairness affected transformations made training data , particularly imbalanced datasets removing sensitive attribute insufficient predictions , expected , key achieve models additionally , standard random respect true labels sometimes performing random
embedded traditional models rational action treat agent though environment , act environment outside agents known functional relationship environment , model environment every detail , need reason internal parts provide survey obstacles formalizing good reasoning agents embedded environment agents must optimize environment type must rely models fit within modeled environment must reason another physical system , made parts modified work cross purposes
survey algorithms analysis adaptive online learning present tools analysis follow regularized leader \( \) , dual averaging , mirror descent algorithms regularizer \( , function learning rate \) chosen adaptively based data used prove regret bounds hold every round , also allows data dependent regret bounds style algorithms \( e g , online gradient descent adaptive per coordinate learning rates \) present results large number prior works unified manner , using modular tight analysis key arguments easily approach pre known analysis techniques produce bounds tight achieved potential functions primal dual analysis , prove general exact equivalence arbitrary adaptive mirror descent algorithm correspond update , allows us analyze mirror descent algorithm framework key bridging gap dual averaging mirror descent algorithms lies analysis algorithm family regret bounds proved general form , arbitrary norms non smooth time varying weight
addmc exact weighted model counting algebraic decision diagrams compute exact weighted model counts formulas algorithm employs dynamic programming , algebraic decision diagrams primary data structure technique implemented addmc , new model counter empirically evaluate various heuristics used addmc also compare addmc state art exact model \( , , , , \) two largest model counting benchmark families \( planning \) addmc solves benchmarks total within given
dynamic scores matrices score problem aligning two strings , b order determine similarity fundamental field pattern matching important concept domain scores matrix local alignment comparison two strings namely , let k denote scores matrix containing alignment score every substring b , let j denote scores matrix containing alignment score every suffix b every prefix r n paper consider problem maintaining scores matrix scoring function score , supporting single character operations n algorithms exploit sparsity parameters l \( , b \) delta b l matrix k propose algorithm supports incremental operations \( delta \) time whilst matrix j propose algorithm supports single type incremental operation , either operation operation b , \( l \) time structure also extended support operations simultaneously \( l log log l \) time
optimization based alignment inertial navigation system comparison extension paper , optimization based alignment \( oba \) methods investigated main focus vector observation construction procedures inertial navigation system \( \) contributions study twofold first , oba method extended able estimate biases coupled based construction process existing oba methods extension transforms initial alignment estimation problem solved using nonlinear filtering algorithms second contribution comprehensive evaluation oba methods extensions different vector observations construction procedures terms convergence speed steady state estimate using field test data collected different grades study expected facilitate selection appropriate oba methods different grades
ensembles kernel predictors paper examines problem learning finite possibly large set p base kernels presents theoretical empirical analysis approach addressing problem based ensembles kernel predictors includes novel theoretical guarantees based complexity corresponding hypothesis sets , introduction analysis learning algorithm based hypothesis sets , series experiments using ensembles kernel predictors several data sets convex combinations kernel based hypotheses general regularized nonnegative combinations analyzed theoretical , algorithmic , empirical results compared achieved using learning kernel techniques , viewed another approach solving problem
testing reactive probabilistic processes define testing equivalence de reactive probabilistic processes , e processes internal due random behaviour characterize testing equivalence terms traces characterization follows equivalence insensitive exact moment time internal probabilistic choice occurs , inherent original testing equivalence de also show decidability testing equivalence finite systems complete model may known
reproducibility evaluation slant whole brain segmentation across clinical magnetic resonance imaging protocols whole brain segmentation structural magnetic resonance imaging \( mri \) essential understanding functional relationships traditionally , multi segmentation regarded standard method whole brain segmentation past years , deep convolutional neural network \( dcnn \) segmentation methods demonstrated advantages accuracy computational efficiency recently , proposed spatially localized network tiles \( slant \) method , able segment 3d mri brain scan anatomical regions commonly , dcnn segmentation methods yield performance external , especially testing patterns presented training recently , obtained acquired , multi sequence mri brain cohort acquired , de identified brain mri scans patients using seven different mri protocols moreover , subject least two scans different mri protocols , assess slant method 's intra inter protocol reproducibility slant achieved less 0 coefficient variation \( \) intra protocol experiments less 0 15 inter protocol experiments results show slant method achieved high intra inter protocol reproducibility
sphere packing bound memoryless channels sphere packing bounds \( \) polynomial block length derived codes two families memoryless channels using 's method \( possibly non stationary \) memoryless channels \( possibly multiple \) additive cost constraints stationary memoryless channels convex constraints composition \( e empirical distribution , type \) input codewords variant 's inner bound derived order show sphere packing bounds tight terms exponential decay rate error probability block length mild hypotheses
emptyheaded boolean algebra based graph processing present graph pattern engine , emptyheaded , uses recent algorithmic advances join processing patterns boolean algebra operations exploit simd parallelism emptyheaded engine demonstrates treating graph patterns general join processing problem compete often outperform specialized approaches existing systems graph queries core boolean algebra operation performed emptyheaded set intersection extracting simd parallelism set intersections graph data challenging graph data several ways contributions demonstration new type engine boolean algebra core , exploration set intersection representations algorithms set intersections optimized demonstrate emptyheaded outperforms specialized graph engines order magnitude relational systems two orders magnitude results suggest new style engine promising new direction future graph engines
avoiding reasoning shortcuts adversarial evaluation training model development multi hop multi hop question answering requires model connect multiple pieces evidence scattered long context answer question paper , show multi hop \( et al , 2018 \) dataset , examples often contain reasoning shortcuts models directly locate answer word matching question sentence context demonstrate issue constructing adversarial documents create answers shortcut affect validity original answer performance strong baseline models significantly adversarial evaluation , indicating indeed exploiting shortcuts rather performing multi hop reasoning adversarial training , baseline 's performance improves still limited adversarial evaluation hence , use control unit dynamically question different reasoning guide model 's multi hop reasoning show 2 hop model trained regular data robust adversaries baseline model adversarial training , 2 hop model achieves improvements counterpart trained regular data , also outperforms adversarially trained 1 hop baseline hope insights initial improvements motivate development new models combine explicit compositional reasoning adversarial training
graph based framework flexible baseband function splitting placement c baseband architecture radio access networks \( c \) recently proposed support efficient cooperative communications reduce deployment operational costs however , massive bandwidth required aggregate baseband samples remote radio heads \( \) central incurs huge cost , existing baseband compression algorithms solve issue paper , propose graph based framework effectively reduce cost properly splitting baseband processing functions network baseband structures represented directed graphs , nodes correspond baseband functions , edges information flows functions mapping graph computational costs , transform problem finding optimum location place baseband functions problem finding optimum clustering scheme graph nodes solve problem using genetic algorithm customized function module simulation results show proper splitting placement schemes significantly reduce cost expense increased computational cost also find cooperative processing structures delay requirements increase possibility centralized placement
using syntax ground referring expressions natural images introduce , neural network referring expression recognition task \( \) image object referred natural language expression approach task first rely syntactic analysis input referring expression order inform structure computation graph given tree input expression , explicitly map syntactic relationships present tree composed graph neural modules defines architecture performing localization syntax based approach aids localization textit target object auxiliary supporting objects mentioned expression result , interpretable previous methods \( 1 \) determine referring expression points object image \( 2 \) track localization target object determined network study property empirically introducing new set annotations dataset evaluate localization supporting objects experiments show achieves state art accuracy identifying supporting objects , maintaining comparable performance localization target objects
model insider threats assess optimum number rules rules , , policies basis society used coordinate activities individuals variety goals purposes history \( many rules \) makes difficult compete \( rules \) lead implies optimal number rules two rules create boundaries define latitude individual perform activities paper creates toy model work environment examines respect latitude provided normal individual latitude provided insider threat simulations toy model illustrate four regimes respect insider threat , possibly optimal , point , regimes depend number rules \( n \) minimum latitude \( \) required normal individual carry activities toy model mapped onto standard 1d model theoretical physics behavior observed allows toy model generalized wide array complex models well studied theoretical physics community also show behavior finally , estimating n possible determine regime particular environment
bilingual gan step towards parallel text generation latent space based gan methods attention based sequence sequence models achieved impressive results text generation unsupervised machine translation respectively leveraging two domains , propose adversarial latent space based model capable generating parallel sentences two languages translating bilingual generation goal achieved sampling latent space shared languages first two denoising autoencoders trained , shared encoders back translation enforce shared latent state two languages decoder shared two translation directions next , gan trained generate synthetic code mimicking shared latent space code fed decoder generate text either language perform experiments datasets , english language pair , document performance using supervised unsupervised machine translation
performance trade uplink downlink full duplex communications paper , formulate two multi objective optimization problems \( \) orthogonal frequency division multiple access \( ofdma \) based band full duplex \( \) wireless communications aim study exploit performance trade uplink downlink wireless radio simultaneously receives frequency consider maximizing system throughput first minimizing system aggregate power consumption second uplink downlink , taking account impact self interference \( \) quality service study throughput transmit power trade uplink downlink via solving two problems non convex mixed integer non linear programming \( \) generally intractable order circumvent difficulty , penalty function introduced reformulate problem mathematically tractable form subsequently , transformed single objective optimization problem \( \) via weighted method addressed minimization \( mm \) approach simulation results demonstrate interesting trade considered competing objectives
fair kernel regression via fair feature embedding kernel space recent years , significant efforts mitigating demographic biases machine learning methods however , little done kernel methods paper , propose new fair kernel regression method via fair feature embedding \( f 2 e \) kernel space motivated prior works feature selection kernel space feature processing fair machine learning , propose learn fair feature embedding functions minimize demographic discrepancy feature distributions kernel space compared state art fair kernel regression method several baseline methods , show f 2 e achieves significantly lower prediction disparity across three real world data sets
pulse shaped ofdm 5g systems ofdm based filtering functionalities considered key flexible interface design multi service support future 5g systems one candidate category pulse shaped ofdm , follows idea filtering aims fully maintaining advantages standard ofdm systems addressing drawbacks paper , elaborate several pulse shaping design methods , show pulse shapes exploited additional degree freedom provide better frequency localization efficient spectrum utilization pre defined spectrum mask performance analysis evaluation results show , practical mobile communication systems , application pulse shaping simple effective means achieve lower band leakage ofdm systems virtually costs fact , complexity increase amounts 1 2 compared cp ofdm addition , system robustness time frequency distortions shown substantially improved proper pulse shape design allowing flexible configuration physical layer parameters per according diverse requirements future 5g services , pulse shaped ofdm systems efficiently facilitate asynchronous transmissions spectrum access , rendering beneficial various mobile internet things applications index terms ofdm , pulse shaping , multi , filter corresponding author , com x iv 1 60 5 2 cs 3 0 2 6
graph based selective outlier ensembles ensemble technique characterized mechanism generates components mechanism combines common way achieve consensus enable component equally aggregation process problem approach poor components likely negatively affect quality consensus result address issue , alternatives explored literature build selective classifier cluster ensembles , subset components contributes computation consensus family ensemble methods , outlier ensembles least studied recently , selection problem outlier ensembles discussed work define new graph based class ranking selection methods method class characterized two main steps \( 1 \) mapping rankings onto graph structure \( 2 \) mining resulting graph identify subset rankings define specific instance graph based ranking selection class specifically , map problem selecting ensemble components onto mining problem graph extensive evaluation conducted variety heterogeneous data methods empirical results show approach outperforms state art selective outlier ensemble techniques
less zero shot learning online textual documents noise suppression classifying visual concept merely associated online textual source , wikipedia article , attractive research topic zero shot learning burden manually collecting semantic attributes several recent works approach exploring various ways connecting visual text domains paper idea consider one important factor textual representation usually noisy zero shot learning application consideration motivates us design simple effective zero shot learning method capable noise text r n specifically , propose l 2 , 1 norm based objective function simultaneously noisy signal text learn function match text document visual features also develop optimization algorithm efficiently solve resulting problem experiments two large datasets , demonstrate proposed method significantly outperforms competing methods rely online information sources without explicit noise suppression make depth analysis proposed method provide insight kind information documents useful zero shot learning
computing matched filter linear time fundamental problem wireless communication time frequency shift \( \) problem find time frequency shift signal noisy environment shift result time sender receiver , non zero speed sender respect receiver classical solution discrete analog problem called matched filter algorithm uses pseudo random \( \) length p , arithmetic complexity \( p 2 cdot log \( p \) \) , using fast fourier transform introduce novel approach designing new allow faster matched filter algorithm use techniques group representation theory design \( \) , enable us introduce two fast matched filter \( \) algorithms , called algorithm , cross algorithm methods solve problem \( p cdot log \( p \) \) operations discuss applications algorithms mobile communication , gps ,
generating high quality random numbers high throughput parallel approach work , employing data representation building blocks algorithms , showcase capability scalability proposed method variety prng methods category block stream demonstrating suitability stream high throughput prng , example , implement investigate 2 0 prng paradigm internal functions data structure based \( linear feedback shift \) nature prng implementation perfectly gpu 's many core structure due oriented architecture allows usage bit technique improve performance simd fully parallel gpu implementation , gpu capable generating remarkable number 32 pseudo random bits clock cycle compare implementation significant satisfactory performance throughput randomness criteria proposed implementation successfully nist test statistical randomness bit wise correlation criteria best best knowledge , method outperforms current best implementations literature computer based prng optical solutions terms performance performance per cost , maintaining acceptable measure randomness highest performance among implemented proposed method achieved 2 0 algorithm shows 1 improvement state art nvidia 's high performance prng , library , achieving 1 6 throughput nvidia
practical prediction human movements across device types spatiotemporal understanding predicting mobility essential design evaluation future mobile edge caching networking consequently , research prediction human mobility drawn significant attention last decade employing information theoretic concepts machine learning methods , earlier research shown evidence human behavior highly predictable r n despite existing studies , needed capture intrinsic mobility characteristics constraining predictability , explore dimensions \( e g device types \) spatio temporal , especially change human behavior technology analyze extensive datasets fine spatial granularity \( ap level \) covering 16 study reveals device type important factor affecting predictability ultra devices smartphones go mode usage \( hence dubbed \) , whereas use \( dubbed \) r n goal study investigate practical prediction mechanisms quantify predictability aspect human mobility modeling , across time , space device types apply systematic analysis wireless traces large university compare several algorithms using varying degrees temporal spatial granularity two modes devices vs analysis , quantify mobility less predictable mobility addition , pattern consistent across various spatio temporal , different methods \( markov chains , neural networks deep learning , entropy based estimators \) work importance predictability essential aspect human mobility , direct application predictive caching , user behavior modeling mobility simulations
learning understanding supporting devops artifacts docker growing use devops tools frameworks , increased need tools techniques support code current state art static assistance tools like docker limited shallow syntactic validation identify three core challenges learning , understanding , supporting developers writing devops artifacts \( \) nested languages devops artifacts , \( ii \) rule mining , \( iii \) lack semantic rule based analysis address challenges introduce , , enabled us , 000 github repositories r n focusing docker , extracted approximately , 000 unique dockerfiles , also identified gold set dockerfiles written docker experts addressed challenge \( \) reducing number effectively nodes 80 via technique call parsing address challenge \( ii \) , introduced novel rule mining technique capable recovering two rules benchmark curated automated mining , able recover 16 new rules found manual rule collection address challenge \( iii \) , manually collected set rules dockerfiles files gold set rules best practices , avoid docker build failures , improve image size build latency created used rules , found , average , dockerfiles github rules five times frequently dockerfiles gold set also found industrial dockerfiles better sourced github r n learned rules used aid developers creating dockerfiles , post hoc fashion identify issues , improve , existing dockerfiles
modeling analysis scma enhanced d2d cellular hybrid network sparse code multiple access \( scma \) recently proposed future wireless networks , allows spectrum resource sharing enables system paper , apply scma device device \( d2d \) communication cellular hybrid network , targeted using overload feature scma support massive device connectivity expand network capacity particularly , develop stochastic geometry based framework model analyze scma , considering modes based results , analytically compare scma orthogonal frequency division multiple access \( ofdma \) using area spectral efficiency \( \) quantify closed form gain scma ofdma notably , shown system significantly improved using scma gain scales linearly scma codeword dimension besides , d2d users probability balance cross tier interference mode derive optimal probability meanwhile , study resource allocation mode obtain optimal codebook allocation rule interestingly found optimal scma codebook allocation rule independent cellular network parameters cellular users densely deployed results helpful implementation scma hybrid system
x search private web search using intel exploitation user search queries search engines heart economic model consequence , offering private web search functionalities essential users care privacy nowadays , exists satisfactory approach enable users access search engines privacy preserving way existing solutions either costly due heavy use mechanisms \( e g , private information retrieval protocols \) , subject attacks \( e g , , , \) rely weak adversarial models \( e g , \) paper introduces x , novel private web search mechanism building software extensions \( \) proposed intel compare x closest competitors , , using dataset real web search queries evaluation shows \( 1 \) x offers stronger privacy guarantees competitors stronger adversarial model \( 2 \) better state art identification attacks \( 3 \) performance perspective , x outperforms competitors terms latency throughput orders magnitude
snippets taxonomy web search engines paper authors analyzed 50 000 keywords results collected localized google search engine proposed taxonomy snippets search results regular , rich , news , entity types snippets observed correlations overlapping snippets keywords results show commercial keywords cause results rich entity types snippets , whereas keywords resulting snippets commercial nature found significant number snippets scholarly articles rich conclude findings conclusion research limitations
robust positioning patterns low redundancy robust positioning pattern large array allows mobile device locate position reading possibly corrupted small window around paper , provide constructions binary positioning patterns , equipped efficient algorithms , robust constant number errors redundancy within constant factor optimality furthermore , constructions correct rank errors obtain binary positioning patterns robust errors rank less constant number additionally , construct q ary robust positioning sequences robust large number errors , length upper bound r n construction binary positioning sequences robust constant number errors least known redundancy explicit constructions efficient algorithms hand , binary robust positioning arrays , construction first explicit construction whose redundancy within constant factor optimality algorithms constructions run time cubic sequence length array dimension
get assembly verification oriented lifting formal methods software development made great last two decades , point application safety critical embedded software success extension non critical software one challenges example , c use assembly low level optimizations system primitives usually results driving state art formal developed c thus propose , automated , generic , verification oriented lifting technique assembly semantically equivalent c code , order take advantage existing c extensive experiments real world c code assembly \( including \) show feasibility benefits
neural networks forgetting spurious pure ones standard model associative neural networks accounts biological learning acts harmonic pattern recognition , however maximal storage capacity alpha sim 0 14 , far theoretical bound symmetric networks , e alpha 1 inspired mechanisms , propose extension model standard line \( awake \) learning mechanism \( allows storage external information terms patterns \) line \( sleep \) mechanism \( allows spurious pattern removal pure pattern reinforcement \) obtained daily able theoretical bound alpha 1 , remaining also extremely robust thermal noise neural features analyzed analytically numerically particular , beyond obtaining phase neural dynamics , focus give explicit temporal evolution matrix analytically prove algorithm makes kernel converge high probability projection matrix built pure stored patterns furthermore , obtain sharp explicit estimate sleep rate order ensure convergence finally , run extensive numerical simulations \( mainly monte carlo sampling \) check approximations underlying analytical \( e g , developed whole theory called symmetric level , standard reference framework \) possible finite size effects , finding overall full agreement theory
correct k means clustering recently , arxiv introduced new type algorithm \( called correct algorithm \) combines fast solvers optimality provided convex relaxations paper , devise algorithm problem k means clustering first , prove 's semidefinite relaxation k means tight high probability distribution clusters called stochastic ball model proof follows new dual integral solutions semidefinite program next , show test optimality proposed k means solution using dual time finally , analyze version spectral clustering designed solve k means case two clusters particular , show time method typically recovers clusters stochastic ball model
bayesian approach online classifier ensemble propose bayesian approach recursively estimating classifier weights online learning classifier ensemble contrast past methods , stochastic gradient descent online boosting , approach estimates weights recursively updating posterior distribution specified class loss functions , show possible formulate suitably defined likelihood function hence use posterior distribution approximation global empirical loss stream training data sampled stationary process , also show approach admits superior rate convergence expected loss possible standard stochastic gradient descent experiments real world datasets , formulation often performs better state art stochastic gradient descent online boosting algorithms
mobile ambients modern society dependent distributed software systems verify different modelling languages mobile ambients developed analyse quality mobile ambients good model distributed computation , analyse level synchronisation distributed components express therefore , rely earlier established synchronisation patterns turns mobile ambients fully distributed , express enough synchronisation express synchronisation pattern called however , express strictly less synchronisation standard pi calculus reason , show good preserving encoding standard pi calculus mobile ambients also encoding mobile ambients join calculus , e , expressive power mobile ambients languages finally , discuss results used obtain fully distributed variant mobile ambients
uncertainty propagation deep neural networks using extended kalman filtering extended kalman filtering \( \) used quantify input uncertainty deep neural network \( dnn \) assuming mild hypotheses input distribution methodology yields results comparable existing methods uncertainty propagation dnns computational overhead considerably additionally , allows model error naturally incorporated output uncertainty
complex model dynamic epistemic logic fault tolerant distributed computing usual epistemic model multi agent systems graph , whose edges labeled agents distinguish two states propose uncover higher dimensional information implicit graph , using model dual , complex state model complex , one vertex per agent edge \( u , v \) labeled set agents , corresponding u v consisting one vertex agent use dynamic epistemic logic study complex epistemic model changes agents communicate show topological invariants preserved initial epistemic complex epistemic complex action model applied , depend reliable communication turn topological properties determine knowledge agents may gain communication
active robotic mapping deep reinforcement learning propose approach learning agents active robotic mapping , goal map environment quickly possible agent learns map efficiently simulated environments rewards corresponding fast constructs accurate map contrast prior work , approach learns exploration policy based user specified prior environment configurations sensor model , allowing specialize specifications evaluate approach simulated mapping scenario find achieves performance slightly better near optimal exploration scheme , suggesting could useful complicated problem scenarios
experiment design causal structure learning study problem causal structure learning limited perform k non adaptive experiments size 1 formulate problem finding best intervention target set optimization problem , aims maximize average number edges whose directions resolved prove objective function submodular greedy algorithm \( 1 frac 1 e \) approximation algorithm problem present accelerated variant greedy algorithm , lead orders magnitude performance speedup validate proposed approach synthetic real graphs results show compared purely setting , algorithm majority edges small number
control signal spoofing attack uav systems aerial vehicle \( uav \) system vulnerable control signal spoofing attack due wireless communications correspondence , physical layer approach proposed combat control signal spoofing attack , e , determine whether received control signal packet ground control station \( \) potential malicious attacker \( \) , need share secret key consider worst case uav prior knowledge utilizing channel feature arrival , distance based path loss , factor , construct generalized log likelihood radio \( \) test framework handle problem accurate approximations false successful detection rate provided efficiently evaluate performance
adaptive training correlated fading channels feedback consider data transmission time selective , correlated \( first order markov \) rayleigh fading channel subject average power constraint channel estimated receiver pilot signal , estimate fed back transmitter estimate used coherent , adapt data pilot powers derive \( \) equation optimal policy continuous time limit channel state diffusion process , estimated kalman filter receiver finding explicit solution equation , well proving \( differentiable \) solution exists , appears quite challenging however , assuming solution exist , explicitly determine optimal pilot data power control policies optimal pilot policy zero maximum \( peak constrained \) value \( control \) , approximates optimal discrete time policy low signal noise ratios \( \) \( , large \) boundary defined terms system state \( estimated channel mean associated error variance \) , explicitly computed optimal policy , transmitter power decreasing training power channel , thereby increasing data rate numerical results show significant increase achievable rate due adaptive training scheme feedback , relative constant \( \) training , require feedback gain relatively low fast fading results verified monte carlo simulations
neural population models present method using neural networks model evolutionary population dynamics , draw recent deep learning adversarially trained neural networks interactions conduct experiments demonstrate models evolutionary game theory capable describing behavior neural population systems
improving overhead computation pre processing times grid scheduling system computational grid enormous environments heterogeneous resources stable among internet based computing systems however , managing resources systems special problems scheduler systems need get last information nodes information centers purpose job scheduling paper , focus online updating resource information centers processed provided data based assumed hierarchical model hybrid knowledge extraction method used classifying grid nodes based prediction features point research scheduler systems n't extra time getting date information grid nodes experimental result shows advantages approach compared conservative methods , especially due ability predict behavior nodes based comprehensive data tables node
semantic asset potential digital transformations industrial manufacturing domain led several reference frameworks numerous approaches hand , semantic web community made significant contributions field , instance data service description , integration heterogeneous sources devices , ai techniques distributed systems two streams work , however , mostly briefly regard others requirements , practices contribute gap providing semantic asset , based representation 4 0 component provide ontology latest data model specification , created mapping , supply resources validate entities introduce basic reasoning asset data model furthermore , discuss different assumptions presentation patterns , analyze implications semantic representation original data evaluate thereby created , conclude semantic lifting , also restricted embedded devices , therefore meets needs 4 0 scenarios
efficient convolution kernel implementation widely used mobile cpus class algorithms help reduce overall compute complexity many modern deep convolutional neural networks \( cnns \) although lot research done model algorithmic optimization cnn , little attention paid efficient implementation algorithms embedded cpus , usually limited memory low power budget paper aims gap focuses efficient implementation based convolution modern arm cortex cpus , widely used mobile devices today specifically , demonstrate reduction inference latency using set optimization strategies improve utilization computational resources , effectively leveraging simd instruction set evaluated proposed region wise multi channel implementations arm cortex platform using several representative cnns results show significant performance improvements full network , 60 , existing based optimization techniques
unsupervised anomaly detection generative adversarial networks guide discovery obtaining models capture imaging markers relevant disease treatment monitoring challenging models typically based large amounts data annotated examples known markers aiming automating detection high annotation effort limitation vocabulary known markers limit power approaches , perform unsupervised learning identify anomalies imaging data candidates markers propose , deep convolutional generative adversarial network learn manifold normal anatomical variability , novel anomaly scoring scheme based mapping image space latent space applied new data , model labels anomalies , scores image patches indicating fit learned distribution results optical coherence tomography images demonstrate approach correctly identifies anomalous images , images containing fluid
approximating minimum cycle mean consider directed graphs edge labeled integer weight study fundamental algorithmic question computing value cycle minimum mean weight contributions twofold \( 1 \) first show algorithmic question \( n 2 \) time problem logarithmic number min plus matrix n n matrices , n number vertices graph \( 2 \) second , weights nonnegative , present first \( 1 epsilon \) approximation algorithm problem running time algorithm tilde \( \) \( n omega log 3 \( epsilon \) epsilon \) , \( n omega \) time required classic n n matrix multiplication w maximum value weights
collaborative synchronized multi device taking picture traditionally one task paper present novel system allows multiple mobile devices work synchronized fashion capture highly dynamic scene , creating entirely new experience social interactions system contains two components client app runs participating devices , server program device capturing session , server collects images devices fly create , devices visual guidance system also allows one camera host send direct visual instructions others guide camera adjustment , devices take pictures time preliminary study suggests proposed system help users capture high quality experience r n video system action provided http url
efficient approximation algorithm steiner tree problem steiner tree problem one classic fundamental mathcal np hard problems given arbitrary weighted graph , seek minimum cost tree spanning given subset vertices \( terminals \) emph et al proposed 1 epsilon approximation algorithm linear program solved every iteration component emph et al shown possible achieve approximation guarantee solving lp relaxation however , optimizing lp relaxation exactly strongly np hard article presents efficient two phase heuristic greedy strategy achieves approximation ratio 1
high dimensional robust estimation arbitrary corruption heavy consider problem sparsity constrained estimation explanatory response variables heavy \( bounded 4 th moments \) , fraction arbitrary focus k sparse , high dimensional regime number variables sample size n related n sim k log define natural condition call robust descent condition \( rdc \) , show gradient estimator satisfies rdc , robust hard thresholding \( using gradient estimator \) , guaranteed obtain good statistical rates contribution paper showing rdc flexible enough concept recover known results , obtain new robustness results specifically , new results include \( \) k sparse high dimensional linear logistic regression heavy tail \( bounded 4 th moment \) explanatory response variables , linear time computable median means gradient estimator satisfies rdc , hence robust hard thresholding optimal \( b \) instead heavy \( 1 sqrt k log \( \) \) fraction arbitrary explanatory response variables , near linear time computable gradient estimator satisfies rdc , hence robust hard thresholding optimal demonstrate effectiveness approach sparse linear , logistic regression , sparse precision matrix estimation synthetic real world us data
enhancing evolutionary conversion rate optimization via multi armed bandit algorithms conversion rate optimization means designing web interfaces perform desired action \( purchase \) site one promising approach , implemented , optimize design using evolutionary algorithms , evaluating candidate design online actual evaluations costly noisy , several challenges available traffic used efficiently \? good solutions identified reliably \? high conversion rate maintained optimization \? paper proposes new technique address issues traffic allocated candidate solutions using multi armed bandit algorithm , using traffic evaluations useful best arm identification mode , best candidate identified reliably end evolution , campaign mode , overall conversion rate optimized entire evolution process multi armed bandit algorithms thus improve performance reliability machine discovery noisy real world environments
swedish perspective software development software engineering core society ill decisions major consequences , made 2017 , data caused deal made swedish many \( \) rapidly digital transition , thus important overview widespread , , software development part public present software development swedish , complemented document analysis survey show 39 2 develop software internally , matching number developers large companies findings suggest development largely private counterparts , established best practices implemented still , identify improvement potential areas strategic , , collaboration across , quality requirements swedish new next year , hope software engineering community contribute clear voice
personal semantic web space based computing environment semantic web technologies support canonical representation information presenting users method meaning understood least interpreted parties semantic web computing platform rather information platform dynamic structures , interactions evolve leading systems dynamic semantic web
folding holes cube piece paper unit cube \? prior work studied tree like , holes remain open problem present sufficient conditions one several holes fold cube , conditions cube folding impossible particular , show five special emph simple holes guarantee
internet things infrastructure secure smart healthcare authors propose , infrastructure flexible , cost effective , secure , privacy preserving deployment internet things systems smart healthcare applications services
spectral compressed sensing via structured matrix completion paper studies problem recovering sparse object small number time domain samples specifically , object interest ambient dimension n assumed mixture r complex multi dimensional , underlying assume value unit disk conventional compressed sensing paradigms suffer em basis mismatch issue imposing discrete dictionary fourier representation address problem , develop novel nonparametric algorithm , called enhanced matrix completion \( \) , based structured matrix completion algorithm starts data low rank enhanced form multi fold hankel structure , attempts recovery via norm minimization mild incoherence conditions , allows perfect recovery number samples exceeds order mathcal \( r log 2 n \) also show , many instances , accurate completion low rank multi fold hankel matrix possible number observed entries proportional information theoretical limits \( except logarithmic gap \) robustness bounded noise applicability super resolution demonstrated numerical experiments
mobile robots global communication model problem graphs asks k leq n robots placed initially arbitrarily nodes n node anonymous graph autonomously reach configuration robot distinct node graph problem significant interest due relationship fundamental robot coordination problems , exploration , , load balancing etc paper , consider em global communication model robot communicate robot graph \( graph unknown robots \) provide three novel deterministic algorithms , two arbitrary graphs one arbitrary trees , synchronous setting robots perform actions every time step arbitrary graphs , first algorithm based traversal guarantees \( min \( , k delta \) \) steps runtime using theta \( log \( max \( k , delta \) \) \) bits robot , number edges delta maximum degree graph second algorithm arbitrary graphs based traversal guarantees \( max \( , k \) delta \( delta \) \) steps runtime using \( max \( , delta log k \) \) bits robot , diameter graph algorithm arbitrary trees also based guarantees \( max \( , k \) \) steps runtime using \( max \( , delta log k \) \) bits robot results significant improvements compared existing results established em local communication model robot communication robots present node particularly , based algorithm optimal memory time constant degree arbitrary graphs based algorithm arbitrary trees optimal respect runtime k leq \( \)
complexity k synchronization show complexity function p x \( n \) , counts number distinct factors length n sequence x , k synchronized sense x k automatic application , generalize recent results give analogous results number distinct factors length n primitive words powers contrast , show function counts number factors length n necessarily k synchronized k automatic sequences
motion planning irreducible path spaces motion mechanical system defined path configuration space computing path computational complexity scaling exponentially dimensionality configuration space propose reduce dimensionality configuration space introducing irreducible path path minimal volume paper consists three parts part , define space irreducible paths show planning path irreducible path space preserves completeness motion planning algorithm part ii , construct approximation irreducible path space kinematic chain certain assumptions part iii , conduct motion planning using irreducible path space mechanical environment , mechanical eight arms system motion humanoid robot moving room demonstrate concept irreducible path applied motion planning algorithm taking curvature constraints account
exploiting n best hypotheses improve smt approach grammatical error correction grammatical error correction \( gec \) task detecting correcting grammatical errors texts written second language learners statistical machine translation \( smt \) approach gec , sentences written second language learners translated correct sentences , achieved state art accuracy however , smt approach unable utilize global context paper , propose novel approach improve accuracy gec , exploiting n best hypotheses generated smt approach specifically , build classifier score n best hypotheses classifier used select appropriate rank n best hypotheses apply methods state art gec system uses smt approach experiments show methods achieve statistically significant improvements accuracy best published results benchmark test dataset gec
full duplex cognitive radio networks traditional cognitive radio networks , secondary users \( \) typically access spectrum primary users \( \) two stage \( \) protocol , e , sense spectrum holes first stage transmit second stage paper , propose novel \( lat \) protocol help full duplex \( fd \) technique allows simultaneously sense access spectrum analysis sensing performance su 's throughput given proposed lat protocol find due self interference caused fd , increasing transmitting power always benefit su 's throughput , implies existence power throughput tradeoff besides , though lat protocol suffers self interference , allows longer transmission time , performance traditional protocol limited channel spatial correction relatively transmission period end , also present adaptive scheme improve throughput lat protocols numerical results provided verify proposed protocol theoretical results
emergence evolution research fronts hiv aids research paper , identified analyzed emergence , structure dynamics research fronts established biomedical knowledge hiv aids search papers hiv aids , human , hiv 1 acquired web science \( \) , carried citation network papers constructed , sub network papers highest number inter citations \( minimal degree \) selected perform combination network clustering text mining identify research fronts analyze dynamics research fronts identified sub network front related clinical knowledge disease patient nine fronts related study specific molecular structures mechanisms two fronts related development rest fronts related study disease cellular level interestingly , emergence fronts successive time suggest transition focus emergence evolution biomedical fronts hiv aids research explained partition problem elements interactions leading increasingly specialized communities , also changes technological context health problem changes reality hiv aids
big scores let correlation coefficients fool metrics provide alternative way evaluating scholarly journals based iterative ranking procedure analogous google 's pagerank algorithm metrics recently adopted impact factor journal citation reports metrics differ sufficiently useful addition \? \( \) otherwise , based finding 0 95 correlation coefficient score total citations sample journals field medicine conclusion illustrate basic statistical provide complete analysis 2006 journal citation reports demonstrate statistically significant differences information provided metrics provided impact factor total citations
deep stacked hierarchical multi patch network image deblurring despite deep end end learning methods shown superiority removing non uniform motion blur , still exist major challenges current multi scale scale recurrent models 1 \) operations coarse fine scheme result expensive runtime 2 \) simply increasing model depth finer scale levels cannot improve quality deblurring tackle problems , present deep hierarchical multi patch network inspired spatial matching deal images via fine coarse hierarchical representation deal performance saturation w r depth , propose stacked version multi patch model proposed basic multi patch model achieves state art performance dataset faster runtime compared current multi scale methods process image resolution , first real time deep motion deblurring model images stacked networks , significant improvements \( 1 \) achieved dataset increasing network depth moreover , varying depth stacked model , one adapt performance runtime network different application scenarios
interactive segmentation medical images fully convolutional neural networks image segmentation plays essential role medicine tasks segmentation approaches either manual , semi automated fully automated manual segmentation offers full control quality results , , time consuming prone operator bias fully automated methods require human effort , often deliver sub optimal results without providing users means make corrections semi automated approaches keep users control results providing means interaction , main challenge offer good trade precision required interaction paper present deep learning \( dl \) based semi automated segmentation approach aims smart interactive tool region interest medical images demonstrate use segmenting multiple computed tomography \( ct \) approach solves clinical challenges \( \) requires one user deliver excellent 2d segmentations fast reliable fashion \( ii \) generalize previously unseen structures cases \( iii \) results quickly smart intuitive way arbitrary degree precision chosen user \( iv \) ensures high accuracy present approach compare techniques previous work show advantages brought method
massive access beyond 5g iot networks noma np hardness learning paper studies problem online user grouping , scheduling power allocation beyond 5g cellular based internet things networks due massive number devices trying network , non orthogonal multiple access method adopted order accommodate multiple devices radio resource block different previous works , objective maximize number served devices transmission powers real time requirements well limited operating energy first , formulate general problem mixed integer non linear program \( \) transformed easily special cases second , study computational complexity characterizing np hardness different special cases , problem multiple noma grouping scheduling subproblems , efficient online competitive algorithms proposed , show use online algorithms combine solutions reinforcement learning setting obtain power allocation hence global solution problem analysis simulation results illustrate performance proposed algorithms comparison optimal state art methods
spatial outage capacity wireless networks address fundamental question wireless networks , surprisingly , studied maximum density active links satisfy certain outage constraint \? call quantity spatial outage capacity \( soc \) , give rigorous definition , analyze poisson networks aloha specifically , provide exact analytical approximate expressions density links satisfying outage constraint give simple upper lower bounds soc high reliability regime target outage probability close zero , obtain exact closed form expression soc , reveals interesting counter intuitive result transmitters need always active achieve soc , e , transmit probability needs set 1 achieve soc
view ranking image rank based learning deep neural network widely used image however , performance ranking based methods often poor mainly due two reasons 1 \) image ranking task rather pairwise comparison 2 \) caused pooling layer view generation damage performance composition learning paper , develop novel model overcome problems address first problem , formulate image ranking problem find best view composition second problem , refined view sampling \( called \) proposed extract refined feature maps candidate view generation given series candidate views , proposed model learns top 1 probability distribution views best one integrating refined sampling ranking , proposed network called achieves state art performance accuracy speed
approximation algorithms submodular partition study algorithms submodular partition problem \( submp \) instance submp consists finite ground set v , subset k elements 1 , 2 , , k called terminals , non negative submodular set function f 2 v rightarrow mathbb r v provided value oracle goal partition v k sets 1 , , k 1 le le k , sum 1 k f \( \) submp generalizes well known problems cut problem graphs hypergraphs , node cut problem graphs submp functions \( instead symmetric functions \) considered , cite previous algorithms based greedy splitting strategies recent work cite proposed convex programming relaxation submp based extension submodular function showed applicability special cases paper obtain following results arbitrary submodular functions via relaxation \( \) 2 approximation submp improves \( k 1 \) approximation cite \( ii \) \( 1 5 1 k \) approximation submp f symmetric improves 2 \( 1 1 k \) approximation cite ,
joint channel estimation nonlinear distortion ofdm receivers nonlinear distortion power \( pa \) significantly degrade performance orthogonal frequency division \( ofdm \) communication systems paper presents joint maximum likelihood channel frequency response nonlinear pa model estimator ofdm signals derivation estimator based series representation power nonlinearity suitable wide range memoryless pa models sub optimal decision aided algorithm adaptive nonlinear distortion effects receiver side also presented shown proposed algorithms used g p wireless receivers without modifications transmitter side performance proposed algorithms studied means computer simulation
user preferences modeling learning photo generation paper consider automatically create photo collages created set images limited area task formulated optimization problem differently existing state art approaches , exploit subjective experiments model learn user preferences end , design experimental framework identification criteria need taken account generate photo five different photo datasets used create collages using state art criteria first subjective experiment several subjects evaluated collages , different criteria involved subjective definition identify new global local criteria design algorithms quantify relative importance criteria automatically learned exploiting user preferences , new collages generated validate framework , performed several visual experiments involving different users results shows proposed framework allows learn novel computational model effectively inter user definition learned definition generalizes well new photo datasets different sizes used learning moreover , compared two state art approaches , collages created using framework majority users
ice segmentation deep learning paper deals problem computing surface ice concentration two different types ice ice images presents results solve problem using several state art semantic segmentation methods based deep convolutional neural networks \( cnns \) task presents two main challenges limited availability labeled training data great difficulty visually distinguishing two types ice , even humans , leading noisy labels results used analyze extent best deep learning methods currently existence handle challenges
delay synchronous sgd large scale decentralized neural network training data parallelism become de facto standard training deep neural network multiple processing units work propose , decentralized \( without parameter server \) synchronous version delay asynchronous stochastic gradient descent \( \) algorithm approach , allow computation communication , compensate inherent error first order correction gradients prove effectiveness approach training convolutional neural network large achieving state art results
finding patterns knowledge base using keywords compose table answers aim provide table answers keyword queries knowledge bases queries referring multiple entities , like cities population movies , better represent relevant answer table aggregates set entities entity joins within table scheme pattern paper , study find highly relevant patterns knowledge base user given keyword queries compose table answers knowledge base modeled directed graph called knowledge graph , nodes represent entities knowledge base edges represent relationships among node edge labeled type text pattern aggregation contain keywords texts structure types node edges propose efficient algorithms find patterns relevant query class scoring functions show hardness problem theory , propose path based indexes memory two query processing algorithms proposed one fast practice small queries \( small patterns answers \) utilizing indexes one better theory , running time linear sizes indexes answers , handle large queries better also conduct extensive experimental study compare approaches naive known techniques
impact exponent parameter value partition matrix performance fuzzy c means algorithm soft clustering plays important rule clustering real world data data item contributes one cluster fuzzy logic based algorithms always suitable performing soft clustering tasks fuzzy c means \( fcm \) algorithm popular fuzzy logic based algorithm case fuzzy logic based algorithm , parameter like exponent partition matrix clustering task plays important rule performance algorithm paper , experimental analysis done fcm algorithm observe impact parameter performance algorithm
provably acceleration gradient descent applications matrix sensing present theoretical results convergence emph non convex accelerated gradient descent matrix factorization models ell 2 norm loss purpose work study effects acceleration non convex settings , provable convergence acceleration considered emph de facto property technique applied matrix sensing problems , estimation rank r optimal solution x star mathbb r n times n contributions follows \) show acceleration gradient descent linear rate fact novel non convex matrix factorization settings , common assumptions ii \) proof technique requires acceleration parameter carefully selected , based properties problem , condition number x star condition number objective function iii \) currently , proof leads dependence condition number \( \) parameter , similar recent results non accelerated algorithms iv \) acceleration observed practice , synthetic examples two real applications multi unit activities recovery single , quantum state tomography quantum computing simulators
large scale scene completion semantic segmentation 3d scans introduce , novel data driven approach taking incomplete 3d scan scene input predicting complete 3d model along per semantic labels key contribution method ability handle large scenes varying spatial extent , managing cubic growth data size scene size increases end , devise fully convolutional generative 3d cnn model whose filter kernels invariant overall scene size model trained scene deployed arbitrarily large scenes test time addition , propose coarse fine inference strategy order produce high resolution output also leveraging large input context sizes extensive series experiments , carefully evaluate different model design choices , considering deterministic probabilistic models completion semantic inference results show outperform methods size environments processing efficiency , also regard completion quality semantic segmentation performance significant margin
facial expressions analysis occlusions based facial motion propagation although much progress made facial expression analysis field , facial occlusions still challenging main innovation brought contribution consists exploiting facial movement propagation recognizing expressions presence important occlusions movement induced expression extends beyond movement thus , movement occurring occluded region propagates towards neighboring visible regions presence occlusions , per expression , compute importance facial region construct adapted facial frameworks boost performance per expression binary classifier output expression binary classifier fed fusion process aims constructing , per occlusion , unique model facial expressions considered evaluations highlight robustness approach presence significant facial occlusions
bilinear recovery using adaptive vector consider problem jointly recovering vector band matrix c noisy measurements \( b \) c w , \( \) known affine linear function b \( e , \( b \) n 0 n n 1 n q n b n n n n known matrices n n \) problem applications matrix completion , robust pca , dictionary learning , self calibration , blind , joint channel symbol estimation , compressive sensing matrix uncertainty , many tasks solve bilinear recovery problem , propose bilinear adaptive vector approximate message passing \( \) algorithm demonstrate numerically proposed approach competitive state art approaches bilinear recovery , including lifted bilinear generalized approximate message passing
multi antenna cooperative wireless systems diversity multiplexing tradeoff perspective consider general multiple antenna network multiple sources , multiple destinations multiple relays terms diversity multiplexing tradeoff \( dmt \) examine several general problem taking account processing capability relays \( half duplex full duplex \) , network geometry \( clustered non clustered \) first study multiple antenna relay channel full duplex relay understand effect increased degrees freedom direct link find dmt upper bounds investigate achievable performance decode forward \( df \) , compress forward \( cf \) protocols results suggest df dmt optimal terminals one antenna , may maintain good performance degrees freedom direct link increased , whereas cf perform optimally also study multiple antenna relay channel half duplex relay show half duplex dmt behavior significantly different full duplex case find cf dmt optimal half duplex relaying well , first protocol known achieve half duplex relay dmt next study multiple access relay channel \( \) dmt finally , investigate system single source destination pair multiple relays , node single antenna , show even assumption full duplex relays clustered network , virtual multi input multi output \( mimo \) system never fully mimic real mimo dmt cooperative systems multiple sources multiple destinations limitation remains effect
mixmatch holistic approach semi supervised learning semi supervised learning proven powerful paradigm leveraging unlabeled data mitigate large labeled datasets work , current dominant approaches semi supervised learning produce new algorithm , mixmatch , works low entropy labels data augmented unlabeled examples mixing labeled unlabeled data using show mixmatch obtains state art results large margin across many datasets labeled data amounts example , cifar 10 labels , reduce error rate factor 4 \( 11 \) factor 2 10 also demonstrate mixmatch help achieve dramatically better accuracy privacy trade differential privacy finally , perform ablation study components mixmatch important success
pbe cc congestion control via centric physical layer bandwidth measurements wireless networks becoming ever sophisticated , imposing delay , , throughput damage end end network flows today 's internet therefore argue fine grained mobile based wireless measurements inform precise congestion control algorithm well defined mobile 's wireless physical layer proposed congestion control algorithm based physical layer bandwidth measurements taken \( pbe cc \) , captures latest 5g new radio increase wireless capacity , yet create abrupt available wireless capacity pbe cc sender precisely rapidly implement proof concept prototype pbe measurement module software defined pbe sender receiver c extensive performance evaluation compares pbe cc head head leading cellular aware wireless oblivious congestion control protocols proposed research community deployment , mobile static mobile scenarios , busy networks results show 6 3 higher average throughput , simultaneously reducing delay 1 8x
optimal price anarchy cost sharing games design distributed algorithms central study multiagent systems control paper , consider class combinatorial cost minimization problems propose framework designing distributed algorithms priori performance guarantees near optimal approach problem game theoretic perspective , assigning agents cost functions equilibrium efficiency \( price anarchy \) optimized agents' cost functions specified , algorithm capable computing nash equilibrium system performance guarantee matching price anarchy towards goal , formulate problem computing price anarchy tractable linear program present framework designing agents' local cost functions order optimize worst case equilibrium efficiency finally , investigate implications findings framework applied systems convex , costs
vertex cover beyond vertex cover \( \) problem , given graph g , positive k ell , two vertex covers g size k , determine whether transformed sequence ell vertex every operation results vertex cover size k motivated results establishing w 1 hardness parameterized ell , complexity problem restricted various graph classes particular , show remains w 1 hard bipartite graphs , np hard fixed parameter tractable \( regular \) graphs bounded degree , solvable polynomial time trees \( additional restrictions \) graphs
accurate reconstruction finite rate innovation signals sphere develop method accurate reconstruction non bandlimited finite rate innovation signals sphere signals consisting finite number functions sphere , develop filter based method accurate recovery parameters functions using finite number observations bandlimited signal comparison existing techniques , proposed method enables accurate reconstruction primarily due better conditioning systems involved recovery parameters recovery k sphere , proposed method requires samples signal bandlimited harmonic \( \) domain degree equal greater k sqrt k frac 1 4 frac 1 2 comparison existing state art technique , required , consequently number samples , proposed method less also conduct numerical experiments demonstrate proposed technique accurate existing methods factor 10 7 2 le k le 20
temporal localization moments video collections natural language paper , introduce task relevant video moments large corpus , videos given natural language query task poses unique challenges system must efficiently identify relevant videos localize relevant moments videos task contrast prior work relevant moments single video searches large collection already segmented videos task , introduce alignment language \( \) , model features natural language query sequence short video compose candidate moment video approach goes beyond prior work aggregates video features candidate moment allowing finer alignment moreover , approach efficient resulting level representations , makes suitable moment localization large video collections evaluate approach three recently proposed datasets temporal localization moments video natural language extended video corpus moment retrieval setting , , show model outperforms recently proposed moment context network \( \) criteria across datasets proposed task , obtaining 8 11 boost average recall median rank , respectively , achieves 5x faster retrieval 8x smaller index size video corpus
nonlinear distortion reduction ofdm reliable perturbations data novel method correcting effect nonlinear distortion orthogonal frequency division multiplexing signals proposed method depends adaptively selecting distortion subset data , using tools compressed sensing sparse bayesian recovery estimate distortion central method fact \( \) decoded different levels confidence , depending coupled function magnitude phase distortion , addition respective channel strength moreover , required method , significant improvement terms achievable rate achieved relative previous work
multi channel hybrid access stochastic geometric analysis two tier networks consisting , channel access mechanism open access , closed access , hybrid access hybrid access arises compromise open closed access mechanisms , fraction available spectrum resource shared remaining paper focuses hybrid access mechanism multi channel employ orthogonal spectrum access schemes considering randomized channel assignment strategy , analyze performance downlink using stochastic geometry technical tools , model distribution poisson point process neyman cluster process derive distributions signal interference plus noise ratios , mean achievable rates , established expressions numerical evaluation , shed key insights performance tradeoff analytical results numerical simulations
learning good representation via continuous attention paper present scientific discovery good representation learned via continuous attention interaction unsupervised learning \( ul \) reinforcement learning \( rl \) modules driven intrinsic motivation specifically , designed intrinsic rewards generated ul modules driving rl agent focus objects period time learn good representations objects later object recognition task evaluate proposed algorithm without extrinsic reward settings experiments end end training simulated environments applications shot object recognition demonstrated effectiveness proposed algorithm
unsupervised transfer traditional methods chinese synthesis view characters assembly radicals , rely manual definition key points , still time recent work computer vision proposes new approach treat every chinese character independent image , pre processing post processing character combination transfer network network , one well another despite quite satisfying performance model , training process requires supervised , means training data character source domain target domain needs perfectly paired sometimes pairing time , sometimes perfect pairing , pairing traditional chinese simplified chinese characters paper , proposed unsupervised transfer method n't need pairing
deep active learning long tail paper pool based active learning deep neural networks motivated dataset compression ideas , present novel active learning algorithm queries consecutive points pool using first space neural activation representation layer show consistent improvement sample complexity passive learning \( random sampling \) three datasets mnist , cifar 10 , cifar 100 addition , algorithm outperforms traditional uncertainty sampling technique \( obtained using softmax activations \) , identify cases uncertainty sampling slightly better random sampling
considering functional spreadsheet operator usage suggests value example driven modelling decision support systems spreadsheet surveys reporting use error focus practical application spreadsheet particular industry typically studies illustrate particular percentage spreadsheets used optimisation percentage used analysis much less common classes function , defined , used build spreadsheet models alternative analysis allows insight programming nature spreadsheets may assist researchers targeting particular structures spreadsheet software investigation , understanding functional make spreadsheets allows effective evaluation novel approaches programming point view allows greater insight studies report spreadsheets used since explicit functional structures use spreadsheets conclude deeper understanding use operators operator 's relationship error would provide insight spreadsheet error problem considering functional spreadsheet operator usage suggests value example driven modelling decision support systems
channel estimation hybrid beamforming millimeter wave communication systems low resolution adcs potential tremendous spectrum resource makes millimeter wave \( \) communications promising technology high power consumption due large number antennas analog digital \( adcs \) beamforming overcome large propagation losses practice hybrid beamforming architecture low resolution adcs considered reduce power consumption , estimation channels becomes challenging evaluate several channel estimation algorithms systems hybrid beamforming low resolution adcs simulation , show 1 \) infinite bit adcs least squares estimation worse channel estimation performance one bit adcs orthogonal matching pursuit \( \) snr range interest , 2 \) three four bit achieve channel estimation performance close case using , 3 \) receiver single rf chain yield better estimates four rf chains enough frames exploited , 4 \) one bit adcs , exploitation higher transmit power frames performance enhancement affects estimation performance certain point
based regularization signal estimation linear discrete ill posed problems estimating values unknown parameters corrupted measured data faces lot challenges ill posed problems problems , many fundamental estimation methods fail provide meaningful solution work , propose new regularization approach new regularization parameter selection approach linear least squares discrete ill posed problems proposed approach based enhancing singular value structure ill posed model matrix better solution unlike many regularization algorithms seek minimize estimated data error , proposed approach developed minimize mean squared error estimator objective many typical estimation scenarios performance proposed approach demonstrated applying large set real world discrete ill posed problems simulation results demonstrate proposed approach outperforms set benchmark regularization methods cases addition , approach also enjoys runtime offers highest level robustness tested benchmark regularization methods
serverless computing one step forward two steps back serverless computing offers potential program cloud , go manner paper address critical gaps first generation serverless computing , place potential dominant trends modern computing notably data centric distributed computing , also open source hardware put together , gaps make current serverless bad fit cloud innovation particularly bad data systems innovation addition main current serverless architectures , set challenges believe must met potential cloud storage millions cores offer innovative developers
generating live video comments based visual textual contexts introduce task automatic live commenting live commenting , also called , emerging feature online video sites allows real time comments fly across like right side live comments mixture video comments automatic live commenting requires ai agents videos interact human also make comments , good ai agent 's ability dealing dynamic vision language work , construct large scale live dataset 2 , videos , live comments , introduce two neural models generate live comments based visual textual contexts , achieve better performance previous neural baselines sequence sequence model finally , provide retrieval based evaluation protocol automatic live commenting model asked sort set candidate comments based log likelihood score , evaluated metrics mean rank putting together , demonstrate first
neural language model dynamically representing meanings unknown words entities study addresses problem identifying meaning unknown words entities respect word embedding approaches used neural language models proposed method fly construction exploitation word embeddings input output layers neural model tracking contexts extends dynamic entity representation used et al \( 2016 \) incorporates copy mechanism proposed independently et al \( 2016 \) et al \( 2016 \) addition , construct new task dataset called language modeling evaluating ability capture word meanings reading experiments conducted using novel dataset show proposed variant rnn language model outperformed baseline model furthermore , experiments also demonstrate dynamic updates output layer help model predict entities , whereas input layer effective predict words following entities
logic programming applications abstractions implementations article presents overview applications logic programming , classifying based abstractions implementations logic languages support applications three key abstractions join , recursion , constraint essential implementations loops , fixed points , , respectively corresponding kinds applications database queries , analysis , combinatorial search , respectively also discuss language extensions programming paradigms , example application problems application areas , example systems support variants abstractions different implementations
collaborative high accuracy localization mobile multipath environments study problem high accuracy localization mobile nodes multipath rich environment sub accuracies required employ peer peer framework vehicles nodes get pairwise multipath degraded ranging estimates local neighborhoods together fixed number nodes challenge overcome multipath barrier redundancy order provide desired accuracies especially severe multipath conditions fraction received signals corrupted multipath dominating analytical graphical model framework based particle filtering reveal high accuracy localization promise simulations also address design questions many fraction line \( los \) measurements needed achieve specified target accuracy \? , analytically characterizing performance improvement localization accuracy function number nodes network fraction los measurements particular , static node placement , show lower bound \( \) , fundamental lower bound localization accuracy , expressed product two factors scalar function depends parameters noise distribution matrix depends geometry node locations underlying connectivity graph , simplified expression obtained helps scaling behavior estimation error function number agents network bound suggests even small fraction los measurements provide significant improvements , small fraction measurements significantly degrade performance analysis extended mobile setting performance compared derived
safe exploration optimizing contextual bandits contextual bandit problems natural fit many information retrieval tasks , learning rank , text classification , recommendation , etc however , existing learning methods contextual bandit problems one two drawbacks either explore space possible document rankings \( e , actions \) , thus , may optimal ranking , present suboptimal rankings user , thus , may user experience introduce new learning method contextual bandit problems , safe exploration algorithm \( sea \) , drawbacks sea starts using baseline \( production \) ranking system \( e , policy \) , user experience , thus , safe execute , suboptimal performance , thus , needs improved sea uses counterfactual learning learn new policy based behavior baseline policy sea also uses high confidence policy evaluation estimate performance newly learned policy performance newly learned policy least good performance baseline policy , sea starts using new policy execute new actions , allowing actively explore favorable regions action space way , sea never performs worse baseline policy , thus , user experience , still exploring action space , thus , able find optimal policy experiments using text classification document retrieval confirm comparing sea \( variant called \) online offline learning methods contextual bandit problems
learning naive bayes classifiers frequently , training data associated cost consider situation learner may purchase data training , subject budget particular , examine case feature label associated cost , total cost feature labels acquired training must exceed budget paper compares methods choosing feature label purchase next , given budget current belief state naive bayes model parameters whereas active learning traditionally focused \( greedy \) strategies query selection , paper presents tractable method incorporating knowledge budget decision making process , improves performance
quality estimation english outputs using naive bayes classifier paper present approach estimating quality machine translation system various methods estimating quality output sentences , paper focus na bayes classifier build model using features extracted input sentences features used finding likelihood sentences training data used determining scores test data basis scores determine class labels test data
multimodal trajectory optimization motion planning existing motion planning methods often two drawbacks 1 \) goal configurations need specified user , 2 \) single solution generated given condition practice , multiple possible goal configurations exist achieve task although choice goal configuration significantly affects quality resulting trajectory , trivial user specify optimal goal configuration addition , objective function used trajectory optimization often non convex , multiple solutions achieve comparable costs study , propose framework determines multiple trajectories correspond different modes cost function reduce problem identifying modes cost function estimating density induced distribution based cost function proposed framework enables users select solution multiple candidate trajectories , thereby making easier tune cost function obtain satisfactory solution evaluated proposed method motion planning tasks 2d 3d space experiments show proposed algorithm capable determining multiple solutions tasks
winner take autoencoders paper , propose winner take method learning hierarchical sparse representations unsupervised fashion first introduce fully connected winner take autoencoders use mini batch statistics directly enforce lifetime sparsity activations hidden units propose convolutional winner take autoencoder combines benefits convolutional architectures autoencoders learning shift invariant sparse representations describe way train convolutional autoencoders layer layer , addition lifetime sparsity , spatial sparsity within feature map achieved using winner take activation functions show winner take autoencoders used learn deep sparse representations mnist , cifar 10 , imagenet , street view numbers face datasets , achieve competitive classification performance
completeness sorting networks isomorphism isomorphism problem really important excellent practical solutions described literature however , computational complexity analysis classification \( \) isomorphism problem currently open problem paper prove checking whether two sorting networks complete general \( graph isomorphism \) problem known np , widely neither p np complete recent research suggests problem moreover , state sorting network isomorphism problem general isomorphism problem every sorting network represented complexity classification presented paper applies sorting networks , well general isomorphism problem main consequence work currently polynomial time algorithm exists solving sorting network isomorphism problem however \( \) sorting network isomorphism problem efficiently solved polynomial time
variational discriminator bottleneck improving imitation learning inverse rl gans constraining information flow adversarial learning methods proposed wide range applications , training adversarial models notoriously effectively balancing performance generator discriminator critical , since discriminator achieves high accuracy produce relatively gradients work , propose simple general technique constrain information flow discriminator means information bottleneck constraint mutual information observations discriminator 's internal representation , effectively discriminator 's accuracy maintain useful informative gradients demonstrate proposed variational discriminator bottleneck \( \) leads significant improvements across three distinct application areas adversarial learning algorithms primary evaluation studies applicability imitation learning dynamic continuous control skills , running show method learn skills directly emph raw video demonstrations , substantially outperforming prior adversarial imitation learning methods also combined adversarial inverse reinforcement learning learn reward functions optimized new settings finally , demonstrate train gans effectively image generation , improving upon number prior methods
speaker adaptation end end ctc models propose two approaches speaker adaptation end end \( \) automatic speech recognition systems one kullback leibler divergence \( \) regularization multi task learning \( \) approaches aim address data sparsity especially output target sparsity issue speaker adaptation systems regularization model forcing output distribution adapted model close one utilizes jointly trained auxiliary task improve performance main task investigated approaches temporal classification \( ctc \) models three different types output units experiments short message task demonstrated outperforms regularization particular , adaptation obtained 8 8 4 0 relative word error rate reductions \( \) supervised unsupervised word ctc model , 9 6 3 8 relative unit ctc model , respectively
context free languages scattered words known b context free language \( \) consists scattered words , integer n , depending language , rank word language bounded n every context free language \( \) first part paper , prove scattered words rank every word language bounded integer depending language r n establish operational characterizations well ordered scattered words prove language consisting well ordered words generated languages containing letters alphabet substitution ordinary context free languages omega power operation also establish corresponding result scattered words define expressions well ordered scattered words final part paper give applications
minimal suffix rotation substring optimal time text given advance , substring minimal suffix queries ask determine minimal non suffix substring specified location occurrence text develop data structure answering queries optimally constant time linear time preprocessing improves upon results et al \( 2014 \) , whose trade solution characterized theta \( n log n \) product time complexities next , extend queries support \( 1 \) , construction query time preserved apply generalized queries compute minimal maximal given substring constant time linear time preprocessing r n data structures mainly rely properties lyndon words lyndon combine algorithmic combinatorial tools , fusion trees notion order isomorphism strings
responsibility analysis abstract interpretation given behavior interest program , determining corresponding responsible entity task critical importance , especially program security classical static analysis techniques \( e g dependency analysis , analysis , , etc \) assist scope responsibility , none explicitly identify responsible entity meanwhile , causality analysis generally analyzing programs , structural equations model \( \) actual causality information inherent programs , making analysis programs paper , novel definition responsibility based abstraction event trace semantics proposed , applied program security scientific fields briefly speaking , entity responsible behavior b , free choose input value , choice first one ensures occurrence b execution compared current analysis methods , responsibility analysis precise addition , definition responsibility takes account observer , , best knowledge , new innovative idea program analysis
holistic approach log data analysis high performance computing systems case ibm q complexity cost managing high performance computing rise automating management repair predictive models minimize human attempt increase system availability contain costs building predictive models accurate enough useful automatic management cannot based restricted log data requires holistic approach data analysis disparate sources provide detailed multi scale characterization study based four datasets reporting power consumption , temperature , workload , hardware software events ibm q show system runs rich parallel workload , low correlation among components terms temperature power , higher correlation terms events expected , power temperature correlate strongly , events negative correlations load power power workload show moderate correlations , scale components aim study systematic , integrated characterization computing infrastructure discovery correlation sources levels serve basis future predictive modeling efforts
view adaptive recurrent neural networks high performance human action recognition skeleton data skeleton based human action recognition recently increasing attention due popularity 3d skeleton data one main challenge lies large view variations captured human actions propose novel view adaptation scheme automatically observation viewpoints occurrence action rather positioning based human defined prior criterion , design view adaptive recurrent neural network \( rnn \) lstm architecture , enables network adapt suitable observation viewpoints end end extensive experiment analyses show proposed view adaptive rnn model \( 1 \) transform various views much consistent viewpoints \( 2 \) maintain continuity action rather transforming every frame position body orientation model achieves state art performance three benchmark datasets current largest rgb dataset , scheme outperforms state art impressive 6 gain accuracy
information theoretically aided reinforcement learning agents reinforcement learning agents challenging problem reward optimized often function , gradient methods many local demonstrate , experimental setting , incorporating intrinsic reward optimization landscape preserving global interest show policy gradient optimization locomotion complex significantly improved extrinsic reward intrinsic reward defined terms mutual information time consecutive sensor
category based routing social networks membership dimension small world phenomenon short classic experiment shows individuals route messages along short paths social networks , given simple categorical information \( prominent major \) , networks short paths pairs nodes \( called small world phenomenon \) moreover , participants able route messages along paths even though person aware small part network topology conjecture participants scenarios use greedy routing strategy forward messages categories common , similar strategies recently proposed routing messages dynamic ad hoc networks mobile devices paper , introduce network property called membership dimension , characterizes cognitive load required maintain relationships participants categories social network show connected network system categories support greedy routing , categories made small membership dimension underlying network exhibits small world phenomenon
predicting relative difficulty single sentences without surrounding context problem accurately predicting relative reading difficulty across set sentences arises number important natural language applications , finding effective usage examples intelligent language systems yet significant research explored document level reading difficulty , special challenges involved aspects single sentences received much less attention , particularly considering role surrounding introduce evaluate novel approach estimating relative reading difficulty set sentences , without surrounding context using different sets lexical grammatical features , explore models predicting pairwise relative difficulty using logistic regression , examine rankings generated pairwise difficulty labels using bayesian system form final ranking also compare rankings derived sentences assessed without context , find contextual features help predict differences relative difficulty judgments across two conditions
differentially private sparse data problem data provide version dataset without revealing sensitive information individuals contribute data model differential privacy allows private release providing strong guarantees output basic mechanism achieves differential privacy adding noise frequency counts tables \( , subset count data cube \) derived dataset however , dataset sparse underlying space , case multi attribute relations , effect adding noise increase size published data implicitly creates huge number data points mask true data , making almost impossible work r n present techniques overcome allow efficient private release sparse data , maintaining guarantees differential privacy approach release compact summary noisy data generating noisy data would still costly , show shortcut step , instead directly generate summary input data , without vast intermediate noisy data outline variety sampling filtering methods , show use resulting summary approximate , private , query answering experimental study shows effective , practical solution , comparable improved utility costly approach
fine grained language composition although run time language composition common , takes form function interface \( \) useful , tend coarse grained slow paper introduce novel fine grained syntactic composition python allows users embed language inside , including variables across languages composition raises novel design implementation challenges show good solutions found design challenges resulting implementation imposes acceptable performance overhead , ,
automatic generation smooth curves interpretable low dimensional parameters many real world objects designed smooth curves , especially domain , shapes \( e g , \) shapes \( e g , \) designed facilitate design process objects , propose deep learning based generative model synthesize smooth curves model maps low dimensional latent representation sequence discrete points sampled rational b curve demonstrate performance method completing synthetic real world generative tasks results show method generate diverse realistic curves , preserving consistent shape variation latent space , favorable latent space design optimization design space exploration
toward dimensional emotion detection categorical emotion annotations propose framework makes model predict fine grained dimensional emotions \( , vad \) trained corpus annotated coarse grained categorical emotions train model minimizing distances predicted vad score distribution textit categorical emotion distributions terms vad , proxy target vad score distributions model , simultaneously classify given sentence categorical emotions well predict vad scores use pre trained bert large fine tune dataset \( 11 categorical emotions \) evaluate \( vad dimensional emotions \) , order show approach reaches comparable performance state art classifiers categorical emotion classification task significant positive correlations ground truth vad scores also , one training model supervision vad labels , outperforms state art vad regression models present examples showing model emotional words suitable given text even words seen categorical labels training
static dynamic values computation monte carlo tree search \( \) one widely used methods planning , many recent advances artificial intelligence , one typically performs computations \( e , simulations \) collect statistics possible future consequences actions , accordingly many popular methods variants decide computations perform exploration exploitation work , take direct approach , explicitly quantify value computation based expected impact quality action chosen approach goes beyond limitations existing computation value based methods two senses \( \) able account impact non immediate \( , future \) computations \( ii \) non immediate actions show policies optimize computation values optimal certain assumptions obtain results competitive state art
augmented reality large scene based registration framework paper , mobile camera positioning method based forward inverse robot proposed , realize far point positioning imaging position tracking large scene enhancement precision motion framework overhead cameras combining ground system sensor array object mobile robot platform various sensors , realize good 3 image registration , solve artifacts mobile robot large space position initialization problem , effectively implement large space augmented reality , human computer interaction , information summary finally , feasibility effectiveness method verified experiments
shortest path problem rectangular complexes global curvature cat \( 0 \) metric spaces far reaching common generalization euclidean spaces simple polygons two points x cat \( 0 \) metric space connected unique shortest path c \( x , \) paper , present efficient algorithm answering two point distance queries cat \( 0 \) rectangular complexes two subclasses , rectilinear polygons \( cat \( 0 \) rectangular complexes links vertices bipartite graphs \) \( cat \( 0 \) rectangular complexes arising plane inner vertices degrees 4 \) namely , show cat \( 0 \) rectangular complex k n vertices , one construct data structure size \( n 2 \) , given two points x , email protected \? k , shortest path c \( x , \) x computed \( \( p , q \) \) time , p q vertices two faces k containing points x , respectively , c \( x , \) \? k \( \( p , q \) \) \( p , q \) distance p q underlying graph k k rectilinear polygon , one construct data structure optimal size \( n \) answer two point shortest path queries \( \( p , q \) email protected \) time , maximal degree vertex g \( k \) finally , k , one construct data structure size \( \) answer two point shortest path queries \( \( p , q \) \) time
distributed structure joint multiple access channel paper , obtain improved lower bound error exponent memoryless multiple access channel via use linear codes , thus demonstrating structure beneficial even capacity may achieved via random codes show multiple access channel additive finite field , error probability , hence error exponent , achievable linear code associated single user channel , also achievable multiple access channel particular , linear codes allow attain joint , hence , attain single user exponent single user channel , whenever latter achieved uniform distribution thus , additive channels , low rates , needed , approach strictly improves performance previous results , used one users even multiple access channel additive , may transformed channel transformation information lossy , show distributed structure gain nearly additive cases loss finally , apply similar approach gaussian multiple access channel believe due power constraints , impossible attain single user error exponent , obtain improvement best known achievable error exponent , given , certain parameters accomplished using nested lattice triplet chosen parameters
stochastic service guarantee analysis based time domain models stochastic network calculus theory stochastic service guarantee analysis computer communication networks current stochastic network calculus literature , traffic server models typically based cumulative amount traffic cumulative amount service respectively however , network scenarios applicability models limited , hence new ways modeling traffic service needed address limitation paper presents time domain models results stochastic network calculus particularly , define traffic models , based probabilistic lower bounds cumulative packet inter arrival time , server models , based probabilistic upper bounds cumulative packet service time addition , examples demonstrating use proposed time domain models provided basis proposed models , five basic properties stochastic network calculus also proved , implies broad applicability proposed time domain approach
resilience numerical methods position fault models methodologies future extreme scale computer systems may data corruption \( \) applications , order energy increase performance however , resilience research come useful abstract programming models reasoning existing work randomly bits running applications , shows average case behavior low level , artificial hardware model algorithm developers need understand worst case behavior higher level data types actually use , order make algorithms resilient also , know little may manifest future hardware , seems draw conclusions average case argue instead numerical algorithms benefit numerical fault model , manifest perturbations point data algorithms use checks bound exclude error results computations given selective reliability programming model requires reliability needed , checks make algorithms reliable despite checks , general correctness , wise even hardware perfectly reliable
design strategies geometric synthesis orthoglide type mechanisms paper addresses geometric synthesis orthoglide type mechanism , family 3 dof parallel rapid applications , combine advantages mechanisms parallel kinematic architectures possess quasi isotropic kinematic performances made three actuated fixed , mutually orthogonal connected mobile platform via three chains platform cartesian space fixed orientation , similar conventional machine three strategies proposed define orthoglide geometric parameters \( link lengths actuated joint limits \) functions cubic workspace size properties expressed bounds velocity transmission factors , condition number low intrinsic set additional design goals expressed minimal link length requirement design strategy , analytical expressions computing orthoglide parameters proposed showed proposed strategies yield pareto optimal solutions , differ kinematic performances outside cartesian cube \( within workspace bounded actuated joint limits \) proposed technique illustrated numerical examples orthoglide prototype design
tool interactive machine learning models key challenge developing deploying machine learning \( ml \) systems understanding performance across wide range inputs address challenge , created tool , open source application allows practitioners probe , visualize , analyze ml systems , minimal coding tool lets practitioners test performance situations , analyze importance different data features , visualize model behavior across multiple models subsets input data also lets practitioners measure systems according multiple ml fairness metrics describe design tool , report real life usage different organizations
inspired data encoding multi level memory cell mapping inspired algorithms sensor hardware require shifting signal processing digital analog domain , memory technologies beyond conventional binary storage units using building analog data storage one promising approaches emerging non memory technologies recently , multi level memory \( \) cell storing discrete analog values developed memory system implemented combining configuration given example , memory cell 3 sub cells store ternary bits overall achieved 10 27 discrete levels however , use proposed memory cell analog signal processing data encoder required generate control programming store discrete analog values paper , present design performance analysis data encoder generates write pattern signals 10 level memory
limitations standardized science tests benchmarks artificial intelligence research position paper position paper , argue standardized tests science sat tests good benchmarks measuring progress artificial intelligence systems understanding basic science primary problem tests designed test aspects knowledge ability challenging people aspects challenging ai systems different particular , standardized tests test knowledge obvious people none knowledge assumed ai systems individual standardized tests also specific features necessarily appropriate ai benchmark analyze physics subject sat detail new state science test briefly also argue advantages offered using standardized tests mostly either minor one major real advantage significance easily explained public argue even somewhat mixed conclude , first , appropriate collections style problems could , second , better kinds benchmarks style problems present collection sample style problems test kinds knowledge missing standardized tests
practical study deterministic regular expressions large scale xml data regular expressions fundamental concept computer science widely used various applications paper focused deterministic regular expressions \( dres \) considering researchers n't large datasets evidence , first harvested large corpus real data web conducted practical study investigate usage dres one feature work data set sufficiently large compared previous work , obtained using several data collection strategies proposed results show 98 expressions relax , expressions , relax determinism constraint observations indicate dres commonly used practice results also show study subclasses dres necessary far know , first analyze determinism subclasses dres relax , give results furthermore , give discussions applications data set obtain data set original data , useful practice value right find current research new subclasses dres insufficient , therefore necessary study also analyze relationships among define , used xml design
fly optimization parallel computation symbolic invariants group invariants used high energy physics define quantum field theory interactions paper , presenting parallel algebraic computation special invariants called even focusing one particular invariant finds recent interest physics results invariants cost performing basic computations multivariate polynomials involved computation , polynomials get larger increasing number terms however , cases , small traditionally , high performance software optimized running smaller data set order use information set tuning parameters since \( communication computation \) costs evolve computation , first iterations computation might representative rest computation approach cannot applied case cope evolution , presenting approach get performance data tune algorithm execution
modeling interpolation ambient magnetic field gaussian processes anomalies ambient magnetic field used features indoor positioning navigation using 's equations , derive present bayesian non parametric probabilistic modeling approach interpolation magnetic field model magnetic field components jointly imposing gaussian process \( gp \) prior latent scalar potential magnetic field gp model terms hilbert space representation , circumvent computational associated gp modeling provide computationally efficient justified modeling tool ambient magnetic field model allows sequential updating estimate time dependent changes magnetic field model shown work well practice different applications demonstrate mapping magnetic field pi robot using standard smartphone
sequence editing guidance propose task sequence editing \( \) editing input sequence generate output sequence satisfies given numerical outcome value measuring certain property sequence , requirement keeping main content input sequence example , input sequence could word sequence , review sentence text review sentence , outcome could review , outcome could click rate major challenge performing outcome related , edit change outcome paper , proposed framework contains two latent factors , namely , outcome factor content factor , disentangled input sentence allow convenient editing change outcome keep content framework pseudo parallel sentences modeling content similarity outcome differences enable better disentanglement latent factors , allows generating output better satisfy desired outcome keep content dual reconstruction structure capability generating expected output exploiting latent factors pseudo parallel sentences evaluation , dataset yelp review sentences ratings outcome extensive experimental results reported discussed elaborate framework
anomaly detection traffic scenes via spatial aware motion reconstruction anomaly detection driver 's perspective driving important autonomous vehicles part advanced driver assistance systems \( \) , driver timely manner compared traditional studied scenes university market surveillance videos , difficult detect abnormal event driver 's perspective due camera , moving background , change vehicle velocity , etc tackle specific problems , paper proposes spatial localization constrained sparse coding approach anomaly detection traffic scenes , first measures motion orientation magnitude , respectively , two aspects obtain robust detection result main contributions , follows 1 \) work describes motion orientation magnitude object , respectively , new way , demonstrated better traditional motion descriptors 2 \) spatial localization object taken account considering sparse reconstruction framework , utilizes scene 's structural information outperforms conventional sparse coding methods 3 \) results motion orientation magnitude adaptively weighted fused bayesian model , makes proposed method robust able handle kinds abnormal events efficiency effectiveness proposed method validated testing nine difficult video sequences captured observed experimental results , proposed method effective efficient popular competitors yields higher performance
optimal prefix free code linear time describe algorithm computing optimal prefix free code n positive integer weights time linear number machine words weights algorithm takes advantage common non algebraic instructions , specific results optimal prefix free codes result improves state art complexities \( n lg n \) algebraic decision tree model \( n lg lg n \) ram model computation huffman 's codes , landmark compression coding since
conceptual model measuring complexity spreadsheets spreadsheets widely used industry , even critical business processes implies need proper risk assessment spreadsheets evaluate reliability validity spreadsheet 's outcome related research shown , risk spreadsheet errors strongly related spreadsheet 's complexity therefore , spreadsheet researchers proposed various metrics quantifying different aspects spreadsheet order assess complexity however , shared understanding potential complexity drivers spreadsheets present work addresses research gap proposing conceptual model integrating aspects identified related literature potential drivers spreadsheet complexity sense , model forms foundation structured definition complexity metrics , thus reproducibility results time , forms foundation identifying applicable complexity metrics scientific domains
car segmentation pose estimation using 3d object models image segmentation 3d pose estimation two key algorithm scene understanding however , state art crf based models image segmentation rely mostly 2d object models construct top high order potentials paper , propose new top potentials image segmentation pose estimation based shape volume 3d object model show complex top potentials easily decomposed standard forms efficient inference segmentation pose estimation tasks experiments car dataset show knowledge segmentation helps perform pose estimation better
multi target regression via input space expansion treating targets inputs many practical applications supervised learning task involves prediction multiple target variables common set input variables prediction targets binary task called multi label classification , targets continuous task called multi target regression tasks , target variables often exhibit statistical dependencies exploiting order improve predictive accuracy core challenge family multi label classification methods address challenge building separate model target input space targets treated additional input variables despite success methods multi label classification domain , applicability effectiveness multi target regression studied paper , introduce two new methods multi target regression , called stacked single target ensemble chains , adapting two popular multi label classification methods family furthermore , highlight inherent problem methods discrepancy values additional input variables training prediction develop extensions use sample estimates target variables training order tackle problem results extensive experimental evaluation carried large diverse collection datasets show , discrepancy appropriately , proposed methods attain consistent improvements independent baseline moreover , two versions ensemble regression chains perform significantly better four state art methods including regularization based multi task learning methods multi objective random forest approach
ptas class stochastic dynamic programs develop framework obtaining polynomial time approximation schemes \( ptas \) class stochastic dynamic programs using framework , obtain first ptas following stochastic combinatorial optimization problems given set n items , item n value x independent random variable known \( discrete \) distribution pi em probe subset p subseteq n items time item , observe value realization , follows distribution pi em adaptively probe items item reward maximum among realized values goal design adaptive policy expected value reward maximized best knowledge , best known approximation ratio 1 1 e , due cite also obtain ptas generalizations variants problem problems
fully associative patch based 1 n matcher face recognition paper focuses improving face recognition performance patch based 1 n signature matcher learns correlations different facial patches fully associative patch based signature matcher \( \) proposed local matching identity patch contributes global matching identities patches proposed matcher consists three steps first , based signature , local matching identity corresponding matching score patch computed , fully associative weight matrix learned obtain global matching identities scores patches last , l1 regularized weighting applied combine global matching identity patch obtain final matching identity proposed matcher integrated system evaluation experimental results indicate proposed matcher achieves better performance current system rank 1 accuracy improved significantly 3 0 dataset dataset , respectively
detection games fully active adversaries study binary hypothesis testing problem defender must decide whether test sequence drawn given memoryless source p 0 , attacker correct detection respect previous works , adversarial setup addressed paper considers attacker active hypotheses , namely , fully active attacker , opposed partially active attacker active one hypothesis fully active setup , attacker sequences drawn p 0 alternative memoryless source p 1 , certain distortion level , possibly different two hypotheses , maximize distinguishing two sources , e , induce false positive false negative errors detector , also referred defender model defender attacker interaction game study two versions game , neyman game bayesian game main result characterization attack strategy asymptotically dominant \( e , optimal matter defender strategy \) universal , e , independent p 0 p 1 analysis equilibrium , also derive best achievable performance defender , requirement exponential decay rate false positive error probability neyman setup tradeoff error bayesian setup analysis characterizing conditions two sources given distortion levels
connected searching weighted trees paper consider problem connected edge searching weighted trees et al claim l , p , p , n , capture mobile agents , parallel algorithms architectures , , new , , , , pp 200 exists polynomial time algorithm finding optimal search strategy , , strategy minimizes number used however , due algorithm , problem turns open proven paper considered problem strongly np complete even node weighted trees \( weight edge 1 \) one vertex degree greater 2 also shown exists polynomial time algorithm finding optimal connected search strategy given bounded degree tree arbitrary weights edges vertices fpt algorithm respect maximum degree tree
learning stop reading machine comprehension teaching computer read answer general questions document challenging yet problem paper , describe novel neural network architecture called reasoning network \( \) machine comprehension tasks make use multiple turns effectively exploit reason relation among queries , documents , answers different previous approaches using fixed number turns inference , introduce termination state relax constraint reasoning depth use reinforcement learning , dynamically determine whether continue comprehension process intermediate results , reading existing information adequate produce answer achieve superior performance machine comprehension datasets , including unstructured cnn daily mail datasets , dataset , structured graph reachability dataset
automata guided reinforcement learning demonstrations tasks complex temporal structures long pose challenge reinforcement learning agents due difficulty tasks terms reward functions well large learning signals propose address problems combining temporal logic \( \) reinforcement learning demonstrations method automatically generates intrinsic rewards align overall task goal given task specification policy resulting framework interpretable hierarchical structure validate proposed method experimentally set robotic manipulation tasks
modeling sentiment dependencies graph convolutional networks aspect level sentiment classification aspect level sentiment classification aims distinguish sentiment one aspect terms sentence existing approaches mostly model different aspects one sentence independently , ignore sentiment dependencies different aspects however , find dependency information different aspects bring additional valuable information paper , propose novel aspect level sentiment classification model based graph convolutional networks \( gcn \) effectively capture sentiment dependencies multi aspects one sentence model firstly introduces bidirectional attention mechanism position encoding model aspect specific representations aspect context words , employs gcn attention mechanism capture sentiment dependencies different aspects one sentence evaluate proposed approach 2014 datasets experiments show model outperforms state art methods also conduct experiments evaluate effectiveness gcn module , indicates dependencies different aspects highly helpful aspect level sentiment classification
autonomous mobile robot navigation uneven unstructured indoor environments robots increasingly operating indoor environments designed shared people however , robots working safely autonomously uneven unstructured environments still face great challenges many modern indoor environments designed mind presents opportunity robots navigate areas avoiding paper , present integrated software hardware system autonomous mobile robot navigation uneven unstructured indoor environments modular software framework incorporates capabilities perception navigation robot first builds 3d representation uneven environment 3d mapping using odometry , 2d rgb data project 2d maps generate map based layer differences safe map serves input efficient autonomous navigation furthermore , employ variable step size rapidly exploring random trees could step size automatically , eliminating tuning step sizes according environments conduct extensive experiments simulation real world , demonstrating efficacy efficiency system
automated security policy implementation using reinforcement learning malware detection ever present challenge organizational organizations often deploy numerous different malware detection tools , combine output produce final classification file approach two significant drawbacks first , requires large amounts computing resources time since every incoming file needs analyzed detectors secondly , difficult accurately dynamically enforce predefined security policy needs organization \( e g , tolerant organization false false positives \) study propose , reinforcement learning \( rl \) based method malware detection approach receives organizational policy defined solely perceived costs correct incorrect computing resources dynamically detection tools sets detection threshold file demonstrate effectiveness robustness approach extensive evaluation multiple organizational policies performed well scenarios , even achieving near optimal accuracy 96 21 \( compared optimum 96 86 \) approximately 20 running time baseline
fully private pipeline deep learning electronic health records introduce end end private deep learning framework , applied task predicting 30 day electronic health records using differential privacy training homomorphic encryption inference , demonstrate proposed pipeline could maintain high performance providing robust privacy guarantees information data transmission attacks model also explore several techniques address privacy utility trade deploying neural networks privacy mechanisms , improving accuracy differentially private training computation cost operations using ideas machine learning cryptography
role emotions contributors activity case study community analyze relation emotions activity contributors open source software project case study builds extensive data sets project 's bug tracking platform , quantify activity contributors , mail , quantify emotions contributors means sentiment analysis project known period within bug community followed considerable changes community organization performance central analyze event negative emotions , email discussions central , level whole community contributors extend study consider activity patterns contributors general find contributors likely become express strong positive negative emotions bug tracker , expected value emotions list use insights develop bayesian classifier risk contributors project analysis new perspectives measuring online motivation means sentiment analysis real time predictions open source software projects
late weak markov automata weak bisimilarity distribution based equivalence notion markov automata gained popularity reasonable behavioural equivalence markov automata paper studies strictly notion late weak bisimilarity enjoys valuable properties important subclasses trace distribution equivalence partial information , compositionality preserved distributed intersection two scheduler classes thus still reasonable compositional theory markov automata
security gps ins based road location tracking systems location information critical wide variety navigation tracking applications today , gps de facto outdoor localization system shown vulnerable signal spoofing attacks inertial navigation systems \( ins \) emerging popular complementary system , especially road transportation systems enable improved navigation tracking well offer resilience wireless signals spoofing , jamming attacks paper , evaluate security guarantees ins aided gps tracking navigation road transportation systems consider adversary required travel source location destination , ins aided gps system goal adversary travel alternate locations without detected developed evaluated algorithms achieve goal , providing adversary significant latitude algorithms build graph model given road network enable us derive potential destinations attacker reach without even ins aided gps tracking navigation system algorithms render sensors generate road trajectories plausible paths \( terms turn curvature \) also designed , built , demonstrated actively using combination carefully controlled implemented evaluated impact attack using real world simulated driving traces 10 cities located around world evaluations show possible attacker reach destinations far 30 away true destination without detected also show possible adversary reach almost 60 80 possible points within target region cities
note spectral clustering graph data spectral clustering singular value decomposition \( \) widely used technique analyzing graph data note , present connections using simple linear algebra , aiming provide depth understanding future research
phoneme viseme mappings visual equivalent although precisely defined , common working definition viseme set identical appearance therefore phoneme one viseme class viseme may represent many one many mapping mapping introduces ambiguity using viseme classifiers ambiguity performance audio visual classifiers operating real expressive speech , also considerable choice possible mappings paper explore issue choice viseme phoneme map show definite difference performance viseme phoneme mappings explore maps appear work better others also devise new algorithm constructing phoneme viseme mappings labeled speech data new , , shown perform better previously known units
probabilistic line searches stochastic optimization deterministic optimization , line searches standard tool ensuring stability efficiency stochastic gradients available , direct equivalent far formulated , uncertain gradients allow strict sequence decisions search space construct probabilistic line search combining structure existing deterministic methods notions bayesian optimization method gaussian process surrogate optimization objective , uses probabilistic belief conditions monitor descent algorithm low computational cost , user controlled parameters experiments show effectively removes need define learning rate stochastic gradient descent
lattice based conceptual spaces explore cognitive functionalities prosthetic arm upper prosthetic viewed independent cognitive system order develop conceptual space paper , provide detailed reasoning prosthetic arm build conceptual spaces help theory called geometric framework conceptual spaces proposed conceptual spaces concepts , similarities , properties , quality dimensions prototype applied specific prosthetic system conceptual space built prosthetic arm concept lattice used lattice represented conceptual spaces cognitive functionalities generalization \( similarities \) \( differences \) achieved lattice represented conceptual space might well prove design intelligent assist humans geometric framework conceptual spaces holds similar concepts closer geometric structures way similar concept lattices hence , also propose use concept lattice represent concepts geometric framework conceptual spaces also , extend discussion insights conceptual spaces bidirectional hand
style aware content loss real time style transfer recently , style transfer received lot attention much research processing , approaches still principled , art historical style single image , previous work limited single instance style shows benefit images moreover , previous work relied direct comparison art domain rgb images cnns pre trained imagenet , requires millions labeled object bounding boxes introduce extra bias , since without consideration circumvent issues , propose style aware content loss , trained jointly deep encoder decoder network real time , high resolution images videos propose quantitative measure evaluating quality image also art rank patches approach previous work qualitative results ranging small image patches stylistic images videos show approach better captures nature style affects content
intelligence edge beyond machine intelligence \( mi \) technologies design applications computational intelligence systems , introducing remarkable scientific technological across domains mi improve internet things \( iot \) several ways , optimizing management large data improving automation transmission large scale iot considering mi iot context , mi services deployment must account latency demands network bandwidth requirements extent , moving intelligence towards iot end device aims address requirements introduces notion distributed mi \( mi \) also iot context however , current mi limited lack mi currently , intelligence bound application exploits , limiting specific intelligence service additional applications objective article propose novel approach cope constraints focuses intelligence application traditional device 's stack introducing intelligence layer provides services application layer paradigm aims provide final users control intelligence services boosting develop solutions could theoretically reach device based definition emerging paradigm , explore several aspects related intelligence distribution impact whole mi
end end training hybrid cnn crf models stereo propose novel principled hybrid cnn crf model stereo estimation model allows exploit advantages , convolutional neural networks \( cnns \) conditional random fields \( \) unified approach cnns compute expressive features matching distinctive color edges , turn used compute unary binary costs crf inference , apply recently proposed highly parallel dual block descent algorithm needs small fixed number iterations compute high quality approximate main contribution paper , propose theoretically sound method based structured output support vector machine \( \) train hybrid cnn crf model large scale data end end trained models perform well despite fact using shallow cnns apply kind post processing final output crf evaluate combined models challenging stereo benchmarks 2014 kitti 2015 also investigate performance individual component
towards evaluating plan generation approaches texts recent research behaviour understanding language shown possible automatically generate behaviour models textual instructions models usually goal oriented structure modelled different formalisms planning domain planning domain definition language one major problem still remains benchmark datasets comparing different model generation approaches , approach usually evaluated domain specific application allow objective comparison different methods model generation textual instructions , report introduce dataset consisting textual instructions english language , refinement structured form well manually developed plans instructions dataset publicly available community
low latency communications numerous applications demand communication schemes minimize transmission delay achieving given level reliability extreme case high frequency saving fraction route new game communications often carried , links reduce transmission delays large distances due direct faster wave propagation order bridge large distances , information sent multihop relay network r n motivated applications , papers present information theoretic approach design optimal multihop networks minimizes end end transmission delay characterize delay introduced coding , derive error achievable multihop networks formulate solve optimization problem determines optimal selection amplify forward decode forward relays present optimal solution several examples networks prove high snr optimum transmission scheme relays perform amplify forward analyze impact deploying noisy feedback
joint learning correlated sequence tasks using bidirectional recurrent neural networks stream words produced automatic speech recognition \( asr \) systems typically natural language processing applications expect segmented well texts input , available asr output paper proposes novel technique jointly modeling multiple correlated tasks using bidirectional recurrent neural networks , leads improved performance tasks method could extended joint modeling correlated sequence labeling tasks
fast counting via color coding adaptive sampling randomized technique color coding behind state art algorithms estimating graph counts algorithms , however , yet capable scaling well large graphs edges paper develop novel tools counting via color framework result , new algorithm , , able scale well larger graphs time provide accurate counts ever achieved thanks two types improvements first , design new data structures support fast common color coding operations , accuracy versus running time memory usage drastically reduce time memory requirements color coding second , develop adaptive sampling strategy , based fractional set cover problem , breaks additive approximation barrier standard sampling strategy gives multiplicative approximations , allowing us count frequent also extremely rare ones r n give idea improvements , 40 minutes counts 7 nodes graph nodes 1 8 b edges 30 500 times larger state art , respectively terms nodes edges accuracy side , one produces accurate counts approx 10 000 distinct 8 node graphs state art algorithms fail even find second frequent method requires high end machine results show color coding bring mining massive graphs using ordinary hardware
diffuse radius simple polygon shown every simple polygon general position n single point light source lfloor \( n 2 \) 4 rfloor diffuse , bound best possible point property computed \( n log n \) time also shown minimum number diffuse needed given simple polygon single point approximated additive constant polynomial time
sparse signal recovery quadratic measurements via convex programming paper consider system quadratic equations 2 b j , j 1 , , , x r n unknown normal random vectors z j r n quadratic measurements b j r known system assumed , e , n prove exists sparse solution x , e , k components x non zero , solving convex optimization program , solve x multiplicative constant high probability , provided k \( \( log n \) \( 1 2 \) \) hand , prove k \( log n \( \) \( 1 2 \) \) necessary class naive convex relaxations exact
robust closed loop biped locomotion planner based time varying model predictive control developing robust locomotion humanoid robots complex task due nature robots also terrain robust locomotion planner one fundamental components generating stable biped locomotion paper presents optimal closed loop biped locomotion planner plan reference trajectories even challenging conditions proposed planner designed based time varying model predictive control \( \) scheme able consider constraints states , inputs outputs system also mixed input output moreover , proposed planner takes account vertical motion center mass \( com \) generate mostly human like additionally , planner uses concept component motion \( \) reference online improve level robot presence severe performance also robustness proposed planner validated performing several simulations using matlab simulation results show proposed planner capable generating biped locomotion
fast order based approach core maintenance graphs widely used many applications social networks , collaboration networks , biological networks one important graph analytics explore cohesive subgraphs large graph among several cohesive subgraphs studied , k core one computed linear time static graph since graphs evolving real applications , paper , study core maintenance reduce computational cost compute k cores graph graphs updated time time dynamically identify drawbacks existing efficient algorithm , needs large search space find vertices need updated , high overhead maintain index built , graph updated propose new order based approach maintain order , called k order , among vertices , graph updated new algorithm significantly outperform state art algorithm 3 orders magnitude 11 large real graphs tested report findings paper
design non orthogonal beamspace multiple access cellular internet things paper , study problem massive connections limited radio spectrum cellular internet things \( iot \) fifth generation \( 5g \) wireless network address challenging issues associated channel state information \( csi \) acquisition beam design context massive connections , propose new non orthogonal beamspace multiple access framework particular , user \( ues \) non orthogonal temporal frequency domain , also beam domain analyze performance proposed non orthogonal beamspace multiple access scheme , derive upper bound weighted sum rate terms channel conditions system parameters improving performance , propose three non orthogonal transmit beam construction algorithms different beamspace resolutions finally , extensive simulation results show substantial performance gain obtained proposed non orthogonal beamspace multiple access scheme baseline ones
rgb image based data analysis via discrete theory persistent understanding comparing images purposes data analysis currently computationally task group university \( \) recently developed open source code detect fundamental topological features image computationally feasible manner made possible fact computers store images cubical cellular complexes complexes studied using techniques discrete theory expand functionality code introducing methods software analyzing images encoded , , \( rgb \) , image encoding popular publicly available data methods allow extraction key topological information rgb images via informative diagrams introducing novel methods transforming rgb paradigm allows us perform data analysis directly rgb images representing scarcity variability well crime variability introduce software enabling user predict future image properties , towards aim rapid image based data behavior prediction
learning disentangled representations recommendation user behavior data recommender systems driven complex interactions many latent factors behind users' decision making processes factors highly , may range high level ones user , low level ones characterize user 's preference executing learning representations uncover latent factors bring enhanced robustness , interpretability , however , learning disentangled representations user behavior challenging , remains largely existing literature paper , present micro disentangled variational auto encoder \( \) learning disentangled representations user behavior approach achieves disentanglement inferring high level concepts associated user \( e g , \) , capturing preference user regarding different concepts separately micro disentanglement regularizer , information theoretic interpretation , forces dimension representations independently reflect low level factor \( e g , size color \) empirical results show approach achieve substantial improvement state art baselines demonstrate learned representations interpretable controllable , potentially lead new paradigm recommendation users given fine grained control targeted aspects recommendation lists
robust imperceptible adversarial attacks capsule networks capsule networks preserve hierarchical spatial relationships objects , thereby potential performance traditional convolutional neural networks \( cnns \) performing tasks like image classification large body work explored adversarial examples cnns , effectiveness capsule networks yet well studied work , perform analysis study vulnerabilities capsule networks adversarial attacks perturbations , added test inputs , small imperceptible humans , fool network propose greedy algorithm automatically generate targeted imperceptible adversarial examples black box attack scenario show kind attacks , applied german traffic sign recognition benchmark \( \) , capsule networks moreover , apply kind adversarial attacks 5 layer cnn 9 layer cnn , analyze outcome , compared capsule networks study differences behavior
graph convolutional reinforcement learning learning cooperate crucially important multi agent environments key understand mutual interplay agents however , multi agent environments highly dynamic , agents keep moving neighbors change quickly makes hard learn abstract representations mutual interplay agents tackle difficulties , propose graph convolutional reinforcement learning , graph convolution dynamics underlying graph multi agent environment , relation kernels capture interplay agents relation representations latent features produced convolutional layers gradually increased receptive fields exploited learn cooperation , cooperation improved temporal relation regularization consistency empirically , show method substantially outperforms existing methods variety cooperative scenarios
versus solvability promise problems finite classical quantum automata framework papers cite , , concept em promise problems introduced started systematically explored promise problems seen partial em decision problems fundamental decision problems formal languages used considered basic ones complexity theory issues moreover , papers explored cite depth systematically , promise problems context theory main computational complexity classes well context public key cryptography r n present paper variety issues explored concerning dealing promise problems level finite , classical , quantum also semi quantum automata two modes , em em solvability introduced basic properties explored also capture explore case even case promise simple \( say regular \) , disjoint subsets called yes cases addition , results concerning complexity impacts outcomes operations promise problems shown well significant power quantum versions classical automata demonstrated dealing promise problems
social mobility aware device device content delivery mobile online social network services seen rapid increase , huge amount user generated social media contents propagating users via social connections significantly traditional content delivery paradigm first , contents generated users edge servers well fit receivers becomes difficult due limited bandwidth storage capacities motivated device device \( d2d \) communication allows users smart devices transfer content directly , propose bandwidth intensive social contents device device manner based large scale measurement studies social content propagation user mobility patterns edge network regions , observe \( 1 \) device device replication significantly help users social contents nearby neighboring peers \( 2 \) social propagation mobility patterns affect contents replicated \( 3 \) replication strategies depend regional characteristics \( em e g , users move across regions \) r n using measurement insights , propose joint emph propagation mobility aware content replication strategy edge network regions , social contents assigned users edge network regions according joint consideration social graph , content propagation user mobility formulate replication scheduling optimization problem design distributed algorithm using historical , local partial information solve trace driven experiments verify superiority proposal compared conventional pure movement based popularity based approach , design significantly \( 2 4 times \) improve amount social contents successfully device device replication
ruin theory dynamic spectrum allocation lte u networks lte band \( lte u \) promising solution overcome scarcity wireless spectrum however , benefits lte u , essential maintain effective wifi systems , hence , major challenge lte u deployment paper , problem spectrum sharing among wifi lte u system studied particular , fair time sharing model based emph ruin theory proposed share redundant spectral resources band lte u without performance wifi system fairness among wifi lte u maintained applying concept probability ruin particular , probability ruin used perform efficient cycle allocation lte u , provide fairness wifi system maintain certain wifi performance simulation results show proposed ruin based algorithm provides better fairness wifi system compared equal cycle sharing among wifi lte u
breast cancer detector early detection breast cancer screening yields 20 35 increase rate however , enough serve growing population women seeking screening although commercial computer aided detection \( \) software available decades , improve interpretation full field digital \( \) images due low sensitivity spectrum findings work , leverage large set images bounding boxes significant findings train deep learning detector extreme sensitivity building upon work architecture , train model produces segmentation like images high spatial resolution , aim 2d gaussian ground truth boxes replace pixel wise l 2 norm weak supervision loss designed achieve high sensitivity , false positives false noise bounding boxes tolerance predictions resulting system achieves sensitivity findings 0 99 4 8 false positive markers per image utilized system , model could enable novel workflow focus attention trust locations proposed model , interpretation process attention potential findings could otherwise due nearly perfect sensitivity , proposed detector also used high performance proposal generator two stage detection systems
collaborative information bottleneck paper investigates multi terminal source coding problem logarithmic loss fidelity necessarily lead additive distortion measure problem motivated extension information bottleneck method multi source scenario several encoders build rate limited descriptions sources order maximize information respect \( hidden \) sources precisely , study fundamental information theoretic limits called \( \) two way collaborative information bottleneck \( \) \( ii \) collaborative distributed information bottleneck \( \) problems problem consists two encoders separately observe marginal \( dependent \) components x 1 x 2 cooperate multiple limited information aim extracting information hidden variables \( 1 , 2 \) , arbitrarily dependent \( x 1 , x 2 \) hand , two encoders separately observe x 1 x 2 third node two encoders order obtain information hidden variable relevance \( \) measured terms normalized \( per sample \) multi letter mutual information metric \( log loss fidelity \) interesting tradeoff arises constraining complexity descriptions , measured terms rates needed encoders decoders involved inner outer bounds complexity relevance region problems derived optimality characterized several cases interest resulting theoretical complexity relevance regions finally evaluated binary symmetric gaussian statistical models
cyclic nearly cyclic multiagent interactions plane cyclic pursuit local averaging interactions extensively analyzed context multiagent , field distributed robotics paper reviews results structured dynamical systems , discusses application nearly cyclic interactions among n point agents plane , leading interesting limiting geometric configurations particular , consider modeled operator , explain decoupled independent evolving modes , focusing nearly cyclic interactions break symmetry leading factor rather interaction matrices
strong equivalences lpmln programs incorporating methods answer set programming \( asp \) markov logic networks \( \) , lpmln becomes powerful tool non , uncertain knowledge representation reasoning facilitate applications extend lpmln , investigate strong equivalences lpmln programs paper , regarded important property field logic programming field asp , two programs p q strongly equivalent , asp program r , programs p q extended r stable models words , asp program replaced one strong equivalent without considering context , helps us logic programs , enhance inference engines , construct human friendly knowledge bases etc since lpmln combination asp , notions strong equivalences lpmln quite different asp firstly , present notions p strong w strong equivalences lpmln programs secondly , present characterization notions generalizing model approach asp finally , show use strong equivalences lpmln programs , present sufficient necessary syntactic condition guarantees strong equivalence single lpmln rule program
scalable katz ranking computation large static dynamic graphs network analysis defines number centrality measures identify central nodes network fast computation measures major challenge algorithmic network analysis , katz centrality one established centrality measures paper , consider problem computing rankings katz centrality particular , propose upper lower bounds katz score given node previous approaches relied numerical approximation heuristics compute katz centrality rankings , construct algorithm iteratively improves upper lower bounds correct katz ranking obtained extend algorithm dynamic graphs maintaining correctness guarantees experiments demonstrate static graph algorithm outperforms numerical approaches heuristics 1 5x 3 5x , depending desired quality guarantees dynamic graph algorithm improves upon static algorithm update less edges provide efficient parallel cpu gpu implementations algorithms enable near real time katz centrality computation graphs hundreds millions nodes seconds
efficient computation population counts using simd instructions several fields statistics , machine learning , , categorical variables frequently represented one encoded vectors example , given 8 distinct values , map value single bit set motivated quickly compute statistics encodings given stream k bit words , seek compute k distinct sums corresponding bit values indexes 0 , 1 , 2 , , k 1 k bit words one encoded sums correspond frequency histogram multiple sum problem generalization population count problem seek sum bit values accordingly , refer multiple sum problem population count using simd \( single instruction , multiple data \) instructions recent intel processors , describe algorithms computing 16 bit position population count using less half cpu cycle per 16 bit word best approach uses times fewer instructions 50 times faster baseline code using regular \( non simd \) instructions , sufficiently large inputs
robustness graph perturbations despite interest graph neural networks little effort verify improve robustness even given recent findings showing extremely vulnerable adversarial attacks graph structure node attributes propose first method \( non \) robustness graph perturbations general class models includes graph neural networks label feature propagation exploiting connections pagerank markov decision processes efficiently \( many threat models exactly \) computed furthermore , investigate robust training procedures increase number robust nodes maintaining improving clean predictive accuracy
balancing reconstruction quality trade exists reconstruction quality prior evidence lower bound \( \) loss variational autoencoder \( vae \) models use learning satisfactory approaches deal balance prior reconstruction objective , methods dealing problem heuristics paper , show noise variance \( often set fixed value \) gaussian likelihood p \( x z \) real valued data naturally act provide balance learning noise variance loss , automatically obtain optimal trade reconstruction error prior constraint variance interpreted intuitively necessary noise level current model best explanation observed dataset , allowing variance inference flexible used uncertainty estimator reconstructed generated samples demonstrate noise variance crucial component vae learning , showcase performance mnist , fashion mnist datasets find approach significantly improve quality generated samples whilst maintaining smooth latent space manifold represent data method also offers uncertainty final generative model
divergence scaling fixed length binary output one one distribution matching distribution matching process mapping uniformly distributed input sequence onto sequences approximate output desired discrete memoryless source original input sequence recovered special case binary output alphabet one one mapping studied fixed length distribution matcher proposed optimal sense minimizing divergence output distribution binary memoryless target distribution upper lower bounds divergence computed increase output block length n follows recently proposed constant composition distribution matcher performs within constant gap minimal achievable divergence
learning sparse neural networks via ell 0 ell 1 relaxed variable splitting method application multi scale curve classification study convolutional neural networks \( cnn \) relaxed variable splitting method ell 0 transformed ell 1 \( ell 1 \) , application complex curves texts written different , words written 's disease patients cnn contains 3 convolutional layers , followed maximum pooling , finally fully connected layer contains largest number network weights ell 0 penalty , achieved 99 test accuracy distinguishing vs regular hand 86 weights fully connected layer zero comparable sparsity test accuracy also proper choice ell 1 penalty
almost perfect privacy additive gaussian privacy filters study maximal mutual information random variable \( representing non private information \) additive gaussian channel guaranteeing epsilon bits information random variable x \( representing private information \) correlated quantity g epsilon \( x , \) , show perfect privacy , e , epsilon 0 , one g 0 \( x , \) 0 pair continuous random variables \( x , \) derive second order approximation g epsilon \( x , \) small epsilon approximation shown related strong data processing inequality mutual information suitable conditions joint distribution p next , motivated operational interpretation data privacy , formulate privacy utility tradeoff setup using estimation theoretic quantities obtain explicit bounds tradeoff epsilon sufficiently small using approximation formula derived g epsilon \( x , \)
np lower bounds parallel np lower bounds decade , paper developed certain cases allows one prove problems hard parallel access np however , problems toolkit applies directly overly natural past year , problems previously known np hard hard shown hard even class sets solvable via parallel access np many problems extremely natural , minimum equivalent expression problem \( original motivation creating polynomial hierarchy \) , problem determining winner election system introduced , problem determining inputs heuristic algorithms perform well present article , survey recent progress lower bounds
distributed storage systems distributed storage codes recently received lot attention community independently , another body work proposed integrity checking schemes cloud storage , none , however , customized coding based storage efficiently support repair work , bridge gap two currently work propose nc audit , novel cryptography based remote data integrity checking scheme , designed specifically network coding based distributed storage systems nc audit combines , first time , following desired properties \( \) efficient checking data integrity , \( ii \) efficient support nodes , \( iii \) protection information leakage checking performed third party key ingredient design nc audit novel combination , homomorphic message authentication code \( mac \) scheme network coding , , novel chosen attack \( \) secure encryption scheme compatible evaluation java implementation nc audit shows audit costs storage node modest amount computation time lower bandwidth prior work
hybrid consensus protocol introduce , new consensus algorithm public blockchain settings consistency protocol merging proof work \( \) proof \( \) coherent stochastic process encompasses hardware economic security without sacrificing availability , empirical results indicate proposed protocol fair scalable arbitrary number miners
n 8 x n 7 linear programming model quadratic assignment problem paper theorem 21 22 error modeling idea , needs 9 dimensional variables instead 8 dimensional variables defined 6 9 r n examples correct model \( 9 index variables \) \( 1 \) , , linear programming formulation set partitioning problem , international journal operational research 8 4 \( 2010 \) pp \( 2 \) , , linear programming formulation vertex problem , international journal mathematics operational research 2 3 \( may 2010 \) pp \( 3 \) , , problem linear programming formulation , transactions mathematics , 6 6 \( \) pp
characterizing twitter verified user network social network platforms , twitter , support concept verification verified accounts platform wide public interest separately authenticated platform repeated platforms verification however , significant body prior work suggests verified status enhanced platform result , status highly among public hence , attempt characterize network verified users twitter compare results similar analysis performed entire twitter network extracted entire network verified users twitter \( 2018 \) obtained , user profiles 79 , , connections subsequently network analysis , found sub graph verified users full twitter users graph aspects short diameter however , findings contrast earlier findings multiple aspects , power law degree distribution , slight significantly higher reciprocity rate , paper moreover , attempt presence salient components within sub graph detect absence respect popularity , contrast full twitter graph finally , demonstrate time series verified user activity levels best knowledge , work represents first quantitative attempt characterizing verified users twitter
adaptive ddos attack detection method based multiple kernel learning distributed service \( ddos \) attacks caused huge economic losses society become one main threats internet security current detection methods based single feature fixed model parameters cannot effectively detect early ddos attacks cloud big data environment paper , adaptive ddos attack detection method \( \) based multiple kernel learning \( \) proposed based ddos attack flow , distribution addresses communication , define five features describe network flow characteristic based ensemble learning framework , weight dimension adaptively increasing inter class mean gradient reducing intra class variance gradient descent , classifier established identify early ddos attack training simple multiple kernel learning \( smkl \) models two characteristics including inter class mean squared difference growth \( smkl \) intra class variance descent \( smkl \) sliding window mechanism used coordinate smkl smkl detect early ddos attack experimental results indicate method detect ddos attacks early accurately
enabling continuous learning neural network evolution hardware modern deep learning systems rely \( \) hand tuned neural network topology , \( b \) massive amounts labeled training data , \( c \) extensive training large scale compute resources build system perform efficient image classification speech recognition unfortunately , still far away implementing adaptive general purpose intelligent systems would need learn autonomously unknown environments may access three components reinforcement learning evolutionary algorithm \( \) based methods circumvent problem continuously interacting environment updating models based obtained rewards however , deploying algorithms ubiquitous autonomous agents edge \( robots drones \) demands extremely high energy efficiency due \( \) tight power energy , \( ii \) continuous interaction environment , \( iii \) connectivity cloud run heavy weight processing address need , present , prototype based learning system , comprises closed loop learning engine called eve inference engine called adam eve evolve topology weights neural networks completely hardware task hand , without requiring hand optimization backpropagation training adam continuously environment optimized efficiently running irregular neural networks generated eve identifies leverages multiple unique parallelism unique term level parallelism , level parallelism suite environments observed 2 5 orders magnitude higher energy efficiency state art embedded cpu gpu systems
network games consider network game , nodes improve communication costs connecting high speed network n nodes connected static network node decide individually become high speed network goal node v minimize private costs , e , sum \( sum game \) maximum \( max game \) communication distances v nodes plus fixed price alpha 0 communication distance 0 , also improve distances shortcuts sum game , show alpha leq n 1 , price anarchy theta \( n sqrt alpha \) range equilibria always exist range alpha \( n 1 , n \( n 1 \) \) price anarchy theta \( sqrt alpha \) , alpha geq n \( n 1 \) constant max game , show price anarchy either theta \( 1 n sqrt alpha \) , alpha geq 1 , 1 given graph girth least 4 alpha , equilibria always exist concerning dynamics , sum game max game potential games sum game , even show weakly acyclic
computing fr e chet distance shortcuts np hard study shortcut fr ' e chet distance , natural variant fr ' e chet distance , allows us take shortcuts point along one curves classic fr distance distance measure hence quite sensitive outliers shortcut fr ' e chet distance allows us cut across outliers hence produces significantly meaningful results dealing real world data har recently described approximation algorithms restricted case shortcuts start end input vertices show , general case , problem computing shortcut fr ' e chet distance np hard first hardness result variant fr ' e chet distance two curves plane also present two algorithms decision problem 3 approximation algorithm general case exact algorithm vertex restricted case algorithms run \( n 3 log n \) time
planning information processing constraints model uncertainty markov decision processes information theoretic principles learning proposed solve particular classes markov decision problems mathematically , approaches variational free energy principle allow solving mdp planning problems information processing constraints expressed terms kullback leibler divergence respect reference distribution consider generalization mdp planners taking model uncertainty account model uncertainty also formalized information processing constraint , derive unified solution single generalized variational principle provide generalized value iteration scheme together convergence proof limit cases , generalized scheme includes standard value iteration known model , bayesian mdp planning , robust planning demonstrate benefits approach grid world simulation
decoupled deep neural network semi supervised semantic segmentation propose novel deep neural network architecture semi supervised semantic segmentation using heterogeneous annotations existing approaches semantic segmentation single task region based classification , algorithm classification segmentation , learns separate network task architecture , labels associated image identified classification network , binary segmentation subsequently performed identified label segmentation network decoupled architecture enables us learn classification segmentation networks separately based training data image level pixel wise class labels , respectively facilitates reduce search space segmentation effectively exploiting class specific activation maps obtained bridging layers algorithm shows performance compared semi supervised approaches even much less training images strong annotations pascal voc dataset
compactness implementation flexibility shape may suggest whether drawn political , reason , quantifying shape , particular compactness , key task growing body literature suggests analyzes compactness measures mathematically , little consideration given scores calculated practice , consider effects number decisions must made interpreting implementing set popular compactness scores show choices made quantifying compactness may become political tools , decisions leading disparate scores show full range implementation flexibility used , make clearly appear quantitatively reasonable using compactness standard practices paper release packages c , python , r correctly , efficiently , calculate variety compactness scores
layer semantic segmentation propose convolutional layer semantic segmentation objective enhancing capabilities neural networks multi scale processing layers adaptively change size effective receptive field based processed context generate powerful features achieved multiple convolutional layers different rates , combined attention mechanism learns focus optimal scales driven context sharing weights parallel convolutions make network scale invariant , modest increase number parameters proposed layer easily integrated existing networks improve model 's power evaluate models challenging tasks multi segmentation ct brain tumor segmentation mri achieve promising performance
learning cross modality encoder representations transformers vision language reasoning requires understanding visual concepts , language semantics , , importantly , alignment relationships two modalities thus propose \( learning cross modality encoder representations transformers \) framework learn vision language connections , build large scale transformer model consists three encoders object relationship encoder , language encoder , cross modality encoder next , model capability connecting vision language semantics , pre train model large amounts image sentence pairs , via five diverse representative pre training tasks masked language modeling , masked object prediction \( feature regression label classification \) , cross modality matching , image question answering tasks help learning intra modality cross modality relationships fine tuning pre trained parameters , model achieves state art results two visual question answering datasets \( e , vqa \) also show pre trained cross modality model adapting challenging visual reasoning task , nlvr2 , improve previous best result 22 absolute \( \) lastly , demonstrate detailed ablation studies prove novel model components pre training strategies significantly contribute strong results also present several attention different encoders code pre trained models publicly available https url
busy machines heuristic busy well known specific example non computable function whilst many aspect problem investigated , always easy find thorough convincing evidence claims made particular machines , size numbers involved means obvious problem addressed paper address issues discuss framework busy problem similar problems may addressed , appropriate processes providing evidence claims made also show simple heuristic , call , used evaluate machines extremely large number execution steps required also show empirical results implementation heuristic show heuristic effective known machines
optimal merging high speed lane dedicated connected autonomous vehicles future , high vehicle \( hov \) dedicated might restricted autonomous vehicles , e g connected vehicles motion control vehicles would likely travel high new criteria merging vehicle proposed reduce flow , gaps , within , considered minimize hov lane time , vehicle acceleration , optimal merge position determined simulations linear combinations deviation equilibrium vehicle velocity differences merging vehicle lead vehicle \( hov lane \) vehicle \( hov lane \) merging vehicle merging vehicle , due acceleration limitations , generally merge significantly lower velocity hov lane average velocity queue vehicles held suitable gap approach
attention based information fusion using multi encoder decoder recurrent neural networks number devices sensors , modeling distributed sensor networks increasing interest recurrent neural networks \( rnn \) considered particularly well suited modeling sensory streaming data predicting future behavior , incorporating information neighboring sensor stations often beneficial propose new rnn based architecture context specific information fusion across multiple spatially distributed sensor stations , latent representations multiple local models , modeling one sensor station , weighted , according importance prediction particular importance assessed depending current context using separate attention function demonstrate effectiveness model three different real world sensor network datasets
new benchmark approach fine grained cross media retrieval cross media retrieval return results various media types corresponding query media type existing generally focus coarse grained cross media retrieval users image query , coarse grained cross media retrieval treats , users get results , may include species similar appearance \( image video \) , descriptions \( text \) \( audio \) , coarse grained cross media retrieval consistent human , generally fine grained requirement exactly relevant results instead however , focus fine grained cross media retrieval , highly challenging practical task therefore , paper , first construct new benchmark fine grained cross media retrieval , consists 200 fine grained , contains 4 media types , including image , text , video audio best knowledge , first benchmark 4 media types fine grained cross media retrieval , propose uniform deep model , namely , simultaneously learns 4 types media without discriminative jointly consider three constraints better common representation learning classification constraint ensures learning discriminative features fine grained , center constraint ensures compactness characteristic features , ranking constraint ensures sparsity characteristic features different extensive experiments verify usefulness new benchmark effectiveness new benchmark source code made available https github com
construction sequences high nonlinear complexity function field provide sequence high nonlinear complexity function field mathcal h mathbb f q 2 sequence obtained using rational function certain ell rational places mathcal h , 2 leq ell leq q particular improve lower bounds k th order nonlinear complexity obtained h c , f
transfer learning auxiliary discriminative task unsupervised anomaly detection unsupervised anomaly detection high dimensional data like mobility networks challenging task study different approaches feature engineering high dimensional data focus research field study aims investigate transferability features learned network classification unsupervised anomaly detection propose use auxiliary classification task extract features unlabelled data supervised learning , used unsupervised anomaly detection validate approach designing experiments detect anomalies mobility network data new , compare results traditional unsupervised feature learning approaches pca autoencoders find feature learning approach yields best anomaly detection performance datasets , outperforming studied approaches utility approach feature engineering , applied problems similar nature
efficient identity based batch verification scheme based ring signature vehicular ad hoc networks \( \) one important components intelligent transportation system \( \) , aims provide information communication vehicles safety critical vehicular communication requires security , privacy , , efficiency satisfy requirements simultaneously , several conditional privacy preserving authentication schemes proposed employing ring signature however , methods paid little attention issues like textit choose valid ring members textit set ring paper , introduce efficient conditional privacy preserving scheme provides appropriate approach establishing list ring members moreover , proposed scheme also supports batch verification significantly reduce computational cost according analysis security , scheme sufficiently several common attacks performance results show proposed scheme efficient practical low computation communication cost
bilinear faster rcnn image tampering detection technological advances leading increase mechanisms image tampering , detection methods must continue match one problem current methods require prior knowledge method order determine features extract image localize region interest machine learning algorithm used learn different types tampering large set various image types , big enough database easily classify images \( training entire image feature map image \) , still left question features train , localize manipulation solve , object detection networks faster rcnn , combine \( region proposal network \) cnn recently adapted detection utilizing ability propose bounding boxes objects interest localize tampering artifacts work , existing bilinear faster rcnn model developed modified second stream input \( error level analysis \) jpeg compression level mask
collaborative learning mitigating poisoning attacks client side detection collaborative learning allows multiple clients train joint model without sharing data client performs training locally model updates central server aggregation since server visibility process generating updates , collaborative learning vulnerable poisoning attacks malicious client generate update introduce functionality joint model existing solutions detecting updates , however , fail recently proposed attacks , especially non setting paper , present novel defense scheme detect anomalous updates non settings key idea realize client side cross validation , update evaluated local data server weights updates based evaluation results performing aggregation adapt distribution data non setting , dynamic client allocation mechanism designed assign detection tasks suitable clients detection process , also protect client level privacy prevent malicious clients training data clients , integrating differential privacy design without detection performance experimental evaluations two real world datasets show scheme significantly robust two representative poisoning attacks
one shot neural architecture search posteriori distribution guided sampling emergence one shot approaches greatly advanced research neural architecture search \( nas \) recent approaches train parameterized super network \( one shot model \) sample evaluate number sub networks , weights one shot model overall searching cost significantly reduced training sub networks however , network sampling process treated weights independently trained super network perform sub optimally sub networks paper , propose novel one shot nas scheme address issues key innovation explicitly estimate joint posteriori distribution network architecture weights , sample networks evaluation according brings two benefits first , network sampling guidance posteriori probability efficient conventional random uniform sampling second , network architecture weights sampled pair alleviate sub optimal weights problem note estimating joint posteriori distribution trivial problem adopting variational methods introducing hybrid network representation , distribution approximation problem end end neural network training problem variational dropout result , proposed method reduces number sampled sub networks orders magnitude validate method fundamental image classification task results cifar 10 , cifar 100 imagenet show method best trade precision speed among nas methods cifar 10 , speed searching process achieve higher precision best network found existing nas methods
unsupervised learning classifier competitive error performance unsupervised learning classification model described achieves classification error probability competitive popular supervised learning classifiers svm model based incremental execution small step shift rotation operations upon selected discriminative arrival input samples applied , conjunction selected feature , subset imagenet dataset benchmark , yields 6 2 top 3 probability error exceeds merely 2 result achieved \( supervised \) k nearest neighbor , using feature result may also popular unsupervised learning schemes k means shown practically dataset
geometric maximum problem consider problem cities points r fixed distances computed according geometric distances , determined norm show polyhedral norm , problem finding tour maximum length solved polynomial time arithmetic operations assumed take unit time , algorithms run time \( n f 2 log n \) , f number determining polyhedral norm thus example \( n 2 log n \) algorithms cases points plane rectilinear norms contrast fact finding minimum length tour case np hard approach extended general case quasi norms necessarily symmetric unit ball , get complexity \( n 2 log n \) r n special case two dimensional metrics f 4 \( includes rectilinear norms \) , present simple algorithm \( n \) running time algorithm use addressing , running time remains valid even comparison based models sorting requires omega \( n log n \) time basic mechanism algorithm provides intuition polyhedral norms allow fast algorithms r n results simplicity polyhedral norms , prove case euclidean distances r 2 , maximum tsp np hard sheds new light well studied difficulties euclidean distances
self attentional models lattice inputs lattices efficient effective method encode ambiguity systems natural language processing tasks , example capture multiple speech recognition hypotheses , represent multiple linguistic analyses previous work extended recurrent neural networks model lattice inputs achieved improvements various tasks , models suffer slow computation paper extends recently proposed paradigm self attention handle lattice inputs self attention sequence modeling technique inputs one another computing pairwise similarities gained popularity strong results computational efficiency extend models handle lattices , introduce probabilistic reachability masks incorporate lattice structure model support lattice scores available also propose method adapting embeddings lattice structures apply proposed model speech translation task find outperforms baselines much faster compute previous neural lattice models training inference
deep matching prior network toward tighter multi oriented text detection detecting scene text challenging task multi orientation , perspective distortion , variation text size , color scale research focused using rectangular bounding box sliding window localize text , may result redundant background noise , even information loss address issues , propose new convolutional neural networks \( cnns \) based method , named deep matching prior network \( \) , detect text tighter first , use sliding several specific intermediate convolutional layers roughly recall text higher overlapping area shared monte carlo method proposed fast accurate computing areas , designed sequential protocol relative regression exactly predict text compact moreover , auxiliary smooth loss also proposed position text , better overall performance l2 loss smooth l1 loss terms robustness stability effectiveness approach evaluated public word level , multi oriented scene text database , 2015 robust reading competition challenge 4 scene text localization performance method evaluated using f measure found 70 64 , outperforming existing state art method f measure 63
ergodic capacity analysis wireless af relaying systems alpha fading channels paper , consider two hop amplify forward \( af \) relaying system , relay node energy constrained energy source node literature , three main energy harvesting \( eh \) protocols , namely , time relaying \( \) , power splitting \( ps \) relaying \( \) ideal relaying receiver \( \) unlike existing studies , paper , consider fading channels respect , derive accurate unified analytical expressions ergodic capacity protocols independent distributed \( n \) fading channels three special cases model , namely , rayleigh , fading channels investigated analysis verified numerical simulation results shown finding optimal value ps factor protocol eh time fraction protocol crucial step achieving best network performance
fog without fog deep multimodal sensor fusion unseen weather fusion multimodal sensor streams , camera , lidar , measurements , plays critical role object detection autonomous vehicles , base decision making inputs existing methods exploit redundant information good conditions , fail weather sensory streams distorted rare scenarios represented available datasets , existing fusion architectures designed handle address data challenge present novel multimodal dataset acquired 10 , 000 driving although dataset first large multimodal dataset weather , labels lidar , camera , gated sensors , facilitate training extreme weather rare end , present deep fusion network robust fusion without large corpus labeled training data covering distortions proposal level fusion , propose single shot model adaptively features , driven measurement entropy validate proposed method , trained clean data , extensive validation dataset dataset models published
hilbert epsilon operator choice abstract hilbert hilbert 's e operator relevant proof theoretic semantically , left e operator briefly literature semantics hilbert 's epsilon operator , propose new semantics following features avoid \( right uniqueness \) , admit choice , choice , classical logics moreover , semantics e proof search natural sense cases interpretation articles natural language
cityflow multi agent reinforcement learning environment large scale city traffic scenario traffic signal control emerging application scenario reinforcement learning besides important problem affects people 's daily life commuting , traffic signal control poses unique challenges reinforcement learning terms adapting dynamic traffic environment coordinating thousands agents including vehicles pedestrians key factor success modern reinforcement learning relies good simulator generate large number data samples learning commonly used open source traffic simulator , however , scalable large road network large traffic flow , study reinforcement learning traffic scenarios motivates us create new traffic simulator cityflow fundamentally optimized data structures efficient algorithms cityflow support flexible definitions road network traffic flow based synthetic real world data also provides user friendly interface reinforcement learning importantly , cityflow times faster capable supporting city wide traffic simulation interactive render monitoring besides traffic signal control , cityflow could serve base transportation studies create new possibilities test machine learning methods intelligent transportation domain
np completeness results graph burning geometric graphs graph burning runs discrete time steps aim graph burning problem vertices given graph least amount time steps least number required time steps known burning number graph spread social influence , , social modeled using graph burning less burning number , spread r n computationally , graph burning hard already proved burning path , graphs , trees maximum degree three np complete work study graph burning geometric graphs show np completeness results several sub classes precisely , show burning problem np complete interval graph , permutation graph disk graph
formal connections template models via approximate simulation reduced order template models like linear inverted \( \) inverted \( \) widely used tools controlling high dimensional humanoid robots however , connections whole body models formal , preventing formal guarantees comes integrated controller design take small step towards addressing gap considering notion approximate simulation derived simulation relations discrete transition systems formal methods , approximate similarity means outputs two systems remain epsilon close paper , consider case controlling via planning model show approximately derive linear constraints sufficient conditions maintaining ground allows rapid planning template model solving quadratic program constraints full model demonstrate efficacy planning control paradigm simulated recovery scenario planar 4 link
sparse vector recovery gaussian message passing low cost message passing \( mp \) algorithm recognized promising technique sparse vector recovery however , existing mp algorithms either focus mean square error \( mse \) value recovery ignoring sparsity requirement , support error rate \( ser \) sparse support \( non zero position \) recovery ignoring value novel low complexity gaussian mp \( \) proposed perform value recovery well support recovery particularly , proposed , support related messages value related gaussian messages jointly processed assist addition , strict lower bound developed mse via aided minimum mean square error \( ga mmse \) method ga mmse lower bound shown tight high signal noise ratio numerical results provided verify advantage terms final mse , ser convergence speed
modeling behaviors situations demonstrations paper presents learning demonstration approach programming safe , autonomous behaviors driving scenarios simulation used create targeted driving situation , one containing road side creating significant occlusion urban neighborhood , collect optimal driving behaviors 24 users paper employs key frame based approach combined algorithm linearly combine models order extend behavior novel variations target situation approach theoretically agnostic kind framework used modeling data results suggest generalizes well variations containing additional number occurring sequence linear combination algorithm analysis driving data , also suggests decision making algorithms need consider trade road rules immediate rewards tackle complex cases
predicting basic level concept hierarchy basic level , according experiments cognitive , level abstraction hierarchy concepts humans perform tasks greater accuracy levels argue applications use concept hierarchies knowledge graphs , could significantly improve user interfaces concepts basic level concepts paper examines extent basic level learned data test utility three types concept features , inspired basic level theory lexical features , structural features frequency features evaluate approach , create training set manually labelled examples includes concepts different domains findings include basic level concepts accurately identified within one domain concepts difficult label humans also classify automatically experiments provide insight classification performance across domains could improved , necessary identification basic level concepts larger scale
two stream convolutional networks dynamic saliency prediction recent years , visual saliency estimation images much attention computer vision community however , predicting saliency videos received little attention inspired recent success deep convolutional neural networks based static saliency mod els , work , study two different two stream networks dynamic saliency prediction prove generalization capability models , also introduce novel , empirically data tion technique task test models dataset report superior results existing mod els moreover , perform transfer learning experiments , recently proposed static saliency dataset , finetuning models optical flows estimated static images experiments show taking motion account way helpful static saliency estimation
empirical review java program repair tools large scale experiment 2 bugs 23 repair attempts past decade , research test suite based automatic program repair grown significantly year , new approaches implementations major software engineering however , approaches evaluated single benchmark bugs , also rarely researchers paper , present large scale experiment using 11 java test suite based repair tools 5 benchmarks bugs goal better understanding current state automatic program repair tools large diversity benchmarks investigation guided hypothesis repair tools might generalized across different benchmarks bugs found 11 tools 1 \) able generate patches 21 bugs 5 benchmarks , 2 \) better performance compared benchmarks , generating patches bugs compared 10 30 bugs benchmarks experiment comprises 23 , repair attempts total , used find causes non patch generation causes reported paper , help repair tool designers improve techniques tools
compression data streams information content according complexity , every finite binary string shortest code information content effectively investigate extent holds infinite binary sequences \( streams \) devise new coding method uniformly codes every stream x random stream , way first n bits x first \( x n \) bits , partial computable information content measure defined x , x n initial segment x length n consequence , g computable upper bound initial segment prefix free complexity x , x computable random oracle use g \( making use computable bound g \) one achieve oracle use bounded k \( x n \) log n provides strong shannon 's source coding theorem algorithmic information theory
trajectory based optimal segment computation road network databases finding location new facility facility maximal number customers challenging problem existing studies either model customers static sites thus consider customer movement , focus theoretical aspects provide solutions shown empirically scalable given road network , set existing facilities , collection customer route , optimal segment query returns optimal road network segment \( \) new facility propose practical framework computing query , route traversal assigned score distributed among road segments route according score distribution model query returns road segment \( \) highest score achieve low latency , essential large search space propose two algorithms adopt different approaches computing query algorithm uses graph augmentation , uses iterative road network partitioning empirical studies real data sets demonstrate algorithms capable offering high performance realistic settings
semantic segmentation deep convolutional neural networks total variation segmentation segmentation ubiquitous requirement digital due large variability biological tissue , machine learning techniques shown superior performance standard image processing methods part segmentation challenge , present learning based algorithm segment tissue benign cancer images according protocol two deep convolutional neural networks \( cnn \) trained pixel classifiers cnn predictions regularized using ground segmentation based weighted total variation produce final segmentation result two test sets , approach achieves tissue classification accuracy 98 94 , making use inherent capability system distinguish benign tissue
beyond sentiment analysis pure emotion lexicon sentiment analysis aims uncover emotions information form , performed basis , goal classify information positive negative emotion recent research explored ways capture emotions go beyond methods work , require critical resource lexicon appropriate task hand , terms range emotions captures diversity past , sentiment analysis created experts , behavioural , strict rules lexicon evaluation also performed experts gold paper , propose method lexicon acquisition , scalable , cost effective , n't require experts gold also compare crowd expert evaluations lexicon , assess overall lexicon quality , evaluation capabilities crowd
optimal hashing based time space trade offs approximate near neighbors see paper full abstract r n show tight upper lower bounds time space trade offs c approximate near neighbor search problem dimensional euclidean space n point datasets , develop data structure space n 1 rho u \( 1 \) \( \) query time n rho q \( 1 \) n \( 1 \) every rho u , rho q geq 0 begin equation c 2 sqrt rho q \( c 2 1 \) sqrt rho u sqrt 2 1 end equation r n first data structure achieves sublinear query time near linear space every approximation factor c 1 , improving upon , 2015 data structure long line work problem space regimes builds locality sensitive filtering , , , , soda 2016 data dependent hashing , , , , soda 2014 , , 2015 r n matching lower bounds two types conditional first , prove whole trade restricted model computation , captures known hashing based approaches show cell probe lower bounds one two match trade rho q 0 , improving upon best known lower bounds , , , 2010 particular , first space lower bound \( static data structure \) two polynomially smaller one probe bound show result two , establish exploit connection locally codes
contextual language model adaptation conversational agents statistical language models \( lm \) play key role automatic speech recognition \( asr \) systems used conversational agents asr systems provide high accuracy variety speaking styles , domains , vocabulary paper , present dnn based method adapt lm user agent interaction based generalized contextual information , predicting optimal , context dependent set lm interpolation weights show framework contextual adaptation provides accuracy improvements different possible mixture lm partitions relevant \( 1 \) goal oriented conversational agents 's natural partition data requested application \( 2 \) non goal oriented conversational agents data using topic labels come predictions topic classifier obtain relative improvement 3 1 pass decoding strategy 6 2 pass decoding framework , model also show 15 relative improvement recognizing named entities significant value conversational asr systems
multimodal style transfer via graph cuts assumption widely used recent neural style transfer methods image styles described global deep features like gram covariance matrices alternative approaches represented styles local pixel neural patches despite recent progress , existing methods treat semantic patterns style image uniformly , resulting results complex styles paper , introduce flexible general universal style transfer technique multimodal style transfer \( mst \) mst explicitly considers matching semantic patterns content style images specifically , style image features clustered sub style components , matched local content features graph cut formulation reconstruction network trained transfer sub style render final result also generalize mst improve existing methods extensive experiments demonstrate superior effectiveness , robustness , flexibility mst
blockchain based liability attribution framework autonomous vehicles autonomous vehicles auto insurance liability model compared current model liability largely attributed driver , autonomous vehicles consideration entities including auto , software provider , service vehicle owner proliferation sensors connecting technologies autonomous vehicles enables autonomous vehicle sufficient data liability attribution , yet increased connectivity vehicle attacks interacting entities possibilities motivate potential entities collision event liability data collected vehicular sensors vehicular communications integral part evidence liability event , also need record interactions entities identify potential instances may role paper , propose blockchain \( bc \) based framework integrates entities liability model provides evidence liability attribution first describe liability attribution model , identify key requirements describe adversarial capabilities entities also , present detailed description data contributing evidence framework uses bc partitions bc data access relevant bc participants finally , conduct security analysis verify identified requirements met resilience proposed framework identified attacks
multi label methods prediction sequential data number methods available classification multi label data increased rapidly recent years , yet relatively links made related task classification sequential data labels indices considered time indices , problems often seen equivalent paper detect elaborate connections multi label methods markovian models , study suitability multi label methods prediction sequential data study draw upon suitable techniques area develop two novel competitive approaches applied either kind data carry empirical evaluation investigating performance real world sequential prediction tasks demand , route prediction well showing several popular multi label algorithms fact easily applicable tasks , novel approaches , benefit unified view areas , prove competitive established methods
apply chinese radicals neural machine translation deeper character level neural machine translation \( nmt \) , researchers face challenge seen \( vocabulary \) words translation solve , researchers propose splitting languages english german sub words paper , try address issue improve nmt language chinese whose characters even sophisticated composition integrate chinese radicals nmt model different settings address unseen words challenge chinese english translation hand , also considered semantic part system since chinese radicals usually carry essential meaning words constructed meaningful radicals new characters integrated nmt systems models use attention based nmt system strong baseline system experiments standard chinese english nist translation shared task data 2006 show designed models outperform baseline model wide range state art evaluation metrics including , , character , addition traditional nist scores , especially level translation also interesting findings results various experiment settings performance words characters chinese nmt , different languages instance , full character level nmt may perform well state art languages researchers demonstrated recently , however , chinese nmt model , word boundary knowledge important model learning
subsets counting problems show two problems computing n times n matrix operatorname poly \( n \) bit counting number cycles directed n vertex operatorname exp \( operatorname poly \( n \) \) edges reduced relatively smaller instances effect derive first deterministic algorithms two problems run \( 2 n \) time worst case classic operatorname poly \( n \) 2 n time algorithms two problems known since early 's algorithms run 2 n omega \( sqrt n log n \) time
neural block sampling efficient monte carlo inference often requires manual construction model specific proposals propose approach automated proposal construction training neural networks provide fast approximations block learned proposals generalize occurrences common structural within given model across models , allowing construction library learned inference primitives accelerate inference unseen models model specific training required explore several applications including open gaussian mixture models , learned proposals outperform hand tuned , real world named entity recognition task , 's ability local modes yields higher final f1 scores single site
matching features without descriptors implicitly matched interest points extraction matching interest points many geometric computer vision problems traditionally , matching achieved assigning descriptors interest points matching points similar descriptors paper , propose method interest points instead already implicitly matched detection time , descriptors need calculated , stored , , matched achieved convolutional neural network multiple output channels thought collection variety detectors , specialized specific visual features paper describes design train network way results successful relative pose estimation performance despite limitation interest point count overall matching score slightly lower traditional methods , approach free thus enables localization systems significantly smaller memory multi agent localization systems lower bandwidth requirements network also outputs confidence specific interest point resulting valid match evaluate performance relative state art alternatives
private approximations moment matrix using existing techniques linear regression introduce three differentially private algorithms approximates moment matrix data algorithm , contrast existing algorithms output positive definite matrices , correspond existing techniques linear regression literature specifically , discuss following three techniques \( \) regression , propose setting regularization coefficient approximating solution using transform preserve privacy \( ii \) show adding small batch random samples data preserves differential privacy \( iii \) show sampling moment matrix bayesian posterior inverse distribution differentially private provided prior set correctly also evaluate techniques experimentally compare existing analyze algorithm et al
unsupervised concatenation hashing sparse constraint cross modal retrieval advantage low storage cost high efficiency , hashing learning received much attention retrieval field multiple modal data representing common object semantically complementary , many works focus learning unified binary codes however , works ignore importance manifold among data fact , still interesting problem directly preserve local manifold structure among samples hamming space since different modalities , adopt concatenated feature multiple modality feature represent original object framework , locally linear embedding locality preserving projection introduced reconstruct manifold structure original space hamming space besides , norm regularization projection matrices exploit discriminative features different modalities simultaneously extensive experiments performed evaluate proposed method , dubbed unsupervised concatenation hashing \( \) , three publicly available datasets experimental results show superior performance outperforming state art unsupervised hashing models
bandlimited field reconstruction wireless sensor networks wireless sensor networks often used environmental monitoring applications context sampling reconstruction physical field one important problems solve focus bandlimited field find conditions network topology reconstruction field successful , given probability review irregular sampling theory , analyze problem using random matrix theory show even irregular spatial distribution sensors may lead successful signal reconstruction , provided number collected samples large enough respect field bandwidth furthermore , give basis analytically determine probability successful field reconstruction
identifying micro blog data containing customer needs design new products services starts identification needs potential customers users many existing methods like observations , surveys , experiments draw upon specific efforts needs individuals time , huge amount user generated content micro freely accessible cost information already analyzed monitor towards existing , yet needs paper , important foundation propose machine learning approach identify posts express needs evaluation tweets e mobility domain demonstrates small share relevant tweets identified remarkable precision recall results applied huge data sets , developed method enable scalable need support innovation across thousands users , thus augment service design tool set available
finding subcube heavy hitters data streams data streams typically items large number dimensions study fundamental heavy hitters problem setting formally , data stream consists dimensional items x 1 , ldots , x n k dimensional subcube subset distinct coordinates 1 , , k subseteq subcube heavy query rm query \( , v \) , v n k , outputs yes f \( v \) geq gamma f \( v \) gamma 4 , f ratio number stream items whose coordinates joint values v subcube heavy hitters query rm \( \) outputs joint values v return yes rm query \( , v \) one dimensional version problem 1 heavily studied data stream theory , databases , networking signal processing subcube heavy hitters problem applicable cases r n present simple reservoir sampling based one pass streaming algorithm solve subcube heavy hitters problem tilde \( gamma \) space optimal poly logarithmic factors given established lower bound worst case , theta \( 2 gamma \) large , goal circumvent quadratic bottleneck r n main contribution model based approach subcube heavy hitters problem particular , assume dimensions related via naive bayes model , without latent dimension assumption , present new two pass , tilde \( gamma \) space algorithm problem , fast algorithm answering rm \( \) \( k gamma 2 \) time work direction model based data stream analysis , much remains explored
decoupled data based approach stochastic optimal control problems paper studies stochastic optimal control problem systems unknown dynamics novel decoupled data based control \( \) approach proposed , solves problem decoupled open loop closed loop fashion shown near optimal first , open loop deterministic trajectory optimization problem solved using black box simulation model dynamical system using standard nonlinear programming \( nlp \) solver linear quadratic \( \) controller designed trajectory dependent system learned using input output experimental data computational examples used illustrate performance proposed approach three benchmark problems
sensitivity conjecture log rank conjecture functions small alternating numbers sensitivity conjecture log rank conjecture among important challenging problems complexity , sensitivity conjecture known hold monotone functions , log rank conjecture f \( x \) f \( x \) monotone functions f , bit wise , respectively paper , extend results functions f alternate values relatively small number times monotone path 0 n 1 n two , contribute recent line research functions small alternating numbers
computing cycles bipartite graphs using degree distribution spectrum graph counting short cycles bipartite graphs fundamental problem interest analysis design low density parity check \( ldpc \) codes vast majority research area focused algorithmic techniques recently , proposed computational technique count number cycles length g bi regular bipartite graph , g girth graph information required computation node degree nodes partition , well eigenvalues adjacency matrix graph \( graph spectrum \) paper , result extended compute number cycles length g 2 , ldots , 2 , bi regular bipartite graphs , well number 4 cycles 6 cycles irregular half regular bipartite graphs , g geq 4 g geq 6 , respectively
gender bias coreference resolution evaluation methods introduce new benchmark , , coreference resolution focused gender bias corpus contains style sentences entities corresponding people referred \( e g , , \) demonstrate rule based , feature rich , neural coreference system link entities higher accuracy anti entities , average difference 21 1 f1 score finally , demonstrate data augmentation approach , combination existing word embedding techniques , removes bias demonstrated systems without significantly affecting performance existing coreference benchmark datasets dataset code available http url
driver identification using sensor data single turn continue advance , cars becoming sensors perform everyday driving operations sensors help car navigate , reduce , provide however , also used learn drivers paper , propose method predict , sensor data collected single turn , identity driver given set individuals problem terms time series classification , dataset contains sensor one turn , repeated several times multiple drivers build classifier find unique patterns individual 's driving style , visible data even short road segment test approach , analyze new dataset collected , test vehicles equipped data storing sensor real show turns particularly well suited detecting variations across drivers , especially compared focus 12 frequently made turns dataset , include , urban , , , obtaining accurate identification results learning useful insights driver behavior variety settings
scholarly twitter metrics twitter popular among data sources form basis called tweets scholarly documents early indicators citations well measures impact chapter provides overview twitter activity basis scholarly metrics critical point view equally describes potential limitations scholarly twitter metrics literature twitter scholarly communication analyzing 24 million tweets linking scholarly documents , aims provide basic understanding tweets cannot measure context research evaluation going beyond limited explanatory power low correlations tweets citations , chapter considers types scholarly documents popular twitter , , order understand tweets scholarly documents measure although chapter able solve problems associated creation meaningful metrics social media , particular issues aims provide basis advanced scholarly twitter metrics
evaluation security solutions android systems increasing usage smartphones security solutions designed developed many security solutions fail cope advanced attacks properly designed smartphone platforms therefore , need methodology evaluate effectiveness since android operating system highest market share today , focus study review state art security solutions android based smartphones addition , present set evaluation criteria aiming evaluating security mechanisms specifically designed android based smartphones believe proposed framework help security solution designers develop effective solutions assist security experts evaluate effectiveness security solutions android based smartphones
auction based approximate algorithm grid system scheduling resource provider strategies paper new mathematical model proposed task scheduling resource allocation grid systems novel model , load balancing , strategies constraints solution restricted predefined quality service users different strategies defined resource providers based amount submitted grid solve proposed model , modern approximate auction based algorithm developed implemented prototype grid simulator namely multi grid results illustrated 18 different large scale grid systems different random capabilities different users outcomes reveal reasonable performance proposed auction based algorithm solve grid system optimization models
texture fields learning texture representations function space recent years , substantial progress achieved learning based reconstruction 3d objects time , generative models proposed generate highly realistic images however , despite success closely related tasks , texture reconstruction 3d objects received little attention research community state art methods either limited low resolution constrained experimental setups major reason limitations common representations texture inefficient hard interface modern deep learning techniques paper , propose texture fields , novel texture representation based continuous 3d function parameterized neural network approach limiting factors like shape discretization , proposed texture representation independent shape representation 3d object show texture fields able represent high frequency texture naturally modern deep learning techniques experimentally , find texture fields compare state art methods conditional texture reconstruction 3d objects enable learning probabilistic generative models unseen 3d models believe texture fields become important building block next generation generative 3d models
regularization effective technique reduce fitting neural networks deep neural networks learning models high capacity therefore prone fitting many regularization techniques dropout , , weight decay attempt solve problem fitting reducing capacity respective models \( et al , 2014 \) , \( et al , 2013 \) , \( , \) paper introduce new form regularization learning problem way reduces fitting without sacrificing capacity model models make early stages training carry information learning problem adjusting labels current training weighted average real labels , exponential average past soft targets achieved regularization scheme powerful dropout without necessarily reducing capacity model , simplified complexity learning problem regularization proved effective tool various neural network architectures
human comprehension fairness machine learning bias machine learning several areas , medicine , hiring , response , computer developed definitions fairness correct bias algorithms definitions based established legal norms , others largely mathematical whether general public fairness definitions , importantly , whether understand definitions take initial steps toward bridging gap ml researchers public , addressing question non technical understand basic definition ml fairness \? develop metric measure comprehension one definition demographic parity validate metric using online surveys , study relationship comprehension sentiment , , application hand
learning constrained hidden markov models robot navigation bridging topological gap hidden markov models \( \) partially observable markov decision processes \( pomdps \) provide useful tools modeling dynamical systems particularly useful representing topology environments road networks , typical robot navigation planning work presented describes formal framework incorporating readily available information constraints models algorithm learns taking advantage information , learning pomdps made generate better solutions require fewer iterations , robust face data reduction experimental results , obtained simulated real robot data , demonstrate effectiveness approach
people spread rumours social media looking conversational threads breaking news people increasingly rely social media latest updates use social media situations comes new information released may encourage rumours , many remain long point release little known , however , dynamics life cycle social media rumour paper present methodology enabled us collect , identify dataset rumour threads \( 4 , tweets \) associated 9 events analyse dataset understand users spread , support , rumours later proven true false , distinguishing two levels status rumour life cycle e , veracity status resolved identification rumours associated event , well resolved rumour true false , performed members research team events real time study shows rumours ultimately proven true tend resolved faster turn false whilst one readily see users rumours , users appear less capable distinguishing true false rumours veracity remains question fact , show users support every rumour also analyse role different types users , finding highly users news post well , appear certain evidence nevertheless , often prove pieces information give rise false rumours study need developing robust machine learning techniques provide assistance real time veracity rumours findings study provide useful insights achieving aim
unsupervised neural bayesian models zero resource speech processing settings unlabelled speech data available , zero resource speech technology needs developed without , dictionaries , language modelling text two central problems zero resource speech processing \( \) finding frame level feature representations make easier linguistic units \( phones words \) , \( ii \) segmenting clustering unlabelled speech meaningful units thesis , argue combination top bottom modelling tackling two problems r n address problem frame level representation learning , present correspondence autoencoder \( cae \) , neural network trained weak top supervision unsupervised term discovery system combining top supervision unsupervised bottom initialization , cae yields much discriminative features previous approaches present unsupervised bayesian model segments clusters unlabelled speech words imposing consistent top segmentation also using bottom knowledge detected boundaries , system outperforms several others multi speaker conversational english speech data finally , show clusters discovered bayesian model made less speaker gender specific using features cae instead traditional acoustic features r n summary , different models systems presented thesis show top bottom modelling improve representation learning , segmentation clustering unlabelled speech data
learning scale backbone recognition localization convolutional neural networks typically encode input image series intermediate features decreasing resolutions structure suited classification tasks , perform well tasks requiring simultaneous recognition localization \( e g , object detection \) encoder decoder architectures proposed resolve applying decoder network onto backbone model designed classification tasks paper , argue encoder decoder architecture generating strong multi scale features scale backbone propose , backbone scale intermediate features cross scale connections learned object detection task neural architecture search achieves state art performance one stage object detector 60 less computation , outperforms resnet counterparts 6 ap architecture transfer classification tasks , achieving 6 top 1 accuracy improvement challenging fine grained dataset
intelligent data context internet things internet things allow us optimize equipment resource usage , enabling increased automation enabling new cost efficient business model tremendous growth opportunities , challenges diverse devices spanning across multiple networks , need manage exponential growth sensor generated data make sense huge data meaningful ways multitude diversity best addressed fundamentally systems , architecture applications go next step exploit value sensor data would require real time analytics gain intelligence events historical analysis used look trends , analyze collections sensor data correlation formulate based usage patterns paper , present framework diversity ability represent sensor data internet business goals driven information processing , information derived intelligence information control elements framework enable creation new innovative applications enhance exploit value internet things
towards general direct product testing theorem direct product encoding string 0 , 1 n underlying domain v subseteq n k , function v \( \) gets input set v outputs restricted direct product testing problem , given function f v 0 , 1 k , goal test whether f close direct product encoding , e , whether exists 0 , 1 n sets , f \( \) v \( \) \( \) natural test follows select pair \( , \) v according underlying distribution v times v , query f pair , check consistency intersection note distribution may viewed weighted graph vertex set v referred test graph direct products studied various specific domains test graphs \( example see \) paper , study direct products general setting , addressing question properties domain test graph allow one prove direct product testing theorem \? towards goal introduce notion coordinate expansion test graph roughly speaking test graph coordinate global local expansion , certain nice intersection properties sampling show whenever test graph coordinate expansion admits direct product testing theorem additionally , every k n provide direct product domain v subseteq n k size n , called sliding window domain prove direct product
benchmark problem transportation networks note , propose case study traffic flow modeled hybrid system describe two general classes networks model flow along merging rate traffic flow via control input classes networks easily scaled accommodate arbitrary state dimension model discrete time affine dynamics moreover , present several control objectives especially relevant traffic flow management proposed model flexible offers benchmark evaluating tools techniques developed hybrid systems
problem abstract interpretation problem abstract interpretation asks , roughly speaking , whether following question decidable given program p , safety \( emph e g , non reachability \) specification , abstract domain invariants mathcal , exist invariant mathcal guaranteeing program p meets specification problem course parameterised classes programs invariant domains one considers paper , show problem affine programs invariants \( unions \) moreover , show decidability recovered important special case simple linear loops
interpreting cloud computer vision points mining study stack intelligent services becoming increasingly pervasive application developers want leverage latest advances areas computer vision provide new services products users , large technology enable via apis apis promise easy integrate demand machine intelligence , current design , interface much underlying machine learning techniques power apis look like conventional apis abstract away data driven probabilistic behaviour implications treating apis way , traditional cloud services , cloud storage , concern objective study determine various points developers face implementing systems rely intelligent services , specifically provide computer vision use stack developers appear face using computer vision services , classifying questions two recent classification \( related general questions \) find , unlike fields like mobile development , contrast types questions asked developers indicate shallow understanding underlying technology systems discuss several implications findings via learning suggest software engineering community improve services nature developers use
geometric complexity theory stronger occurrence geometric complexity theory two papers \( j , \) aims separate algebraic complexity classes via representation theoretic coordinate specific group papers also conjecture vanishing behavior would sufficient separate complexity classes \( called occurrence \) existence strong occurrence recently 2016 two successive papers , \( \) \( j \) raises question whether separating group via representation theoretic stronger separating via occurrences paper provides first time setting separating achieved , separation occurrences provably impossible setting surprisingly simple natural study variety products homogeneous linear forms \( called variety \) variety polynomials bounded border rank \( e higher variety variety \) side result prove slight generalization 's reciprocity theorem , proves conjecture new infinite family cases
semi dynamic connectivity plane motivated path planning problem consider following procedure assume two points plane take mathcal k step add mathcal k compact convex set contain procedure sets mathcal k separate show add one set mathcal k \( 1 k alpha \( n \) \) time plus time needed find sets mathcal k newly added set , n cardinality mathcal k , k number sets mathcal k newly added set , alpha \( cdot \) inverse function
complexity polygons edge point 2 transmitters consider generalization classical art problem , instead light source , , called k transmitters , model wireless device signal pass k show np hard compute minimum cover point 2 transmitters , point k transmitters , edge 2 transmitters simple polygon point 2 transmitter result extends orthogonal polygons addition , give results number edge 2 transmitters general , monotone , orthogonal monotone , orthogonal polygons
neural metric learning fast end end relation extraction relation extraction \( \) information extraction task several models typically assume named entity recognition \( ner \) already performed previous step another independent model several recent efforts , end end , seek exploit inter task correlations modeling ner tasks jointly earlier work area commonly reduces task table filling problem wherein additional expensive decoding step involving beam search applied obtain globally consistent cell labels efforts employ table filling , global optimization form decoding ner component still necessary competitive performance introduce novel neural architecture utilizing table structure , based repeated applications 2d convolutions pooling local dependency metric based features , improves state art without need global optimization validate model datasets end end demonstrate approx 1 gain \( f score \) prior best results training testing times seven ten times faster latter highly time sensitive end user applications
robust seed mask generation interactive image segmentation interactive medical image segmentation , anatomical structures extracted reconstructed volumetric images first iterations user interaction traditionally consist drawing initial estimate object extract time consuming first phase , efficient selective refinement current segmentation results labeled , especially near border object , challenging detect replace human may substantially impact overall segmentation quality propose automatic pipeline well configuration based saliency recognition , order time consuming initial interaction phase segmentation median dice score 22 first user interaction test data set error rate 0
neighbourhood structures bisimilarity basic model theory neighbourhood structures standard semantic tool used reason non normal modal logics logic neighbourhood models called classical modal logic terms , neighbourhood frame composed , denoted 2 2 use modelling derive notions equivalence neighbourhood structures 2 2 bisimilarity behavioural equivalence well known concepts , distinct , since 2 2 preserve weak introduce third , intermediate notion whose relations call \( based \) give back style 2 2 , show single , capture behavioural equivalence , structures , better approximation behavioural equivalence 2 2 also introduce notion modal saturation neighbourhood models , investigate relationship image prove theorem image neighbourhood mod els main results 's theorem model theoretic proof interpolation classical modal logic
investigation transfer learning based sentiment analysis text classification approaches usually required task specific model architectures huge labeled datasets recently , thanks rise text based transfer learning techniques , possible pre train language model unsupervised manner leverage perform effective downstream tasks work focus show potential use transfer learning techniques text classification specifically , perform binary multi class sentiment classification product review movie review datasets show transfer learning based approaches perform better task specific models trained 3 times much data furthermore , approaches perform well language modeling pre trained 1 30 data release pre trained models code open source
optimal secrecy systems special case distortion based characterization recent work characterizing optimal performance secrecy systems made use distortion like metric partial secrecy replacement traditional metric work use log loss function show optimal performance limits characterized , fact , special cases distortion based counterparts observation n't whole secrecy also causal framework secrecy \( past source symbols actions revealed eavesdropper \)
large scale evolution convolutional neural networks using computing work presents new algorithm called evolutionary exploration augmenting convolutional topologies \( exact \) , capable evolving structure convolutional neural networks \( cnns \) exact part modeled augmenting topologies \( \) algorithm , allow scale large scale distributed computing environments evolve networks convolutional filters addition versions , exact implemented part computing project , allowing large scale evolution period two , 4 , 500 computers science grid trained , 000 cnns networks reaching 98 32 test data accuracy mnist handwritten dataset results even stronger backpropagation strategy used train cnns fairly \( units , l2 regularization nesterov \) initial test runs done without refinement backpropagation hyperparameters , exact evolutionary strategy independent method used train cnns , could improved advanced techniques like elastic distortions , dropout networks also quite interesting , showing structures significant differences standard human designed architectures
android inter app communication threats detection techniques abstract digital , smart phones become essential component many routine tasks like shopping , paying , transferring , , etc mobile devices attractive attack surface cyber hold personal details \( accounts , locations , , \) potential capabilities eavesdropping \( cameras , wireless connections \) android , popular , target malicious trying use android app tool break control device android malware authors use many anti analysis techniques analysis tools researchers commercial anti malware companies putting great effort detect malicious apps making use combinations static , dynamic behavior based analysis techniques despite security mechanisms provided android , apps carry malicious actions inter app communication one inter app communication threats collusion collusion , malicious functionality across multiple apps participating app part communicate information another app inter component communication \( \) require special also inform user communication participating app needs request minimal set , may make appear benign current state art techniques analyze one app time many surveys app analysis techniques android however focus single app analysis survey several inter app communication threats , particular collusion among multiple apps paper , present android vulnerabilities may exploited attacks , privacy leakage collusion attacks cover existing threat analysis , scenarios , detailed comparison tools intra inter app analysis best knowledge first survey inter app communication threats , app collusion state art detection tools android
correlation distribution ternary decimation paper , let n 3 1 2 \( , 3 n 1 \) 1 studying weight distribution ternary code counting numbers solutions equations finite field mathbb f 3 n , correlation distribution ternary sequence period 3 n 1 decimation sequence completely determined first time correlation distribution non binary decimation determined since
local computation optimization multi agent systems number optimization problems multi agent systems \( e g task allocation network load sharing \) exhibit highly local structure , agent 's decision variables directly coupled agent 's variables objective function constraints nevertheless , existing algorithms distributed optimization generally exploit locality structure problem , requiring agents compute exchange full set decision variables paper , develop rigorous notion locality structural properties linearly constrained convex optimization problem \( particular , sparsity structure constraint matrix objective function \) amount information agents exchange compute arbitrarily high quality approximation problem start leverage notion locality develop locality aware distributed optimization algorithm , show , problems individual agents require know small portion optimal solution , algorithm requires limited inter agent communication numerical results show convergence rate algorithm directly explained locality parameter proposed , proposed theoretical bounds remarkably tight well conditioned problems
adding forward erasure correction quic initially implemented google , quic growing interest first stable specification quic v1 expected end 2018 deliver features tcp http 2 r n flexible design adopted quic enables new protocol support variety different use cases paper , revisit reliable transmission mechanisms included quic specifically , design , implement evaluate forward erasure correction extensions quic design supports generic fec frame implementation includes , reed solomon convolutional schemes evaluate performance applying experimental design wide range packet loss conditions single path scenarios , data two schemes short loss reed solomon outperforms longer also apply fec multipath quic new packet scheduler helps recover packets
mixture models introduce generative model , call mixture models \( \) based mixtures basic n component distributions local structures \( e g patches image \) dependencies n local structures represented priors tensor prior probabilities assigning n component distribution local structure n n general form , intractable priors tensor typically exponential size however , n priors tensor decomposed gives rise arithmetic circuit turn transforms n convolutional arithmetic circuit \( \) corresponds shallow \( single hidden layer \) n network priors tensor decomposed cp \( sum rank 1 \) approach corresponds n deep network decomposition follows hierarchical \( \) model n n representation several attractive properties first , inference tractable n implemented forward pass deep network second , architectural design model n follows deep networks community design , e , structure determined two easily n understood factors size pooling number channels finally , demonstrate effectiveness n model tackling problem classification missing data , leveraging unique ability n tractable leads optimal classifiers distribution
mixture separability loss deep convolutional network image classification machine learning , cost function crucial measures good bad system image classification , well known networks consider modifying network structures applying cross entropy loss end network however , using cross entropy loss causes network stop updating weights training images correctly classified problem early saturation paper proposes novel cost function , called mixture separability loss \( \) , updates weights network even training images accurately predicted consists class within class loss class loss maximizes differences inter class images , whereas within class loss minimizes similarities intra class images designed proposed loss function different convolutional layers network order utilize intermediate feature maps experiments show network learning process obtains promising results public datasets , street view number \( \) , advanced research \( cifar \) , self collected computer vision \( \) gender dataset
unsupervised network via encoding human design years , computer vision researchers amount effort designing image features visual object recognition task propose incorporate valuable experience guide task training deep neural networks idea network task process hand designed feature extraction learning process , neural network integrates previous research knowledge learns model visual objects way similar hand designed features finetuning step , learns object specific representations labeled data classification power two convolutional neural networks one process histogram oriented gradients feature extraction , process region covariance feature extraction finetuning , achieve substantially better performance baseline methods
bounds size small depth approximating majority paper , show every constant 0 epsilon 1 2 every constant geq 2 , minimum size depth boolean circuit epsilon approximates majority function n variables exp \( theta \( n 1 \( 2d 2 \) \) \) lower bound every geq 2 upper bound 2 previously shown , contribution paper give matching upper bound geq 3
android hiv study malware machine learning detection machine learning based solutions successfully employed automatic detection malware android applications however , machine learning models known lack robustness inputs crafted adversary far , adversarial examples android malware detectors rely syntactic features , perturbations implemented simply modifying android manifest recent android malware detectors rely semantic features rather manifest , existing methods longer effective paper , introduce new highly effective attack generates adversarial examples android malware detected current models end , propose method applying optimal perturbations onto android using model based transferability concept , perturbations successfully model likely original models well develop automated tool generate adversarial examples without human intervention apply attacks contrast existing works , adversarial examples crafted method also recent machine learning based detectors rely semantic features control flow graph perturbations also implemented directly onto 's rather android manifest recent detectors evaluated proposed manipulation methods adversarial examples using datasets \( malware samples \) used results show , malware detection rates 96 1 , 97 1 , small distortion generated adversarial examples manipulation method
convolutional feature joint object segmentation topic semantic segmentation considerable progress due powerful features learned convolutional neural networks \( cnns \) 13 current leading approaches semantic segmentation exploit shape information extracting cnn features masked image regions strategy introduces artificial boundaries images may impact quality extracted features besides , operations raw image domain require compute thousands networks single image , time consuming paper , propose exploit shape information via convolutional features proposal segments \( e g , super pixels \) treated masks convolutional feature maps cnn features segments directly masked maps used train classifiers recognition propose joint method handle objects \( e g , , , \) framework state art results demonstrated benchmarks pascal voc new pascal context , computational speed
family likelihood search multiuser detectors upper bound bit error rate lower bound asymptotic multiuser efficiency paper , bit error performance family likelihood search \( \) multiuser detectors analyzed upper bound ber detector obtained bounding fixed point region worst initial detector concept errors developed applied upper bound special instance , upper bound reduced local maximum likelihood detectors upper bound comparable optimum detector obtained lower bound asymptotic multiuser efficiency \( \) obtained shown nontrivial channels detector achieve unit user number lower bound provides means seeking good set sequences power distribution spectral power efficient
face forensics pixel level analysis progress face manipulation methods made possible synthesize realistic fake face images , poses potential threats society face forensics techniques distinguish images large scale dataset provided enormous training data generated prominent face manipulation methods facilitate anti fake research however , previous works focus classification problem considering global prediction investigation problem , find training classification network often fails capture high quality features , might lead sub optimal solutions paper , problem pixel level analysis , e formulating pixel level segmentation task evaluating multiple architectures segmentation classification tasks , show superiority problem segmentation perspective different ablation studies also performed investigate makes effective efficient anti fake model strong baselines also established , , hope , could shed light field face forensics
improved bound fraction correctable deletions consider codes fixed worst case symbol deletions fixed k 2 , construct family codes alphabet size k positive rate , allow efficient recovery worst case deletion fraction approaching 1 frac 2 k sqrt k particular , binary codes , able recover fraction deletions approaching 1 \( sqrt 2 1 \) sqrt 2 1 approx 0 previously , even non largest deletion fraction known correctable positive rate 1 theta \( 1 sqrt k \) , around 0 17 binary case r n result largest fraction correctable deletions k ary codes 1 theta \( 1 k \) , since 1 1 k upper bound even simpler model locations missing symbols known r n gap \( sqrt 2 1 \) 1 2 limit worst case deletions correctable binary codes remains open question
target agnostic attack deep models exploiting security vulnerabilities transfer learning due lack enough training data high computational cost train deep neural network scratch , transfer learning extensively used many deep neural network based applications , face recognition , image classification , speech recognition , etc commonly used transfer learning approach involves taking part pre trained model , adding layers end , training new layers small dataset approach , efficient widely used , imposes security vulnerability pre trained models used transfer learning usually available publicly , including potential paper , show without additional knowledge pre trained model , attacker launch effective efficient force attack instances input target class high confidence note assume attacker access target specific information , including samples target classes , trained model , probabilities assigned softmax class , thus called target agnostic attack assumptions render previous attacks , best knowledge evaluate proposed attack , perform set experiments face recognition speech recognition tasks show effectiveness attack work sheds light fundamental security challenge transfer learning deep neural networks
combinatorial solution non rigid 3d shape image matching propose combinatorial solution problem non matching 3d shape 3d image data end , model shape triangular mesh allow triangle mesh transformed achieve suitable matching image distance relative rotation matching image shape information paper , resolve two major challenges firstly , address resulting large np hard combinatorial problem suitable graph theoretic approach secondly , propose efficient 6 dimensional lie group \( 3 \) knowledge first combinatorial formulation non rigid 3d shape image matching contrast existing local \( gradient descent \) optimisation methods , obtain solutions require good within bound optimal solution evaluate proposed method two problems non rigid 3d shape shape non rigid 3d shape image registration demonstrate provides promising results
overview embedding models entities relationships knowledge base completion knowledge bases \( \) real world facts entities relationships useful resources variety natural language processing tasks however , knowledge bases typically incomplete , useful able perform knowledge base completion link prediction , e , predict whether relationship knowledge base likely true article serves brief overview embedding models entities relationships knowledge base completion , date experimental results standard benchmark datasets fb15k , , fb15k , ,
data augmentation wearable sensor data disease monitoring using convolutional neural networks convolutional neural networks \( cnns \) successfully applied many challenging classification applications , typically require large datasets training availability labeled data limited , data augmentation critical preprocessing step cnns however , data augmentation wearable sensor data investigated yet paper , various data augmentation methods wearable sensor data proposed proposed methods cnns applied classification motor state disease patients , challenging due small dataset size , noisy labels , large intra class variability appropriate augmentation improves classification performance 77 86
low rank approximations computing observation impact data assimilation present efficient computational framework quantify impact individual observations four dimensional variational data assimilation proposed methodology uses first second order sensitivity analysis , together matrix free algorithms obtain low rank approximations impact matrix illustrate application methodology important applications data pruning identification sensors two dimensional shallow test system
learning rate decay loss usual deep neural network optimization process , learning rate important hyper parameter , greatly affects final convergence effect purpose learning rate control gradually reduce impact noise network paper , use fixed learning rate method loss control magnitude update used image classification , semantic segmentation , gans verify method experiments show loss decay strategy greatly improve performance model
method identifying origin digital images using convolution neural network rapid development deep learning techniques created new challenges identifying origin digital images generative adversarial networks variational autoencoders create plausible digital images whose contents present natural scenes paper , consider origin three categories natural image \( \) , computer generated graphic \( \) , deep network generated image \( \) method presented effectively identifying origin digital images based convolutional neural network \( cnn \) uses local global framework reduce training complexity labeled data , cnn trained predict origin local patches image origin full size image determined majority voting unlike previous methods , cnn takes raw pixels input without aid residual map experimental results revealed high frequency components also frequency ones contribute origin identification proposed method achieved 95 21 identification accuracy several common post processing operations including jpeg compression , scaling , geometric transformation , contrast quantitative results demonstrate proposed method effective feature based methods
multi user communication networks coordinated multi armed bandit approach communication networks shared many users widespread challenge nowadays paper address several aspects challenge simultaneously learning unknown stochastic network characteristics , sharing resources users keeping coordination overhead minimum proposed solution combines multi armed bandit learning lightweight based coordination scheme , ensures convergence stable allocation resources work considers single user level algorithms two scenarios unknown fixed number users , dynamic number users analytic performance guarantees , proving convergence stable configurations , presented setups algorithms designed based system wide perspective , rather focusing single user welfare thus , maximal resource utilization extensive experimental analysis covers convergence stable configuration well reward maximization experiments carried wide range setups , demonstrating advantages approach existing state art methods
throughput region spatially correlated interference packet networks multi user wireless packet networks interference , typically modeled packet collision , throughput bottleneck users become aware interference pattern via feedback use information contention resolution packet conventional random access protocols communication resolve contention reduces network throughput increases latency power consumption work take different approach develop opportunistic random access protocols rather conventional methods allow wireless nodes communicate without observe interference pattern use interference pattern knowledge channel statistics counter negative impact interference result approach better use resources \( e g , time energy \) higher network throughput prove optimality protocols using rank ratio inequality important part contributions integration spatial correlation assumptions results identify spatial correlation regimes inherently feedback becomes good feedback , correlation regimes feedback provide throughput gain
relationship word complexity computational complexity prove several results relationship word complexity function set turing degrees points , call turing spectrum among results , show turing spectrum realized via linear complexity consists union finite set finite number , turing spectrum realized via exponential complexity \( e positive entropy \) contains cone , every turing spectrum either contains degree 0 union wide range complexity growth rates linear exponential
asymptotic degree distributions large homogeneous random networks little theory counterexample random graph models , degree distribution individual node \( empirical \) degree distribution graph records nodes given degree introduce general framework explore two degree distributions coincide asymptotically large homogeneous random networks discussion carried three basic statistical assumptions degree sequences \( \) weak form distributional \( ii \) existence asymptotic \( \) degree distribution \( iii \) weak form asymptotic show asymptotic equality may fail homogeneous random networks \( \) \( ii \) hold \( iii \) counterexample found class random threshold graphs finding random threshold graphs cannot used model scale free network modeling , proposed authors results also formulated non homogeneous models making use random sampling procedure nodes
multi objective metric temporal planner domain independent heuristic forward planner handle actions , metric resource constraints , goals designed capable handling multi objective nature metric temporal planning technical contributions include \( \) planning graph based methods deriving heuristics sensitive cost \( ii \) techniques adjusting heuristic estimates take action interactions metric resource limitations account \( iii \) linear time greedy post processing technique improve execution flexibility solution plans implementation using many techniques presented paper one best domain independent planners domains metric temporal constraints third international planning competition , held describe technical details extracting heuristics present empirical evaluation current implementation
unified approach transfer learning training noisy labels present \( source selection target optimization \) , new method exploiting source dataset solve classification problem target dataset based following simple intuition source examples informative others target problem capture intuition , source samples given weights weights solved jointly source target classification problems via optimization scheme target therefore gets choose source samples informative classification task furthermore , nature optimization acts kind regularization target , mitigating overfitting may applied classic transfer learning , well problem training datasets noisy labels show state art results problems
acl2 meets gpu formalizing cuda based pairs shortest path algorithm acl2 graphics processing units \( gpus \) gained capability gpu development environments , developers increasingly gpu load main host cpu numerically intensive , computations modern gpus feature hundreds cores , offer programming double precision point , even limited recursion shift cpu gpu , however , raises question know new gpu based algorithms correct \? r n order explore new verification , formalized pairs shortest path \( apsp \) algorithm weighted graphs , originally coded nvidia 's cuda language , acl2 acl2 specification written using single object \( \) tail recursion , tail recursion combination yields translation programming languages , well efficient , scalable executable specifications within acl2 acl2 version apsp algorithm process millions vertices edges little generation , one speed host based version apsp coded c result theorem r n addition formalizing apsp algorithm \( uses 's shortest path algorithm core \) , also provided capability original apsp code , namely shortest path recovery path recovery accomplished using secondary acl2 implementing stack , proven correct conclude experiment , acl2 version apsp kernels back c , resulting less 5 , also performed partial back cuda , , surprisingly , slight performance increase
mathematical methods interpreting last 50 years seen impressive development mathematical methods analysis processing digital images , mostly context , biomedical imaging various forms engineering arts mostly process , works last 10 years rapid emergence arts , however , arts domain becoming increasingly receptive digital image processing methods importance paying attention therefore increases paper discuss range mathematical methods digital image restoration digital latter provide interesting opportunity digital manipulation traditionally remain time also serve example possibilities mathematics digital restoration offer generic objective toolkit arts
shape similarity correspondence important operation geometry processing finding correspondences pairs shapes distance , measure metric spaces , found highly useful shape comparison , explore applicability related shape similarity measures problem shape correspondence , adopting spectral type distances propose evaluate spectral kernel distance , spectral embedding distance novel spectral quasi distance , comparing manifolds different viewpoints matching shapes spectral domain , important attributes surface structure aligned purpose testing ideas , introduce fully automatic framework finding intrinsic correspondence two shapes proposed method achieves state art results shape matching protocol applied , usual , benchmarks
detecting arbitrary attacks using continuous side information wireless networks paper focuses byzantine attack detection gaussian two hop one way relay network , amplify forward relay may conduct byzantine attacks symbols destination attack detection , utilize wireless medium make destination observe signals , detection scheme developed destination using observations statistically check observations relay hand , gaussian channel continuous , allows possible byzantine attacks conducted within continuous alphabet \( \) existing work discrete channel applicable investigating performance proposed scheme main contribution paper prove wireless relay network satisfies non channel condition , proposed detection scheme achieves asymptotic performance arbitrary attacks allow stochastic distributions symbols vary arbitrarily depend pre shared secret secret transmission needed detection furthermore , also prove relay network non long channel coefficients non zero , essential restrict many practical systems
reinforcement learning unsupervised auxiliary tasks deep reinforcement learning agents achieved state art results directly cumulative reward however , environments contain much variety possible training signals paper , introduce agent also many pseudo reward functions simultaneously reinforcement learning tasks share common representation , like unsupervised learning , develop absence extrinsic rewards also introduce novel mechanism focusing representation upon extrinsic rewards , learning rapidly adapt relevant aspects actual task agent significantly outperforms previous state art atari , averaging expert human performance , challenging suite first person , three dimensional emph tasks leading mean speedup learning 10 times averaging expert human performance
tag problem swarm robots optimization problem naturally arises study swarm robotics tag problem \( \) set robots , robot move locations robot awake , assist robots objective robots awake early possible problems areas combinatorial optimization routing , , scheduling , covering , algorithmic characteristics surprisingly different consider scenarios graphs geometric environments graphs , robots sleep vertices length function edges awake robots travel along edges , time depending edge length scenarios , consider offline version problem , awake robot position robots prove problem np hard , even special case star graphs also establish hardness approximation , showing np hard obtain approximation factor better 5 3 , even graphs bounded degree lower bounds complemented several positive algorithmic results , including \( 1 \) show natural greedy strategy star graphs tight worst case performance 7 3 give polynomial time approximation scheme \( ptas \) star graphs \( 2 \) give simple \( log \) competitive online algorithm graphs maximum degree locally bounded edge weights \( 3 \) give ptas , running nearly linear time , embedded instances
seed driven geo social data extraction full version geo social data attractive source variety problems mining mobility patterns , link prediction , location recommendation , influence maximization however , new geo social data increasingly suffers several limitations paper , aim remedy problem effective data extraction geo social data sources first identify categorize limitations extracting geo social data order overcome limitations , propose novel seed driven approach uses points one source seed queries others additionally handle differences , dynamics within sources proposing three variants optimizing search radius furthermore , provide optimization based recursive clustering minimize number requests adaptive procedure learn specific data distribution source comprehensive experiments six popular sources show seed driven approach yields 14 3 times data overall , request optimized algorithm 95 data less 16 requests thus , proposed seed driven approach set new effective efficient extraction geo social data
progressive em latent tree models hierarchical topic detection hierarchical latent tree analysis \( \) recently proposed new method topic detection differs fundamentally based methods terms topic definition , topic document relationship , learning method shown discover significantly coherent topics better topic hierarchies however , relies expectation maximization \( em \) algorithm parameter estimation hence efficient enough deal large datasets paper , propose method drastically speed using technique inspired recent advances moments method empirical experiments show method greatly improves efficiency efficient state art based method hierarchical topic detection finds substantially better topics topic hierarchies
human pose estimation using deep consensus voting paper consider problem human pose estimation single still image propose novel approach location image position keypoint using convolutional neural net voting scheme allows us utilize information whole image , rather rely sparse set keypoint locations using dense , multi target , produces good keypoint predictions , also enables us compute image dependent joint keypoint probabilities looking consensus voting differs previous methods joint probabilities learned relative keypoint locations independent image finally combine joint probabilities order identify optimal pose configuration show competitive performance human pose pose datasets
light effective method extractive summarization based sentence embeddings paper introduces summarization transformation selection scoring extractive text summarization method leverages semantic information existing sentence embedding spaces method creates extractive summary selecting sentences closest embeddings document embedding model learns transformation document embedding minimize similarity extractive summary ground truth summary transformation composed dense layer , training done cpu , therefore , moreover , inference time short linear according number sentences second contribution , introduce dataset , composed judgments corresponding dataset , results show method performs similarly state art extractive methods effective training inferring time
enhanced language representation informative entities neural language representation models bert pre trained large scale corpora well capture rich semantic patterns plain text , fine tuned consistently improve performance various nlp tasks however , existing pre trained language models rarely consider incorporating knowledge graphs \( \) , provide rich structured knowledge facts better language understanding argue informative entities enhance language representation external knowledge paper , utilize large scale textual corpora train enhanced language representation model \( \) , take full advantage lexical , syntactic , knowledge information simultaneously experimental results demonstrated achieves significant improvements various knowledge driven tasks , meanwhile comparable state art model bert common nlp tasks source code paper obtained https url
black box understanding dqns recent years growing interest using deep representations reinforcement learning paper , present methodology tools analyze deep q networks \( dqns \) non blind matter using tools reveal features learned dqns aggregate state space hierarchical fashion , explaining success moreover able understand describe policies learned dqns three different games suggest ways interpret , optimize deep neural networks reinforcement learning
attention based extraction structured information street view imagery present neural network model based cnns , rnns novel attention mechanism achieves 2 accuracy challenging street name signs \( \) dataset , significantly outperforming previous state art \( \) , achieved furthermore , new method much simpler general previous approach demonstrate model , show also performs well even challenging dataset derived google street view , goal extract business names store fronts finally , study speed accuracy tradeoff results using cnn feature different surprisingly , find deeper always better \( terms accuracy , well speed \) resulting model simple , accurate fast , allowing used scale variety challenging real world text extraction problems
algorithm finding points near point cross matching spatial datasets abstract index n dimensional metric space efficiently support points near point queries either within dataset two datasets approach uses relational algebra b tree mechanism found almost relational database systems hence , algorithm gives relational implementation points near point , spatial cross match , self match queries article earlier article algorithm describes algorithmic improvements includes implementation point near point , self match , cross match using city stream database 1 introduction article goes neighborhood relational algebra spatial data search 1 introduced three spatial methods points regions sphere \( 1 \) hierarchical triangular mesh \( \) good point near point point region queries high dynamic range region sizes , \( 2 \)
strength uniqueness quantification primitive positive formulas uniqueness quantification \( exists \) quantifier first order logic one requires exactly one element exists satisfying given property paper investigate strength uniqueness quantification used place existential quantification conjunctive formulas given set relations gamma , called primitive positive definitions \( pp definitions \) fully classify boolean sets relations uniqueness quantification strength existential quantification pp definitions give several results valid arbitrary finite domains also consider applications exists pp definitions computer science , used study computational complexity problems number solutions important using classification give new simplified proof theorem unique satisfiability problem , prove general result unique constraint satisfaction problem
uniform equivalence epistemic logic programs epistemic logic programs \( elps \) extend answer set programming \( asp \) epistemic negation received interest recent years led development new research efficient solving systems elps practice , elps often written modular way , module modules sets facts input , passing sets facts output interesting question presents conditions module replaced another one without changing outcome , set input facts \? problem known uniform equivalence , studied extensively asp elps , however , investigation , yet , missing paper , therefore propose characterization uniform equivalence directly applied language state art solvers also investigate computational complexity deciding uniform equivalence two elps , show third level polynomial hierarchy
classical realizability ae paper treat specification problem classical realizability \( defined 20 \) case ae continuity 10 11 , characterize universal formula strategies game \( defined according formula \) first section recall definition classical realizability , well technical results section 5 , introduce details specification problem intuition game theoretic point view adopt later first present game g 1 , prove adequate complete language contains instructions 18 , using interaction constants substitution execution threads show language contain , game complete , present second game g 2 adequate complete general case last section , draw attention model theoretic point view , use specification result show ae absolute realizability models
privacy preserving action recognition smart using low resolution depth images computer vision systems greatly assist healthcare improve medical facility treatment , often face patient due perceived privacy associated visual surveillance video frames extremely low resolutions degrade private information surveillance videos measure amount activity recognition information low resolution depth images , also apply trained super resolution model enhance utility images implement techniques two actual healthcare surveillance scenarios , hand compliance activity , show privacy preserving techniques preserve enough information realistic healthcare tasks
feedback control autonomous bipedal robot motivated towards achieving multi modal locomotion , paper , develop framework bipedal robot dynamically pair various terrain developed control strategy enables bipedal robot interact balance , forward velocities , achieve fast turns , move terrain , , , outdoor terrain sensor suite comprising tracking depth cameras visual slam well based global planner timed elastic band based local planning framework enables us achieve autonomous navigating obstacle course present numerical experimental work
domain specific language kinematic models fast implementations robot dynamics algorithms rigid body dynamics algorithms play crucial role several components robot controller simulations real time constraints high frequency control loops time requirements specific applications demand functions efficient despite availability established algorithms , efficient implementation specific robot still error prone task however , components simply necessary get high performance controllers r n achieve efficient yet well implementations dynamics algorithms propose use domain specific language describe dynamics model robot since algorithms parameterized model , executable code tailored specific robot generated , thanks facilities available approach allows users deal high level description robot hand crafted development resources efforts focused open research questions r n preliminary results generation efficient code inverse dynamics presented proof concept approach
bayesian optimization machine learning practical engineering machine learning systems still field relying collection quickly evolving tools best practices hope serve useful resource machine learning practitioners looking take advantage bayesian optimization techniques outline four example machine learning problems solved using open source machine learning libraries , highlight benefits using bayesian optimization context common machine learning applications
refinement cut user guided segmentation algorithm science contribution , semi automatic segmentation algorithm \( medical \) image analysis presented precise , approach category interactive algorithms , provide real time feedback segmentation result however , even interactive real time approaches always cases user cannot find satisfying segmentation , e g due homogeneous object background , noise inside object difficult cases algorithm still needs additional user support however , additional user support intuitive rapid integrated segmentation process , without breaking interactive real time segmentation feedback propose solution user support algorithm easy fast placement one seed points guide algorithm satisfying segmentation result also difficult cases additional seed \( \) restrict \( \) segmentation algorithm , time , still enable continue interactive real time feedback segmentation practical application science , approach tested medical data clinical routine 2d 3d
geometric lattice structure covering application attribute reduction matroids reduction covering decision systems important problem data mining , covering based sets serve efficient technique process problem geometric lattices widely used many fields , especially greedy algorithm design plays important role reduction problems therefore , meaningful combine geometric lattices solve optimization problems paper , obtain geometric lattices matroids apply issue attribute reduction first , geometric lattice structure covering constructed matroids atoms studied used describe lattice second , considering closed sets finite matroid form geometric lattice , propose dependence space matroids study attribute reduction issues space , application geometric lattices attribute reduction furthermore , special type information system taken example illustrate application word , work points interesting view , namely , geometric lattice study attribute reduction issues information systems
word embeddings parsing information bottleneck pre trained word embeddings like bert contain rich syntactic semantic information , resulting state art performance various tasks propose fast variational information bottleneck \( \) method compress embeddings , keeping information helps discriminative compress word embedding either discrete tag continuous vector discrete version , automatically compressed tags form alternative tag set show experimentally tags capture information traditional tag annotations , tag sequences accurately level tag granularity continuous version , show experimentally word embeddings method yields accurate 8 9 languages , unlike simple dimensionality reduction
adaptively sparse transformers attention mechanisms become ubiquitous nlp recent architectures , notably transformer , learn powerful context aware word representations layered , multi attention multiple heads learn diverse types word relationships however , standard softmax attention , attention heads dense , assigning non zero weight context words work , introduce adaptively sparse transformer , wherein attention heads flexible , context dependent sparsity patterns sparsity accomplished softmax alpha differentiable generalization softmax allows low scoring words receive precisely zero weight moreover , derive method automatically learn alpha parameter controls shape sparsity alpha allowing attention heads choose focused spread behavior adaptively sparse transformer improves interpretability head diversity compared softmax transformers machine translation datasets findings quantitative qualitative analysis approach include heads different layers learn different sparsity preferences tend diverse attention distributions softmax transformers furthermore , cost accuracy , sparsity attention heads helps uncover different head
zero temperature limit algorithm minimize free energy discovery fixed points belief propagation coincide stationary points free energy , several researchers proposed provably algorithms directly minimize free energy algorithms formulated non zero temperature \( thus finding fixed points sum product algorithm \) possible extension zero temperature obvious present zero temperature limit double loop algorithm , max product fixed point inner loop algorithm max sum diffusion certain conditions , algorithm combines complementary advantages max product belief propagation max sum diffusion \( lp relaxation \) yields good approximation ground states max
physical layer network coding two way relaying qam design modulation schemes physical layer network coded two way relay network studied literature known every network coding map satisfies law representable latin square relationship used get network coding maps satisfying law , scenario end nodes use psk signal sets addressed previously paper , address case end nodes use qam signal sets fading scenario , certain channel conditions , termed singular fade states , end end performance greatly reduced formulating procedure finding exact number singular fade states qam , show square qam signal sets give number singular fade states compared psk signal sets reduces computational complexity relay node shown criterion partitioning complex plane , purpose using particular network code particular fade state , different used psk using modified criterion , describe procedure analytically partition complex plane representing channel condition show qam \( 4 \) signal set used , conventional network mapping fails remove ill effects 1 , singular fade state signal sets arbitrary size show doubly block latin square removes singular fade state qam finally shown qam gives superior performance psk
optimization evaluation nested queries procedures many database applications perform complex data retrieval update tasks nested queries , queries user defined functions , written using procedural sql constructs , often used applications forward evaluation queries involves repeated execution parameterized sub queries blocks containing queries procedural code r n important problem arises optimizing nested queries well queries joins , aggregates set operations problem finding optimal sort order number possible sort orders show even special case problem np hard , present practical heuristics effective easy incorporate existing query r n also consider iterative execution queries updates inside complex procedural blocks user defined functions stored procedures parameter important means improving performance enables set processing key challenge parameter lies given procedure function process batch parameter values propose solution , based program analysis rules , automate generation batched forms procedures replace iterative database calls within loops single call batched form r n present experimental results proposed techniques , results show significant gains performance
demonstration fully nonlinear spectrum system highly nonlinear optical transmission regime report 3 db increase nonlinear threshold 64 0 16 qam continuous nonlinear spectrum signal nonlinear multiplexing multi , showing first ever fully nonlinear spectrum system highly nonlinear regime
modeling conceptual characteristics virtual machines cpu utilization prediction cloud services grown rapidly recent years , provide high flexibility cloud users computing requirements demand allocate computing resources cloud , important cloud service providers aware potential utilization various resources future paper focuses predicting cpu utilization virtual machines \( \) cloud conduct empirical analysis 's workloads identify important conceptual characteristics cpu utilization among , including locality , propose neural network method , named time aware residual networks \( resnet \) , model observed conceptual characteristics network depth cpu utilization prediction conduct extensive experiments evaluate effectiveness proposed method results show resnet consistently outperforms baseline approaches various metrics including , mae
towards information based spatiotemporal patterns foundation agent representation dynamical systems present arguments existing methods representing agents fall short applications crucial artificial life using thought experiment involving dynamical systems model argue , , concept counterfactual variation compatible agent representation dynamical systems propose information theoretic notion integrated spatiotemporal patterns believe serve basic building block agent definition argue patterns capable solving problems mentioned also test preliminary experiments
data encoding byzantine resilient distributed optimization study distributed optimization presence byzantine adversaries , data computation distributed among worker machines , arbitrarily pre specified programs , \( \) node iteratively computes model parameter vector em generalized linear models work , primarily focus two iterative algorithms em gradient descent \( pgd \) em coordinate descent \( \) gradient descent \( \) special case algorithms pgd typically used data parallel setting , data across different samples , whereas , used model parallelism setting , data across parameter space r n paper , propose method based data encoding error correction real numbers combat adversarial attacks leq lfloor frac 1 2 rfloor worker nodes , information theoretically optimal give deterministic guarantees , method assume probability distribution data develop em sparse encoding scheme enables computationally efficient data encoding decoding demonstrate trade corruption threshold resource requirement \( storage computational communication complexity \) example , leq frac 3 , scheme incurs em constant overhead resources , required plain distributed pgd algorithms provide adversarial protection r n encoding scheme extends em efficiently \( \) data streaming model , data samples come online fashion encoded , \( ii \) making em stochastic gradient descent \( sgd \) byzantine resilient end , give experimental results show efficacy method
tight bounds symmetric divergence measures refined bound lossless source coding tight bounds several symmetric divergence measures derived terms total variation distance shown bounds pair two three element probability distributions application bounds lossless source coding provided , improving certain bound another application bounds recently introduced et al channel code detection
paying attention attention highlighting influential samples sequential analysis \( et al 2016 \) , hierarchical attention network \( \) created document classification attention layer used visualize text influential classifying document , thereby explaining model 's prediction successfully applied sequential analysis task form real time monitoring turn taking conversations however , discovered instances attention weights uniform point \( indicating turns influential classifier \) , preventing meaningful visualization real time human review classifier improvement observed attention weights turns conversations , indicating turns varying influence based state leveraging observation , develop method create informative real time \( human \) cases uniform attention weights using changes turn importance time
failure analysis interval passing algorithm compressed sensing work , perform complete failure analysis interval passing algorithm \( ipa \) compressed sensing , efficient iterative algorithm k sparse nonnegative n dimensional real signal boldsymbol x small number linear measurements boldsymbol particular , show ipa fails recover boldsymbol x boldsymbol fails recover corresponding binary vector support , also positions values measurement matrix importance success recovery based observation , introduce termatiko sets show ipa fails fully recover boldsymbol x support boldsymbol x contains termatiko set , thus giving complete \( graph theoretic \) description sets ipa two heuristics locate small size termatiko sets presented binary column regular measurement matrices 4 cycles , provide lower bound termatiko distance , defined smallest size termatiko set measurement matrices constructed parity check matrices array ldpc codes , upper bounds termatiko distance provided column weight 7 , column weight 3 , exact termatiko distance corresponding provided next , show adding redundant rows measurement matrix create new termatiko sets , rather potentially removes termatiko sets thus improves performance algorithm provided efficiently search redundant rows finally , present numerical results different specific measurement matrices also based ensembles measurement matrices , well simulation results ipa performance , showing influence small size termatiko sets
perfect secrecy physical layer network coding systems structured interference physical layer network coding \( \) proposed next generation networks contribution , investigate schemes embedded perfect secrecy exploiting structured interference relay networks two users single relay practical scenario users employ finite uniform signal input distributions propose upper bounds \( \) achievable perfect secrecy rates make explicit used describe two simple , explicit encoders achieve perfect secrecy rates close respect relay single antenna single relay setting lastly , generalize system mimo relay channel relay antennas users optimal precoding matrices maintain required secrecy constraint studied results establish design transmission schemes enhanced throughput guaranteed data confidentiality feasible next generation systems
massively multilingual word embeddings introduce new methods estimating evaluating embeddings words languages single shared embedding space estimation methods , , use dictionaries monolingual data require parallel data new evaluation method , , shown correlate better previous ones two downstream tasks \( text categorization parsing \) also describe web evaluation facilitate research area , along open source methods
multi round communication lower bound gap hamming consequences gap hamming distance problem context proving space lower bounds number key problems data stream model problem , alice bob decide whether hamming distance n bit input strings large \( e , least n 2 sqrt n \) small \( e , n 2 sqrt n \) care neither large small theta \( sqrt n \) gap problem specification crucial capturing approximation allowed data stream algorithm r n thus far , randomized communication , omega \( n \) lower bound problem known one way setting prove omega \( n \) lower bound randomized protocols use constant number rounds r n consequence conclude , instance , epsilon approximately counting number distinct elements data stream requires omega \( 1 epsilon 2 \) space , even multiple \( constant number \) input stream extends earlier one pass lower bounds , answering long open question obtain similar results approximating frequency moments approximating empirical entropy data stream r n process , also obtain tight n theta \( sqrt n log n \) lower upper bounds one way deterministic communication complexity problem finally , give simple combinatorial proof omega \( n \) lower bound one way randomized communication complexity
bridging stereo matching optical flow via spatiotemporal correspondence stereo matching flow estimation two essential tasks scene understanding , spatially 3d temporally motion existing approaches focused unsupervised setting due limited resource obtain large scale ground truth data construct self learnable objective , co related tasks often linked together form joint framework however , prior work usually utilizes independent networks task , thus allowing learn shared feature representations across models paper , propose single principled network jointly learn spatiotemporal correspondence stereo matching flow estimation , newly designed geometric connection unsupervised signal temporally adjacent stereo pairs show method performs several state art baselines unsupervised depth flow estimation kitti benchmark dataset
associative accelerate approximate nearest neighbor search nearest neighbor search active field machine learning appears many application cases , including classification object retrieval canonical version , complexity search linear dimension collection vectors search performed recently many works focused reducing dimension vectors using quantization techniques hashing , providing approximate result paper focus instead tackling collection vectors namely , introduce technique partitions collection vectors stores part associative memory query vector given system , associative identify one contain closest match exhaustive search conducted part vectors stored selected associative memory study effectiveness system messages store generated uniform pm 1 random variables 0 1 sparse random variables also conduct experiment synthetic data real data show possible achieve interesting trade offs complexity accuracy
observer variation aware medical image segmentation combining deep learning surrogate assisted genetic algorithms recently great progress automatic segmentation medical images deep learning algorithms works observer variation problem makes training data heterogeneous far attempts made explicitly capture variation , propose approach capable mimicking different styles segmentation , potentially improve quality clinical automatic segmentation methods work , instead training one neural network available data , train several neural networks data different segmentation variations separately priori may styles segmentation exist data different styles necessarily map one one different , automatically determined achieve searching best data partition genetic algorithm therefore , network learn specific style segmentation training data provide proof principle results open sourced segmentation mri data simulated observer variations approach provides improvement 23 \( depending simulated variations \) terms dice surface dice coefficients compared one network trained data
propel probabilistic parametric regression loss convolutional neural networks recently , convolutional neural networks \( cnns \) field computer vision widespread success attributed representation learning capabilities classification tasks , cnns widely employed probabilistic output shown significance providing additional confidence predictions however , probabilistic methodologies widely applicable addressing regression problems using cnns , regression involves learning continuous , many cases , multi target variables propose probabilistic parametric regression loss \( propel \) enables probabilistic regression using cnns propel fully differentiable , hence , easily incorporated end end training existing cnn architectures proposed method flexible learns complex probabilities higher dimensional multi regression problems utilize propel based cnn address problem learning hand head orientation color images comprehensive experimental validation comparisons existing cnn regression loss functions provided experimental results indicate propel significantly improves performance cnn , reducing model parameters compared existing state art
low latency networking short survey big data infrastructure supporting numerous online services demand , significantly impacts user experience provider revenue , translated timing requirements flows networks thus low latency networking becoming major concern industry academia r n provide short survey recent progress made networking community low latency networks propose taxonomy categorize existing work based four main techniques , reducing queue length , , flows , exploiting multi path review select papers , highlight principal ideas , discuss also present perspectives research challenges opportunities , future work space
improving slot filling performance neural networks dependency structures slot filling \( sf \) aims extract values certain types attributes \( slots , person cities \) given entity large collection source documents paper propose effective dnn architecture sf following new strategies \( 1 \) take regularized dependency graph instead raw sentence input dnn , compress wide contexts query candidate \( 2 \) incorporate two attention mechanisms local attention learned query candidate , global attention learned external knowledge bases , guide model better select contexts determine slot type experiments show framework outperforms state art relation extraction \( 16 absolute f score gain \) slot filling validation individual system \( 8 5 absolute f score gain \)
multiple failures regenerating codes using idea interference alignment , constructed class minimum storage regenerating codes repair one systematic one parity check node optimal repair bandwidth code structure , show addition single node failure , double node failures optimal repair bandwidth well give example repair double failures regenerating code six nodes , give proof general case
strongly controllable group codes mixing group shifts solvable groups translation nets algorithms branch group strongly controllable group code shift group show shift group characterized simple way addition shown strongly controllable group code labeled latin squares , strongly controllable latin group code , shift group solvable moreover mathematical structure latin square \( translation net \) shift group strongly controllable latin group code closely related thus strongly controllable latin group code viewed natural extension latin square sequence space lastly construct shift groups show sufficient construct simpler group , state group shift group give algorithm find state group , easy construct controllable latin group code
scaling greedy equivalence search continuous variables implemented r program , causal search algorithms widely effectively used scientific problems severe dimensionality constraints however , implementation improvements possible extend feasible dimensionality search problems several orders magnitude describe optimizations greedy equivalence search \( \) allow search 50 , 000 variable problems 13 minutes sparse models samples , 4 processor computer , 18 hours sparse models samples 1 , 000 , 000 variables node center 40 processors g ram , data generated linear , gaussian model
power conditional samples distribution testing paper define examine power em conditional sampling oracle context distribution property testing conditional sampling oracle discrete distribution mu takes input subset subset n domain , outputs random sample drawn according mu , conditioned \( independently prior samples \) conditional sampling oracle natural generalization ordinary sampling oracle always n r n show conditional sampling oracle , testing uniformity , testing identity known distribution , testing label invariant property distributions easier ordinary sampling oracle hand , also show distribution properties sample complexity remains near maximal even conditional sampling
update rules parameter estimation bayesian networks paper examines problem parameter estimation bayesian networks missing values hidden variables perspective recent work line learning , provide unified framework parameter estimation encompasses line learning , model continuously adapted new data cases , traditional batch learning , pre set samples used one time model selection process batch case , framework encompasses gradient projection algorithm em algorithm bayesian networks framework also leads new line batch parameter update schemes , including parameterized version em provide empirical theoretical results indicating parameterized em allows faster convergence maximum likelihood parameters standard em
model vulnerability distributional shifts image transformation sets vulnerability computer vision models distributional shifts problem terms combinatorial optimization , evaluating regions input space \( black box \) model vulnerable carried combining image transformations given set standard search algorithms embed idea training procedure , define new data augmentation rules iterations , accordingly image transformations current model vulnerable empirical evaluation classification semantic segmentation problems suggests devised algorithm allows train models robust content preserving image transformations , general , distributional shifts
deep learning reverse migration diffuse optical tomography artificial intelligence \( ai \) learn complicated non linear physics \? propose novel deep learning approach learns non linear physics obtains accurate 3d distribution optical anomalies contrast traditional black box deep learning approaches inverse problems , deep network learns integral equation describes essential physics migration diffuse near \( \) media example clinical relevance , applied method prototype diffuse optical tomography \( \) show deep neural network , trained simulation data , accurately recover location anomalies within live without use contrast agent
error correcting codes projective spaces via rank metric codes diagrams coding projective space received recently lot attention due application network coding reduced form linear subspaces play key role solving coding problems projective space paper propose method design error correcting codes projective space use approach design codes first , select constant weight code codeword defines skeleton basis subspace reduced form skeleton contains design rank metric code rank metric code lifted constant dimension code union codes final constant dimension code particular codes constructed recently subset codes rank metric codes used construction form new class rank metric codes present decoding algorithm constructed codes projective space efficiency decoding depends efficiency decoding constant weight codes rank metric codes finally , use final constant dimension codes obtain large codes projective space constant dimension
universal lesion detector ct scans pseudo masks hard negative example mining automatic lesion detection computed tomography \( ct \) scans important task medical imaging analysis still challenging due similar \( e g intensity texture \) , making especially difficult develop universal lesion detector instead developing specific type lesion detector , work builds universal lesion detector \( \) based mask r cnn , able detect different kinds whole body parts state art object detector , mask r cnn adds branch predicting segmentation masks region interest \( \) improve detection performance however , almost impossible manually large scale dataset pixel level lesion masks train mask r cnn lesion detection address problem , work constructs pseudo mask lesion region considered surrogate real mask , based mask r cnn employed lesion detection hand , work proposes hard negative example mining strategy reduce false positives improving detection performance experimental results dataset demonstrate enhanced using pseudo masks proposed hard negative example mining strategy achieves sensitivity 86 21 five false positives per image
binary energy harvesting channel finite energy storage consider capacity energy harvesting communication channel finite sized battery abstraction problem , consider system energy encoder fixed quantity , physical layer modeled accordingly finite discrete alphabet channel based fixed quantity , tractability , consider case binary energy unit capacity battery noiseless binary channel available energy state , state dependent channel causal state information available transmitter , state correlated time channel inputs future states show channel equivalent additive geometric noise timing channel causal information noise available transmitter provide single letter capacity expression involving auxiliary random variable , evaluate expression certain auxiliary random variable selection , noise concentration lattice type coding timing channel evaluate achievable rates proposed auxiliary selection extend results noiseless ternary channels
differentially private federated learning client level perspective federated learning recent advance privacy protection context , aggregates parameters optimized decentralized fashion multiple clients resulting model distributed back clients , ultimately converging joint representative model without explicitly share data however , protocol vulnerable differential attacks , could party contributing federated optimization attack , client 's contribution training information data set revealed analyzing distributed model tackle problem propose algorithm client differential privacy preserving federated optimization aim contributions training , balancing trade privacy loss model performance empirical studies suggest given sufficiently large number participating clients , proposed procedure maintain client level differential privacy minor cost model performance
based coordinated white space spectrum sharing home networks idea database monitor secondary use white space \( tvws \) spectrum assist coordinating secondary usage ground considering home networking use case , leverage database interference aware coordinated tvws sharing among secondary users \( home networks \) using em short term auctions , thereby realize dynamic secondary market enable based coordinated tvws sharing framework , propose enhanced em market driven tvws spectrum access model short term auctions , propose online multi unit , iterative truthful mechanism called verum takes consideration spatially heterogeneous spectrum availability , inherent characteristic tvws context prove verum truthful \( e , best strategy every based true \) also efficient allocates spectrum users value evaluation results scenarios real home distributions urban dense urban environments using realistic tvws spectrum availability maps show verum performs close optimal allocation terms revenue coordinating spectrum manager comparison two existing efficient truthful multi unit spectrum auction schemes , , shows verum better terms revenue , spectrum percentage bidders diverse conditions taking together , verum seen offer users encouraging use tvws spectrum greater spectrum availability \( measured percentage bidders \) well coordinating spectrum manager revenue generation
weakly supervised discriminative feature learning state information person identification unsupervised learning identity discriminative visual feature appealing real world tasks manual costly however , images identity visually images taken different states , e g different camera views poses visual discrepancy leads great difficulty unsupervised discriminative learning , real world tasks could often know states without human annotation , e g easily camera view labels person identification facial pose labels face recognition work propose utilizing state information weak supervision address visual discrepancy caused different states formulate simple pseudo label model utilize state information attempt refine assigned pseudo labels weakly supervised decision boundary rectification weakly supervised feature drift regularization evaluate model unsupervised person identification pose invariant face recognition despite simplicity method , could outperform state art results , datasets standard resnet 50 backbone also find model could perform standard supervised fine tuning results three datasets code available https url
identity bounds interpretation statistical physics applications information theory identity two versions bound probability certain large deviations event , established identity interpretation statistical physics , namely , equilibrium composite system consists multiple particles several information theoretic application examples , analysis large deviations probability naturally arises , described viewpoint statistical mechanical interpretation results several relationships information theory statistical physics , hope , reader find
end end latency bounds time sensitive networking based asynchronous traffic shaping compute bounds end end worst case latency size per class deterministic network based \( \) asynchronous traffic shaping \( \) , proposed time sensitive networking \( \) group implementation interleaved , traffic network , thus avoiding due interleaved , traffic every , allows computation explicit delay bounds furthermore , obtain novel , tight per flow bound response time , input , smaller existing network calculus bounds also compute per flow bound response time interleaved based results , compute bounds per class , use newly computed delay bounds along recent results interleaved literature derive tight end end latency bounds show less sums per delay bounds
logic interactive turing reduction paper gives completeness proof fragment calculus respect semantics computability logic , interactive algorithmic reduction concept precisely , associated concept generalization turing traditional , input output problems computational tasks arbitrary degrees primary secondary
beyond precision study recall initial retrieval neural representations vocabulary mismatch central problem information retrieval \( \) , e , relevant documents may contain \( symbolic \) terms query recently , neural representations shown great success capturing semantic , leading new possibilities alleviate vocabulary mismatch problem however , existing efforts direction devoted ranking stage leverage neural representations help rank set candidate documents , typically obtained initial retrieval stage based symbolic index search scheme \( e g , inverted index \) naturally raises question relevant documents found initial retrieval stage due vocabulary mismatch , would chance rank top positions later therefore , paper , study problem employ neural representations improve recall relevant documents initial retrieval stage specifically , meet efficiency requirement initial stage , introduce neural index neural representations documents , propose two hybrid search schemes based neural symbolic indices , namely parallel search scheme sequential search scheme experiments show hybrid index search schemes improve recall initial retrieval stage small overhead
characterizing application scheduling edge fog cloud computing resources cloud computing grown become popular distributed computing service offered commercial providers recently , edge fog computing resources emerged wide area network part internet things \( iot \) three resource abstraction layers complementary , provide distinctive benefits scheduling applications clouds active area research , workflow models flexible abstraction specify applications execution however , application programming scheduling models edge fog still , benefit cloud resources time , also value using resources application execution article , present taxonomy concepts essential solving problem scheduling applications edge , cloud computing resources first characterize resource capabilities limitations infrastructure , design taxonomy application models , quality service \( qos \) constraints goals , scheduling techniques , based literature review also key research papers using taxonomy survey benefits developers researchers distributed resources designing applications , selecting relevant computing abstraction \( \) , developing selecting appropriate scheduling algorithm also gaps literature open problems remain
relational reasoning sequential attention paper proposes attention module augmented relational network called \( sequential attention relational network \) carry relational reasoning extracting reference objects making efficient pairing objects greatly reduces computational memory requirements relational network , computes object pairs also shows high accuracy sort dataset compared models , especially relational questions
highly data driven mpc minimal intervention shared control present shared control paradigm improves user 's ability operate complex , dynamic systems potentially environments without priori knowledge user 's objective paradigm , role autonomous partner improve general safety system without constraining user 's ability achieve behaviors approach relies data driven , model based representation joint human machine system evaluate , parallel , significant number potential inputs user may wish provide samples used \( 1 \) predict safety system horizon , \( 2 \) minimize influence autonomous partner resulting shared control algorithm maximizes allocated human partner improve sense , improving safety evaluate efficacy shared control algorithm human subjects study \( n 20 \) conducted two simulated environments balance car experiment , users free operate system however would like \( e , specified task \) asked try avoid regions state space using modern computational resources \( e , gpus \) approach able consider 10 , 000 potential trajectories time step control loop running balance car results study show shared control paradigm improves system safety without knowledge user 's goal , maintaining high levels user satisfaction low levels code available online https url
class narrow sense bch codes bch codes important class cyclic codes applications satellite communications , , disk , two dimensional codes although bch codes widely studied , parameters known special classes recently , et al made new progress bch codes however , still limited knowledge dimension bch codes , weight distribution bch codes paper , generalize results bch codes several previous papers r n dimension narrow sense bch codes length frac q 1 lambda designed distance 2 leq delta leq frac q \( 1 \) 2 1 lambda 1 , lambda factor q 1 r n weight distributions two classes narrow sense bch codes length frac q 1 2 designed distance delta frac \( q 1 \) q 1 q lfloor \( 1 \) 2 rfloor 1 2 delta frac \( q 1 \) q 1 q lfloor \( 1 \) 2 rfloor 1 2 determined r n weight distribution class bch codes length frac q 1 q 1 determined r n particular , subclass class bch codes optimal respect bound optimal linear codes obtained class bch codes characterized
modular vehicle control transferring semantic information unseen weather conditions using gans end end supervised learning shown promising results self driving cars , particularly conditions trained however , may necessarily perform well unseen conditions paper , demonstrate knowledge one weather condition semantic labels available completely new set conditions access labeled data problem addressed task vehicle control independent perception control modules , changing one affect train control module data available condition keep fixed even new conditions perception module used interface new weather conditions control model perception module turn trained using semantic labels , assume already available weather condition control model trained however , obtaining conditions error prone process therefore , propose use generative adversarial network \( gan \) based model retrieve semantic information new conditions unsupervised manner introduce architecture , model \( semantic labels available \) model \( semantic labels available \) model used vehicle without control module
adversarial based neural networks affect wild growing interest affective computing research nowadays given crucial role bridging humans computers progress recently accelerated due emergence data one recent advance field use adversarial learning improve model learning augmented samples however , use latent features , feasible adversarial learning , largely explored , yet technique may also improve performance affective models , demonstrated related fields , computer vision expand analysis , work , explore use latent features proposed adversarial based networks recognition wild specifically , models operate several modalities discriminator , conditioned extracted latent features generator experiments recently released dataset suggest progressive improvements results finally , show competitive results affective behavior analysis wild \( \) challenge dataset
exact algorithms 0 1 integer programs linear equality constraints paper , show \( 1 n \) time \( 1 n \) space exact algorithms 0 1 integer programs constraints linear coefficients arbitrary real numbers algorithms faster exhaustive search almost faster algorithm inequality version problem , , \( arxiv \) , motivated work rather improving time space complexity , advance simple direction many np hard problems terms exact exponential algorithms specifically , extend algorithms linear optimization problems
context aware prediction word forms fundamental complex characteristic language paper propose new task predicting form given base form lemma appropriate given context present encoder decoder style neural network produce derived form character character , based corresponding character level representation base form context demonstrate model able generate valid context sensitive known base forms , less accurate lexicon agnostic setting
optimization code rates wiretap channels propose new framework determining wiretap code rates single input single output eavesdropper wiretap channels capacity eavesdropper 's channel available transmitter framework , introduce effective secrecy throughput \( \) new performance metric explicitly captures two key features wiretap channels , namely , reliability secrecy notably , measures average rate information transmitted transmitter intended receiver without provide easy implement methods determine wiretap code rates two transmission schemes 1 \) adaptive transmission scheme capacity main channel available transmitter 2 \) fixed rate transmission scheme capacity main channel available transmitter extended absolute passive eavesdropping scenario even average signal noise ratio eavesdropper 's channel available transmitter notably , solutions wiretap code rates require us set reliability secrecy constraints transmission within wiretap channels
dual path networks work , present simple , highly efficient dual path network \( dpn \) image classification presents new topology connection paths internally revealing equivalence state art residual network \( resnet \) densely convolutional network \( densenet \) within framework , find resnet enables feature usage densenet enables new features exploration important learning good representations enjoy benefits path topologies , proposed dual path network common features maintaining flexibility explore new features dual path architectures extensive experiments three benchmark datasets , , pascal voc , clearly demonstrate superior performance proposed dpn state arts particular , dataset , shallow dpn best \( \) smaller model size , less computational cost 8 lower memory consumption , deeper dpn \( dpn \) state art single model performance 2 times faster training speed experiments large scale scene dataset , pascal voc detection dataset , pascal voc segmentation dataset also demonstrate consistently better performance densenet , resnet latest model various applications
improving mae cce label noise label noise inherent many deep learning tasks training set becomes large typical approach tackle noisy labels using robust loss functions categorical cross entropy \( cce \) successful loss function many applications however , cce also fitting samples corrupted labels easily contrast , mean absolute error \( mae \) noise tolerant theoretically , generally works much worse cce practice work , three main points first , explain mae generally performs much worse cce , introduce new understanding fundamentally intrinsic sample weighting schemes perspective every sample 's gradient magnitude respect vector consequently , find mae 's differentiation degree training examples small informative ones cannot contribute enough non informative training therefore , mae generally training data noise rate high second , based finding , propose improved mae \( \) , mae 's good noise robustness moreover , differentiation degree training data points controllable addresses problem mae third , effectiveness cce mae evaluated empirically extensive experiments , focus image classification synthetic corrupted labels video retrieval real noisy labels
inequality entropy power inequality entropy power inequality \( \) inequality \( \) viewed information concerning linear transformations random variables provides lower bounds entropy linear transformations random vectors independent components , hand , provides upper bounds entropy random vector terms linear transformations paper , present new entropy inequality generalizes considering variety independence relations among components random vector main technical contribution proof strategy leverages prove gaussian optimality certain entropy expressions independence constraints
deep model transferability attribution maps exploring transferability heterogeneous tasks sheds light intrinsic , consequently enables knowledge transfer one task another reduce training effort latter paper , propose simple yet approach estimating transferability deep networks , especially handling vision tasks unlike work relies large number annotations supervision thus computationally , proposed approach requires human annotations imposes constraints architectures networks achieved , specifically , via deep networks model space , wherein network treated point distances two points measured deviations produced attribution maps proposed approach several magnitude times faster , meanwhile preserves task wise topological structure highly similar one obtained code available https url
rt slam generic real time visual slam implementation article presents new open source c implementation solve slam problem , focused , high execution speed based original object oriented architecture , allows combination numerous sensors landmark types , integration various approaches proposed literature system capacities illustrated presentation inertial vision slam approach , several improvements existing methods introduced , high dynamic motions results hand held camera presented
bias aware policy active learning data efficiency learning based algorithms important since high quality clean data expensive well hard collect order achieve high model performance least number samples , active learning technique queries important subset data original dataset active learning domain , one research heuristic uncertainty based method useful learning based system recently , works propose apply policy reinforcement learning \( \) querying important data seems general heuristic uncertainty based method method depends data feature reliable human prior however , two problems sample policy learning , applying active learning precise , sample policy learning occurs sampling within large action space , meanwhile , class lead paper , propose bias aware policy network called active learning \( \) , prevents , improves sample efficiency policy learning structure without ignoring global \( overview whole unlabeled set \) experiment , outperforms baseline methods mnist dataset mnist last least , investigate generalization policy learned mnist dataset directly applying mnist show agent generalize outperform directly learned policy constrained labeled sets
space complexity 2 dimensional approximate range counting study problem 2 dimensional orthogonal range counting additive error given set p n points drawn n times n grid error parameter eps , goal build data structure , orthogonal range r , return number points p cap r additive error eps n well known solution problem em eps approximation , subset subseteq p estimate number points p cap r number points cap r known eps approximation size \( frac 1 eps log 2 5 frac 1 eps \) exists p respect orthogonal ranges , best lower bound omega \( frac 1 eps log frac 1 eps \) eps approximation rather restricted data structure , allowed store information coordinates points p paper , explore achieved without data structure first describe simple data structure uses \( frac 1 eps \( log 2 frac 1 eps log n \) \) bits answers queries error eps n prove lower bound data structure answers queries error eps n must use omega \( frac 1 eps \( log 2 frac 1 eps log n \) \) bits lower bound information theoretic show collection 2 omega \( n log n \) point sets large em union combinatorial discrepancy , thus hard distinguish unless use omega \( n log n \) bits
1d cnn time series classification stronger baseline time series classification task using 1d cnn , selection kernel size important ensure model capture right scale salient signal long time series existing work 1d cnn treats kernel size hyper parameter tries find proper kernel size grid search time consuming inefficient paper theoretically analyses kernel size impacts performance 1d cnn considering importance kernel size , propose novel scale 1d cnn \( cnn \) architecture capture proper kernel size model learning period specific design kernel size configuration developed enables us kernel size represent receptive fields proposed cnn method evaluated using datasets experiment results demonstrate method stronger baseline multiple performance indicators , including critical difference , counts , average accuracy also published experimental source codes github \( https url \)
multi http traffic analysis commodity hardware based local knowledge tcp streams paper propose implement novel techniques performance evaluation web traffic \( response time , response code , etc \) , underlying tcp connection , traffic analysis throughput furthermore , proposed software http traffic analysis runs standard hardware , cost effective besides , present sub tcp connection load balancing techniques significantly increase throughput expense http transactions techniques provide performance evaluation statistics single alternative full tcp connection
network together node classification via cross network deep network embedding network embedding highly effective method learn low dimensional node vector representations original network structures well preserved however , existing network embedding algorithms mostly developed single network , fail learn generalized feature representations across different networks paper , study cross network node classification problem , aims leveraging abundant labeled information source network help classify unlabeled nodes target network task , features learned nodes across different networks end , novel cross network deep network embedding \( \) model proposed incorporate domain adaptation deep network embedding learn label discriminative network invariant node vector representations one hand , leverages network structures capture nodes within network , mapping strongly connected nodes similar latent vector representations hand , node attributes labels capture nodes across different networks making labeled nodes across networks aligned latent vector representations extensive experiments conducted , demonstrating proposed model significantly outperforms state art network embedding algorithms cross network node classification
private information retrieval non replicated databases consider problem private information retrieval \( pir \) single message k messages n non non replicated databases different majority existing literature , considers case replicated databases databases store content form k messages , , consider case non replicated databases special non replication structure database stores k messages message stored across r different databases generates r regular graph structure storage system vertices graph messages edges databases derive general upper bound 2 depends graph structure specialize problem storage systems described two special types graph structures cyclic graphs emph fully connected graphs prove pir capacity case cyclic graphs frac 2 k 1 , pir capacity case fully connected graphs min frac 2 k , frac 1 2 end , propose novel achievable schemes graph structures capacity achieving central insight schemes introduce dependency queries submitted databases contain desired message , requests compressed cases , results show severe degradation pir capacity due non replication
variations stochastic shortest path problem contribution , revisit stochastic shortest path problem , show recent results allow one improve classical solutions present algorithms synthesize strategies multiple guarantees distribution length paths reaching given target , rather simply minimizing expected value concepts algorithms propose applications general results obtained recently markov decision processes described series recent papers
open source dataset machine learning techniques automatic recognition historical machine learning techniques presented automatic recognition historical letters \( \) st \( \) new image dataset letters \( cgcl \) pre processed recognition prediction machine learning methods dataset consists images 34 types letters explanatory data analysis cgcl datasets shown letters dimensionality reduction methods , example , distributed stochastic neighbor embedding \( \) due worse letter representation comparison hand writing logistic regression \( \) 2d convolutional neural network \( cnn \) models applied model demonstrated area curve \( auc \) values receiver operating characteristic \( \) lower 0 92 0 60 cgcl , respectively cnn model auc values close 0 99 cgcl \( despite much smaller size quality cgcl comparison \) condition high lossy data augmentation cgcl dataset published available data science community open source resource
energy efficiency optimization mimo distributed antenna systems paper , propose transmit covariance optimization method maximize energy efficiency \( ee \) single user distributed antenna system , remote access units \( \) user equipped multiple antennas unlike previous related works , rate requirement selection taken consideration , total circuit power consumption related number active given setup , first propose optimal transmit covariance optimization method solve ee optimization problem fixed set active specifically , split problem three subproblems , e , rate maximization problem , ee maximization problem without rate constraint , power minimization problem , efficiently solved , novel distance based selection method proposed determine optimal set active simulation results show performance proposed selection almost identical optimal exhaustive search method significantly reduced computational complexity , performance proposed algorithm significantly outperforms existing ee optimization methods
structured output learning abstention application accurate opinion prediction motivated supervised opinion analysis , propose novel framework devoted structured output learning abstention \( \) structure prediction model able predicting labels structured output cost chosen user flexible way purpose , decompose problem learning pair predictors , one devoted structured abstention , structured output prediction compare fully labeled training data predictions potentially containing , define wide class abstention aware losses learning achieved surrogate regression appropriate feature space prediction abstention performed solving new pre image problem thus , extends recent ideas structured output prediction via surrogate problems calibration theory enjoys statistical guarantees resulting excess risk hierarchical abstention aware loss , shown relevant fine grained opinion mining gives state art results task moreover , abstention aware representations used predict user review ratings based sentence level opinion predictor
power efficient sensing communication scheme joint source channel network coding using compressive sensing propose joint source channel network coding scheme , based compressive sensing principles , wireless networks awgn channels \( may include multiple access broadcast \) , sources exhibiting temporal spatial dependencies goal provide reconstruction sources within allowed distortion level receiver perform joint source channel coding source randomly source values lower dimensional space consider sources satisfy restricted \( \) condition well general sources randomness network allows mapping lower dimensional spaces approach relies using analog random linear network coding receiver uses compressive sensing decoders reconstruct sources key insight fact , compressive sensing analog network coding preserve source characteristics required compressive sensing decoding
research directions innovation design automation one click manufacturing services intelligent machines manufacturing created opportunities consumers products fit needs turn would drive demand manufacturing services however , based manufacturing system production extremely low quantity variety products expensive implement new emerging technology design automation driven data driven computational design , manufacturing service enabled micro holds promise towards innovation paper , scientific , technology infrastructure challenges identified solved , impact emerging technologies product innovation future organization discussed
f 2 linear relations number generators sequence generators obtained linear two element field f 2 , e , f 2 linear generators , widely used number generators example , one successful applications advantage generators assess quickly using theoretical criteria , dimension v bit accuracy compute dimensions , several polynomial time lattice reduction algorithms proposed case f 2 linear generators paper , order assess non random bit patterns dimensions higher dimension v bit accuracy , focus relationship points dual lattices f 2 linear relations significant v bits output sequences , consider new n v based minimum weight f 2 linear relations whose degrees minimal v next , numerically show low weight f 2 linear relations dimensions higher , show output vectors specific small p values tests also report variants , well generators , significantly improved perspective n v
neural turing machines extend capabilities neural networks coupling external memory resources , interact attentional processes combined system analogous turing machine von architecture differentiable end end , allowing efficiently trained gradient descent preliminary results demonstrate neural turing machines infer simple algorithms , sorting , associative recall input output examples
mining temporal evolution knowledge graph features literature based discovery prediction literature based knowledge discovery process identifies important implicit relations among information embedded published literature existing techniques information retrieval natural language processing attempt identify hidden connections information concepts within published literature , however , techniques concept predicting future emerging relations among scientific knowledge components within literature keyword co occurrence network \( \) , built upon author selected keywords \( e , knowledge entities \) , considered knowledge graph focuses knowledge components knowledge structure scientific domain relationships knowledge entities using data two research domains medical domain , , temporal , long short term memory recurrent neural network , study proposed framework successfully predict future literature based emerging connections among knowledge units problem dynamic supervised link prediction task , proposed framework integrates novel node edge level features temporal importance keywords computed bipartite networks , communities keywords , built upon relations , relative importance temporal citation counts used feature construction process node edge level features input lstm network forecast feature values positive negatively labeled non connected keyword pairs classify accurately high classification performance rates suggest features predicting emerging connections scientific knowledge units emerging trend analysis
classification random boolean networks provide first classification different types random boolean networks \( rbns \) study differences rbns depending degree determinism updating scheme , first define three new types rbns note similarities differences different types rbns aid public software developed particularly , find point independent updating scheme , rbns different depending determinism non determinism rather depending also show way mapping non synchronous deterministic rbns synchronous rbns results important use specific types rbns modelling natural phenomena
formal verification self assembling systems paper introduces theory practice formal verification self assembling systems interpret well studied abstraction self assembly , abstract tile assembly model \( \) , computation tree logic \( ctl \) , temporal logic often used model checking consider class rectilinear tile assembly systems class includes systems studied theoretical literature , \( algorithmic \) dna tile self assembling systems realized date present polynomial time algorithm , given tile assembly system input , either provides counterexample 's whether unique terminal assembly using partial order reductions , verification search space algorithm reduced exponential size \( n 2 \) , n x n size assembly surface reduction asymptotically best possible report experimental results obtained translating tile assembly simulator files petri net format smart model checking engines devised et al model runs \( x n 4 \) time , number tile types tile assembly system , n x n surface size model checking problem practical limit usually insufficient memory store state space limit case amount memory required represent rules model \( storage state space reachability graph small comparison \) discuss overcome obstacle means front end tailored characteristics self assembly
study issues concerns whole progress whole \( \) allow large number individuals fully improve modern healthcare , enabling new era personalized medicine diagnosis treatment tailored patient 's genetic also allows individuals motivated personal access genetic information , use , e g , trace however , progress also number privacy concerns , sensitivity information well studied paper presents study users' perception privacy issues , well toward different programs report series semi structured , involving 16 participants , analyze results quantitatively analysis shows users exhibit common trust concerns discrimination , demand strict control genetic information finally , highlight need research area follow studies build initial findings
mri ct translation gans present detailed description reference implementation preprocessing steps necessary public image registration evaluation \( \) dataset task magnetic resonance imaging \( mri \) x computed tomography \( ct \) translation furthermore describe implement three state art convolutional neural network \( cnn \) generative adversarial network \( gan \) models report statistics visual results two
path type guarded recursive types type theory , types used represent processes , thus crucial formal verification non reactive programs proof assistants based type theory , currently , programming reasoning types difficult two reasons need recursive definitions , lack built identity types important notion bisimilarity r n guarded recursion sense recently suggested possible approach dealing problem productivity , allowing encoded types indeed , types encoded using combination guarded recursion universal quantification clocks paper studies notion bisimilarity guarded recursive types cubical type theory , extension cubical type theory guarded recursion prove , , abstract , category theoretic notion bisimilarity final guarded equivalent \( sense type theory \) path equality \( primitive notion equality cubical type theory \) example study guarded notion labelled transition systems , show , special case general theorem , path equality adaptation usual notion processes particular , implies guarded recursion used give simple reasoning proofs bisimilarity work seen step towards obtaining bisimilarity path equality types using encodings mentioned
tools techniques malware detection analysis one major serious threats internet faces today vast amounts data files need evaluated potential malicious malicious software , often referred malware designed nature capability change code spread moreover , diversity volume variants effectiveness traditional defenses typically use signature based techniques unable detect previously unknown malicious variants malware families share typical behavioral patterns origin purpose behavioral patterns obtained either dynamically exploited detect classify unknown malware known families using machine learning techniques survey paper provides overview techniques tools detecting analyzing malware
calculus system clustering ranking calculus new proof theoretic semantic approach introduced g needs theory computability logic earlier article formulas computability logic generalized concept version termed ranking , showed , clustering ranking , one capture , refine generalize called extended logic 's treatment extended logic , however , purely , system proposed present paper constructs calculus system clustering ranking , sound complete w r propositional fragment based semantics system considered conservative extension classical propositional logic also , limited 2 ranks , purely propositional extended logic full
efficient neural network kernels arm cortex cpus deep neural networks becoming increasingly popular always iot edge devices performing data analytics right source , reducing latency well energy consumption data communication paper presents , efficient kernels developed maximize performance minimize memory neural network \( \) applications arm cortex processors targeted intelligent iot edge devices neural network inference based kernels achieves 4 improvement runtime throughput 4 improvement energy efficiency
video trajectory classification anomaly detection using hybrid cnn vae classifying time series data using neural networks challenging problem length data varies video object trajectories , key many visual surveillance applications , often found varying length trajectories used understand behavior \( normal anomalous \) moving objects , need represented correctly paper , propose video object trajectory classification anomaly detection using hybrid convolutional neural network \( cnn \) variational autoencoder \( vae \) architecture first , introduce high level representation object trajectories using color gradient form next stage , semi supervised way moving object trajectories extracted using temporal unknown incremental clustering \( \) , applied trajectory class labeling anomalous trajectories using distributed stochastic neighbor embedding \( \) finally , hybrid cnn vae architecture used trajectory classification anomaly detection results obtained using publicly available surveillance video datasets reveal proposed method successfully identify important traffic anomalies vehicles following lane driving , speed variations , abrupt termination vehicle movement , vehicles moving directions proposed method able detect anomalies higher accuracy compared existing anomaly detection methods
path planning minimizing expected cost success consider general path planning problem robot graph edge costs , node boolean value success failure \( respect task \) given probability objective plan path robot graph minimizes expected cost success paper , goal bring understanding problem start showing problem optimally solved formulating infinite horizon markov decision process , exponential space complexity formally prove np hardness address space complexity , propose path planner , using game theoretic framework , asymptotically gets arbitrarily close optimal solution moreover , also propose two fast non path planners show performance framework , extensive simulations two scenarios searching object scientific studies , robot looking connected remote station \( real data \) numerical results show considerable performance improvement existing state art approaches
learning maintain natural image statistics maintaining natural image statistics crucial factor restoration generation realistic looking images training cnns , usually adversarial training \( gan \) , output images lie manifold natural images gans powerful , perfect hard train results still often suffer artifacts paper propose complementary approach , whose goal train forward cnn maintain natural internal statistics look explicitly distribution features image train network generate images natural feature distributions approach reduces orders magnitude number images required training achieves state art results single image super resolution , high resolution surface normal estimation
case study formal verification self adaptive behaviors decentralized system self adaptation promising approach manage complexity modern software systems self adaptive system able adapt autonomously internal dynamics changing conditions environment achieve particular quality goals particular interest decentralized systems , central control adaptation one important challenge self adaptive systems , particular decentralized control adaptation , provide guarantees intended runtime paper , present case study use model checking verify behavioral properties decentralized self adaptive system , contribute formalized architecture model decentralized traffic monitoring system prove number self adaptation properties flexibility robustness model main processes system use timed automata , specification required properties use timed computation tree logic use tool specify system verify flexibility robustness properties
discussions signal uncertainty principle shannon channel capacity equation research breaking shannon limit method far , transmission rate digital communication theoretical upper limit proposed shannon 70 years , academia industry lack new theories point direction increasing transmission rate paper , completeness shannon channel capacity equation analyzed framework signal uncertainty principle , brings shannon theory solid physical theoretical basis theoretical method breaking shannon limit proposed finally , proved time non orthogonal multi digital modulation technology studied 20 years practical method break shannon limit
automatic pattern classification unsupervised learning using dimensionality reduction data mirroring neural networks paper proposes unsupervised learning technique using multi layer mirroring neural network 's clustering algorithm multi layer mirroring neural network neural network trained generalized data inputs \( different categories image patterns \) perform non linear dimensionality reduction resultant low dimensional code used unsupervised pattern classification using 's algorithm adapting non linear activation function \( modified function \) weights bias terms small random values , mirroring input pattern training , weights bias terms way input presented output back propagating error mirroring neural network capable reducing input vector great degree \( approximately 1 original size \) also able reconstruct input pattern output layer reduced code units feature set \( output central hidden layer \) extracted network fed 's algorithm , classify input data patterns classes implementation 's algorithm , initial seed points selected way enough perfectly different categories thus new method unsupervised learning formulated demonstrated paper method impressive results applied classification different image patterns
constructing permutation arrays using partition extension give new lower bounds \( n , \) , various positive n n , \( n , \) largest number n symbols pairwise hamming distance least large sets n symbols pairwise hamming distance necessary component constructing error correcting permutation codes , proposed power line communications technique , em partition extension , applicable constructing sets n , n describe three new techniques , em sequential partition extension , em parallel partition extension , em modified product operation , extend applicability partition extension different ways describe partition extension gives improved lower bounds \( n , n 1 \) using mutually orthogonal latin squares \( \) present efficient algorithms computing new partitions iterative greedy algorithm algorithm based integer linear programming algorithms yield partitions positions \( symbols \) used input partition extension techniques report many new lower bounds \( n , \) found using techniques n
sparse collaborative nonnegative representation helps pattern classification use sparse representation \( sr \) collaborative representation \( cr \) pattern classification widely studied tasks face recognition object categorization despite success sr cr based classifiers , still whether ell 1 norm sparsity ell 2 norm collaborative property brings success sr cr based classification paper , investigate use nonnegative representation \( nr \) pattern classification , largely previous work analyses reveal nr boost representation power homogeneous samples limiting representation power heterogeneous samples , making representation sparse discriminative simultaneously thus providing effective solution representation based classification sr cr experiments demonstrate proposed nr based classifier \( nrc \) outperforms previous representation based classifiers deep features inputs , also achieves state art performance various visual classification tasks
learning refine human pose estimation multi person pose estimation images videos important yet challenging task many applications despite large improvements human pose estimation enabled development convolutional neural networks , still exist lot difficult cases even state art models fail correctly localize body motivates need additional refinement step addresses challenging cases easily applied top existing method work , introduce pose refinement network \( \) takes input image given pose estimate learns directly predict refined pose jointly reasoning input output space order network learn refine incorrect body joint predictions , employ novel data augmentation scheme training , model hard human pose cases evaluate approach four popular large scale pose estimation benchmarks single multi person pose estimation , pose estimation , pose tracking , report systematic improvement state art
developing cybersecurity education awareness small medium sized enterprises smes purpose study focus cybersecurity strategy propose high level programme cybersecurity education awareness used targeting small medium sized enterprises businesses \( smes \) city level essential component cybersecurity strategy building awareness education online threats protect data services programme based existing research provides unique insight city based project similar aims , structure work , review conducted literature cybersecurity education awareness , particularly smes theoretical analysis complemented using case study , innovative programme seeks work businesses significantly enhance security analyses , best practices important lessons recommendations produce high level programme cybersecurity education awareness , literature informative education awareness , may always reach real world however , existing , one explored study , great potential , room improvement knowledge areas , , combined benefit communities , study contributes current research outline high level programme cybersecurity education awareness targeting smes research , literature space insights advances challenges faced going programme presented analyses allow us proposal core programme assist improving security education , awareness training targets smes
one time based data protection distributed environments one time \( \) based data protection integrity mobile code remote host presented data protection required mobile agent could retrieve information would nodes network case , information management could rely encryption key data integrity mobile code must protected malicious , removing collected data , could cover information server sent agent algorithm described article seems simple enough , easily implemented scheme based non interactive protocol allows remote host change data fly , time , information handling
computational complexity series similar role playing games \( fe \) popular turn based role playing game \( \) series paper studies computational complexity simplified version fe \( floor tiles tiles , attributes characters constants 8 , movement distance per character turn fixed 6 tiles \) , proves 1 simplified fe complete \( thus actual fe least hard \) 2 poly round fe np complete , even map cycle free , without units , small constant poly round fe decide whether player game certain number rounds polynomial map size map called cycle free corresponding planar graph cycle free hardness results also hold similar series , final ,
universal patterns folding efficiently grid present two universal patterns enable material fold connected surface made unit squares 3d cube grid example , surface folding efficient target surfaces equivalent sphere , needs target surface area , folding two layers material geometric results offer new way build matter substantially efficient possible square n times n material , fold surface area \( n \) may stack theta \( n 2 \) layers one point also show rigid motion without collisions , possible general 2d folding r n achieve results , develop new approximation algorithms surface grid , simultaneously give 2 approximation tour length 8 3 approximation number turns length turns area folding , build past approximation algorithms two objectives 2d
dictionary learning global sparsity constraint new method proposed paper learn overcomplete dictionary training data samples current methods enforce similar sparsity constraint input samples , proposed method attempts impose global sparsity constraint entire data set enables proposed method assign atoms dictionary represent various samples optimally adapt complicated structures underlying entire data set sparse coding sparse pca techniques , simple algorithm designed implementation method efficiency convergence proposed algorithm also theoretically analyzed based experimental results implemented series signal image data sets , method performs better current dictionary learning methods original dictionary recovering , input data , salient data structure revealing
learning representations visual observations work explore new approach robots world simply observing particular investigate effectiveness learning task agnostic representations continuous control tasks extend time networks \( \) learn visual observations embedding multiple frames jointly embedding space opposed single frame show , able encode position velocity attributes significantly accurately test usefulness self supervised approach reinforcement learning setting show representations learned agents observing take random actions , agents perform tasks successfully , enable learning continuous control policies using algorithms like policy optimization \( \) using learned embeddings input also demonstrate significant improvements real world dataset relative error reduction 39 4 motion attributes 11 1 static attributes compared single frame baseline video results available https url
attention interpretable attention mechanisms recently boosted performance range nlp tasks attention layers explicitly weight input representations , also often assumed attention used identify information models found important \( e g , specific word \) test whether assumption holds manipulating attention weights already trained text classification models analyzing resulting differences predictions observe ways higher attention weights correlate greater impact model predictions , also find many ways hold , e , gradient based rankings attention weights better predict effects conclude attention predicts input overall importance model , means fail safe indicator
efficient face alignment via locality constrained representation robust recognition practical face recognition studied past decades , still remains open challenge current approaches already achieved substantial recognition accuracy however , performance usually dramatically face samples address problem , propose highly efficient robust locality constrained representation \( \) algorithm practical real time face recognition specifically , locality constraint correlated atoms ones , applied construct dictionary face alignment simultaneously align face update locality constrained dictionary , obtaining final alignment moreover , make use block structure accelerate derived analytical solution experimental results public data sets show significantly outperforms several state art approaches terms efficiency scalability even better performance
learning 2 images deep reinforcement learning approach paper , propose deep reinforcement learning \( drl \) solution grasping problem using 2 images source information particular , developed simulated environment robot equipped aim reaching blocks planar surfaces blocks different dimensions , shapes , position orientation 3d allowed us simulate real world setup , depth camera placed fixed position stream images used policy network learn solve task explored different drl algorithms problem configurations experiments demonstrated effectiveness proposed drl algorithm applied tasks guided visual depth camera inputs using proper policy , proposed method estimates robot tool configuration reaches object surface negligible position orientation errors , best knowledge , first successful attempt using 2 images input drl algorithm , solve grasping problem 3d world coordinates
deep learning vs traditional computer vision deep learning limits possible domain digital image processing however , say traditional computer vision techniques progressive development years prior rise dl become paper analyse benefits drawbacks approach aim paper discussion whether knowledge classical computer vision techniques maintained paper also explore two computer vision combined several recent hybrid methodologies reviewed demonstrated ability improve computer vision performance tackle problems suited deep learning example , combining traditional computer vision techniques deep learning popular emerging domains vision 3d vision deep learning models yet fully
blinkdb queries bounded errors bounded response times large data paper , present blinkdb , massively parallel , sampling based approximate query engine running ad hoc , interactive sql queries large data key insight blinkdb builds one often make reasonable decisions absence perfect answers example , reliably detecting server using distributed collection system logs require analyzing every request processed system based insight , blinkdb allows one trade query accuracy response time , enabling interactive queries massive data running queries data samples presenting results annotated meaningful error achieve , blinkdb uses two key ideas previous work area \( 1 \) adaptive optimization framework builds maintains set multi dimensional , multi resolution samples original data time , \( 2 \) dynamic sample selection strategy selects appropriately sized sample based query 's accuracy response time requirements built open source version blinkdb validated effectiveness using well known h benchmark well real world analytic workload derived experiments 100 node cluster show blinkdb answer wide range queries real world query trace 17 data less 2 seconds \( 100 times faster \) , within error 2 10
sparse combinatorial group testing low energy massive random access present random access schemes machine type communication massive number low energy wireless devices want transmit short information packets focus device discovery problem , extensions joint discovery data transmission well data transmission without communicating device identities formulate problem combinatorial group testing one , goal exactly identify set items pool n items energy constraint physical layer constraint number tests item , study resulting sparse combinatorial group testing problem r n sparse setting , restrict number tests item w max easy observe w max leq , must n e , testing every item individually optimal show w max 1 , number tests decreases n \( 1 \) sqrt n generally , w max 1 positive integer l 1 leq sqrt l 1 n , achieve \( 1 \) n 1 \( l 1 \) using 's construction particular choice field size also prove nearly matching lower bound shows omega \( 2 l 1 n 1 \( l 1 \) \) shows sparse setting fractional power n , rather logarithmic n classical setting r n since encoding decoding efficiency important energy efficiency , demonstrate construction decoded \( poly \( \) \( \) \) time entry codeword computed space poly \( log n \) shows construction \( nearly \) achieves fundamental lower bound , also favorable encoding decoding complexity
bounds number type space filling curves z curve one example space filling curve given level refinement l , maps interval 0 , 2 dl \) one one set dimensional edge length 2 l form unit cube similar curves proposed triangular tetrahedral unit domains contrast hilbert curve continuous , type curves produce r n prove curve domain bounded number face connected case arbitrary dimension , star shaped bound indeed two case dimensions 2 3 , bound proportional depth refinement l paper theoretical computational studies frequency quantitative assessment
estimation space time varying parameters using diffusion algorithm study problem distributed adaptive estimation networks nodes cooperate estimate physical parameters vary space time domains use set basis functions characterize space varying nature parameters propose diffusion least mean squares \( \) strategy recover parameters successive time measurements analyze stability convergence proposed algorithm , derive closed form expressions predict learning behavior steady state performance terms mean square error find estimation space varying parameters using distributed approaches , covariance matrix regression data node becomes rank analysis reveals proposed algorithm overcome difficulty large extent network stochastic matrices used combine information nodes provide computer experiments illustrate support theoretical findings
coarse grained analysis simulators networks rare events computations show equation free approach computations exploited extract , computational strict systematic way dynamical attributes , detailed large scale stochastic models , neurons interact complex networks particular show equation free approach exploited perform system level tasks , stability analysis estimation mean appearance times rare events , need obtaining analytical approximations , providing demand model reduction using detailed simulator black box , compute coarse grained equilibrium diagrams , examine stability solution perform rare events analysis respect certain characteristics underlying network topology connectivity degree
discrepancy random low degree set systems motivated conjecture , consider random setting n elements sets element lies randomly chosen sets setting , showed \( \( log \) 1 2 \) discrepancy bound regime n leq \( 1 \) bound n r n paper , give tight \( sqrt \) bound entire range n , mild assumption omega \( log log \) 2 result based two steps first , applying partial method case n log \( 1 \) using properties random set system show overall discrepancy \( sqrt \) second , reduce general case n leq log \( 1 \) using lp duality careful counting argument
currycheck checking properties programs present currycheck , tool automate testing programs written functional logic programming language currycheck unit tests well property tests parameterized one arguments latter case , currycheck tests properties systematically test cases , smaller finite domains , currycheck actually prove properties unit tests properties defined module without thus , also useful document intended semantics source code furthermore , currycheck also supports automated checking specifications occurring source programs hence , currycheck useful tool contributes property specification based development reliable well tested declarative programs
information theoretic security covert communication information theoretic secrecy , particular wiretap channel formulation , provides protection message adversary eve widely studied last two decades contrast , covert communications analogous formulation provides protection even detection presence message adversary , drawn significant interest recently two security topics generally applicable different scenarios however , explore learned studying common framework similar identical mathematical formulation , introduce power optimization problems secrecy covert communications scenario , exploit common aspects problems employ similar tools respective optimizations moreover , due practical limitations , assume channel
transformation compatibility measure multiple lidar scans rigid registration multi view multi platform lidar scans fundamental problem 3d mapping , robotic navigation , large scale urban modeling applications data acquisition lidar sensors involves multiple areas different points view , thus generating partially overlapping point clouds real world scenes traditionally , \( iterative closest point \) algorithm used acquired point clouds together form unique point cloud captures scanned real world scene conventional faces local issues often needs coarse initial alignment converge optimum work , present algorithm multiple , overlapping lidar scans introduce geometric metric called transformation compatibility measure \( \) aids choosing similar point clouds registration iteration algorithm lidar scan similar reference lidar scan transformed using technique optimization transformation using gradient descent simulated annealing techniques applied improve resulting registration evaluate proposed algorithm four different real world scenes experimental results shows registration performance proposed method comparable superior traditionally used registration methods , algorithm achieves superior registration results even dealing outliers
compressed differential erasure codes efficient data paper , study problem storing data reliable efficient manner distributed storage systems propose new storage technique called differential erasure coding \( dec \) differences \( \) subsequent versions stored rather whole objects , typical delta encoding technique however , unlike delta encoding techniques , dec exploits sparsity \( e , differences two successive versions non zero entries \) updates store using compressed sensing techniques applied erasure coding first show dec provides significant savings storage size data whenever update patterns characterized place subsequently , propose practical dec framework storage size benefits place also real world update patterns insertions deletions overall data sizes conduct experiments several synthetic workloads demonstrate practical variant dec provides significant reductions storage overhead \( 60 depending workload \) compared baseline storage system incorporates concepts , delta encoding technique store data across network
automatic registration cone beam ct scanned surface via deep pose regression neural networks clustered similarities registration cone beam computed tomography \( ct \) images scanned model essential planning propose novel method performs fully automatic registration cone beam ct image scanned model build robust automatic initial registration method , method applies deep pose regression neural networks reduced domain \( e , 2 dimensional image \) subsequently , fine registration performed via optimal clusters majority voting system achieves globally optimal transformations cluster attempts optimize local transformation parameters clusters determines optimal cluster set regions surface effectively removed based consensus among optimal clusters accuracy registration evaluated euclidean distance 10 landmarks scanned model annotated experts field experiments show proposed method 's registration accuracy , measured landmark distance , outperforms existing methods 30 77 70 addition achieving high accuracy , proposed method requires neither human interactions priors \( e g , surface extraction \) main significance study twofold 1 \) light weighted neural networks indicates applicability neural network extracting pose cues easily obtained 2 \) introduction optimal cluster based registration method avoid artifacts matching procedures
rehand secure region based fast user anonymity small cell networks 5g due higher density mobile devices radio resources , fifth generation \( 5g \) mobile networks introduce small cell concept radio access technologies , called small cell networks \( \) , improve radio spectrum utilization however , increases chance due smaller coverage micro base station , e , home \( \) 5g subsequently , latency increase costs authenticated key exchange protocol , ensures entity authentication communication confidentiality secure , also increase thus , work presents secure region based scheme \( rehand \) user anonymity fast 5g rehand greatly reduces communication costs ues small cells within region base station , e , 5g , computation costs due symmetry based operations compared three related works , rehand dramatically reduces costs 92 99 99 nevertheless , work demonstrates security rehand theoretically formal proofs
formal system models active objects propose active object languages development tool formal system models distributed systems additionally formalization based term system , use established software engineering concepts , including software product lines object orientation come extensive tool support illustrate modeling approach weak memory model resulting executable model modular clear interfaces communicating participants object oriented modeling relaxations basic memory model expressed self contained variants software product line modeling language use formal active object language comes extensive tool set rapid formalization core ideas , early validity checks terms formal invariant proofs , debugging support executing test runs hence , approach supports formal system models early feedback
learning fast mixing models structured prediction markov chain monte carlo \( mcmc \) algorithms often used approximate inference inside learning , slow mixing difficult approximations degrade learning alleviate issues , define new model family using strong markov chains , whose mixing times precisely controlled parameter also develop algorithm learn models , involves maximizing data likelihood induced stationary distribution chains show empirical improvements two challenging inference tasks
estimation throughput tradeoff cognitive radio systems understanding performance cognitive radio systems great interest perform dynamic spectrum access , different paradigms literature , system \( us \) much attention recent past according us , power control mechanism employed secondary transmitter \( st \) constrain interference primary receiver \( pr \) certain threshold however , requires knowledge channel towards pr st knowledge obtained estimating received power , assuming pilot channel transmission pr estimation never perfect , hence induced error may true performance us motivated fact , propose novel model captures effect channel estimation errors performance system specifically , characterize performance us terms estimation throughput tradeoff furthermore , determine maximum achievable throughput secondary link based numerical analysis , shown conventional model performance us
new perspective fo model checking dense graph classes study first order \( fo \) model checking problem dense graphs , namely fo \( fo \) sparse graph classes give structural characterization graph classes fo interpretable graphs bounded degree characterization allows us efficiently compute fo interpretation input graph consequence , obtain fpt algorithm invariant fo model checking graph class fo interpretable \( fo \) graph class bounded degree approach use obtain results may also independent interest
empirical computational several forms computing systems , ranging nonlinearity paper exploration conceptual issues course investigating speed phenomena small turing machines present results test may experimental approaches notion computational test involves systematic attempt computation large number small turing machines \( 3 4 state , 2 symbol \) means integer sequence prediction using specialized function program massive experiment investigation rates convergence decision procedures decidability sets addition discussion \( \) predictability deterministic computing systems practice investigation novel approach discussion question context computer simulation , thus represents interesting exploration boundary concerns computational experiments
teaching natural language computers natural language , whether humans , processed generated computers , requires networked structures reflect processes semantic , syntactic , , linguistic , social , emotional , modules able produce novel useful behavior following repeated practice gets root artificial intelligence human language paper investigates modalities involved language like applications computers , aims fine tune questions ask better account context , self awareness ,
security protocol exploit analysis 5g specifications third generation project \( \) released first 5g security specifications 2018 paper reviews 5g security architecture , requirements main processes context known new protocol exploits although security enhanced compared previous generations tackle known protocol exploits , analysis identifies potentially system assumptions critical security well number protocol edge cases could render 5g systems vulnerable adversarial attacks example , null encryption null authentication supported used valid system configurations , certain key security functions still left outside scope specifications moreover , pre message exploits appears rely implicit assumption management public keys global operators parallel , existing threats international mobile identity \( \) network security features ue public key home network operator comparison lte protocol exploits reveals 5g security specifications , release 15 , fully address user privacy network availability concerns , one edge case compromise privacy , security availability 5g users services
region adaptive dense network efficient motion deblurring paper , address problem dynamic scene deblurring presence motion blur restoration images affected severe blur network design large receptive field , existing networks attempt achieve simple number generic convolution layers , kernel size , scales image processed however , techniques ignore non uniform nature blur , come expense increase model size inference time present new architecture composed region adaptive dense modules implicitly discover spatially varying shifts responsible non uniform blur input image learn filters capability complemented self module captures non local spatial relationships among intermediate features spatially varying processing capability incorporate modules densely connected encoder decoder design utilizes pre trained densenet filters improve performance network facilitates interpretable modeling spatially varying deblurring process multi scale processing large filters entirely extensive comparisons prior art benchmark dynamic scene deblurring datasets clearly demonstrate superiority proposed networks via significant improvements accuracy speed , enabling almost real time deblurring
preliminary report probabilistic attack normal form constellation semantics 's work abstract frameworks growing interest extending 's semantics order describe complex real life situations several approaches take direction weighted probabilistic extensions one prominent probabilistic approaches constellation probabilistic abstract frameworks et al paper , present normal form constellation probabilistic abstract frameworks furthermore , present transformation general constellation probabilistic abstract frameworks presented normal form way illustrate simpler normal form equal representation power general one
answering answer set programming survey explanation approaches artificial intelligence \( ai \) approaches problem solving decision making becoming complex , leading decrease solutions union 's new general data protection tries tackle problem right explanation decisions made ai systems one ai paradigms may affected new answer set programming \( asp \) thanks emergence efficient solvers , asp recently used problem solving variety domains , including medicine , cryptography , ensure successful application asp problem solving paradigm future , explanations asp solutions crucial survey , give overview approaches provide answer question answer set solution given problem , notably line , causal graphs , explanations provenance , highlight similarities differences moreover , review methods explaining set answer set solution exists
efficient distributed online prediction stochastic optimization approximate distributed averaging study distributed methods online prediction stochastic optimization approach iterative round nodes first perform local computations communicate order aggregate information decision variables synchronization accomplished use distributed averaging protocol exact distributed averaging protocol used , known optimal regret bound mathcal \( sqrt \) achieved using distributed mini batch algorithm et al \( 2012 \) , total number samples processed across network focus methods using approximate distributed averaging protocols show optimal regret bound also achieved setting particular , propose gossip based optimization method achieves optimal regret bound amount communication required depends network topology second largest transition matrix random walk network setting stochastic optimization , proposed gossip based approach achieves nearly linear scaling optimization error guaranteed epsilon mathcal \( frac 1 n epsilon 2 \) rounds , involves mathcal \( log n \) gossip iterations , nodes communicate well connected graph scaling law also observed numerical experiments cluster
differentially private algorithms empirical machine learning important use private data build machine learning classifiers literature differentially private classification algorithms , find practical real applications due two reasons first , existing differentially private classifiers provide poor accuracy real world datasets second , known differentially private algorithm empirically evaluating private classifier private test dataset r n paper , develop differentially private algorithms mirror real world empirical machine learning workflows consider private classifier training algorithm present private algorithms selecting features input classifier though adding preprocessing step takes away privacy budget actual classification process \( thus potentially making less accurate \) , show novel preprocessing techniques significantly increase classifier accuracy three real world datasets also present first private algorithms empirically constructing receiver operating characteristic \( \) curves private test set
adversarial examples modern machine learning review recent research found many families machine learning models vulnerable adversarial examples inputs specifically designed cause target model produce outputs survey , focus machine learning models visual domain , methods generating detecting examples extensively studied explore variety adversarial attack methods apply image space content , real world adversarial attacks , adversarial defenses , transferability property adversarial examples also discuss various methods adversarial attack defense aim provide extensive coverage field , reader intuitive understanding mechanics adversarial attack defense mechanisms community researchers studying fundamental set problems
dealing sparse rewards reinforcement learning successfully navigating complex environment obtain desired outcome difficult task , recently capable humans perception time , especially introduction deep reinforcement learning , greatly increased difficulty tasks automated however , traditional reinforcement learning agents requires environment able provide frequent extrinsic rewards , known accessible many real world environments project aims explore contrast existing reinforcement learning solutions difficulties environment provide sparse rewards different reinforcement solutions implemented several video game environments varying difficulty varying frequency rewards , properly investigate applicability solutions project introduces novel reinforcement learning solution combining aspects two existing state art sparse reward solutions , driven exploration unsupervised auxiliary tasks
broadcast signaling millimeter wave cell discovery performance analysis design insight availability abundant spectrum enabled millimeter wave \( mm wave \) prominent candidate solution next generation cellular networks highly directional transmissions essential exploitation mm wave compensate high propagation loss attenuation directional transmission , nevertheless , specific design mm wave initial cell discovery , conventional directional broadcast signaling may fail cell discovery information address issue , paper provides analytical framework mm wave cell discovery based information theoretical approach design compared considering four fundamental representative broadcast signaling schemes evaluate discovery latency signaling overhead schemes simulated realistic system parameters analytical simulation results reveals four key findings \( \) cell discovery without knowledge timing , analog hybrid beamforming performs well digital beamforming terms cell discovery latency \( ii \) single beam exhaustive scan optimize latency , however leads overhead penalty \( iii \) multi beam simultaneous scan significantly reduce overhead , provide flexibility achieve trade latency overhead \( iv \) latency overhead relatively insensitive extreme low block error rates
new analysis manifold embeddings signal recovery compressive measurements compressive sensing \( cs \) exploits surprising fact information contained sparse signal preserved small number compressive , often random linear measurements signal strong theoretical guarantees established concerning embedding sparse signal family random measurement operator accuracy sparse signals recovered noisy compressive measurements paper , address similar questions context different modeling framework instead sparse models , focus broad class manifold models , arise parametric non parametric signal families using tools theory empirical processes , improve upon previous results concerning embedding low dimensional manifolds random measurement operators also establish deterministic probabilistic instance optimal bounds ell 2 manifold based signal recovery parameter estimation noisy compressive measurements line analogous results sparsity based cs , conclude much stronger bounds possible probabilistic setting work supports growing evidence manifold based models used high accuracy compressive signal processing
understanding predictability exploration human mobility predictive models human mobility important applications many fields traffic control , ubiquitous computing contextual predictive performance models literature varies quite broadly , high 93 low 40 work investigate factors influence accuracy next place prediction , using high precision location dataset users periods 3 one year show easier achieve high accuracy predicting time bin location predicting next place moreover demonstrate temporal spatial resolution data strong influence accuracy prediction finally uncover exploration new locations important factor human mobility , measure average 20 transitions new places , approx 70 locations discuss mechanisms important factors limiting ability predict human mobility
adding partial functions constraint logic programming sets partial functions common abstractions formal specification z , b , executable programming languages usually provide little support paper propose add partial functions primitive feature constraint logic programming \( clp \) language , namely log although partial functions could top log , providing first class adds valuable flexibility form set theoretic formulas language safely deal particular , paper shows log constraint solver naturally extended order accommodate new primitive constraints dealing partial functions efficiency new version empirically assessed running number non trivial set theoretical goals involving partial functions , obtained specifications written z
developing knowledge enhanced disease risk prediction models regional repositories precision medicine requires precision disease risk prediction models literature , lot well established \( inter \) risk models , applying local population , prediction performance becomes address localization issue , paper exploits way develop knowledge enhanced localized risk models one hand , tune models learning regional electronic health record \( \) repositories , hand , propose knowledge data learning process experiments , leverage cohort equations \( , acc estimate risk \) develop localized risk prediction model diabetes experimental results show , directly using algorithm cohort , auc 0 , knowledge enhanced localized risk model achieve higher prediction performance auc 0 \( improved 10 7 \)
ranking significant clinical reports medical errors major public health concern leading cause many healthcare centers use reporting systems medical practitioners write preliminary medical report report later reviewed , , range stylistic corrections critical errors case due large quantity reports written daily , often difficult manually review reports find errors learn address challenge , propose novel ranking approach , consisting textual preliminary final versions reports approach learns rank reports based degree discrepancy versions allows medical practitioners easily identify learn reports interpretation substantially \( report \) crucial step towards potential errors medical practitioners learn errors , thus improving patient care long run evaluate model dataset radiology reports show approach outperforms previously proposed approaches recent language models 4 5 15 4
expressive power overlapping architectures deep learning expressive efficiency relation two architectures b , function realized b could replicated , exists functions realized , cannot replicated b unless size grows significantly larger example , known deep networks exponentially efficient respect shallow networks , sense shallow network must exponentially large order approximate functions represented deep network polynomial size work , extend study expressive efficiency attribute network connectivity particular effect convolutional process , e , convolution smaller filter size \( receptive field \) theoretically analyze aspect network 's design , focus well established surrogate called convolutional arithmetic \( \) , demonstrate empirically results hold standard well specifically , analysis shows overlapping local receptive fields , broadly connectivity , results exponential increase expressive capacity neural networks moreover , connectivity increase expressive capacity , show common types modern architectures already exhibit exponential increase , without relying fully connected layers
incremental dynamic construction layered networks certain classes problems , including perceptual data understanding , robotics , discovery , learning , represented incremental , dynamically constructed belief networks automatically constructed networks dynamically extended modified evidence new individuals becomes available main result paper incremental extension connected network way network connected structure changes algorithm deterministic guaranteed complexity single node addition order proportional number nodes \( size \) network additional speed achieved maintaining path information despite incremental dynamic nature , algorithm also used probabilistic inference belief networks fashion similar exact inference algorithms
scheduled peg construction ldpc codes upper layer fec progressive edge growth \( peg \) algorithm one widely used method constructing finite length ldpc codes paper consider peg algorithm together scheduling distribution , order edges established graph goal find scheduling distribution yields best performance terms decoding overhead , performance metric specific erasure codes widely used upper layer forward error correction \( ul fec \) formulate optimization problem , show addressed using genetic optimization algorithms also exhibit peg codes optimized scheduling distribution , whose decoding overhead less half decoding overhead classical peg counterparts
quantitative algebras quantitative algebras \( \) algebras metric spaces defined quantitative theories introduced authors related paper presented 2016 algebras provide mathematical foundation metric semantics probabilistic , stochastic quantitative systems paper considers issue investigate entire spectrum types quantitative equations used theories \( \) simple quantitative equations \( ii \) horn c equations variables hypotheses , c \( iii \) general case horn case characterize class prove variety theorems extend generalize classical results model theory algebras first order structures
connecting multiple unicast network error correction reduction show solving multiple unicast network coding problem reduced solving single unicast network error correction problem , adversary may single edge network specifically , present efficient reduction maps multiple unicast network coding instance network error correction instance preserving feasibility reduction holds zero probability error model vanishing probability error model previous reductions restricted zero error case application reduction , present constructive example showing single unicast network error correction capacity may achievable , result separate interest
modeling evaluating ring search algorithm wireless reactive protocols case high dynamic topology , reactive routing protocols provide convergence faster route route maintenance frequent reduce routing efficiency terms broadcast cost b k , expected time cost e costs optimized using different mechanisms , select three reactive routing protocols ad hoc demand distance vector \( \) , dynamic source routing \( \) , dynamic demand \( \) model ring search \( \) optimization mechanism selected protocols reduce b k e novel contribution work enhancement default protocols optimize b k e using ns 2 , evaluate compare default used protocols , enhanced , modeling analytical comparison , adjusting time live \( \) value network , efficient optimizations b k e achieved
distributed turbo like codes multi user cooperative relay networks paper , distributed turbo like coding scheme wireless networks relays proposed consider scenario multiple sources communicate single destination help relay proposed scheme regarded decode forward type relay information sources properly combines generate extra redundancy , transmitted destination amount redundancy generated relay simply according requirements terms performance , throughput power destination , decoding information sources performed jointly exploiting redundancy provided relay iterative fashion overall communication network viewed concatenated code proposed distributed scheme achieves significant performance gains respect non cooperation system , even large number users furthermore , presents high flexibility terms code rate , block length number users
maximizing partial decode forward rate gaussian mimo relay channel known symmetric gaussian signals optimal input signals partial decode forward \( \) coding scheme gaussian multiple input multiple output \( mimo \) relay channel , currently method find optimal covariance matrices compute optimal achievable rate since optimization non convex problem original formulation paper , show possible find convex problem means approximation primal decomposition derive explicit solution inner problems well explicit gradient outer problem , efficient plane method applied solving outer problem accuracy provably algorithm might previous approximation , additionally propose modified algorithm , cannot give converge guarantee , provides rigorous upper lower bounds optimum original rate maximization numerical simulations , bounds become tight considered instances problem , showing proposed method find global optimum instances
interpretability conditional probability estimates agnostic setting study interpretability conditional probability estimates binary classification agnostic setting scenario agnostic setting , conditional probability estimates necessarily reflect true conditional probabilities instead , certain calibration property among data points classifier predicted p \( 1 x \) p , p portion actually label 1 cost sensitive decision problems , calibration property provides adequate support us use bayes decision theory paper , define novel measure calibration property together empirical counterpart , prove uniform convergence result new measure enables us formally calibration property conditional probability , provides new insights problem estimating conditional probabilities
observability radius networks paper studies observability radius network systems , measures robustness network perturbations edges consider linear networks , dynamics described weighted adjacency matrix dedicated sensors subset nodes allow perturbations certain edge weights objective preventing observability modes network dynamics network setting , work considers perturbations desired sparsity structure , thus extending classic literature observability radius linear systems paper proposes two sets results first , propose optimization framework determine smallest norm desired mode existing sensor nodes second , study expected observability radius networks given structure random edge weights provide fundamental robustness bounds dependent connectivity properties network analytically characterize optimal perturbations line star networks , showing line networks inherently robust star networks
collaborative aerial ground robotic system fast exploration exploration unknown environments using autonomous robots considered fundamental problem robotics applications search 10 , industrial 3d modelling
large order binary de sequences via work shows efficiently construct binary de sequences , even large orders , using cycle method cycles generated chosen period e whose irreducible characteristic polynomial derived primitive polynomial degree n satisfying e frac 2 n 1 decimation proof determining 's equivalent identifying conjugate pairs shared pair cycles approach quickly finds enough number conjugate pairs two cycles ensure existence trees containing vertices adjacency graph r n characteristic polynomial f \( x \) product distinct irreducible polynomials , combine approach via 's recently proposed method determine conjugate pairs allows us efficiently generate de sequences larger orders along way , establish new properties 's
convolutional recurrent neural network based progressive learning speech enhancement recently , progressive learning shown capacity improving speech quality speech combined deep neural network \( dnn \) long short term memory \( lstm \) based speech enhancement algorithms , especially low signal noise ratio \( snr \) conditions nevertheless , due large number parameters highly computational complexity , hard implement current resource limited micro controllers thus , important significantly reduce amount parameters computational load practical applications purpose , propose novel progressive learning framework convolutional recurrent neural networks called pl crnn , takes advantages convolutional neural networks recurrent neural networks drastically reduce amount parameters simultaneously improve speech quality speech numerous experiments verify effectiveness proposed pl crnn model indicate yields consistent better performance pl dnn pl lstm algorithms also gets results close even better crnn terms various evaluation metrics compared pl dnn , pl lstm state art crnn models , proposed pl crnn algorithm reduce amount parameters 77 , 93 93 , respectively
perceptually weighted rank correlation indicator objective image quality assessment field objective image quality assessment \( iqa \) , rho tau , assign uniform weights quality levels assume pair images , two popular rank correlation indicators indicators successfully measure average accuracy iqa metric ranking multiple processed images however , two important perceptual properties first , sorting accuracy \( sa \) high quality images usually important poor quality images many real world applications , top ranked images users second , due subjective uncertainty making judgments , two perceptually similar images usually , ranks contribute evaluation iqa metric accurately compare different iqa algorithms , paper , explore perceptually weighted rank correlation indicator , rewards capability correctly ranking high quality images attention toward insensitive rank specifically , focus valid pairwise comparison images whose quality difference exceeds given sensory threshold \( st \) meanwhile , image pair assigned unique weight determined quality level rank deviation modifying perception threshold , illustrate sorting accuracy sophisticated sa st curve rather single rank correlation coefficient proposed indicator offers new insight interpreting visual perception behavior furthermore , applicability indicator validated robust iqa metrics degraded enhanced image data
exploring graph structured representation multi hop reading comprehension graph neural networks multi hop reading comprehension focuses one type question , system needs properly integrate multiple pieces evidence correctly answer question previous work approximates global evidence local coreference information , encoding coreference chains gru layers within gated attention reader however , coreference limited providing information rich inference introduce new method better connecting global evidence , forms complex graphs compared perform evidence integration graphs , investigate two recent graph neural networks , namely graph convolutional network \( gcn \) graph recurrent network \( \) experiments two standard datasets show global information leads better answers method performs better published results datasets
counting trees modulo prime many important graph theoretic notions encoded counting graph problems , partition functions statistical physics , particular , independent sets article study complexity p mathsf h mathsf h , problem counting graph input graph graph h modulo prime number p proved dichotomy tractability non modular counting graph depends structure input graph many intractable cases non modular counting become tractable modular counting due common phenomenon cancellation however , subsequent studies counting modulo 2 influence , structure h tractability , shown , yielding similar r n main result shows every tree h every prime p problem p mathsf h mathsf h either polynomial time computable p mathsf p complete addresses conjecture dichotomy every graph h counting modulo 2 order prove result , study structural properties important , study yields dichotomy problem weighted counting independent sets bipartite graph modulo prime p results first suggesting hold one bit functions modulo 2 case modular counting functions p
stochastic computing hardware implementation binarized neural networks binarized neural networks , recently discovered class neural networks minimal memory requirements multiplication , opportunity realization compact energy efficient inference hardware however , neural networks generally entirely binarized first layer remains fixed point input work , propose stochastic computing version binarized neural networks , input also binarized simulations example fashion mnist cifar 10 datasets show networks approach performance conventional binarized neural networks evidence training procedure adapted use stochastic computing finally , implementation scheme investigated , system closely logic memory , implemented spin random access memory analysis shows stochastic computing approach allow considerable savings conventional binarized neural networks terms area \( area reduction fashion mnist task \) also allow important savings terms energy consumption , reasonable reduction accuracy example factor 2 1 , cost 1 4 fashion mnist test accuracy results highlight high potential binarized neural networks hardware implementation , adapting hardware provide important benefits
aloha games spatial reuse aloha games study transmission probabilities group non cooperative users share channel transmit via aloha protocol paper extends aloha games spatial reuse scenarios , studies system equilibrium performance specifically , fixed point theory order theory used prove existence least fixed point unique nash equilibrium \( \) game optimal choice players 's method used construct function obtain conditions examine stability simulations show theories derived applicable large scale distributed systems complicated network topologies empirical relationship network connectivity achievable total throughput finally obtained simulations
image colorization using generative adversarial networks last decade , process automatic image colorization significant interest several application areas including restoration degraded images problem highly ill posed due large degrees freedom assignment color information many recent developments automatic colorization involve images contain common require highly processed data semantic maps input approach , attempt fully generalize colorization procedure using conditional deep convolutional generative adversarial network \( \) network trained datasets publicly available cifar 10 results generative model traditional deep neural networks compared
fast heuristic algorithms post processing techniques design large low cost communication networks challenging design large low cost communication networks paper , formulate challenge collecting steiner tree problem \( \) objective minimize costs transmission initially , note max hard , propose post processing techniques improve suboptimal solutions based techniques , propose two fast heuristic algorithms first one time heuristic algorithm faster less memory algorithms second one improvement state art polynomial time heuristic algorithm find high quality solutions speed first one demonstrate heuristic algorithms comparing state art ones largest existing benchmark instances \( vertices edges \) moreover , generate new instances even larger \( 1 000 000 vertices 10 000 000 edges \) demonstrate advantages large networks state art algorithms slow find high quality solutions instances size , whereas new heuristic algorithms around 6 personal computer ultimately , apply post processing techniques update best known solution notoriously difficult benchmark instance show improve near optimal solutions conclusion , demonstrate usefulness heuristic algorithms post processing techniques designing large low cost communication networks
towards multi drum transcription automatic drum transcription , general automatic music transcription , deals extracting drum note audio source recently , progress transcription performance made using non negative matrix factorization well deep learning methods however , works primarily focus three drum instruments drum , drum , hat yet , many applications , ability drum instruments make standard drum used popular music would desirable work , convolutional convolutional recurrent neural networks trained range drum instruments first , publicly available datasets context discussed overcome limitations , larger synthetic dataset introduced , methods train models using new dataset focusing generalization real world data investigated finally , trained models evaluated publicly available datasets results discussed contributions work comprise \( \) large scale synthetic dataset drum transcription , \( ii \) first steps towards automatic drum transcription system supports larger range instruments evaluating training setups impact datasets context , \( iii \) publicly available set trained models drum transcription additional materials available http url
hierarchical store image dataset visual semantic labels image classification models built visual support systems devices need provide accurate predictions environment focus application technology people visual , daily activities shopping paper , provide new benchmark dataset challenging task application classification , , products , e g packages , stores enable learning process utilize multiple sources structured information , dataset contains large volume natural images also includes corresponding information product online shopping website information encompasses hierarchical structure object classes , well image type object dataset used train evaluate image classification models visually people natural environments additionally , provide benchmark results evaluated pretrained convolutional neural networks often used image understanding purposes , also multi view variational autoencoder , capable utilizing rich product information dataset
threshold secure coding shared key protocols often implemented upper layers communication networks , error correcting codes employed physical layer paper , consider utilizing readily available physical layer functions , encoders decoders , together shared keys provide threshold type security scheme end , effect physical layer communication channels legitimate parties , alice bob , eavesdropper eve assumed noiseless introduce model threshold secure coding , alice bob communicate using shared key way eve get information , information theoretic sense , key well subset input symbols size certain threshold , framework provided constructing threshold secure codes form linear block codes characterizing requirements satisfy reliability security conditions moreover , propose threshold secure coding scheme , based reed muller \( rm \) codes , meets security reliability conditions furthermore , shown encoder decoder scheme implemented efficiently quasi linear time complexity particular , low complexity successive cancellation decoder shown rm based scheme also , scheme flexible adapted given key length
attentional multi reading detection recognizing often requires deep understanding multiple sources information , including utterance , conversational context , real world facts current detection systems consider utterance limited attempts toward taking account conversational context paper , propose interpretable end end model combines information utterance conversational context detect , demonstrate effectiveness empirical evaluations also study behavior proposed model provide explanations model 's decisions importantly , model capable determining impact utterance conversational context model 's decisions finally , provide ablation study illustrate impact different components proposed model
high level robot programming based cad dealing environments purpose purpose paper present cad based human robot interface allows non expert users robot manner similar used human design methodology approach intuitive robot programming achieved using cad generate robot programs line sensory feedback allows minimization effects uncertainty , providing information robot paths robot operation findings found possible generate robot program common cad drawing run without major concerns calibration cad model accuracy research limitations implications limitation proposed system fact designed used particular technological applications practical implications since manufacturing companies cad packages facilities today , cad based robot programming may good program robots without need robot
media based mimo new wireless communications idea media based modulation \( mbm \) , based embedding information variations transmission media \( channel state \) contrast wireless systems data embedded radio frequency \( rf \) source prior transmit antenna mbm offers several advantages vs systems , including information multiple receive antennas , inherent diversity static fading channel mbm particularly suitable transmitting high data rates using single transmit multiple receive antennas \( single input multiple output media based modulation , mbm \) however , complexity issues limit amount data embedded channel state using single transmit unit address shortcoming , current article introduces idea layered multiple input multiple output media based modulation \( mbm \) relying layered structure , mbm significantly reduce hardware algorithmic complexities , well training overhead , vs mbm simulation results show excellent performance terms symbol error rate \( ser \) vs signal noise ratio \( snr \) example , 4 times 16 mbm capable transmitting 32 bits information per \( complex \) channel use , ser 10 5 e b n 0 3 5 db \( ser 10 4 e b n 0 4 5 db \) performance achieved using single transmission without adding redundancy forward error correction \( fec \) means , addition excellent ser vs energy rate performance , mbm need complex fec structures , thereby minimizes transmission delay overall , mbm provides promising alternative mimo massive mimo realization 5g wireless networks
adaptive based system evaluating technological indicator dynamics context smart regional innovation considered important welfare started looking regional dynamics , order focus research innovation strategies smart towards effective policies context , work aims support policy analysis innovation relevant trends exploit database regional application determine dynamics set technological innovation indicators purpose , design develop software system trends indicators contrast conventional knowledge based design , approach biologically inspired based self organization information means functional structure , called track , appears runtime local data occurs tracks allows better critical phenomena events , better assessment levels proposed mechanism works structural parameters correctly tuned given historical context determining correct parameters simple task since different indicators may different dynamics purpose , adopt adaptation mechanism based differential evolution study includes problem characterization literature , well proposed solving approach , experimental setting results
learning protect communications adversarial neural cryptography ask whether neural networks learn use secret keys protect n information neural networks specifically , focus n ensuring confidentiality properties multiagent system , n specify properties terms adversary thus , n system may consist neural networks named alice bob , aim n limit third neural network named eve learns n eavesdropping communication alice bob n specific algorithms neural networks n instead , train end end , adversarially n demonstrate neural networks learn n perform forms encryption , also n apply operations order meet n confidentiality goals
deep learning improved biological activation functions activation functions , logistic , historical development machine learning techniques however field deep learning , largely \( \) exponential \( \) linear units mitigate effects vanishing gradients associated error back propagation logistic however represent true input output relation real conditions , root unit \( \) activation functions introduced , exhibiting input output non substantially biologically plausible since functional form based known current frequency relationships r n order evaluate whether activations improve deep learning performance , networks constructed identical architectures except transfer functions \( , , \) , stacked auto encoders , convolutional networks used test supervised unsupervised learning based mnist dataset results learning performance , using loss error measurements , demonstrate networks train faster counterparts , also lead improved models absence formal results therefore confirm properties biological might prove field deep learning
real time impulse noise suppression images using efficient weighted average filtering letter , propose method real time high density impulse noise suppression images method , first apply impulse detector identify corrupted pixels employ innovative weighted average filter filter takes nearest neighboring image initial image computes weights according relative positions corrupted pixels experimental results show proposed method outperforms best existing methods measure visual quality quite suitable real time applications
approaching fundamental limits wireless network single important factor behind data rate increases users wireless networks past decades , namely adding base stations access points thus getting spatial reuse spectrum trend set continue 5g beyond however , point longer able provide exponentially increasing data rates like end 's law , would massive implications entire technology landscape , depends ever heavily wireless connectivity \? might occurring long possible \? questions explored paper
applying blockchain share clinical data secure scalable data sharing essential collaborative clinical decision making conventional clinical data efforts often , however , creates efficient information exchange effective treatment decision made patients paper provides four contributions study applying blockchain technology clinical data sharing context technical requirements defined shared health information technology \( \) first , analyze requirements implications blockchain based systems second , present , blockchain based architecture designed meet requirements fast healthcare resources \( \) standard shared clinical data third , demonstrate based decentralized app using digital health identities participants case study collaborative decision making remote cancer care fourth , highlight key lessons learned case study
throughput scaling wireless networks random connections paper studies throughput scaling wireless networks channels random connections , channel connections independent distributed \( \) according common distribution channel distribution quite general , limitations mean variance finite previous works shown , channel state information \( csi \) entire network known priori nodes , wireless networks degrees freedom limited rather interference limited work , show case less csi assumption specifically , quantify throughput scaling different communication protocols assumption perfect receiver csi partial transmitter csi \( via feedback \) shown throughput single hop two hop schemes upper bounded respectively , \( 3 \) \( 2 \) , n total number source destination pairs addition , multihop schemes cannot better two hop relaying scheme furthermore , \( 2 \) scaling two hop scheme demonstrated constructive example
entropy rounding method approximation algorithms let matrix , c linear objective function x fractional vector , say lp solution discrete optimization problem task theoretical computer science \( approximation algorithms particular \) obtain integral vector roughly c exceeds c x moderate factor r n give new randomized rounding procedure task , provided bounded delta approximate entropy property means uniformly chosen random signs \( j \) 1 , 1 subset , outcome approximately described using sub linear number bits expectation r n achieve result , well known techniques field discrepancy theory , especially rely 's entropy method , best knowledge never used context approximation algorithms result made constructive using framework based semidefinite programming r n demonstrate procedure rounding fractional solutions column based linear programs generalizations bin packing example obtain polynomial time opt \( log 2 opt \) approximation bin packing first train delivery problem
type logical grammars recent years , interest using proof assistants reason mathematics programming languages grown type logical grammars , closely related type theories systems used functional programming , perfect candidate next apply advantages using proof assistants allow one write formally verified proofs one 's type logical systems , theory , implemented , immediately computed many cases formal proofs written , incomplete , use syntax makes verified proofs often much difficult read paper proofs , almost never directly published paper , try remedy example r n , use model calculus , grammar logic rich vocabulary type operations present verified procedure cut elimination system briefly outline translation proofs calculus programs finally , put system use analysis simple example sentence
neural style transfer audio work creating transformations images sense image generally preserving work , present method creating new using similar approach , treating style transfer problem , starting random noise input signal iteratively using back propagation optimize sound conform filter outputs pre trained neural architecture interest r n demonstration , investigate two different tasks , resulting bandwidth expansion compression , transfer voice instruments feature method single architecture generate different audio style transfer types using set parameters otherwise require different complex hand tuned diverse signal processing
h infty model free reinforcement learning robust stability guarantee reinforcement learning showing great potentials robotics applications , including autonomous driving , robot manipulation locomotion however , complex uncertainties real world environment , difficult guarantee successful generalization sim real transfer learned policies theoretically paper , introduce extend idea robust stability h infty control design policies stability robustness guarantee specifically , sample based approach analyzing stability performance robustness learning based control system proposed based theoretical results , maximum entropy algorithm developed searching function designing policy provable robust stability guarantee without specific domain knowledge , method find policy robust various uncertainties generalizes well different test environments experiments , show method achieves better robustness large parametric variations environment state art results robust generic rl , well classic control anonymous code available experimental results https url
alignment dynamic networks networks model real world systems variety domains network alignment \( na \) aims find node mapping similar regions compared networks na applicable many fields , including computational , na guide transfer biological knowledge well poorly studied species across aligned network regions existing na methods align static networks however , complex real world systems evolve time thus modeled dynamic networks aligning dynamic network representations evolving systems produce superior compared aligning static network representations , currently done purpose , introduce first ever dynamic na method , proof concept dynamic na method extension state art static na method , even though optimize edge well node across aligned networks , static edges similarity static node neighborhoods , dynamic edges \( events \) similarity evolving node neighborhoods purpose , introduce first ever measure dynamic edge rely recent measure dynamic node importantly , two dynamic measures optimized using state art na method confirm hypothesis dynamic na superior static na , fair comparison conditions , synthetic real world networks , computational social network domains includes user friendly graphical interface
modeling semantic using global relation vectors word embedding models rely co occurrence statistics large corpus learn vector representations word meaning vectors proven capture surprisingly fine grained semantic syntactic information may similarly expect co occurrence statistics used capture rich information relationships different words , existing approaches modeling relationships mostly relied manipulating pre trained word vectors paper , introduce novel method directly learns relation vectors co occurrence statistics end , first introduce variant , explicit connection word vectors weighted co occurrence vectors show relation vectors naturally embedded resulting vector space
know impact intelligent assistant team interactions performance time scarcity human ai collaboration rise deployment ai enabled intelligent assistants \( e g , , , etc \) across organizational contexts intelligent assistants help people achieve less time \( personal digital assistant , n \) however , despite increasing presence intelligent assistants collaborative settings , literature deployment technology time scarcity impact team behaviors performance gap literature , collected behavioral data teams subjects 2 \( intelligent assistant available vs available \) x 2 \( time scarce vs scarce control \) experiment results show teams intelligent assistant significantly fewer interactions members compared teams without intelligent assistant teams faced time scarcity also used intelligent assistant often seek assistance task completion compared control condition lastly , teams intelligent assistant task compared without device discuss implications technology theoretical , empirical , practical perspectives
saliency prediction two stage generative adversarial networks web page saliency prediction challenge problem image transformation computer vision paper , propose new model combined web page outline information prediction people 's interest region web page web page image , model generate saliency map indicates region interest people two stage generative adversarial networks proposed image outline information introduced better transferring experiment results dataset show model better performance terms saliency prediction
time series anomaly detection using convolutional neural networks transfer learning time series anomaly detection plays critical role automated monitoring systems previous deep learning efforts related time series anomaly detection based recurrent neural networks \( rnn \) paper , propose time series segmentation approach based convolutional neural networks \( cnn \) anomaly detection moreover , propose transfer learning framework model large scale synthetic time series data set fine weights small scale , multivariate data sets previously unseen classes anomalies multivariate case , introduce novel network architecture approach tested multiple synthetic real data sets successfully
evaluation docker containers scientific workloads cloud hpc community actively evaluating tools support execution scientific applications cloud based environments among various technologies , containers recently gained importance significantly better performance compared full scale virtualization , support devops , work workflow tools docker currently leader technology offers low overhead , flexibility , portability applications , reproducibility singularity another container solution interest designed specifically scientific applications important conduct performance feature analysis container technologies understand applicability application target execution environment paper presents \( 1 \) performance evaluation docker singularity nodes cloud \( 2 \) mechanism docker containers mapped hardware rdma communication \( 3 \) analysis mapping elements parallel workloads containers optimal resource management container tools experiments targeted toward application developers make decisions choosing container technologies approaches suitable hpc workloads cloud infrastructure performance analysis shows scientific workloads docker singularity based containers achieve near performance singularity designed specifically hpc workloads however , docker still advantages singularity use clouds provides overlay networking intuitive way run applications one container per rank fine grained resources allocation docker singularity make possible directly use underlying network containers resource allocation
open system categorical quantum semantics natural language processing originally inspired categorical quantum mechanics \( , \) , categorical compositional distributional model natural language meaning , provides motivated procedure compute meaning sentence , given grammatical structure within representation meaning parts predictions first model outperformed models empirical language processing tasks large scale data moreover , like allows varying model interpret quantum , one also vary model interpret word meaning r n paper show developments categorical quantum mechanics relevant natural language processing firstly , 's construction allows explicitly taking account lexical ambiguity distinguishing two inherently different notions terms model interpret word meaning , means vector space model density matrices despite change model , standard empirical methods comparing meanings easily adopted , demonstrate small scale experiment real world data experiment moreover provides preliminary evidence validity proposed new model word meaning r n secondly , classical structures well non counterparts arise image construction allow encoding relative , , finally , iteration construction , counterpart quantum , enables one accommodate ambiguity
subspace graph rigidity submodular optimization paper presents deterministic , strongly polynomial time algorithm computing matrix rank class symbolic matrices \( whose entries polynomials field \) class introduced , different language , study matroids , proved duality theorem putting problem np cap , result another demonstration sense leads efficient algorithm different paper proved symbolic rank problems efficient probabilistic algorithms , namely , algorithm may interpreted result , long sequence special cases \( polynomial identity testing \) problem finally , showed problem generalizes graph rigidity problem two dimensions , algorithm may seen generalization well known deterministic algorithm latter problem r n two somewhat technical features paper first translation problem symbolic rank one second use submodular optimization hope tools developed useful related problems , particular better understanding graph rigidity higher dimensions
clusters graph distributed algorithm propose novel distributed algorithm cluster graphs algorithm recovers solution obtained spectral clustering without need expensive vector computations prove , propagating graph , local fast fourier transform yields local component every laplacian matrix , thus providing clustering information large graphs , proposed algorithm orders magnitude faster random walk based approaches prove equivalence proposed algorithm spectral clustering derive convergence rates demonstrate benefit using decentralized clustering algorithm community detection social graphs , distributed estimation sensor networks efficient computation distributed multi agent search strategies
predicting large historical data small randomized trials new treatment considered use , whether search engine ranking algorithm , typical question arises , performance exceed current treatment \? conventional way answer counterfactual question estimate effect new treatment comparison conventional treatment running controlled , randomized experiment approach theoretically ensures unbiased estimator , suffers several drawbacks , including difficulty finding representative experimental populations well cost running trials moreover , trials huge quantities available control condition data often completely r n paper propose discriminative framework estimating performance new treatment given large dataset control condition data small \( possibly \) randomized trial comparing new objective , requires minimal assumptions , models relation outcomes different conditions allows us estimate mean effects also generate individual predictions examples outside randomized sample r n demonstrate utility approach experiments three areas search engine operation , diabetes patients , market value estimation results demonstrate approach reduce number size currently performed randomized controlled experiments , thus saving significant time , effort part practitioners
cost virtual machine live migration clouds performance evaluation virtualization become modern data centers , often referred computing clouds capability virtual machine live migration brings benefits improved performance , fault tolerance , allowing workload movement short service however , service levels applications likely negatively affected live migration reason , better understanding effects system performance desirable paper , evaluate effects live migration virtual machines performance applications running inside results show , cases , migration overhead acceptable cannot , especially systems availability strict service level despite , high potential live migration applicability data centers applications results based workload covering domain multi tier web 2 0 applications
wireless information power transfer full duplex communication systems paper considers problem maximizing sum rate simultaneous wireless information power transfer \( \) full duplex bi directional communication system subject energy harvesting transmit power constraints nodes investigate optimum design receive power transmit powers full duplex mode exploiting rate split method , iterative algorithm derived solve non convex problem effectiveness proposed algorithm justified numerical simulations
lsm based storage techniques survey recently , log structured merge tree \( lsm tree \) widely adopted use storage layer modern systems , large number research efforts , database community operating systems community , try improve various aspects lsm trees paper , provide survey recent research efforts lsm trees learn state art lsm based storage techniques provide general taxonomy classify literature lsm trees , survey efforts detail , discuss trade offs survey several representative lsm based open source systems discuss potential future research directions resulting survey
lattice codes gaussian relay channel decode forward compress forward lattice codes known achieve capacity gaussian point point channel , achieving rates independent , distributed \( \) random gaussian lattice codes also known outperform random codes certain channel models able exploit linearity work , show lattice codes may used achieve performance known gaussian random coding techniques gaussian relay channel , show several examples may combined linearity lattices codes multi source relay networks particular , present nested lattice list decoding technique , , lattice codes shown achieve decode forward \( df \) rate single source , single destination gaussian relay channels one relays next present two examples df scheme may combined linearity lattice codes achieve new rate regions channel conditions outperform analogous known gaussian random coding techniques multi source relay channels , derive new achievable rate region two way relay channel direct links compare existing schemes , derive another achievable rate region multiple access relay channel furthermore present lattice compress forward \( cf \) scheme gaussian relay channel exploits lattice scheme achieves rate cover el cf rate evaluated gaussian random codes results suggest structured lattice codes may used mimic , sometimes outperform , random gaussian codes general gaussian networks
impact surface size thermal behavior embedded systems paper introduces new global analytical model heat process occurs cooled embedded systems , assumption exponential cooling laws apply context valid since power consumption reliability highly dependent temperature , designers , later , run time temperature management units must able rely upon accurate cooling models handle heat generation peak temperature exponential cooling models justified actively cooled , e g , cooling , cooled processors however , frequently found embedded systems mobile phones , exponential law may theoretically justified , analyzed tractability exact cooling law cooled body , subject cooling modest level heat loss via focusing embedded , compare performance difference new passive cooling law used exponential one show differences exact solution exponential cooling law significant , even negligible , small surfaces order 2 however , larger surface sizes , cooling component may become comparable cooling component results thus suggest , absence accurate temperature measurements , exponential cooling law accurate enough small sized soc systems require low processing overhead
convex geometry coding problem error constrained dictionary learning article convex geometry class coding problems includes basis pursuit denoising propose novel coding problem convex concave min max problem particular provides nontrivial method update dictionary order obtain better sparse representations hard error constraints , also gives insights underlying geometry coding problem results shed provide new descent type algorithms could used solve coding problem
negotiation automation architecture behavior pattern prediction component era services , growth e commerce transactions , need development intelligent negotiation systems consists feasible architecture , reliable framework flexible multi agent based protocols developed specialized negotiation languages complete semantics support message passing possible using web services internet key issue negotiation automation paper review classical negotiation methods existing architectures frameworks proposing new framework architecture , key feature framework component prediction probabilistic behavior pattern recognition , along classical approaches negotiation frameworks architectures negotiation practically complex activity automate without human intervention future also develop new protocol facilitate automation types negotiation strategies like , , auctions , framework
pac learning bounded tree width graphical models show class strongly connected graphical models k properly efficiently pac respect kullback leibler divergence previous approaches problem , \( 1 \) , \( 7 \) shown class pac learnable reducing combinatorial optimization problem however , k 1 , problem np complete \( 15 \) , unless p np , approaches take exponential amounts time approach differs significantly , first attempts find approximate conditional solving \( polynomially many \) submodular optimization problems , using dynamic programming formulation combine approximate conditional independence information derive graphical model underlying graph tree width specified gives us efficient \( polynomial time number random variables \) pac learning algorithm requires polynomial number samples true distribution , polynomial running time
high snr capacity wireless communication channels setting paper , mostly tutorial nature , deals problem characterizing capacity fading channels high signal noise ratio \( snr \) regime focus practically relevant setting , neither transmitter receiver know channel , aware channel law present , intuitive accessible form , two tools , first proposed \( \) , fundamental importance high snr capacity analysis duality approach infinity property capacity achieving distributions furthermore , apply tools refine results appeared previously literature corresponding proofs
line large scale information network embedding paper studies problem embedding large information networks low dimensional vector spaces , useful many tasks visualization , node classification , link prediction existing graph embedding methods scale real world information networks usually contain millions nodes paper , propose novel network embedding method called , suitable arbitrary types information networks undirected , directed , weighted method carefully designed objective function preserves local global network structures edge sampling algorithm proposed addresses limitation classical stochastic gradient descent improves effectiveness efficiency inference empirical experiments prove effectiveness line variety real world information networks , including language networks , social networks , citation networks algorithm efficient , able learn embedding network millions vertices edges hours typical single machine source code line available online url https github com line
differential hybrid games article introduces differential hybrid games , combine differential games hybrid games kinds games , two players interact continuous dynamics difference hybrid games also provide features hybrid systems discrete games , deterministic differential equations differential games , instead , provide differential equations continuous time game input players , hybrid games , mode discrete time alternating adversarial interaction article differential game logic modalities combined dynamics differential hybrid games shows hybrid games differential games introduces differential game invariants differential game variants proving properties differential games
cognitive robotics never next technical robots going however , interact humans incorporated human collective robots provided human like cognitive mean \? robotics research communities trying hard find way cope problem meanwhile , despite abundant efforts lead meaningful result \( , past ten years , cognitive robotics research 1 39 billion \) next ten years , similar budget going tackle cognitive robotics problems frame human brain project reason expect time result different would like try explain
longer uniform covers bit beyond motivated well known four conjecture problem \( tsp \) , study problem em uniform covers graph g \( v , e \) alpha uniform cover tsp \( , respectively \) alpha vector \( e alpha e \) convex combination vectors \( 2 edge connected spanning , respectively \) polyhedral analysis algorithm directly implies 3 edge connected , cubic graph 1 uniform cover tsp asked graphs \( 1 epsilon \) uniform covers tsp epsilon 0 indeed , four conjecture implies graphs 8 9 uniform covers show graphs 18 uniform covers tsp also study uniform covers show 15 17 vector efficiently written convex combination 2 edge connected spanning r n weighted , 3 edge connected , cubic graph , results show 2 3 vector optimal solution linear programming relaxation , tour weight 27 times optimal tour found efficiently node weighted , 3 edge connected , cubic graphs fall category special case , apply tools obtain even better approximation guarantee r n extend approach input graphs 2 edge connected , present procedure decompose optimal solution relaxation tsp spanning , connected cover 2 edge cut even number times using decomposition , obtain simple 4 3 approximation algorithm minimum weight 2 edge connected spanning subgraphs , node weighted graphs
form function optimizing product design via adaptive preference visual design critical product success , subject intensive research effort yet visual elements , due holistic interactive nature , well optimization using methods preference present systematic methodology incorporate interactive , 3d product configurations like framework method relies rapid , scalable machine learning algorithms adaptively update product designs along standard information oriented product attributes heart parametric account product 's geometry , along novel , adaptive bi level query task estimate visual design form preferences trade offs traditional elements price product features illustrate method 's performance extensive simulations robustness checks , formal proof bi level query methodology 's domain superiority , field test design , using real time 3d rendering online results indicate substantially enhanced predictive accuracy , two quantities beyond reach standard methods trade offs form function overall , specific design elements moreover applications method provides optimal visual designs individuals model derived consumer , well form functional elements
projection free optimization strongly convex constraint sets revisit \( fw \) optimization strongly convex constraint sets provide faster convergence rate fw without line search , showing previously variant fw indeed faster standard variant line search , show fw converge global optimum , even smooth functions convex , quasi convex locally also show , general case \( smooth \) non convex functions , fw line search high probability stationary point rate left \( frac 1 right \) , long constraint set strongly convex one convergence rates non convex optimization
knowledge bert text generation large scale pre trained language model , bert , recently achieved great success wide range language understanding tasks however , remains open question utilize bert text generation tasks paper , present novel approach addressing challenge generic sequence sequence \( \) setting first propose new task , conditional masked language modeling \( c \) , enable fine tuning bert target text generation dataset fine tuned bert \( e , teacher \) exploited extra supervision improve conventional models \( e , student \) text generation leveraging bert 's bidirectional nature , knowledge learned bert encourage auto models plan , imposing global sequence level supervision coherent text generation experiments show proposed approach significantly outperforms strong baselines transformer multiple text generation tasks , including machine translation \( \) text summarization proposed model also achieves new state art results german english english vietnamese datasets
attack trees paper , present proof theory attack trees attack trees well established useful model construction attacks systems since allow exploration high level attacks application scenarios using expressiveness higher order logic , developing generic theory attack trees state based semantics based structures ctl resulting framework allows supported logic analysis meta theory proof calculus attack trees time developed proof theory enables application case studies central correctness completeness result proved connection notion attack tree validity ctl application illustrated example healthcare iot system compliance verification
dual decomposition perspective relax compensate recover relax , compensate recover \( \) paradigm approximate inference probabilistic graphical models previously provided theoretical practical insights iterative belief propagation generalizations paper , characterize technique dual decomposition terms , specific way compensate relaxed equivalence constraints among insights perspective , propose novel heuristics recovering relaxed equivalence constraints goal dual decomposition approximations , way reaching exact solutions also show empirically recovering equivalence constraints sometimes corresponding approximation \( obtaining exact results \) , without increasing much complexity inference
word meaning mappings natural language interfaces paper focuses system , wolfie \( word learning interpreted examples \) , semantic lexicon corpus sentences paired semantic representations lexicon learned consists paired meaning representations wolfie part integrated system learns transform sentences representations logical database queries r n r n experimental results presented demonstrating wolfie 's ability learn useful database interface four different natural languages usefulness learned wolfie compared acquired similar system , results favorable wolfie second set experiments demonstrates wolfie 's ability scale larger difficult , artificially generated , corpora r n r n natural language acquisition , difficult annotated data needed supervised learning however , data fairly active learning methods attempt select annotation training informative examples , therefore potentially useful natural language applications however , results date active learning considered standard classification tasks reduce annotation effort maintaining accuracy , apply active learning semantic show active learning significantly reduce number annotated examples required achieve given level performance
detecting clickbait online social media believe paper , propose approach detection clickbait posts online social media \( \) clickbait posts short user 's attention click article approach based machine learning \( ml \) classifier capable distinguishing clickbait legitimate posts published suggested classifier based variety features , including image related features , linguistic analysis , methods detection order evaluate method , used two datasets provided clickbait challenge 2017 best performance obtained ml classifier auc 0 8 , accuracy 0 , precision 0 , recall 0 addition , opposed previous studies , found clickbait post statistically significant legitimate post finally , found counting number formal english words given content useful clickbait detection
fixed size small object c allocation small objects fixed size , standard runtime system commonly worse time performance compared adapted special application field propose memory , originally developed mesh primitives also small equally sized objects large amount objects leads better results data c new instruction worse proposed synchronization approach free practical scenarios without using machine instructions , compare traversal structure integrated requiring less memory using containers vectors lists , comparable time performance
network oblivious algorithms framework proposed design analysis emph network oblivious algorithms , namely , algorithms run , yet efficiently , variety machines characterized different degrees parallelism communication capabilities framework network oblivious algorithm specified parallel model computation parameter problem 's input size , evaluated model two parameters , capturing parallelism granularity communication latency shown , wide class network oblivious algorithms , optimality latter model implies optimality model , known effectively describe wide significant class parallel platforms proposed framework regarded attempt notion , well established context cache hierarchies , parallel computation effectiveness illustrated providing optimal network oblivious algorithms number key problems limitations oblivious approach also discussed
exploring vision processing unit co processor inference success largely remain dependent novel technology effectively reduce power consumption thermal requirements work , consider integration co processors high performance computing \( hpc \) enable low power , computation offloading certain operations particular , explore called vision processing unit \( \) , highly parallel vector processor power less evaluate inference using pre trained convolutional network model large image dataset imagenet challenge preliminary results indicate multi configuration provides similar performance compared reference cpu gpu implementations , reducing thermal design power \( \) 8x comparison
stronger result fractional strong , recently proved fractional relaxation strong conjecture note generalize result follows let k geq 1 partition vertices graph g sets v 1 , , v r , 1 leq leq r every vertex v max k , v k outside v probability distribution stable sets g stable set drawn distribution vertex v probability 1 v , 1 leq leq r believe result useful tool probabilistic approaches bounding number fractional number
approximation algorithms incremental knapsack problem via programming incremental knapsack problem \( \) , given knapsack whose capacity grows weakly function time time horizon periods capacity knapsack period 1 , , also given set n items placed knapsack item value weight independent time period time period , sum weights items knapsack cannot exceed knapsack moreover , item placed knapsack , cannot removed knapsack later time period seek maximize sum \( \) knapsack values time subject constraints first give constant factor approximation algorithm , mild restrictions growth rate \( constant factor depends growth rate \) give ptas , special case , \( p log n \)
nonparametric policy gradient reinforcement learning \( rl \) algorithms still suffer high sample complexity despite recent need intensive interactions environment especially observed many widely popular policy gradient algorithms perform updates using policy samples price becomes real world scenarios interaction driven robot learning , success rl rather limited address issue building general sample efficiency policy algorithms nonparametric regression density estimation methods construct nonparametric equation principled manner , allows us obtain closed form estimates value function , analytically express full policy gradient provide theoretical analysis estimate show consistent mild smoothness assumptions empirically show approach better sample efficiency state art policy gradient methods
transmission capacities wireless ad hoc networks outage constraints study transmission capacities two wireless networks \( primary network vs secondary network \) operate region share spectrum define transmission capacity product among density transmissions , transmission rate , successful transmission probability \( 1 outage probability \) primary \( pr \) network higher access spectrum without particular considerations secondary \( sr \) network , sr network limits interference pr network carefully controlling density transmitters assuming nodes distributed according poisson point processes two networks use different transmission ranges , quantify transmission capacities two networks discuss tradeoff based asymptotic analysis results show pr network small increase outage probability , sum transmission capacity two networks \( e , overall spectrum efficiency per unit area \) boosted significantly single network
energy reliability aware link optimization battery iot devices non ideal power paper , study cross layer optimization low power wireless links reliability aware applications considering constraints non ideal characteristics hardware internet things \( iot \) devices specifically , define energy consumption \( \) model captures energy cost , power , packet error statistics , packet overhead , etc useful data bit derive models ideal two realistic non linear power models incorporate packet error statistics , develop simple , form functions , accurate closed form packet error rate \( per \) approximation rayleigh block fading using models , derive energy optimal yet reliability hardware conditions limiting optimal signal noise ratio \( snr \) , size together conditions , develop semi analytic algorithm resource constrained iot devices jointly optimize parameters physical \( modulation size , snr \) mac \( size number \) layers relation link distance results show despite reliability constraints , common notion higher ary qam energy optimal short range communication , provide lifetime extension compared often employed modulation iot devices however , reliability constraints reduce range energy efficiency , non ideal traditional pa reduces range 50 , energy gains unless better pa employed
conformant planning via symbolic model checking tackle problem planning nondeterministic domains , presenting new approach conformant planning conformant planning problem finding sequence actions guaranteed achieve goal despite domain approach based representation planning domain finite state automaton use symbolic model checking techniques , particular binary decision diagrams , represent efficiently search automaton paper make following contributions first , present general planning algorithm conformant planning , applies fully nondeterministic domains , uncertainty initial condition action effects algorithm based first , backward search , returns conformant plans minimal length , solution planning problem exists , otherwise problem admits conformant solution second , provide symbolic representation search space based binary decision diagrams \( \) , basis search techniques derived symbolic model checking symbolic representation makes possible analyze potentially large sets states transitions single computation step , thus providing efficient implementation third , present \( conformant model based planner \) , efficient implementation data structures algorithm described , directly based manipulations , allows compact representation search layers efficient implementation search steps finally , present experimental comparison approach state art conformant planners , analysis includes planning problems distribution packages systems , plus problems defined number specific factors approach appears effective strictly expressive , problems comparison possible , outperforms competitors , sometimes orders magnitude
separability reachability sets vector addition systems given two families sets mathcal f mathcal g , mathcal f separability problem mathcal g asks whether two given sets u , v mathcal g exists set mathcal f , u included v disjoint consider two families sets mathcal f modular sets subseteq mathbb n , defined unions equivalence classes modulo natural number n mathbb n , unary sets main result decidability modular unary separability class mathcal g reachability sets vector addition systems , petri nets , vector addition systems states ,
tetrahedral space filling curve adaptive meshes introduce space filling curve triangular tetrahedral refinement computed using operations similar well known z order curve
functional complexity affects scalability energy efficiency trade wsn clustering even though clustering algorithms wireless sensor networks \( wsn \) well investigate subject , increasing interest internet things \( iot \) 5g technologies need new ways overcome new set challenges studies mainly propose new algorithms compare algorithms based set properties \( e g energy efficiency , scalability \) , none focuses underlying mechanisms organizational patterns lead properties address lack understanding applying complex systems science approach investigate properties wsns arising communication patterns network nodes represent different implementations clustering wsns functional topology graph moreover , employ complexity metric functional complexity \( cf \) explain local interactions give rise global behavior network analysis shows higher values cf indicate higher scalability lower energy efficiency
time case study dns poisoning domain name system \( dns \) provides translation domain names ip addresses dns key infrastructure component internet prime target variety attacks one significant threat dns 's dns poisoning attack , dns responses replaced , , attacker identify kind attack , start analysis different kinds response times present analysis typical response times , different levels dns response times , root servers internal caching servers successfully identify empirical dns poisoning attacks based novel method dns response timing analysis present system developed validate technique require changes dns protocol existing network equipment validation system tested data different architectures including cloud environments real data internet service provider \( isp \) method system differ dns poisoning detection methods achieved high detection rates 99 findings suggest used conjunction methods , considerably enhance accuracy methods
follownet robot navigation following natural language directions deep reinforcement learning understanding following directions provided humans enable robots navigate effectively unknown situations present follownet , end end differentiable neural architecture learning multi modal navigation policies follownet maps natural language instructions well visual depth inputs locomotion primitives follownet processes instructions using attention mechanism conditioned visual depth input focus relevant parts command performing navigation task deep reinforcement learning \( rl \) sparse reward learns simultaneously state representation , attention function , control policies evaluate agent dataset complex natural language directions guide agent rich realistic dataset simulated show follownet agent learns execute previously unseen instructions described similar vocabulary , successfully along paths encountered training agent shows 30 improvement baseline model without attention mechanism , success rate novel instructions
phase field model cohesive fracture propagation quasi regime predicted via variational material force based phase field fracture models , models often assume underlying elastic response material non polar yet length scale parameter must introduced enable sharp represented regularized implicit function however , many materials internal contain surface , micro , micro fracture , , nature often exhibit size dependent behaviors path independent path dependent regimes paper intended introduce unified treatment captures size effect materials elastic states introducing cohesive phase field fracture theory , along computational model validation , explore interacting size dependent elastic fracture mechanisms exhibits materials complex achieve goal , introduce distinctive degradation functions force micro rotation energy pairs given regularization profile size dependent responses insensitive length scale parameter regularized interface , apply variational principle derive equations stored energy numerical examples introduced demonstrate proper way identify material parameters capacity new formulation simulate complex patterns quasi static regime
kernel methods riemannian manifold symmetric positive definite matrices symmetric positive definite \( spd \) matrices become popular encode image information geometry riemannian manifold spd matrices proven key success many algorithms however , existing methods approximate true shape manifold locally plane paper , inspired kernel methods , propose map spd matrices high dimensional hilbert space euclidean geometry applies encode geometry manifold mapping , introduce family provably positive definite kernels riemannian manifold spd matrices kernels derived gaussian , exploit different metrics manifold lets us extend kernel based algorithms developed euclidean spaces , svm kernel pca , riemannian manifold spd matrices demonstrate benefits approach problems pedestrian detection , categorization , texture analysis , 2d motion segmentation diffusion tensor imaging \( \) segmentation
super resolution brain mri images using overcomplete dictionaries similarity recently , magnetic resonance imaging \( mri \) images limited resolutions due various constraints physical , technological economic considerations super resolution techniques obtain high resolution mri images traditional methods obtained resolution enhancement brain mri , affecting accuracy following process requirement brain image quality fast increasing paper , propose image super resolution \( sr \) method based overcomplete dictionaries inherent similarity image recover high resolution \( hr \) image single low resolution \( lr \) image explore similarity image search similar blocks whole image present joint reconstruction method based compressive sensing \( cs \) similarity constraints sparsity self similarity image blocks taken constraints proposed method following steps first , dictionary classification method based measurement domain presented image blocks classified smooth , texture edge parts analyzing features measurement domain , corresponding dictionaries trained using classified image blocks equally important , reconstruction part , use cs reconstruction method recover hr brain mri image , considering similarity sparsity image constraints method performs better visually quantitatively existing methods
unsupervised domain adaptation contextual embeddings low resource question detection answering questions primary goal many conversational systems search products current systems focused answering questions structured databases curated knowledge graphs , line community frequently asked questions \( \) lists offer alternative source information question answering systems automatic question detection \( \) key technology need question answering systems utilize existing online like existing annotations questions community driven , making sparse even completely missing many domains therefore , important transfer knowledge related domains tasks recently , contextual embedding models bert outperforming many baselines transferring self supervised information downstream tasks paper , apply bert advance unsupervised adaptation domains using self supervised learning show effectiveness adaptation low resource settings , little training data available target domain analysis reveals unsupervised bert domain adaptation even small amounts data performance bert
structured pruning deep convolutional neural networks real time application deep learning algorithms often high computational complexity frequent memory network pruning promising technique solve problem however , pruning usually results irregular network connections demand extra representation efforts also fit well parallel computation introduce structured sparsity various scales convolutional neural networks , channel wise , kernel wise intra kernel sparsity structured sparsity direct computational resource savings embedded computers , parallel computing environments hardware based systems decide importance network connections paths , proposed method uses particle filtering approach importance weight particle assigned computing rate corresponding connectivity pattern network trained compensate losses due pruning implementing convolutions matrix products , particularly show intra kernel sparsity simple constraint significantly reduce size kernel feature map matrices network finally fixed point optimized reduced word length precision results significant reduction total storage size providing advantages memory based implementations deep neural networks
computational geometry column concept pseudo defined applications described
kernel classification framework metric learning learning distance metric given training samples plays crucial role many machine learning tasks , various models optimization algorithms proposed past decade paper , generalize several state art metric learning methods , large margin nearest neighbor \( \) information theoretic metric learning \( \) , kernel classification framework first , constructed training samples , family degree 2 polynomial kernel functions proposed pairs , kernel classification framework established , generalize many popular metric learning methods , also suggest new metric learning methods , efficiently implemented , interestingly , using standard support vector machine \( svm \) solvers two novel metric learning methods , namely svm triplet svm , developed proposed framework experimental results show svm triplet svm achieve competitive classification accuracies state art metric learning methods significantly less training time
framework data driven physical security insider threat detection paper presents , framework methodology improving physical security insider threat detection facilitate data analysis mitigate insider threats leveraging rule based anomaly detection many cases , rule based anomaly detection detect deviations organizational security policies addition , considered security provenance solution ability fully reconstruct attack patterns provenance graphs analyzed identify actions overcome analytical result bad decision making , false attribution moreover , information used available intelligence \( attempts \) form use cases detect limitations system , coupled provenance graphs many cases indicate physical security architecture ultimately , validation framework use cases demonstrates proves improve organization 's security terms physical security insider threat detection
reliable intersection control non cooperative environments propose reliable intersection control mechanism strategic autonomous connected vehicles \( agents \) non cooperative environments agent access possible desired passing times , reports passing time intersection manager , allocates intersection temporally agents first come first serve basis however , agents might conflicting interests take actions end , analyze strategic behaviors agents formulate nash equilibria possible scenarios furthermore , among nash equilibria identify optimal equilibrium leads fair intersection allocation , describe strategy proof intersection mechanism , achieves reliable intersection control strategic agents incentive passing times
gradient boosting piece wise linear regression trees gradient boosting using decision trees base learners , called gradient boosted decision trees \( \) , successful ensemble learning algorithm widely used across variety applications recently , various construction algorithms implementation designed heavily optimized popular open sourced paper , show accuracy efficiency enhanced using complex base learners specifically , extend gradient boosting use linear regression trees \( pl trees \) , instead constant regression trees show pl trees accelerate convergence moreover , new algorithm fits better modern computer architectures powerful single instruction multiple data \( simd \) parallelism propose optimization techniques speedup algorithm experimental results show pl trees provide competitive testing accuracy comparable less training time algorithm also produces much tree ensembles , thus often reduce testing time costs
event based angular velocity regression networks neural networks \( snns \) inspired networks process information temporal rather values produces whenever significant number occur within short period time due based computational model , snns process output event based , asynchronous sensors without pre processing extremely lower power unlike standard artificial neural networks possible due specialized hardware highly concept snns yet , snns rise popularity artificial neural networks stems fact input format rather also due challenges training networks despite temporal nature recent algorithmic advances , mostly evaluated classification problems propose , first time , temporal regression problem numerical values given events event camera specifically investigate prediction 3 dof angular velocity event camera difficulty problem arises prediction angular velocities continuously time directly irregular , asynchronous event based input directly output event cameras without pre processing ensures benefits provide conventional cameras high temporal resolution , high dynamic range motion blur assess performance snns task , introduce synthetic event camera dataset generated real world images show successfully train perform angular velocity regression
optimal ball balls games successful tool modeling load balancing problems paper , study new scenario , call ball game , defined follows r n balls n according given probability distribution p , time step , non bin balls take balls selected bin according p r n balls game closely models memory access heuristics databases goal bin method maximizes rate , defined expected number balls per step stationary distribution r n study two natural strategies ball bin , bin maximum number balls , random ball , ball random bin show general p , random ball \( 1 \) optimal , whereas bin however , p u , uniform distribution , bin optimal within additive constant
robust unsupervised flexible auto weighted local coordinate concept factorization image clustering investigate high dimensional data clustering problem proposing novel unsupervised representation learning model called robust flexible auto weighted local coordinate concept factorization \( rfa lcf \) rfa lcf integrates robust flexible cf , robust sparse local coordinate coding adaptive reconstruction weighting learning unified model adaptive weighting driven including joint manifold preserving constraints recovered clean data , basis concepts new representation specifically , rfa lcf uses l2 , 1 norm based flexible encode mismatch clean data reconstruction , also applies robust adaptive sparse local coordinate coding represent data using nearby basis concepts , make factorization accurate robust noise robust flexible factorization also performed recovered clean data space enhancing representations rfa lcf also considers preserving local manifold structures clean data space , basis concept space new coordinate space jointly adaptive manner way extensive comparisons show rfa lcf deliver enhanced clustering results
radio link context aware d2d communication reuse mode device device \( d2d \) communication considered one key technologies fifth generation wireless communication system \( 5g \) due certain benefits provided , e g traffic low end end latency d2d link reuse resource cellular user transmission , mutual interference two links introduced paper , propose smart radio resource management \( \) algorithm enables d2d communication reuse cellular resource , taking account context information besides , signaling schemes high efficiency also given work enable proposed algorithm simulation results demonstrate performance improvement proposed scheme terms overall cell capacity
role coded side information single server private information retrieval study role coded side information single server private information retrieval \( pir \) instance single server pir problem includes server stores database k independently uniformly distributed messages , user retrieve one messages server consider settings user initially access coded side information includes linear combination subset messages database assume identities messages form support set coded side information well coding coefficients initially unknown server consider two different models , depending whether support set coded side information includes requested message also consider following two privacy requirements \( \) identities demand support set coded side information need protected , \( ii \) identity demand needs protected model privacy requirements , consider problem designing protocol generating user 's query server 's answer enables user decode message need satisfying privacy requirement characterize \( scalar linear \) capacity setting , defined ratio number information bits message minimum number information bits server \( scalar linear \) protocols satisfy privacy condition converse proofs rely new information theoretic arguments tailored setting single server pir different commonly used techniques multi server pir settings also present novel capacity achieving scalar linear protocols settings considered
real time reconstruction motion geometry segmentation using single depth camera paper proposes real time dynamic scene reconstruction method capable motion , geometry , segmentation simultaneously given live depth stream single rgb camera approach geometry frame frame uses segmentation enhanced node graph structure drive geometry registration step two level node motion optimization proposed optimization space node motions range plausible largely reduced taking advantage motion prior , solved efficient node graph segmentation method compared previous fusion based dynamic scene reconstruction methods , experiments show robust improved reconstruction results occluded motions
counting perfect matchings graphs exclude single crossing minor graph h single crossing drawn plane one crossing single crossing graph h , give \( n 4 \) time algorithm counting perfect matchings graphs h minor runtime \( n 1 5 \) g k 5 k 3 , 3 minor first generalization algorithm counting perfect matchings k 3 , 3 free graphs \( little , \) algorithm uses black boxes counting perfect matchings planar graphs computing certain graph decompositions together independent recent result \( et al 2014 \) graphs k 5 , one first nontrivial algorithms inherently rely
solving missing annotation object detection background loss paper focuses novel challenging detection scenario majority true objects instances unlabeled datasets , missing labeled areas regarded background training previous art problem proposed use soft sampling weight gradients based positive instances , method mainly based two stage detector \( e faster rcnn \) robust friendly missing label scenario paper , introduce superior solution called background loss \( \) automatically loss signals according pre defined threshold input image design built one stage detector faster inspired loss formulation , make several significant modifications fit missing annotation conduct extensive experiments curated pascal voc datasets results demonstrate proposed method outperforms baseline state arts large margin
expected qualitative utility maximization model decision making generalizes expected utility maximization presented model , expected qualitative utility maximization , encompasses criterion independence continuity postulates main ingredient definition qualitative order models real numbers consideration utilities expected qualitative utility maximization characterized original von 's postulates subjective probabilities may defined postulates , original postulates subjective probabilities numbers , matrices subjective expected utility approach keywords utility theory , non standard utilities , qualitative decision theory
rational efficient algorithm view databases dynamics belief knowledge one major components autonomous system able incorporate new pieces information paper , argue apply result belief dynamics theory various practical problems , generalized two first , allow certain part belief second , belief state need closed generalization belief dynamics , referred base dynamics , presented , along concept generalized algorithm horn knowledge bases show horn knowledge base dynamics interesting connection kernel change finally , also show variants rational sense satisfy certain postulates works belief dynamics
incentive based system using verification central problem hiring companies academia often face difficulty skills since skills candidate generally immediately costly test proposed literature verification proof information storage decentralized manner however , approaches deal storing traditional blockchain among techniques consider procedure , questions like \( \) scalability limited , \( b \) uniformity grades multiple , \( c \) honest effort extraction usually addressed propose blockchain based platform named , considers questions , ensure several desirable properties platform effort via payments generates payments users platform , e g , test provide detailed description design platform along provable properties algorithm
geometric mean method incomplete pairwise comparisons creating ranking based pairwise comparisons often , face difficulties completing results direct comparisons case , solution use ranking method based incomplete pc matrix article presents extension well known geometric mean method incomplete pc matrices description methods theoretical considerations showing existence solution optimality proposed approach
road scene synthetic annotation dataset training deep neural networks semantic segmentation , main limiting factor low amount ground truth annotation data available currently existing datasets limited availability data due time cost human effort required accurately consistently label real images pixel level modern video game engines provide open world environments traffic pedestrians pseudo realistic manner well collection road scene dataset utilizing open source tools resources found single player communities , provide method persistent , ground truth , asset annotation game world collecting synthetic dataset containing 1 , 000 , 000 images , demonstrate real time , demand , ground truth data annotation capability method synthetic data dataset , show data generation method provides qualitative well quantitative improvements training networks previous methods use video games surrogate
towards parallel computing internet applications architectures models programming tools development internet wide resources general purpose parallel computing poses challenging task matching computation communication complexity number parallel computing models exist address traditional parallel architectures , number emerging models attempt large scale internet based systems like computational grids survey cover three fundamental aspects application , architecture model , show developed last decade also cover programming tools currently used parallel programming computational grids trend conventional computational models put emphasis efficient communication participating nodes adapting different types communication network conditions effects uncertainties arise large scale systems important understand yet currently little work addresses parallel computing perspective
existence low rank explanations mixed strategy behavior nash equilibrium used model explain observed behavior players strategic settings example , many empirical applications observe player behavior , problem determine exist players equilibrium corresponds observed player behavior computational complexity nash equilibria important consideration framework instance model observed player behavior requires players solved computationally hard problem , explanation provided paper provide conditions nash equilibrium reasonable explanation strategic behavior , e , conditions observed behavior players explained games nash equilibria easy compute identify three structural conditions show data set observed behavior satisfies conditions , consistent matrices observed nash equilibria could computed efficiently conditions admit large complex data sets observed behavior , showing even complexity considerations , nash equilibrium often reasonable model
classification trapezoidal words trapezoidal words finite words n 1 distinct factors length n , every n 0 finite words distinguish trapezoidal words two disjoint subsets open closed trapezoidal words trapezoidal word closed repeated prefix exactly two occurrences word , second one suffix word otherwise open show open trapezoidal words primitive closed trapezoidal words show trapezoidal closed \( therefore \) allows us characterize special factors end several open problems
low power end end hybrid framework surveillance applications success deep learning , object recognition systems deployed real world applications becoming however , inference needs largely take place \( processed servers \) , highly computational memory intensive workload , making intractable low power mobile nodes remote security applications address challenge , paper proposes low power \( \) end end framework object tracking classification using event based cameras possess desirable properties low power consumption \( 5 14 \) high dynamic range \( db \) , unlike traditional approaches using event event processing , work uses mixed frame event approach get energy savings high performance using frame based region proposal method based density foreground events , hardware friendly object tracking implemented using object velocity tackling occlusion scenarios low power classification objects , event camera ibm , time tackle eight instances traffic monitoring application frame based object track input back classification via energy efficient deep network \( \) pipeline using originally collected datasets , train model hardware track outputs , instead using ground truth object locations commonly done , demonstrate efficacy system handle practical surveillance scenarios finally , compare proposed methodologies state art event based systems object tracking classification , demonstrate use case approach low power applications without sacrificing performance
man success early stage understanding dynamic mechanisms drive high impact scientific work \( e g , research papers , \) long research topic many important implications , ranging personal development search , research resources recent advances characterizing modeling scientific success made possible forecast long term impact scientific work , data mining techniques , supervised learning particular , play essential role despite much progress , several key algorithmic challenges relation predicting long term scientific impact largely open paper , propose joint predictive model forecast long term scientific impact early stage , simultaneously addresses number open challenges , including scholarly feature design , non linearity , domain dynamics particular , formulate regularized optimization problem propose effective scalable algorithms solve perform extensive empirical evaluations large , real scholarly data sets validate effectiveness efficiency method
inferring input grammars dynamic control flow program characterized input model , formal input model use diverse areas including vulnerability analysis , reverse engineering , fuzzing software testing , detection unfortunately , input models typical programs often date exist algorithms structure program inputs , either produce grammars , require heuristics target specific parsing patterns r n paper , present general algorithm takes program small set sample inputs automatically context free grammar capturing input language program infer syntactic input structure observing access input characters different locations input works program stack based recursive descent input , including peg , entirely without program specific heuristics prototype produced accurate grammars variety evaluation subjects , including , ,
forecasting crime using model data mining process extract different patterns useful information large dataset according london , immediately increases beginning 2017 different london useful information available prevent crime future basis crime rates london extracting large dataset crime london predicted number future used time series model forecasting london giving 5 years data model forecasting 2 years crime data , exponential smoothing model higher fitting values real dataset reported london collected website resources main concept four parts data extraction \( de \) , data processing \( \) unstructured data , model ibm de crime data web sources 2012 2016 year integrates reduces data give predefined attributes crime prediction analyzed applying , calculated moving average , difference , auto regression model gives 80 correct values , formed accurate model work helps london decision making crime
orthogonal machine learning power limitations double machine learning provides sqrt n consistent estimates parameters interest even high dimensional nonparametric parameters estimated n 1 4 rate key employ neyman orthogonal moment equations first order insensitive perturbations parameters show n 1 4 requirement improved n 1 \( 2k 2 \) employing k th order notion robustness complex higher dimensional parameters partially linear regression setting popular causal inference , show construct second order orthogonal moments treatment residual distributed proof relies 's lemma may independent interest conclude demonstrating robustness benefits explicit doubly orthogonal estimation procedure treatment effect
game theoretic model privacy aware users location tracking nowadays , mobile users vast number applications services might impose privacy threats users' information \( \) location privacy crucial part , , privacy aware users wish maximize privacy , instance , company , collects users' traces third parties maximize location privacy , users decide get offline company cannot localize devices longer user connected network , services might receive , location privacy decreases paper , analyze trade location privacy , level services user experiences , company end , formulate bayesian game user \( \) company \( leader \) present theoretical results characterizing equilibria game best knowledge , work first model rational decision making service provider \( e , company \) conjunction rational decision making users wish protect location privacy evaluate performance approach , used real data , also shown game theoretic strategy company outperforms non strategic methods finally , considered different user privacy types , determined service level user connected long possible
zero resource speech challenge 2019 without present zero resource speech challenge 2019 , proposes build speech without text labels hence , without \( text speech without text \) provide raw audio target voice unknown language \( voice dataset \) , alignment , text labels participants must discover units unsupervised way \( using unit discovery dataset \) align voice way works best purpose novel novel , similar target speaker 's voice describe metrics used evaluation , baseline system consisting unsupervised unit discovery plus standard system , using gold phoneme present overview submitted systems 10 teams discuss main results
pattern generation strategies improving recognition handwritten mathematical expressions recognition handwritten mathematical expressions \( \) challenging problem ambiguity complexity two dimensional moreover , lack large training data serious issue , especially recognition systems paper , propose pattern generation strategies generate shape structural variations improve performance recognition systems based small training set data generation , employ public databases 2014 2016 online first strategy employs local global distortions generate shape variations second strategy online sub online get structural variations hybrid strategy combines strategies maximize shape structural variations generated online images offline recognition tested strategies end end recognition system constructed recent deep learning model convolutional neural network attention based encoder decoder results experiments 2014 2016 databases demonstrate superiority effectiveness strategies hybrid strategy achieved classification rates 45 60 , respectively , databases results competitive compared others reported recent literature generated datasets available research community useful resource recognition research future
strong default negation logic program updates extended version existing semantics answer set program updates fall two categories either consider strong negation heads rules , primarily rely default negation heads rules provide support strong negation means syntactic transformation paper limitations approaches argue types negation first class context updates identify principles constrain interaction simultaneously satisfied existing rule update semantics extend one advanced semantics direct support strong negation show satisfies principles well variety desirable properties
polynomial time corresponds solutions polynomial ordinary differential equations polynomial length journal version outcomes paper twofold implicit complexity r n provide implicit characterization polynomial time computation terms ordinary differential equations characterize class ptime languages computable polynomial time terms differential equations polynomial right hand side result gives purely continuous elegant simple characterization ptime believe first time complexity classes characterized using ordinary differential equations characterization extends functions computable polynomial time sense computable analysis results may provide new perspective classical complexity , giving way define complexity classes , like ptime , simple way , without reference notion \( discrete \) machine may also provide ways state classical questions computational complexity via ordinary differential equations r n continuous time models computation r n results also interpreted terms analog computers analog models computation side effect , get general purpose analog computer \( \) shannon provably equivalent turing machines terms computability complexity , fact never established result provides arguments form turing hypothesis , states realistic \( \) computer equivalent turing machines terms computability complexity
remote sensing image dataset cloud removal cloud based often present optical remote sensing images , thus limiting application acquired data removing clouds pre processing step remote sensing image analysis deep learning achieved great success field remote sensing recent years , including scene classification change detection however , deep learning rarely applied remote sensing image removal clouds reason lack data sets training neural networks order solve problem , paper first proposed remote sensing image cloud removing dataset \( \) proposed dataset consists two parts contains 500 pairs images , pair images cloud size contains sets images , set contains three size images , respectively , reference picture without clouds , picture cloud mask cloud dataset freely available url https url
knowledge based automatic generation linear algebra algorithms code focuses design implementation domain specific linear algebra matrix equations development efficient libraries equations , lie heart software scientific computing , complex process requires variety areas , including application domain , algorithms , numerical analysis high performance computing moreover , process involves collaboration several people considerable amount time , aim developers designing algorithms writing code , generate match even performance written human experts
asynchronous announcements propose multi agent epistemic logic asynchronous announcements , truthful announcements publicly sent individually received agents , order sent additional epistemic modalities logic contains dynamic modalities making announcements agent function initial uncertainty announcements received need truthful , announcements already made may yet received announcements true sent , certain message sequences , like cuts distributed computing provide complete emph asynchronous logic \( aa \) reduction system also demonstrates formula aa equivalent one without dynamic modalities , public logic model checking complexity detailed example modelling message processes distributed computing aa investigation
segmentation output remote sensing basic challenges recommendations work consider application convolutional neural networks \( cnns \) pixel wise labeling \( k , semantic segmentation \) remote sensing imagery \( e g , aerial color hyperspectral imagery \) remote sensing imagery usually stored form large images , referred tiles , large segmented directly using cnns associated hardware result , label inference , smaller sub images , called patches , processed individually \( concatenated \) back together create tile sized label map approach suffers computational result output boundaries propose simple alternative approach input size cnn dramatically increased label inference avoid , substantially limitations evaluate performance proposed approach approach using two popular segmentation cnn models two large scale remote sensing imagery datasets results suggest proposed approach substantially reduces label inference time , also yielding modest overall label accuracy increases approach entry \( overall performance \) building labeling competition
class q ary linear codes derived irreducible cyclic codes recently , linear codes weights widely investigated due applications secret sharing schemes authentication schemes letter , present class q ary linear codes derived irreducible cyclic codes q prime power use sums represent hamming weights obtain bounds minimum hamming distance cases , explicitly determine weight distributions generalize known results quite interesting many new codes obtained letter optimal according bounds linear codes
solving linear programs current matrix multiplication time paper shows solve linear programs form min b , x c top x n variables time \( \( n omega n 2 5 alpha 2 n 2 1 6 \) log \( n delta \) \) omega exponent matrix multiplication , alpha dual exponent matrix multiplication , delta relative accuracy current value omega alpha , algorithm takes \( n omega log \( n delta \) \) time omega 2 , algorithm takes \( n 2 1 6 log \( n delta \) \) time r n algorithm utilizes several new concepts believe may independent interest r n define stochastic central path method r n show maintain projection matrix sqrt w \( top \) 1 sqrt w sub quadratic time ell 2 multiplicative changes matrix w
pc partial channel connections memory efficient differentiable architecture search differentiable architecture search \( \) provided fast solution finding effective network architectures , large memory computing jointly training super net search optimal architecture paper , present novel approach , namely partially connected , sampling small part super net reduce redundancy network space , thereby performing efficient search without comprising performance particular , perform operation search subset channels held part strategy may suffer inconsistency selecting edges super net caused sampling different channels solve introducing edge normalization , adds new set edge level hyper parameters search reduce uncertainty search thanks reduced memory cost , pc trained larger batch size , consequently , enjoys faster speed higher training stability experimental results demonstrate effectiveness proposed method specifically , achieve error rate 2 57 cifar10 within merely 0 1 gpu days architecture search , state art top 1 error rate 24 2 imagenet \( mobile setting \) within 3 8 gpu days search made code available https url
identifying mild brain patients images using visual words mild brain \( \) growing public health problem estimated one million people us tests used assess patient condition monitor patient progress work aims directly use images taken detect whether patient suffers , incorporating machine learning computer vision techniques learn features suitable normal patients focus 3 regions brain , extract multiple patches , use visual word technique represent subject histogram representative patterns derived patches training subjects extracting features , use greedy forward feature selection , choose subset features achieves highest accuracy show experimental studies features perform better simple mean value features used previously
step learning node embeddings via graph attention graph embedding methods represent nodes continuous vector space , preserving information graph \( e g sampling random walks \) many hyper parameters methods \( random walk length \) manually tuned every graph paper , replace random walk hyper parameters trainable parameters automatically learn via backpropagation particular , learn novel attention model power series transition matrix , random walk optimize objective unlike previous approaches attention models , method propose utilizes attention parameters data \( e g random walk \) , used model inference experiment link prediction tasks , aim produce embeddings best preserve graph structure , generalizing unseen information improve state art comprehensive suite real world datasets including social , collaboration , biological networks adding attention random walks reduce error 20 45 datasets , learned attention parameters different every graph , automatically found values optimal choice hyper parameter manually tune existing methods
visual question answering survey methods datasets visual question answering \( vqa \) challenging task received increasing attention computer vision natural language processing communities given image question natural language , requires reasoning visual elements image general knowledge infer correct answer first part survey , examine state art comparing modern approaches problem classify methods mechanism connect visual textual modalities particular , examine common approach combining convolutional recurrent neural networks map images questions common feature space also discuss memory augmented modular architectures interface structured knowledge bases second part survey , review datasets available training evaluating vqa systems various contain questions different levels complexity , require different capabilities types reasoning examine depth question answer pairs visual project , evaluate relevance structured annotations images scene graphs vqa finally , discuss promising future directions field , particular connection structured knowledge bases use natural language processing models
problems parameterized tractable single exponential time logical approach introduce variant modal logic , dubbed existential counting modal logic \( \) , captures vast majority problems known tractable single exponential time parameterized appears results theorem model checking admits algorithm complexity extend adding connectivity requirements , using however , using randomization need introduced logic justified negative result two problems involving non acyclic conditions , c l vertex deletion girth l vertex deletion l 5 , admit robust algorithm unless exponential time hypothesis fails
deep active learning using unlabeled data model training active learning typically focuses training model labeled examples , unlabeled ones used acquisition work setting using labeled unlabeled data model training across active learning cycles using unsupervised feature learning beginning active learning pipeline semi supervised learning every active learning cycle , available data former investigated active learning , study latter context deep learning scarce recent findings respect benefit idea orthogonal acquisition strategies using data , much like ensemble methods use models systematically evaluating number popular acquisition strategies datasets , find use unlabeled data model training brings surprising accuracy improvement image classification , compared differences acquisition strategies thus explore smaller label , even one label per class
automated prediction temporal relations background growing research interest automated answering questions generation summary free form text news article order implement task , computer able identify sequence events , duration events , time event relationship type event pairs , time pairs event time pairs specific problem important accurately identify relationship type combinations event time temporal ordering events defined machine learning approach taken et al \( 2006 \) provides accuracy 5 baseline data researchers used maximum entropy classifier methodology uses annotation tag relationship type events time time complexity quadratic comes tagging documents using human annotation research proposes using decision tree parsing improve relationship type tagging research attempts solve gaps human annotation automating task relationship type tagging attempt improve accuracy event time relationship annotated documents scope information documents domain news used tagging performed within document across documents relationship types identified pair event time chain events research focuses documents using specification contains tags event , , tag attributes , relation , , time etc
nlsemagic nonlinear equation multi dimensional matlab based gpu accelerated integrators using compact high order schemes abstract present simple use , yet powerful code package called nlsemagic numerically integrate nonlinear equation one , two , three dimensions nlsemagic high order finite difference code package utilizes graphic processing unit \( gpu \) parallel architectures codes running gpu many times faster counterparts , much cheaper run standard parallel clusters codes developed portability mind , therefore written interface matlab utilizing gpu enabled c codes interface packages freely distributed , including user set files program summary program nlsemagic v1 0 program summary url http cs v1 0 program program library , university , , n standard , http cs lines distributed program , including test data , etc distributed program , including test data , etc distribution format programming language c , cuda , matlab computer pc , mac operating system , , code \? yes number processors used single cpu , number gpu processors dependent chosen gpu card \( max currently cores \) material setup guide , guide ram highly dependent dimensionality grid size typical medium large problem size three dimensions , sufficient keywords nonlinear equation , gpu , high order finite difference , classification 4 3 , 7 7 nature problem integrate solutions time dependent one , two , three dimensional cubic nonlinear equation solution method integrators utilize fully explicit fourth order scheme time second fourth order space integrators written run nvidia gpus matlab including built visualization analysis tools restrictions main gpu integrators amount ram gpu code currently designed running single gpu features ability visualize real time simulations interaction matlab compiled gpu integrators additional comments setup guide guide provided program dedicated web site nlsemagic com running time three dimensional run grid dimension time steps \( 100 non dimensional time units \) takes one half minutes gpu card
novel apex time network cross dataset micro expression recognition automatic recognition micro expression boosted ever since successful introduction deep learning approaches whilst researchers working topics learn nature micro expression , practice using deep learning techniques processing entire video micro expression recognition apex frame using apex frame able get redundant information temporal evidence micro expression would thereby left paper , propose recognition based spatial information apex frame well temporal information respective adjacent frames , novel apex time network \( \) proposed extensive experiments three benchmarks , demonstrate improvement achieved adding temporal information learned adjacent frames around apex frame , model temporal information robust cross dataset
investigating effect social groups directional pedestrian flow influence among members dyads investigated scenarios characterized directional flow means discrete model room bottleneck varying width simulated model dynamics simulated group members adaptive mechanism , balancing probability movement according group mechanism parameters c delta scenarios simulated two procedures \( 1 \) population composed individual pedestrians , order validate simulation model provide baseline data \( 2 \) population including dyads \( 50 simulated pedestrians \) , order verify impact scenario , presence dyads causes reduction velocities specific flow medium high square room unique central produces results line recent studies literature , also shows dyads negatively affect dynamics , leading generally speed lower pedestrian flow ignoring presence dyads would lead flows
precise topic queries center digital mathematics libraries lie controlled topic documents topics used document digital mathematics library perform searches library latter refined use topics allow precise classification mathematics area document addresses however , major risk users employ precise topics specify queries may employing topic close missing match right resource call topic indeed , since 2009 , issue appeared frequently net platform mathematics experience phenomenon approach solve issue introduce tolerance way queries understood user particular , approach including fuzzy matches introduces noise may prevent user understanding function search engine r n paper , propose way topic employing navigation related topics count search results topic supports user search close topics click away previous search approach realized search engine described detail relation related computed employing textual analysis definitions concepts wikipedia
towards general framework static cost analysis parallel logic programs estimation control resource usage important challenge increasing number computing systems particular , requirements timing energy arise wide variety applications internet things , cloud computing , health , transportation , robots time , parallel computing , \( heterogeneous \) multi core platforms particular , become dominant paradigm computer architecture predicting resource usage platforms poses difficult challenge work static resource analysis focused sequential programs , relatively little progress made analysis parallel programs , specifically parallel logic programs propose novel , general , flexible framework setting cost equations relations performing resource usage analysis parallel logic programs wide range resources , platforms execution models analysis estimates lower upper bounds resource usage parallel program \( without executing \) functions input data sizes addition , also meaningful information better exploit assess potential actual parallelism system develop method solving cost relations involving max function arise analysis parallel programs finally , general framework analysis logic programs independent parallelism , report implementation within system , provide experimental results knowledge , first approach cost analysis parallel logic programs
efficient memory management gpu based deep learning systems gpu \( graphics processing unit \) used many data intensive applications among , deep learning systems one important consumer systems gpu nowadays deep learning applications impose deeper larger models order achieve higher accuracy , memory management becomes important research topic deep learning systems , given gpu limited memory size many approaches proposed towards issue , e g , model compression memory however , either degrade model accuracy require lot manual intervention paper , propose two orthogonal approaches reduce memory cost system perspective approaches models , thus affect model accuracy achieved exploiting iterative nature training algorithm deep learning derive lifetime read write order variables lifetime semantics , able implement memory pool minimal however , optimization problem np complete propose heuristic algorithm reduces 13 3 memory compared nvidia 's default memory pool equal time complexity read write semantics , variables use gpu cpu reduce memory propose multiple strategies automatically decide variable \( \) , reduces memory cost 34 2 without communication overhead
meta learning shot time series classification deep neural networks \( dnns \) achieved state art results time series classification \( tsc \) tasks work , focus leveraging dnns often encountered practical scenario access labeled training data difficult , dnns would prone overfitting leverage recent gradient based meta learning , propose approach train residual neural network convolutional layers meta learning agent shot tsc network trained diverse set shot tasks sampled various domains \( e g healthcare , activity recognition , etc \) solve target task another domain using small number training samples target task existing meta learning approaches limited practice assume fixed number target classes across tasks overcome limitation order train common agent across domains domain different number target classes , utilize triplet loss based learning procedure require constraints number classes shot tsc tasks best knowledge , first use meta learning based pre training tsc approach sets new benchmark shot tsc , outperforming several strong baselines shot tasks sampled datasets tsc observe pre training meta learning paradigm allows network quickly adapt new unseen tasks small number labeled instances
word sense lstm really need 100 billion words recently , et al \( 2016 \) shown e using long short term memory \( lstm \) performing word sense \( \) proposed technique outperformed previous state art several benchmarks , neither training data source code released paper presents results study technique using available datasets \( , , \) software \( \) , emerged state art results obtained much less data et al code trained models made freely available
lower bounds z paper presents new abstract method proving lower bounds computational complexity based notion topological entropy dynamical systems , method captures four previous lower bounds results literature algebraic complexity among results lies 's proof without bit operations compute problem time , best known lower bounds proof nc ptime inspired refinement 's lower bounds , due , 's result larger class machines , showing integer compute time
emergence object segmentation generative models introduce novel framework build model learn segment objects collection images without human annotation method builds observation location object segments locally relative given background without affecting scene approach first train generative model layered scene layered representation consists background image , foreground image mask foreground composite image obtained masked foreground image onto background generative model trained adversarial fashion discriminator , forces generative model produce realistic composite images force generator learn representation foreground layer corresponds object , output generative model introducing random shift foreground image mask relative background generator shift computing output , must produce layered representations realistic random finally , learn segment image defining autoencoder consisting encoder , train , pre trained generator decoder , encoder maps image feature vector , fed input generator give composite image matching original input image generator outputs explicit layered representation scene , encoder learns detect segment objects demonstrate framework real images several object categories
beginning game semantics chapter presents overview computability logic game semantically constructed logic interactive computational tasks resources one non overview , technical section , devoted proof affine logic respect semantics computability logic
discriminative clustering relative constraints study problem clustering relative constraints , constraint relative similarities among instances particular , constraint \( x , x j , x k \) acquired query instance x similar x j x k \? consider scenario answers queries based underlying \( unknown \) class concept , aim discover via clustering different existing methods consider constraints derived yes answers , also incorporate n't know responses introduce discriminative clustering method relative constraints \( \) assumes natural probabilistic relationship instances , underlying cluster , observed constraints objective maximize model likelihood given constraints , enforce cluster separation cluster balance also making use unlabeled instances evaluated proposed method using constraints generated ground truth class labels , \( noisy \) human judgments user study experimental results demonstrate 1 \) usefulness relative constraints , particular n't know answers considered 2 \) improved performance proposed method state art methods utilize either relative pairwise constraints 3 \) robustness method presence noisy constraints , provided human
payments channels payment channel networks like 's network approach high throughput almost blockchain networks however , ability successfully make payments networks relies participants collateral network , key incentive collateral small fees routing payments participants users choose fees , currently , mainly default fees providing insights beneficial choices fees , aim users collateral improve effectiveness network r n paper , consider node mathbf given network topology channel details selects establish channels much gain maximized formalize optimization problem show np hard design greedy algorithm approximate optimal solution step , greedy algorithm selects node maximizes total reward concerning number shortest paths passing mathbf channel fees simulation study leverages real world data set quantify impact gain optimization indicates strategy least factor two better strategies
text graphics separation business card images mobile devices separation text regions background texture graphics important step optical character recognition images texts graphics paper , presented novel text graphics separation technique business card images captured cell phone camera first , background coarse level based intensity variance makes foreground components distinct non text components removed using various characteristic features text graphics finally , text regions binarized processing business card images various resolutions , found optimum performance 98 0 75 mp images , takes 0 17 seconds processing time 1 1 peak memory powerful computer \( 1 processor , 1 ram , 1 l2 cache \) developed technique computationally efficient low memory applicable mobile devices
sparse linear representation paper studies question well signal sparse linear combination reference signals overcomplete dictionary dictionary size exponential dimension signal , exact characterization optimal distortion given function dictionary size exponent number reference signals linear representation roughly speaking , every signal sparse dictionary size exponentially large , matter small exponent furthermore , iterative method similar matching pursuit finds best reference signal stage gives asymptotically optimal representations method essentially equivalent successive refinement multiple descriptions provides simple alternative proof successive white gaussian sources
secure querying federated databases people machines collecting data rate despite data , progress slow sharing open science , business , data intensive many efforts privacy concerns compliance issues example , many interested pooling medical records research , none may arbitrary patient records researchers healthcare providers context propose private data network \( pdn \) , federated database querying collective data mutually parties pdn , database reveal tuples peers query instead , user query honest broker plans coordinates execution multiple private databases using secure computation \( \) , database 's query execution oblivious , program memory traces agnostic inputs others introduce framework executing pdn queries named system sql primitives compute query results union source databases without revealing sensitive information individual tuples peer data providers honest broker honest broker receive results pdn query fast , secure query evaluation , explore heuristics driven optimizer minimizes pdn 's use secure computation partitions query evaluation scalable
integrals gaussians linear domain constraints integrals linearly constrained multivariate gaussian frequent problem machine learning statistics , arising tasks like generalized linear models bayesian optimization yet notoriously hard compute , , numerical values integrals may small present efficient black box algorithm exploits geometry estimation integrals small , gaussian volume , simulate algorithm uses \( \) method combined analytic version slice sampling \( \) adapted linear setting , allows efficient , free sampling , intersections domain boundaries closed form solutions key idea decompose integral easier compute conditional probabilities using sequence nested domains remarkably , allows direct computation integral value thus enables computation extremely small probability demonstrate effectiveness tailored combination high dimensional integrals entropy search bayesian optimization
performance optimum combining poisson field rayleigh fading channels paper studies performance antenna array processing distributed multiple access networks without power control positions nodes determined poisson point process desired signals subject path loss \( exponent greater 2 \) independent rayleigh fading using assumptions , derive exact closed form expression cumulative distribution function output signal interference plus noise ratio optimum combining applied results measure network performance terms outage probability , turn provides insights network capacity gain could achieved antenna array processing present discuss examples applications , well numerical results
comparing population means local differential privacy significance power statistical hypothesis test determines whether hypothesis based samples populations particular , randomized controlled experiments \( b testing \) compare population means using , e g , tests , widely deployed technology companies aid making data driven decisions samples used tests collected users may contain sensitive information data collection testing process may compromise privacy paper , study conduct hypothesis tests compare population means preserving privacy use notation local differential privacy \( ldp \) , recently emerged main tool ensure individual 's privacy without need data propose ldp tests noise every user 's data samples collecting \( users need trust data \) , draw conclusions bounded type \( significance level \) type ii errors \( 1 power \) approaches extended scenario users require ldp provide exact data report experimental results real world datasets verify effectiveness approaches
measuring dataset granularity despite increasing visibility fine grained recognition field , fine thus far precise definition work , building upon clustering theory , framework measuring dataset granularity argue dataset granularity depend data samples labels , also distance function choose propose framework capture desired properties dataset granularity measure provide examples measures satisfy properties assess measure via experiments datasets hierarchical labels varying granularity measuring granularity commonly used datasets measure , find certain datasets widely considered fine grained fact contain subsets considerable size substantially coarse grained datasets generally regarded coarse grained also investigate interplay dataset granularity variety factors find fine grained datasets difficult learn , difficult transfer , difficult perform shot learning , vulnerable adversarial attacks
novel pseudo random number generator based discrete iterations security information transmitted internet , passive active attacks international concern use based pseudo random bit sequence make , field research full expansion mask useful information modulation encryption fundamental part internet exchange protocol paper , new method using discrete iterations generate pseudo random numbers presented pseudo random number generator successfully nist statistical test suite \( nist 22 \) security analysis shows good characteristics application secure image transmission internet proposed end paper
multilingual multi aspect speech analysis current research speech analysis typically oriented towards monolingual single classification tasks paper , present new multilingual multi aspect speech analysis dataset use test current state art multilingual learning approaches evaluate dataset various classification settings , discuss leverage annotations order improve speech detection classification general
deep depth super resolution learning depth super resolution using deep convolutional neural network depth image super resolution extremely challenging task due information loss sub sampling deep convolutional neural network widely applied color image super resolution quite surprisingly , success matched depth super resolution mainly due inherent difference color depth images paper , bridge gap extend success deep convolutional neural network depth super resolution proposed deep depth super resolution method learns mapping low resolution depth image high resolution one end end style furthermore , better learned depth map , propose exploit depth field statistics local correlation depth image color image priors integrated energy minimization formulation , deep neural network learns unary term , depth field statistics works global model constraint color depth correlation utilized enforce local structure depth images extensive experiments various depth super resolution benchmark datasets show method outperforms state art depth image super resolution methods margin
higher order delta processing dynamic frequently views applications ranging algorithmic scientific data analysis require analytics based views databases change high rates views low maintenance cost time , views support classical sql , rather window semantics , enable applications combine current historical data paper , present viewlet transforms , recursive finite technique applied queries viewlet transform query set higher order views views support 's incremental maintenance , leading reduced overall view maintenance cost viewlet transform query admits efficient evaluation , elimination certain expensive query operations , aggressive develop viewlet transforms query execution technique , present heuristic cost based optimization framework , report experiments prototype dynamic data management system combines viewlet transforms optimizing technique system supports thousands complete view second wide range queries
fd net auxiliary time steps fast prediction using free trust region methods discovering underlying physical behavior complex systems crucial , less well understood topic many engineering study proposes finite difference inspired convolutional neural network framework learn hidden partial differential equations given data iteratively estimate future dynamical behavior methodology designs filter sizes mimic finite difference neighboring points learning equation , network predicts future evolution solution using trainable parameters paper , provide numerical results compare efficiency second order trust region conjugate gradient \( \) method first order adam optimizer
power randomization network network viewed game two players , flow player flow player send much material possible network , attempts minimize amount material removing certain number arcs , say gamma arcs introduce randomized network problem allows use randomness select arcs removed model problem two different ways based path based formulations , depending whether flows defined arcs paths , respectively present insights modeling power , complexity , formulations particular , prove z text ni z text rni leq gamma 1 , z text ni z text rni text path leq gamma 1 , z text rni z text rni text path leq gamma , z text ni , z text rni , z text rni text path optimal values network problem randomized versions based path based formulations , respectively also show bounds tight show np hard compute values z text rni z text rni text path general gamma , computable polynomial time gamma 1 , provide \( gamma 1 \) approximation z text ni , gamma approximation z text rni , big \( 1 lfloor gamma 2 rfloor cdot gamma 2 \( gamma 1 \) big \) approximation z text rni text path
towards theory mind inspired generic decision making framework simulation widely used make model based predictions , approaches technique dynamic physical environments medium high complexity general contexts introduction cognitive science concepts work inspired current development use simulation decision making technique , propose generic framework based theory mind , allows agent reason perform actions using multiple simulations automatically created models perceived environment description partial implementation given , aims solve popular game within results approach presented , comparison competition benchmark finally , future developments regarding framework discussed
distributed power control partial channel state information performance characterization design one goals paper contribute finding distributed power control strategies exploit efficiently information available global channel state may local noisy suited way measuring global efficiency distributed power control scheme use long term utility region first , provide utility region characterization general utility functions channel state independent block fading law observation structure memoryless second , corresponding theorem exploited construct iterative algorithm provides one shot power control strategies performance proposed algorithm assessed energy efficient efficient communications shown perform much better state art techniques , additional advantage applicable even presence arbitrary observation structures corresponding noisy channel gain estimates
timed network games clocks network games widely used model selfish resource allocation problems classical model , player selects path connecting source target vertices cost edge depends em load namely , number players thus , fact different users may use resource different times different , plays important role determining costs users reality example , transmitting packets communication network , routing traffic road network , processing task production system , actual sharing congestion resources crucially depends time r n cite , introduced em timed network games , add time component network games vertex v network associated cost function , mapping load v price player v one time unit load edge network guarded time , forces players time vertices work significantly extend way time referred timed network games model study , network equipped em clocks , , timed automata , edges guarded constraints values clocks , traversal may involve clocks argue stronger model captures many realistic networks addition clocks breaks techniques developed cite develop new techniques order show positive results classic network games carry stronger timed setting
prolog debugger declarative programming examples paper contains examples paper prolog debugger declarative programming , discusses \( \) prolog debugger declarative programming r n logic programming declarative programming paradigm programming language prolog makes logic programming possible , least substantial extent however prolog debugger works solely terms operational semantics declarative programming paper tries find methods using declarative point view provide examples applying
strong diameter padded decompositions given weighted graph g \( v , e , w \) , partition v delta bounded diameter cluster bounded delta distribution delta bounded partitions beta padded decomposition every ball radius gamma delta contained single cluster probability least e beta cdot gamma weak diameter cluster c measured w r distances g , strong diameter measured w r distances induced graph g c decomposition weak strong according diameter guarantee r n , proven k r free graphs admit weak decompositions parameter \( r \) , strong decompositions \( r 2 \) parameter known furthermore , case graph g , induced shortest path metric g dimension , weak \( \) padded decomposition constructed , also known tight case strong diameter , known r n construct strong \( r \) padded decompositions k r free graphs , matching state art weak decompositions similarly , graphs dimension construct strong \( \) padded decomposition , also tight use decomposition construct \( \( \) , tilde \( \) \) sparse cover scheme graphs new decompositions cover implications approximating unique games , construction light sparse spanners , path reporting distance
dynamic motion planning aerial surveillance fixed uav present efficient path planning algorithm aerial vehicle urban landscape special emphasis maximizing area constraints uav partially known updating environment bias introduced probabilistic building phase identify certain critical maximal surveillance search space feasible coarse tour connecting generated global path planner local path planner generates smooth motion primitives consecutive nodes global path based uav vehicle taking account obstacles markov decision process \( mdp \) models control policy uav determines optimal action obstacles minimal deviation current path efficacy proposed algorithm evaluated updating simulation environment dynamic static obstacles
vqa visual question answering benchmark requiring external knowledge visual question answering \( vqa \) ideal form lets us study reasoning joint space vision language serves proxy ai task scene understanding however , vqa benchmarks date focused questions simple counting , visual attributes , object detection require reasoning knowledge beyond image paper , address task knowledge based visual question answering provide benchmark , called vqa , image content sufficient answer questions , encouraging methods rely external knowledge resources new dataset includes 14 , 000 questions require external knowledge answer show performance state art vqa models drastically new setting analysis shows knowledge based vqa task diverse , difficult , large compared previous knowledge based vqa datasets hope dataset enables researchers open new research domain see http url dataset
ring interfaces instruction sequences threads services define focus method interfaces connections interfaces instruction sequences , giving rise instruction sequence components provide flexible practical notation interfaces using abstract specification comparable basic process algebra structures thus defined called also define service components two types composition instruction sequences threads services \( called \) lifted level components
visual atari games studying transfer learning rl work , ask following question visual , learned unsupervised way , used order transfer knowledge pairs games even play one game using agent trained another game \? attempt answer research question creating visual pair games source game target game example , given video frame target game , map analogous state source game attempt play using trained policy learned source game demonstrate convincing visual mapping four pairs games \( eight mappings \) , used evaluate three transfer learning approaches
one shot instance segmentation tackle problem one shot instance segmentation given example image novel , previously unknown object category , find segment objects category within complex scene address challenging new task , propose siamese mask r cnn extends mask r cnn siamese backbone encoding reference image scene , allowing target detection segmentation towards reference category demonstrate empirical results highlighting challenges one shot setting transferring knowledge instance segmentation novel object categories works well , targeting detection network towards reference category appears difficult work provides first strong baseline one shot instance segmentation research powerful flexible scene analysis algorithms code available https url
cost epidemic complex network random matrix approach paper quantify total economic impact epidemic r n complex network using tools random matrix theory incorporating direct r n costs , calculate disease cost large r n graph limit \( \) r n process also give upper bound cost arbitrary finite graphs r n illustrate calculated costs using extensive simulations random r n real world networks extend considering total r n social cost epidemic , disease r n costs various strategies determining optimal r n work focuses behavior epidemic , r n contrast previous research , typically focuses determining r n steady state system equilibrium
discriminative visual landmarks place recognition address problem visual place recognition perceptual changes fundamental problem visual place recognition generating robust image representations insensitive environmental changes also different places taking advantage feature extraction ability convolutional neural networks \( cnns \) , investigate localize discriminative visual landmarks contribute similarity measurement , particular , landmark localization network \( \) designed indicate regions image used discrimination detailed experiments conducted open source datasets appearance viewpoint changes proposed approach achieves superior performance state art methods
combinatorial algorithms network design focus designing combinatorial algorithms network design problem \( cap sndp \) cap sndp problem satisfying connectivity requirements edges costs hard capacities begin showing group steiner tree problem \( \) special case cap sndp even connectivity requirement one source sink pair implies first poly logarithmic lower bound cap sndp next provide combinatorial algorithms several special cases problem cap sndp equivalent special case every edge either zero cost infinite capacity consider special case , called connected cap sndp , infinite capacity edges solution required form connected component containing problem motivated similarity connected facility location problem g , solve problem reducing submodular tree cover problem , common generalization connected cap sndp group steiner tree problem generalize recursive greedy algorithm achieving poly logarithmic approximation algorithm submodular tree cover problem result interesting right gives first poly logarithmic approximation algorithms connected hard capacities set multi cover connected source location r n study another special case cap sndp called point point connection problem besides practical applications shift design problems , generalizes many problems k mst , steiner forest point point connection give combinatorial logarithmic approximation algorithm problem reducing degree bounded sndp
even good bots case wikipedia recent years , huge increase number bots online , varying web search engines , online customer service , social media , content editing bots online collaboration communities online world bots however , knowledge automated agents interacting rather poor bots predictable capacity emotions , meaning making , , hence natural expect interactions bots relatively predictable article , analyze interactions bots edit articles wikipedia track extent bots period 2010 , model pairs bots interact time , identify different types interaction trajectories find , although wikipedia bots intended support , often may sometimes continue years unlike humans wikipedia , bots interactions tend occur longer periods time yet , like humans , bots different environments may differently research suggests even relatively bots may give rise complex interactions , important implications artificial intelligence research understanding affects interactions crucial managing social media well , providing adequate cyber security , designing well autonomous vehicles
counting hypergraphs data streams present first streaming algorithm counting arbitrary hypergraph h constant size massive hypergraph g algorithm handle edge insertions edge deletions , applicable distributed setting moreover , approach provides first family graph polynomials hypergraph counting problem close relationship hypergraphs set systems , approach may applications studying similar problems
efficient systematic encoding non binary vt codes \( vt \) codes class codes correct single deletion insertion linear time decoder paper addresses problem efficient encoding non binary vt codes , defined alphabet size q 2 propose simple linear time encoding method systematically map binary message sequences onto vt codewords method provides new lower bound size q ary vt codes length n
mcmc filtering filtering estimating state partially observable markov process sequence observations one widely studied problems control theory , ai , computational statistics exact computation posterior distribution generally intractable large discrete systems nonlinear continuous systems , good deal effort developing robust approximation algorithms paper describes simple stochastic approximation algorithm filtering called em mcmc algorithm applies markov chain monte carlo sampling space state trajectories using proposal distribution recent state variables formal analysis algorithm involves generalization standard coupling arguments mcmc convergence prove ergodic underlying markov process , convergence time mcmc inverse polynomial decay remains bounded length observation sequence grows show experimentally mcmc least competitive approximation algorithms particle filtering
pun gan generative adversarial network pun generation paper , focus task generating pun sentence given pair word senses major challenge pun generation lack large scale pun corpus guide supervised learning remedy , propose adversarial generative network pun generation \( pun gan \) , require pun corpus consists generator produce pun sentences , discriminator distinguish generated pun sentences real sentences specific word senses output discriminator used reward train generator via reinforcement learning , encouraging produce pun sentences support two word senses simultaneously experiments show proposed pun gan generate sentences diverse automatic human evaluation
reduced list decoding reed solomon codes using reliability information decode reed solomon codes using soft information provided receiver extended euclidean algorithm \( \) considered initial step obtain intermediate result final decoding result obtained output least reliable positions received word refer decoding method reduced list decoding , since received positions used interpolation list decoding methods , algorithms consequently complexity interpolation step reduced considerably probability failure adjusting certain parameters , making comparable k algorithm much lower complexity
systems logical relations lifting type effect system semantics type effect systems incorporate information computational effects , e g , state , probabilistic choice , , program may return value semantics type effect systems involves parameterised family whose size exponential number effects derive refined semantics single category , choice algebraic operations , suitable system category relate derived semantics original semantics using logical relations proof uses technique lifting operations
study members german preliminary study compare characteristics , 000 messages collected following members german twitter find significant differences characteristics distinct types using time series regression analysis observe likelihood using increases typical times occur constant time including formal increases probability message chance use tend personal
problems related crossing families given set points plane , emph crossing family collection segments , two points , every two segments internally et al , 14 \( 2 \) , proved set n points contains crossing family size omega \( sqrt n \) also mentioned exist point sets whose maximum crossing family uses frac n 2 points improve upper bound size crossing families 5 frac n 24 also introduce generalizations crossing families , give several lower upper bounds generalized notions
supervised online hashing via similarity distribution learning online hashing extensive research attention facing streaming data online hashing methods , learning binary codes based pairwise similarities training instances , fail capture semantic relationship , suffer poor generalization large scale applications due large variations paper , propose model similarity distributions input data hashing codes , upon novel supervised online hashing method , dubbed similarity distribution based online hashing \( \) , proposed , keep intrinsic semantic relationship produced hamming space specifically , first transform discrete similarity matrix probability matrix via gaussian based normalization address extremely imbalanced distribution issue , introduce scaling student distribution solve challenging initialization problem , efficiently bridge gap known unknown distributions lastly , align two distributions via minimizing kullback leibler divergence \( \) stochastic gradient descent \( sgd \) , intuitive similarity constraint update hashing model new streaming data powerful generalizing ability past data extensive experiments three widely used benchmarks validate superiority proposed state art methods online retrieval task
jpeg images adversarial attacks deep neural networks \( dnns \) integrated critical systems , several methods attack systems developed adversarial attacks make imperceptible modifications image fool dnn classifiers present adaptive jpeg encoder many attacks experimentally , show method produces images high visual quality greatly reducing state art attacks algorithm requires modest increase encoding time , produces compressed image jpeg decoder , classified classifier
co training relationships attributes cross lingual knowledge alignment cross lingual knowledge alignment suffers attribute leveraging attributes also suffers results attributes relationships paper proposes interaction based attribute model capture attribute level interactions estimating entity similarities , eliminating negative impact attributes matrix based strategy adopted model accelerate similarity estimation propose co training framework together three merge strategies combine attribute model relationship model whole framework effectively efficiently infer aligned entities , relationships , attributes , values simultaneously experimental results several cross lingual knowledge datasets show model significantly outperforms state art comparison methods \( improving 2 35 57 terms ratio 1 \)
modulo theories present integer linear programming \( \) modulo theories \( \) instance integer linear programming instance , symbols background theories previous work , approach applied industrial synthesis design problems real time constraints arising development many problems ranging operations research software verification involve linear constraints optimization thus , general modulo theories framework potential widely applicable logical next step development main goal paper provide theoretical accomplished means bc \( \) , branch cut modulo abstract transition system show bc \( \) provides sound complete optimization procedure modulo problem , long decidable , infinite theory compare prototype bc \( \) leading smt solvers
apex accuracy aware differentially private data exploration organizations increasingly interested allowing external data explore sensitive datasets due popularity differential privacy , data want data exploration ensure provable privacy guarantees however , current systems answering queries differential privacy place burden data analysts understand differential privacy , manage privacy budget , even implement new algorithms noisy query answering moreover , current systems provide guarantees data quality care , namely accuracy query answers r n present apex , novel system allows data analysts pose adaptively chosen sequences queries along required accuracy bounds translating queries accuracy bounds differentially private algorithms least privacy loss , apex returns query answers data meet accuracy bounds , proves data owner entire data exploration process differentially private comprehensive experimental study real datasets demonstrates apex answer variety queries accurately moderate small privacy loss , support data exploration entity resolution high accuracy reasonable privacy settings
data extraction charts via single deep neural network automatic data extraction charts challenging two reasons exist many relations among objects , common consideration general computer vision problems different types charts may processed model address problems , propose framework single deep neural network , consists object detection , text recognition object matching modules framework handles charts , may also extended types charts slight augmenting training data model performs successfully 79 4 test simulated charts 0 test simulated charts , charts outside training domain 57 5 3 , respectively
alternating algorithm uplink max min sinr cell free massive mimo local mmse receiver problem max min signal interference plus noise ratio \( sinr \) uplink transmission cell free massive multiple input multiple output \( mimo \) system considered assume system employed local minimum mean square error \( l mmse \) combining objective preserve user fairness solving max min sinr optimization problem , optimizing transmit power user equipment \( ue \) weighting coefficients central processing unit \( cpu \) , subject transmit power constraints ues problem jointly convex hence , decompose original problem two subproblems , particularly optimizing power allocation receiver weighting coefficients , propose alternating algorithm solve two subproblems weighting coefficient formulated generalized problem power allocation approximated geometric programming \( gp \) empirically show proposed algorithm achieves higher min user uplink spectral efficiency \( \) existing fixed power scheme optimized respect transmit power moreover , convergence proposed algorithm numerically illustrated
reinforcement learning sample efficient model predictive control based approach research focus developing reinforcement learning system challenging task autonomous control real sized , difficulties arising large uncertainties challenging environment extremely high cost exploring sampling real end , explore novel gaussian processes \( gp \) based reinforcement learning approach combines sample efficient model based reinforcement learning model predictive control \( mpc \) approach , sample efficient probabilistic model predictive control \( \) , iteratively learns gaussian process dynamics model uses efficiently update control signals within mpc closed control loop system using built efficiently learn task investigating performance simulation modeled upon real driving data , proposed system successfully learns drive real sized equipped single engine sensors measuring gps , speed , direction , task without human demonstration
applying text based affective dialogue system research case studies effects system behaviour interaction context social article presents two studies conducted affective dialogue system text based system user communication used model , generate present different affective social interaction scenarios specifically investigated influence interaction context assigned system participants , well impact pre structured social interaction patterns modelled mimic aspects social scenarios results first study demonstrate social context interaction assigned system influence system evaluation , interaction patterns , textual expressions affective states , well emotional self reports results observed second study show system ability partially exclude without significantly different affective negative system evaluation experimental evidence provides insights perception , modelling generation affective social cues artificial systems realized different modalities , including text modality , thus valuable input applying affective dialogue systems tools studying affect social aspects online communication
improving detection influential nodes complex networks recently increasing amount research devoted question influential nodes \( \) found effectively complex network number measures proposed purpose , instance , high degree centrality measure importance network topology reasonable runtime performance find set nodes highest degree , satisfactory dissemination network due many common neighbors \( \( 1 \) \) common neighbors neighbors \( \( 2 \) \) holds measures well paper , compare high degree centrality measure well known measures using ten datasets order find common seed sets obtained , , propose improved high degree centrality measure \( named \) improve enhance accuracy two , , put threshold number common neighbors already selected seed nodes non seed node investigation selected seed well considering influence score seed nodes directly common neighbors non seed node evaluate accuracy runtime performance , , , applied eight large scale networks finally turns dramatically outperforms well known measures accurate performance identifying influential nodes
empirical evaluation new approach long short term memory lstm standard lstm , although modeling long range , suffers highly complex structure simplified modifications units paper perform empirical comparison standard lstm three new simplified variants obtained eliminating input signal , bias hidden unit signal individual , tasks modeling two sequence datasets experiments show three variants , reduced parameters , achieve comparable performance standard lstm due attention paid learning rate achieve high accuracies
segmentation detection networks word level text introduce algorithm word level text able accurately reliably determine bounding regions individual words text wild system formed cascade two convolutional neural networks first network fully convolutional detecting areas containing text results reliable possibly segmentation input image second network \( inspired popular architecture \) analyzes segment produced first stage , predicts oriented rectangular regions containing individual words post processing \( e g text line grouping \) necessary execution time image x gpu , system achieves highest score date among published algorithms 2015 scene text dataset benchmark
complexity manipulation elections top computational social choice literature , great interest understanding computational complexity act barrier manipulation elections much literature , however , makes assumption agents specify complete preference ordering set candidates many multiagent systems applications , even real world elections , assumption , turn raises question hard elections agents reveal partial preference \? question try address paper particular , look weighted manipulation problem constructive manipulation allowed specify top ordering set candidates provide general results scoring rules , elimination versions scoring rules , plurality rule , family election systems known alpha , protocol finally , also look impact complexity manipulation uncertainty non
automated synthesis enterprise integration patterns adapt based distributed systems future internet becoming reality , providing large scale computing environments virtually infinite number available services composed fit users' needs modern service oriented applications often built assembling distributed services key vision ability automatically compose dynamically coordinate software services service service engineering \( \) approach compose together coordinate services distributed way third party services composed , obtaining distributed coordination adaptation logic required suitably realize non trivial error prone task automatic support needed direction , paper leverages previous work automatic synthesis based systems , describes preliminary steps towards exploiting enterprise integration patterns deal form adaptation
information theoretic principles universal discrete denoising today , internet makes tremendous amounts data widely available often , information behind multiple different available data sets growing importance latent variable models try learn hidden information available imperfect versions example , social media platforms contain pictures person object , yet taken different perspectives simplified scenario , one may consider pictures taken perspective , distorted noise latter application allows rigorous mathematical treatment , content contribution apply recently developed method dependent component analysis image denoising multiple distorted copies one image available , corrupted different unknown noise process simplified scenario , assume distorted image corrupted noise acts independently pixel answer completely question perform optimal denoising , least three distorted copies available first define optimality algorithm presented scenario , describe optimal universal discrete denoising algorithm \( \) case binary data binary symmetric noise , develop simplified variant algorithm , dubbed , prove attain universal denoising uniformly
google matrix dynamical networks study properties google matrix generated coarse grained operator typical map finite size matrix operator constructed method method applied simple dynamical model generates directed networks approximate scale free scaling characteristics certain features similar world wide web approximate scale free degree distributions well two characteristics similar web power law decay pagerank decay pagerank world wide web sensitivity value alpha pagerank simple dynamical play role popular strong concentration pagerank variation google parameter alpha parameters dynamical map drive pagerank google matrix phase attractor google search becomes inefficient
london video task paper describes london team 's video challenge , first explore two sequence sequence models , namely recurrent \( gru \) model transformer model , generate action features investigate effect encoder attention mechanism instead conditioning gru decoder two different representations \( \) max action feature vector \( ii \) output multi label classifier trained predict visual entities action features baselines achieved scores comparable baseline conditioning entity predictions performed substantially better conditioning max feature vector , worse gru based sequence sequence baseline
joint material illumination estimation photo sets wild manipulation shape , material , illumination 2d internet images would greatly benefit reliable factorization appearance material \( e , diffuse \) illumination \( e , environment maps \) one hand , current methods produce high fidelity results , typically require controlled settings , expensive devices , significant manual effort hand , methods automatic work internet images , often extract low frequency lighting diffuse materials work , propose make use set order jointly estimate non diffuse materials sharp lighting setting key observation multiple instances material different illumination \( e , environment \) , different materials illumination provide valuable constraints exploited yield high quality solution \( e , materials environment illumination \) observed materials environments similar constraints also arise observing multiple materials single environment , single material across multiple environments core approach optimization procedure uses two neural networks trained synthetic images predict good gradients parametric space given observation light evaluate method range synthetic real examples generate high quality estimates , compare results state art alternatives via user study , demonstrate photo consistent image manipulation otherwise challenging achieve
application multiuser detection satellite systems study achievable rates single user satellite scenarios show alternatives conventional symbol symbol detection applied user terminals single user detection known suffer strong degradation terminal located near edge coverage area , aggressive frequency reuse adopted reason , consider multiuser detection , take account signal moreover , analyze different transmission strategy , signals two adjacent jointly serve two users time division multiplexing fashion describe information theoretic framework compare different transmission detection strategies computing information rate user reference beam
line art colorization using text tag changing loss line art colorization expensive challenging automate gan approach proposed , called , line art colorization takes input line art color tag information produces quality colored image first , present line art colorization dataset generator network proposed consists convolutional layers transform input line art , pre trained semantic extraction network , encoder input color information discriminator based auxiliary classifier gan classify tag information well addition , propose novel network structure called , makes generator properly even small features , also suggest novel two step training method generator discriminator first learn notion object shape , based learned notion , learn colorization , place color present quantitative qualitative evaluations prove effectiveness proposed method
like face predicting places profile pictures choose , people increasingly relying social networking sites popular site yelp , place comes descriptions reviews , profile pictures people frequent descriptions reviews widely explored research area data mining contrast , profile pictures received little attention previous work showed people able place 's , , activities observing place also observing profile pictures work determining visual cues people may relied upon make showing state art algorithm could make predictions accurately humans times demonstrating visual cues people relied upon differ algorithm
geometric laplacian embedding graph embedding seeks build low dimensional representation graph g low dimensional representation used various downstream tasks one popular approach laplacian , constructs graph embedding based spectral properties laplacian matrix g intuition behind , many embedding techniques , embedding graph must respect node similarity similar nodes must embeddings close one another , distance minimization assumption instead , use laplacian matrix find embedding geometric properties instead spectral ones , leveraging called geometry g introduce new approach , geometric laplacian embedding \( short \) , demonstrate outperforms various techniques \( including laplacian \) tasks graph reconstruction link prediction
wic 10 000 example pairs evaluating context sensitive representations design , word embeddings unable model dynamic nature semantics , e , property words correspond potentially different meanings depending context appear address limitation , specialized word embedding techniques proposed however , despite popularity research topic , evaluation benchmarks exist specifically focus dynamic semantics words paper show existing models performance standard de facto dataset , e , contextual word similarity address lack suitable benchmark , put forward large scale word context dataset , called wic , based annotations curated experts , generic evaluation context sensitive word embeddings wic released https url
solving dominating set larger classes graphs fpt algorithms polynomial kernels show k dominating set problem fixed parameter tractable \( fpt \) polynomial kernel class graphs exclude k , j subgraph , fixed , j 1 strictly includes every class graphs problem previously shown fpt algorithms polynomial kernels particular , result implies problem restricted bounded degenerate graphs polynomial kernel , solving open problem posed
deep weakly supervised anomaly detection anomaly detection typically unsupervised learning task literature due cost difficulty obtain large scale labeled anomaly data , fact small number \( e g , , \) labeled anomalies often made available small trivial cost many real world anomaly detection applications leverage labeled anomaly data , study important anomaly detection problem termed weakly supervised anomaly detection , , addition large amount unlabeled data , limited number labeled anomalies available modeling learning small labeled anomaly data enables anomaly modeling , helps identify anomalies interest address high false positives unsupervised anomaly detection however , problem especially challenging , since \( \) limited amount labeled anomaly data often , always , cannot cover types anomalies \( ii \) unlabeled data often normal instances anomaly address problem formulating pairwise relation prediction task particularly , approach defines two stream regression neural network learn relation randomly sampled instance pairs , e , whether instance pair contains two labeled anomalies , one labeled anomaly , unlabeled data instances resulting model effectively leverages labeled unlabeled data substantially augment training data learn well generalized representations normality comprehensive empirical results 40 real world datasets show approach \( \) significantly outperforms four state art methods detecting known previously unseen anomalies \( ii \) substantially data efficient
ipc benchmark data set learning graph structured data benchmark data sets ingredient evaluation graph based machine learning methods release new data set , compiled international planning \( ipc \) , graph classification , regression , related tasks graph construction \( based ai planning problems \) interesting right , data set different characteristics used benchmarks data set , named ipc , consists two self contained versions , lifted , including graphs large distributed sizes , substantial challenges computation graph models graph kernels graph neural networks graphs data set directed lifted version acyclic , offering opportunity specialized models directed \( acyclic \) structures moreover , graph generator labeling computer thus , data set may extended easily larger scale desired data set accessible url https url
bounds max weight policy applications state space collapse consider multi hop network operating max weight \( \) scheduling policy , show distance queue length process fluid solution remains bounded constant multiple deviation cumulative arrival process average exploit result prove matching upper lower bounds time scale additive state space collapse \( \) takes place implies , two special cases , additive result diffusion scaling non markovian , case , additive result exponential time scale
regression accurate camera camera plays role many robotics computer vision tasks , global localization , recovery tracking failure , loop detection recent random based methods directly predict 3d world locations 2d image locations guide camera pose optimization training , tree samples minimize spatial variance however , greedy often produce uneven sub trees training incorrect 2d 3d correspondences testing address problems , propose sample balanced objective encourage equal numbers samples left right sub trees , novel scheme remedy incorrect 2d 3d correspondence predictions furthermore , extend regression based methods use local features training testing stages outdoor rgb applications experimental results publicly available indoor outdoor datasets demonstrate efficacy approach , shows superior accuracy several state art methods
fundamental matrix estimation study error criteria fundamental matrix \( fm \) describes geometric relations exist two images scene different error criteria used estimating input set correspondences paper , accuracy efficiency aspects different error criteria studied mathematically experimentally proved popular error criterion , symmetric distance , also shown despite similarity algebraic expressions symmetric distance distance , different accuracy properties addition , new error criterion , distance , proposed proved effective use outlier removal phase accuracy efficiency perspectives test accuracy different error criteria , proposed randomized algorithm error based correspondence generation \( cg \) input , cg takes fm desired error value output , cg generates random correspondence error value mathematical analysis algorithm revealed success probability given trial 1 \( 2 3 \) 2 best 1 \( 6 7 \) 2 worst experiments demonstrated algorithm often one trial
atari natural language guided reinforcement learning introduce first deep reinforcement learning agent learns atari games aid natural language instructions agent uses multimodal embedding environment observations natural language self monitor progress list english instructions , reward completing instructions addition increasing game score agent significantly outperforms deep q networks \( dqns \) , asynchronous advantage actor critic \( \) agents , best agents posted often considered atari environment 's revenge
multiple access cellular v2x performance analysis highly vehicular networks vehicle \( v2x \) communication enables vehicles , vulnerable users , infrastructure facilities communicate ad hoc fashion cellular v2x \( c v2x \) , introduced generation project \( \) release 14 standard , recently received significant attention due perceived ability address scalability reliability requirements vehicular safety applications paper , provide comprehensive study resource allocation c v2x multiple access mechanism high density vehicular networks , strongly impact key performance indicators latency packet delivery rate phenomena affect communication performance investigated detailed analysis cases cause possible performance degradation system limitations , provided results indicate unified system configuration may necessary vehicles , , order obtain optimum performance end , show inter dependence different parameters resource allocation procedure aid high fidelity simulator
budget feasible mechanism design via random sampling budget feasible mechanism considers algorithmic mechanism design questions budget constraint total payment mechanism important question field domains exist budget feasible mechanisms admit approximations \( compared optimal solution \) cite showed additive submodular functions admit constant approximation mechanism recently , , , cite \( log \) approximation mechanism functions fundamental question whether , computational constraints , constant factor budget feasible mechanism exists function r n paper , give first attempt question give polynomial time \( frac log n log log n \) sub logarithmic approximation ratio mechanism functions , improving best known ratio \( log 2 n \) , connect budget feasible mechanism design concept approximate core cooperative game theory , show mechanism functions whose approximation , via characterization gap linear program , linear largest value approximate core exists result implies particular class functions , submodular functions , admits constant approximation mechanism believe work could solid step towards solving fundamental problem , possibly , answer
table contents generation documents generation precise detailed table contents \( \) document problem major importance document understanding information extraction despite importance , still challenging task , especially non standardized documents rich layout information commercial documents paper , present new neural based pipeline generation applicable document unlike previous methods , use semantic labeling assume presence document moreover , analyze influence using external knowledge encoded template empirically show approach useful low resource environment finally , propose new domain specific data set sheds light difficulties generation real world documents proposed method shows better performance state art public data set newly released data set
first steps relational lattice relational lattice reduces set six classic relational algebra operators two binary lattice operations natural join inner union give introduction theory emphasis formal algebraic laws new results include criteria applications query transformations
computing stable outcomes symmetric separable games study computational complexity finding stable outcomes games , class coalition games restrict attention symmetric separable games , nontrivial subclass games guaranteed possess stable outcomes games specified undirected edge weighted graph nodes players , outcome game partition nodes , utility node sum edge weights coalition consider several stability requirements defined literature based feasible player deviations , example , giving existing coalition members power extend restrictions considering general forms preference aggregation coalition members particular , consider voting schemes decide coalition members allow player coalition stability requirements consider , existence stable outcome guaranteed potential function argument , local improvements converge stable outcome provide almost complete characterization games terms tractability computing stable outcomes findings comprise positive results form polynomial time algorithms , negative \( completeness \) results negative results extend general games
performance analysis ell 1 synthesis coherent frames signals sparse frame representations comprise much realistic model nature bases studies signal recovery associated sparsity models one major focuses compressed sensing settings , one important widely used signal recovery approach known ell 1 synthesis \( basis pursuit \) present article effective performance analysis \( available \) approach dictionary dbf may highly , even perfectly correlated suitable conditions sensing matrix , error bound recovered signal hat fbf \( ell 1 synthesis method \) established error bound property tilde dbf text fbf , fbf true signal tilde dbf text optimal dual frame dbf sense tilde dbf text hat fbf 1 produces smallest tilde dbf tilde fbf 1 value among dual frames tilde dbf dbf feasible signals tilde fbf new performance analysis usual description dbf , places description examples demonstrated show usual analysis fails explain working performance synthesis approach , newly established results
matching thermal visible face images using semantic guided generative adversarial network designing face recognition systems capable matching face images obtained thermal spectrum obtained visible spectrum challenging problem work , propose use semantic guided generative adversarial network \( gan \) automatically synthesize visible face images thermal counterparts specifically , semantic labels , extracted face parsing network , used compute semantic loss function adversarial network training semantic cues denote high level facial component information associated pixel , identity extraction network generate multi scale features compute identity loss function achieve photo realistic results , perceptual loss function introduced network training ensure visible face perceptually similar target visible face image extensively evaluate benefits individual loss functions , combine effectively learn mapping thermal visible face images experiments involving two face datasets show proposed method achieves promising results face synthesis cross spectral face matching
3d soil mapping based exploration mobile robot paper presents automated method creating spatial maps soil condition outdoor mobile robot effective soil mapping enhance yields , reduce inputs help protect environment traditionally , data collected manually arbitrary set locations , soil maps constructed offline using , form gaussian process regression process costly , limiting quality resolution resulting information instead , propose use outdoor mobile robot automatic collection soil condition data , building soil maps online also adapting robot 's exploration strategy fly based current quality map show using variance reward function robotic exploration allows efficient data collection better soil models work presents theoretical proposal experimental comparison exploration strategies using soil data field generated mobile robot
global bandits continuity standard multi armed bandit \( \) problems assume arms independent however , many application scenarios , information obtained playing arm provides information arms hence , applications , exploited enable faster convergence optimal solution paper , introduce formalize global \( \) , arms globally informative global parameter , e , choosing arm reveals information arms propose greedy policy always selects arm highest estimated expected reward , prove achieves bounded parameter dependent regret hence , policy selects suboptimal arms many times , finite number initial time steps , optimal arm selected remaining time steps probability one addition , also study arms 's rewards affects speed learning specifically , prove parameter free \( worst case \) regret sublinear time , decreases arms also prove sublinear time bayesian risk bound reduces well known bayesian risk bound linearly parameterized bandits arms fully informative applications ranging treatment discovery dynamic pricing
co clustering maximum norm co clustering , , partitioning numerical matrix homogeneous , many applications ranging election analysis many interesting variants co clustering np hard focus basic variant co clustering defined terms minimizing maximum distance two entries context , several np hard well number relevant polynomial time solvable special cases , thus border challenging data clustering problem instance , provide polynomial time solvability partition rows two subsets \( meaning one obtains four \) partitioning rows three subsets , however , np hardness even input matrices containing values 0 , 1 , 2
coalition manipulations shapley algorithm well known shapley algorithm truthful agents previous studies front mostly focus manipulations single set women little known manipulations coalition women types manipulations , manipulation preference lists r n paper , consider problem finding equilibrium coalition women \( liars \) shapley algorithm restrict manipulations induce stable matchings incomplete preference list setting , liars preference lists , show strong nash equilibrium always exists matching equilibria unique equilibrium outcome strongly pareto dominant liars among set matchings achievable manipulation every matched man one matches best single agent manipulation complete preference list setting liars preference list , first show coalition women get worse manipulating jointly performing single agent manipulation , thus strongly pareto dominant outcome may exist manipulation put forward efficient algorithm compute strong nash equilibrium strongly pareto optimal liars derive connections stable problem stable problem , use tools prove results part approach highly nontrivial independent interest
integrating boundary assembling dnn framework named entity recognition chinese social media text named entity recognition challenging task natural language processing , especially noisy social media text chinese word boundaries also entity boundaries , therefore , named entity recognition chinese text benefit word boundary detection , chinese word segmentation yet chinese word segmentation poses difficulty influenced several factors , e g , segmentation criteria , employed algorithm , etc , may generate failure quality named entity recognition followed paper integrate boundary assembling method state art deep neural network model , incorporate updated word boundary information conditional random field model named entity recognition method shows 2 absolute improvement previous state art results
collision based optimal uniformity study fundamental problems \( \) uniformity testing discrete distribution , \( ii \) testing two discrete distributions bounded ell 2 norm problems extensively studied distribution testing sample optimal estimators known cite , , , 15 r n work , show original collision based proposed problems cite , sample optimal , constant factors previous analyses showed sample complexity upper bounds optimal function domain size n , suboptimal polynomial factors error parameter epsilon main contribution new tight analysis establishing collision based information theoretically optimal , constant factors , dependence n dependence epsilon
amplify forward relaying two hop diffusion based molecular communication networks paper studies three node network intermediate nano , relay , placed nano transmitter nano receiver improve range diffusion based molecular communication motivated relaying protocols used traditional wireless communication systems , study amplify forward \( af \) relaying fixed variable factor use molecular communication systems end , derive closed form expression expected end end error probability furthermore , derive closed form expression optimal factor relay node minimization approximation expected error probability network analytical simulation results show potential af relaying improve overall performance nano networks
malicious cooperation benign looking processes recent progress machine learning generated promising results behavioral malware detection behavioral modeling identifies malicious processes via features derived runtime behavior behavioral features hold great promise related malware , therefore considered difficult indeed , significant amount results exists evasion static malware features , evasion dynamic features seen limited work paper examines robustness behavioral malware detectors evasion , focusing particularly anti evasion choose behavior differ significantly benign processes , making low behavioral detection \( difficult candidate evasion \) analysis identifies set novel attacks overall malware workload across small set processes avoid generation significant behavioral features effective attack decreases accuracy state art classifier 98 6 0 using 18 processes furthermore , show attacks effective commercial detectors even black box setting
rnn fisher vectors action recognition image annotation recurrent neural networks \( rnns \) considerable success classifying predicting sequences demonstrate rnns effectively used order encode sequences provide effective representations methodology use based fisher vectors , rnns generative probabilistic models partial computed using backpropagation state art results obtained two central tasks , rely sequences video action recognition image annotation also show surprising transfer learning result task image annotation task video action recognition
new q ary quantum mds codes distances frac q 2 constructions quantum mds codes studied many authors refer table page 3 known constructions however q ary quantum mds n , n 2d 2 , q codes minimum distances frac q 2 sparse lengths n q 1 case n frac q 2 1 q 1 q 1 complete results case n frac q 2 1 q 2 1 factor q 1 q 1 , q ary quantum mds code frac q 2 constructed paper propose direct construct self orthogonal codes f q 2 thus give new q ary quantum codes case moreover present many new q ary quantum mds codes lengths form frac w \( q 2 1 \) u minimum distances frac q 2
onto nested introduce new style framework combines formalism nested illustrate potential framework , present novel modal logics mathsf mathsf , well extensions modal logics mathsf k mathsf shift latter extensions also known mathsf context logic enjoy syntactic cut elimination used proof search procedures optimal complexity mathsf mathsf yields simplified logic simplified system mathsf , might independent interest
learning hypotheses string study classification problems string data hypotheses specified formulas second order logic goal design learning algorithms run time polynomial size training set , independently least sublinear size whole data set prove negative well positive results data set string algorithms local access , learning sublinear time impossible even hypotheses small fragment first order logic allow linear time pre processing string data build index data structure , learning hypotheses possible time polynomial size training set , independently size whole data set
resource allocations secure cognitive satellite networks cognitive satellite networks \( \) recognized promising architecture addressing spectrum scarcity next generation communication networks letter , investigate secure transmission schemes cognitive interference base station \( bs \) introduced enhance security satellite link objectives minimize transmit power jointly optimizing cooperative beamforming artificial noise \( \) guaranteeing secrecy rate constraint satellite link , information rate constraint link total transmit power constraint scenarios perfect imperfect channel cases respectively considered constraints make optimization problems formulated non convex challenging , efficiently solved via certain transformations formulated tractable versions , respectively numerical results provided proposed schemes
package component based framework evolutionary algorithms based decomposition evolutionary algorithms based decomposition \( \) represent widely used class population based solution optimization problems introduce package , offers many variants component oriented framework approach contributes easier reproducibility existing variants literature , well faster development testing new composite algorithms package offers standardized , modular implementation based framework , designed aiming providing researchers practitioners standard way discuss express variants paper introduce design principles behind package , well current components three case studies provided illustrate main aspects package
caching service small cell caching mechanism design service providers wireless network virtualization well recognized way improve flexibility wireless networks functionality system implementing infrastructure spectrum services recent studies shown caching provides better performance serve content requests mobile users paper , propose emph caching applied service mobile networks , e , different service providers \( \) cache contents wireless facilities mobile network operators \( \) specifically , focus scenario emph small cell networks , cache enabled small cell base stations \( \) facilities cache contents deal competition among multiple , design mechanism based multi object auctions , time dependent feature system parameters frequency content replacement taken account simulation results show solution leads satisfactory outcome
navigating infinite space movements consider search problem 2 dimensional infinite grid single mobile agent goal agent find way home , located grid cell chosen adversary initially , agent provided infinite sequence instructions , movements performed agent instruction corresponds movement adjacent grid cell set instructions function initial locations agent home challenge problem stems movements made agent every step , constant probability 0 leq p leq 1 , agent performs random movement instead following current instruction r n paper provides two results problem first , show values p , exist set instructions guide agent home finite expected time second , complement result algorithm , sufficiently small values p , yields finite expected time home particular , show p 1 , approach gives rate polynomially function time sense , approach far superior standard random walk terms time main contribution take home message paper show , value 0 dots p 0 ldots , exists phase transition solvability problem
robot learning play mobile game unknown dynamics advance robotic hardware intelligent software , humanoid robot could play important role various fields including service human assistance heavy job industry unknown dynamics operating smart devices humanoid robot even challenging task robot needs learn actions complex state transitions inside smart devices long time horizon recent advances task learning enable humanoid robots conduct manipulation tasks grasping objects assembling parts paper , explore another step toward building human like robot introducing architecture enables humanoid robots learn operating smart devices requiring complex tasks implement learning architecture research robot experimentally demonstrate robot architecture could play challenging mobile game , game , accurate simulated environment
policy gradients contextual recommendations decision making challenging task online recommender systems decision often needs choose contextual item step set candidates contextual bandit algorithms successfully deployed applications , trade exploration exploitation state art performance minimizing online costs however , applicability existing contextual bandit methods limited simplified assumptions problem , assuming simple form reward function assuming static environment states affected previous actions work , put forward policy gradients contextual recommendations \( pgcr \) solve problem without assumptions restricted class policies marginal probability choosing item \( expectation items \) simple closed form , gradient expected return policy class form moreover , pgcr leverages two useful heuristic techniques called time dependent actor dropout former ensures pgcr empirically greedy limit , latter addresses trade exploration exploitation using policy network dropout bayesian approximation pgcr solve standard contextual bandits well markov decision process generalization therefore applied wide range realistic settings recommendations , personalized advertising evaluate pgcr toy datasets well real world dataset personalized music recommendations experiments show pgcr enables fast convergence low regret , outperforms classic contextual bandits policy gradient methods
prioritized metric structures embedding metric data structures \( distance , distance labeling schemes , routing schemes \) low distortion embeddings provide powerful algorithmic methodology , successfully applied approximation algorithms cite , online algorithms cite , distributed algorithms cite computing cite however , methodology appears limitation worst case performance inherently depends cardinality metric , one could specify advance vertices points enjoy better service \( e , stretch distortion , label size dimension \) given worst case guarantee r n paper alleviate limitation em prioritized metric data structures embeddings show given ranking \( x 1 , x 2 , ldots , x n \) graph vertices \( respectively , metric points \) one devise metric data structure \( respectively , embedding \) stretch \( resp , distortion \) pair containing vertex x j depend rank j vertex also show important parameters , label size \( sense \) dimension , may depend j metric data structures \( resp , embeddings \) achieve prioritized stretch \( resp , distortion \) label size \( resp , dimension \) em simultaneously worst case performance metric data structures embeddings typically asymptotically worse non prioritized counterparts
polynomial time data reduction dominating set dealing np complete dominating set problem undirected graphs , demonstrate power data reduction preprocessing theoretical well practical side particular , prove dominating set restricted planar graphs called problem kernel linear size , achieved two simple easy implement reduction rules moreover , implemented reduction rules , first experiments indicate impressive practical potential rules thus , work seems open new way cope one important problems graph theory combinatorial optimization
particle filter object pose tracking tracking poses objects videos provides rich information robot performing different tasks manipulation navigation work , formulate object pose tracking problem particle filtering framework , 3d rotation 3d translation object decoupled factorization allows approach , called , efficiently estimate 3d translation object along full distribution 3d rotation achieved rotation space fine grained manner , training auto encoder network construct codebook feature embeddings result , track objects arbitrary still maintaining adequate posterior distributions approach achieves state art results two pose estimation benchmarks video showing experiments found https url
empirical study propagation based methods video object segmentation propagation based approaches achieved state art performance video object segmentation , literature lacks fair comparison different methods using settings paper , carry empirical study propagation based methods view approaches unified perspective conduct detailed ablation study core methods , input cues , multi object combination training strategies careful designs , improved end end memory networks achieve global mean 1 2017 set
heuristic optimization energy systems refined metrics compare solutions abstract many optimization problems admit number local , among global optimum problems , various heuristic optimization methods proposed comparing results solvers requires definition suitable metrics energy systems literature , simple metrics best value obtained , mean value , median standard deviation solutions still used however , comparisons carried metrics rather weak , bases proliferation heuristic solvers taking place paper addresses overall issue understanding reasons proliferation , showing conceptual scheme indicates assessment best solver may result formulation new solvers moreover , paper shows use refined metrics defined compare optimization result , associated definition appropriate benchmarks , may make comparisons among solvers robust proposed metrics based concept first order stochastic defined cases \( \) globally optimal solution found \( testing purposes \) \( ii \) number possible solutions large practically cannot guaranteed global optimum found examples provided typical problem energy systems area distribution network conceptual results obtained generally valid compare results optimization problems
opportunistic scheduling cognitive radio based mimo rf networks work proposes optimal metric opportunistic scheduling secondary user transmitters \( su \) cognitive radio based multiple input multiple output radio frequency free space optical \( mimo rf \) decode forward system fixed proportional interference power constraints analyze performance proposed system , closed form expressions derived exact asymptotic outage probabilities considering orthogonal space time block coded transmission fading rf links , link relay destination modeled generalized ' \( mathcal \) channel errors finally , simulation results presented develop several interesting insights end end system performance selection probabilities su also shown proposed system outperforms ones existing current literature
resource allocation multi user downlink urllc ofdma systems paper , study resource allocation downlink orthogonal frequency division multiple access \( ofdma \) systems objective enable ultra reliable low latency communication \( urllc \) meet delay requirements urllc , impact short packet communication taken account resource allocation algorithm design particular , resource allocation design formulated weighted system sum throughput maximization problem quality service \( qos \) constraints urllc users formulated problem non convex , hence , finding global optimum solution high computational complexity thus , algorithm based successive convex optimization proposed find sub optimal solution polynomial time complexity simulation results confirm proposed algorithm facilities urllc significantly improves system sum throughput compared two benchmark schemes
performance evaluation advanced relaying protocols large wireless networks paper studies performance state art cooperative full duplex relaying protocols context large wireless network modelled using stochastic geometry tools investigate outage behaviour different cooperative schemes , namely , decode forward , noisy network coding mixed noisy network coding , considering fading , path loss interference sources relays due high complexity network topology protocols considered , closed form analysis possible , study performed extensive careful numerical simulations , sweeping large number relevant parameters several scenarios particular interest investigated way , conclusions drawn regarding network regimes relay assisted cooperation beneficial potential gains could achieved
simple approach optimal decomposition prior optimal decomposition near optimal column reconstruction methods established combining sampling adaptive sampling paper , propose new approach optimal decomposition near optimal column reconstruction using leverage score sampling approach , sampling adaptive sampling needed moreover , approach first \( \( \) \) optimal algorithm data matrix question also extend approach method , obtaining fast algorithm runs tilde \( n 2 \) \( \( \) \)
continuous adaptation interactive object segmentation learning corrections interactive object segmentation user computer vision model segment object recent works rely convolutional neural networks predict segmentation , taking image corrections made user input training large datasets offer strong performance , keep model parameters fixed test time instead , treat user corrections training examples update model fly data hand enables successfully adapt appearance particular test image , distributions shifts whole test set , even large domain changes , imaging modality changes training testing extensively evaluate method 8 diverse datasets improve fixed model method shows improvements training testing domains differ , produces segmentation masks desired quality 60 70 less user input furthermore achieve state art four standard interactive segmentation datasets pascal , ,
xpath logic xpathlog logic programming style xml data manipulation language define xpathlog style extension xpath xpathlog provides clear , declarative language querying manipulating xml whose perspectives especially xml data integration characterization , formal semantics defined edge labeled graph based model covers xml data model give complete , logic based characterization xml data main language concept xml , xpath xpath logic extends xpath language variable first order logic xpathlog horn fragment xpath logic , providing style , rule based language querying manipulating xml data model theoretic semantics xpath logic serves base xpathlog logic programming language , whereas also equivalent answer set semantics evaluating xpathlog queries given contrast approaches , xpath syntax semantics also used declarative specification database updated used rule heads , xpath filters interpreted specifications elements properties added database
spectral word2vec word2vec due textit et al \( 2013 \) word embedding method widely used natural language processing despite great success frequent use , theoretical justification still main contribution paper propose rigorous analysis highly nonlinear functional word2vec results suggest word2vec may primarily driven underlying spectral method insight may open obtaining provable guarantees word2vec support findings numerical simulations one open question whether nonlinear properties word2vec captured spectral method beneficial , , mechanism
power allocation game networks self learning approach paper investigates energy efficient power allocation two tier , network behaviors base station \( \) users \( \) modeled game guarantees qos requirement individually according cross tier interference , controlling local transmit power non due limit information exchange intra inter , self learning based strategy updating mechanism proposed user learn equilibrium strategies game framework , two different scenarios based continuous discrete power profiles studied , respectively self learning schemes two scenarios designed based local best response studying properties proposed game two situations , convergence property learning schemes provided simulation results provided support theoretical finding different situations proposed game , efficiency learning schemes validated
parallel sweeping heterogeneous 3d equations sweeping three dimensional equations without large introduced several challenging velocity models setup application costs sequential shown \( gamma 2 n 4 3 \) \( gamma n log n \) , gamma \( omega \) frequency dependent number grid points per perfectly matched layer several computational memory improvements introduced relative using black box sparse direct solvers auxiliary problems , competitive iteration counts reported high frequency problems distributed thousands cores two open source packages released along paper parallel sweeping \( \) underlying distributed solver , clique
sketch based randomized algorithms dynamic graph regression well known problem data science machine learning em linear regression , recently extended dynamic graphs existing exact algorithms updating solution dynamic graph regression problem require least linear time \( terms n size graph \) however , time complexity might intractable practice current paper , utilize em randomized transform propose first randomized algorithms given n times matrix embedding graph , n let r number samples required guaranteed approximation error , sublinear function n first algorithm reduces time complexity pre processing \( n \( 1 \) \( 1 \) log 2 \( r 1 \) rm 2 \) edge insertion edge deletion , updates approximate solution \( rm \) time second algorithm reduces time complexity pre processing left \( \( \) 3 epsilon 2 log 7 \( epsilon \) right \) , \( \) number elements edge insertion edge deletion node insertion node deletion , updates approximate solution \( \) time , q left \( frac 2 epsilon 2 log 6 \( epsilon \) right \) finally , show assumptions , n epsilon 1 first algorithm outperforms second algorithm n geq epsilon 1 second algorithm outperforms first algorithm
imbalanced deep learning minority class incremental rectification model learning class imbalanced training data long significant challenge machine learning particular , existing deep learning methods consider mostly either class balanced data imbalanced data model training , ignore challenge learning significantly imbalanced training data address problem , formulate class imbalanced deep learning model based batch wise incremental minority \( sparsely sampled \) class rectification hard sample mining majority \( frequently sampled \) classes model training model designed dominant effect majority classes discovering sparsely sampled boundaries minority classes iterative batch wise learning process end , introduce class rectification loss \( \) function deployed readily deep network architectures extensive experimental evaluations conducted three imbalanced person attribute benchmark datasets \( , x domain , \) one balanced object category benchmark dataset \( cifar 100 \) experimental results demonstrate performance advantages model scalability proposed batch wise incremental minority class rectification model existing state art models addressing problem imbalanced data learning
pseudo ensemble template accurate binary convolutional neural networks attractive strategy implementing lightweight deep convolutional neural networks \( cnns \) despite savings offered , memory , may induce accuracy loss prevents widespread use work aspect introducing , new template designed improve predictive performance binarized cnns via inspired ensemble learning theory , consists compact topology end end trainable organized minimize memory utilization experimental results collected three realistic benchmarks show gap left classical binary models , ensuring substantial memory savings w r state art binary ensemble methods
ng2c n gc big data applications big data applications suffer high times due collection \( gc \) case latency sensitive applications line card detection , graph based computing analysis social networks , etc compromise latency requirements whole application stack result aggressive caching data , ill suited gc design , assumes objects consider applications hold large amounts data memory r n avoid , propose ng2c , new gc algorithm combines n able allocate objects different generations , ng2c able group objects similar lifetime profiles generation objects similar lifetime profiles close , e generation , avoid object \( generations \) \( leads \) responsible duration gc times r n ng2c implemented 8 java virtual machine , extension first gc evaluate ng2c using , , three different first \( \) , concurrent \( \) , ng2c results show ng2c decreases worst observable gc time 94 8 , 0 96 45 , compared current \( \) addition , ng2c negative impact application throughput memory usage
harmonic adversarial attack method adversarial attacks find perturbations fool models images previous works generating noisy edge rich adversarial perturbations , cost degradation image quality perturbations , even small scale , usually easily human vision contrast , propose harmonic attack methods \( \) , generates edge free perturbations using harmonic functions property edge free guarantees generated adversarial images still preserve visual quality , even perturbations large experiments also show adversaries generated often higher rates success transferring models addition , find harmonic perturbations simulate natural phenomena like natural lighting would possible help find cases given models , first step improving
reservoir computing spatiotemporal signal classification without trained output weights reservoir computing recently introduced machine learning paradigm shown well suited processing spatiotemporal data rather training network node connections weights via backpropagation traditional recurrent neural networks , instead fixed connections weights among nodes , traditionally weights output layer neurons trained using linear regression claim signal classification tasks one may weight training step entirely instead use simple supervised clustering method based upon principal components norms reservoir states proposed method mathematically analyzed explored numerical experiments real world data examples demonstrate proposed may outperform traditional trained output weight approach terms classification accuracy sensitivity reservoir parameters
graphical cake consider classical cake problem wish fairly heterogeneous resource , often modeled cake , among interested agents work subject typically assumes cake represented interval paper , introduce generalized setting cake form set edges undirected graph allows us model division road networks unlike canonical setting , common fairness criteria cannot always satisfied setting agent must receive connected subgraph determine optimal approximation obtained number agents arbitrary , exhibit tight guarantees graph case two agents addition , one connected piece per agent allowed , establish best welfare guarantee total number connected pieces also study number variants extensions , including approximate considered , item \( also known division \)
action semantics network considering effects actions multiagent systems multiagent systems \( mass \) , agent makes individual decisions contribute globally system evolution learning mass difficult since agent 's selection actions must take place presence co learning agents moreover , environmental stochasticity uncertainties increase exponentially increase number agents previous works various multiagent coordination mechanisms deep learning architecture facilitate multiagent coordination however , none explicitly consider action semantics agents different actions different agents paper , propose novel network architecture , named action semantics network \( \) , explicitly represents action semantics agents characterizes different influence agents using neural networks based action semantics easily combined existing deep reinforcement learning \( drl \) algorithms boost performance experimental results ii neural show significantly improves performance state art drl approaches compared several network architectures
beyond amt analysis crowd work platforms 's mechanical \( amt \) launch paid crowd work industry eight years , many new offer range alternative models despite , little crowd work research explored platforms near focus amt 's particular limitations overly shape understanding crowd work research questions directions address , present cross platform content analysis seven crowd work platforms begin amt assumptions limitations influenced prior research next , formulate key criteria characterizing crowd work platforms analysis platforms amt , methodology use directions future research cross platform analysis represents study researchers researchers , intended diversity research crowd work accelerate progress
implementing bayesian networks embedded stochastic magnetic \( \) low barrier used implement random number generators \( \) recently shown connected conventional provides three terminal p bit letter show p bit used build p circuit bayesian network \( \) , correlations real world variables obtained measurements corresponding circuit nodes p circuit design two steps first translated behavioral model , called probabilistic spin logic \( \) , defined \( h \) \( j \) coefficients , translated electronic circuit elements benchmark example , mimic family tree three generations show genetic calculated compatible circuit simulator matches well known results
solid geometry processing domains many tasks geometry processing modeled variational problems solved numerically using finite element method solid shapes , requires volumetric discretization , boundary tetrahedral mesh unfortunately , tetrahedral remains open challenge existing methods either conform complex boundary surfaces require manual intervention prevent failure rather create single volumetric mesh entire shape , solid geometry processing domains , large complex shape composed overlapping solid smaller simpler part easier , question becomes account problem modeling solutions together explore previous coupling methods fail , propose method solid domains along boundary surfaces demonstrate superiority method empirical convergence tests qualitative applications solid geometry processing variety popular second order fourth order partial differential equations
sequence discriminative training deep learning based acoustic keyword abstract speech recognition sequence prediction problem besides employing various deep learning approaches frame level classification , sequence level discriminative training proved achieve state art performance large vocabulary continuous speech recognition \( \) however , keyword \( kws \) , one common speech recognition tasks , almost benefits frame level deep learning due difficulty getting competing sequence hypotheses studies sequence discriminative training kws limited fixed vocabulary based methods compared state art deep learning based kws approaches paper , sequence discriminative training framework proposed fixed vocabulary acoustic kws sequence discriminative training sequence level generative discriminative models systematically investigated introducing word independent phone lattices non keyword symbols construct competing hypotheses , feasible efficient sequence discriminative training approaches proposed acoustic kws experiments showed proposed approaches obtained consistent significant improvement fixed vocabulary kws tasks , compared previous frame level deep learning based acoustic kws methods
towards support principle solutions mechanical engineering engineering design process follows series standardized stages development , many aspects common software engineering among stages , principle solution regarded design specification , way final product works usually constructed abstract sketch \( hand drawn constructed cad system \) functional parts product identified , geometric topological constraints formulated , outline semantic approach principle solution annotated , thus making intended requirements explicit available machine processing includes automated detection design errors final cad model , making additional use background ontology engineering knowledge embed approach document oriented design workflow , background ontology semantic annotations documents exploited trace parts requirements design process across different applications
region based image retrieval region based image retrieval \( \) technique early attempts late , researchers found many ways specify region based queries spatial relationships however , way characterize regions , using color , poor time , revisit incorporating semantic specification objects intuitive specification spatial relationships contributions following first , support multiple aspects semantic object specification \( category , instance , attribute \) , propose cnn feature allows us use deep learning technique jointly handle multi aspect object specification second , help users specify spatial relationships among objects intuitive way , propose recommendation techniques spatial relationships particular , mining search results , system feasible spatial relationships among objects system also likely spatial relationships assigned object category names based language prior moreover , object level inverted supports fast generation , ranking based spatial constraints provides users experiences
lightweight hierarchical model hwsnet heterogeneous wireless sensor networks \( hwsnet \) suitable real life applications compared homogeneous counterpart security hwsnet becomes important issue rapid development hwsnet detection system one major efficient methods attacks hwsnet different constraints sensor networks , security solutions designed limited usage computation resources particularly attack sleep attack malicious node forces legitimate nodes energy sensor nodes going low power sleep mode target attack maximize power consumption affected node , thereby decreasing battery life existing works sleep attack mainly focused using mac based protocols , mac \( sensor mac \) , mac \( mac \) , b mac \( mac \) , g mac \( mac \) article , brief review recent detection systems wireless sensor network environment presented finally , framework cluster based layered detection proposed heterogeneous wireless sensor network \( hwsnet \) efficiently detect sleep attack simulation results matlab exhibit effectiveness proposed model
parity check collections iterative erasure decoding correct correctable erasure patterns given size recently interest construction small parity check sets iterative decoding hamming code property \( \) set size three support codeword hence reformulate generalize problem improve construction show parity check collection correctable erasure patterns size hamming code r provides , fact , codes r corresponding generic parity check collection property leads natural way necessary sufficient condition generic parity check collections use condition construct generic parity check collection codes r correcting correctable erasure patterns size , r , thus generalizing known construction 3 discuss optimality construction show improved r large enough finally , discuss directions research
computational higher type theory iii exact equality third series papers extending l 's meaning explanations dependent type theory cartesian cubical realizability framework accounts higher dimensional types extend framework include cumulative hierarchy types , exact equality structure , cumulative hierarchy parts ii , main result theorem closed terms boolean type evaluate either true false computational interpretation cartesian cubical higher type theory based cubical programs equipped deterministic operational semantics
monitoring clouds comparison excess monitoring approaches increasing private cloud providers enterprises , monitoring becoming crucial behind monitoring manifold reasons include saving energy , costs , better maintenance e science , moreover , collection infrastructure application specific data high resolutions paper , present two monitoring approaches implemented two projects excess project aims minimize caused execution applications cloud infrastructure order allow aware deployment scheduling applications , monitoring framework provides necessary set metrics different layers including physical , virtual application layer turn , excess project introduces new energy aware execution models improve energy efficiency software level depth knowledge energy consumption overall behavior applications given infrastructure , subsequent optimized energy achieve goal , excess monitoring framework provides apis allowing developers collect application specific data addition infrastructure data run time perform comparative analysis monitoring approaches , highlighting use cases including hybrid approach benefits monitoring solutions
anti fall non real time fall detector leveraging csi commodity wifi devices fall one major health threats obstacles independent , timely reliable fall detection crucial mitigating effects paper , leveraging fine grained channel state information \( csi \) multi antenna setting commodity wifi devices , design implement real time , non , low cost indoor fall detector , called anti fall first time , csi phase difference two antennas identified salient feature reliably segment fall fall like activities , phase information csi exploited accurately separate fall fall like activities experimental results two indoor scenarios demonstrate anti fall consistently outperforms state art approach , 10 higher detection rate 10 less false rate average
task driven visual saliency attention based visual question answering visual question answering \( vqa \) great progress since may , 2015 classic problem visual textual data system many vqa works explore deep image question encodings fusing methods , attention effective mechanism current attention based methods focus adequate fusion visual textual features , lack attention people focus ask questions image traditional attention based methods single value feature spatial location , losses many useful information remedy problems , propose general method perform saliency like pre selection region features bidirectional lstm \( \) , use novel element wise multiplication based attention method capture correlation information visual textual features conduct experiments large scale vqa dataset analyze effectiveness model demonstrated strong empirical results
private model compression via knowledge distillation demand intelligent mobile applications calls deploying powerful deep neural networks \( dnns \) mobile devices however , performance dnns notoriously relies increasingly complex models , turn associated increase computational expense far mobile capacity worse , app service providers need collect utilize large volume users' data , contain sensitive information , build sophisticated dnn models directly deploying models public mobile devices presents privacy risk benefit device deep learning without capacity privacy concerns , design private model compression framework following knowledge distillation paradigm , jointly use learning , distillation learning , self learning train compact fast neural network knowledge model adaptively bounded carefully enforce differential privacy propose elegant query sample selection method reduce number queries control privacy loss series empirical evaluations well implementation android mobile device show compress models efficiently also provide strong privacy guarantee example , , meaningful \( 9 , 10 6 \) differential privacy guaranteed , compact model trained obtain 20 times compression ratio times speed merely 0 97 accuracy loss
docred large scale document level relation extraction dataset multiple entities document generally exhibit complex inter sentence relations , cannot well existing relation extraction \( \) methods typically focus extracting intra sentence relations single entity pairs order accelerate research document level , introduce docred , new dataset constructed wikipedia three features \( 1 \) docred named entities relations , largest human annotated dataset document level plain text \( 2 \) docred requires reading multiple sentences document extract entities infer relations information document \( 3 \) along human annotated data , also offer large scale supervised data , enables docred adopted supervised weakly supervised scenarios order verify challenges document level , implement recent state art methods conduct thorough evaluation methods docred empirical results show docred challenging existing methods , indicates document level remains open problem requires efforts based detailed analysis experiments , discuss multiple promising directions future research
generative adversarial network face anonymization propose novel architecture able automatically faces images original data distribution ensure total anonymization faces image generating images privacy safe information model based conditional generative adversarial network , generating images considering original pose image background conditional information enables us generate highly realistic faces transition generated face existing background furthermore , introduce diverse dataset human faces , including poses , occluded faces , vast variability finally , present experimental results capability model images preserving data distribution , making data suitable training deep learning models far know , solution proposed guarantees anonymization faces generating realistic images
local space time smoothing version controlled documents unlike static documents , version controlled documents continuously one authors collaborative process makes traditional modeling visualization techniques paper propose new representation based local space time smoothing captures important patterns demonstrate applicability framework using experiments synthetic real world data
industrial big data analytics challenges methodologies applications generating highly r n distributed data various systems , devices applications , r n number challenges data management data analysis r n require new approaches support big data era r n challenges industrial big data analytics real time analysis r n decision making massive heterogeneous data sources r n manufacturing space survey presents new concepts , methodologies , r n applications scenarios industrial big data analytics , r n provide improvements velocity veracity r n problem solving focus five important methodologies r n industrial big data analytics 1 \) highly distributed industrial data r n access integrate highly distributed data sources r n various systems , devices applications 2 \) industrial r n big data cope sampling biases , r n store different data formats structures 3 \) large scale r n industrial data management massive heterogeneous r n data share large scale data 4 \) industrial data analytics track r n data provenance , data generation data preparation r n 5 \) industrial data ensures data trust , integrity r n security phase , introduce current research r n academia , discusses challenges potential r n solutions also examine typical applications industrial r n big data , including smart visibility , machine , energy r n management , proactive maintenance , time supply r n chain discussions aim understand value industrial r n big data lastly , survey discussion open r n problems future directions
fine grained reliability communications around urban intersections safe transportation key use case 5g lte 15 communications , end end reliability 0 expected vehicle vehicle \( \) transmission distance 100 200 since communications reliability related road safety , crucial verify performance , especially prone areas intersections derive closed form expressions transmission reliability near urban intersections finite interference regions analysis based plausible street configurations , traffic scenarios , empirically supported channel propagation show means performance metric serve preliminary design tool meet target reliability apply meta distribution concepts provide careful communications reliability existing work infinite , consider finite road segments practical deployment , fine grained reliability per realization exhibits behavior either performance certain vehicular traffic scenario reliable extremely , relatively average performance words , standard sinr based average performance metrics analytically accurate insufficient practical viewpoint investigating safety critical point process networks meta distribution level may reveal similar
almost near optimal stochastic matching queries stochastic matching problem deals finding maximum matching graph whose edges unknown via queries special case stochastic k set packing , problem find maximum packing sets , exists probability paper , provide edge set query algorithms two problems , respectively , provably achieve fraction optimal solution main theoretical result stochastic matching \( e , 2 set packing \) problem design adaptive algorithm queries constant number edges per vertex achieves \( 1 e \) fraction optimal solution , arbitrarily small e 0 moreover , adaptive algorithm performs queries constant number rounds complement result non adaptive \( e , one round queries \) algorithm achieves \( 0 5 e \) fraction optimum also extend results stochastic k set packing designing adaptive algorithm achieves \( 2 k e \) fraction optimal solution , \( 1 \) queries per element guarantee close best known polynomial time approximation ratio 3 k 1 e deterministic k set packing problem 2013 empirically explore application \( \) algorithms exchange problem , patients end stage failure show generated data real data first match runs exchange even small number non adaptive edge queries per vertex results large gains expected successful matches
coarse grained complexity dynamic algorithms date , way argue polynomial lower bounds dynamic algorithms via fine grained complexity arguments arguments rely strong assumptions specific problems strong exponential time hypothesis \( \) online matrix vector multiplication conjecture \( \) led many , dynamic algorithms still benefits lessons traditional approach together classes problems p np paper study coarse grained complexity theory dynamic algorithms among questions theory answer r n dynamic orthogonal vector \( ov \) easy cell probe model \? research program proving polynomial lower bounds dynamic ov cell probe model motivated fact many conditional lower bounds shown via reductions dynamic ov problem since cell probe model powerful word ram allowed smaller upper bounds , might turn dynamic ov easy cell probe model , making research direction theory implies case , interesting algorithmic consequences dynamic ov maintained worst case update time cell probe model , several important dynamic problems k edge connectivity , \( 1 epsilon \) approximate , \( 1 epsilon \) approximate matching , planar nearest neighbors , 's subset union 3 vs 4 diameter conclusion made replace dynamic ov , e g , subgraph connectivity , single source reachability , 's subset union , 3 vs 4 diameter r n lower bounds k edge connectivity via dynamic ov \? \( see full abstract file \)
approximation uplink inter cell interference small cell networks paper , first time , analytically prove uplink \( ul \) inter cell interference frequency division multiple access \( \) small cell networks \( \) well approximated distribution certain condition approximation allows tractable network performance analysis closed form expressions derived condition , approximation applies , pose particular requirements shapes sizes user equipment \( ue \) distribution areas previous works instead , results show path loss related random variable \( \) associated ue distribution area , low ratio absolute moment variance , approximation hold analytical simulation results show derived condition readily satisfied future dense ultra dense , indicating conclusions useful network performance analysis generation \( 5g \) systems general cell deployment beyond widely used poisson deployment
toolkit modeling simulation resource management techniques internet things edge fog computing environments internet things \( iot \) aims bring every object \( e g smart cameras , wearable , environmental sensors , home , vehicles \) online , hence generating massive amounts data storage systems data analytics applications cloud computing offers services infrastructure level scale iot storage processing requirements however , applications health monitoring response require low latency , delay caused transferring data cloud back application impact performances overcome limitation , fog computing paradigm proposed , cloud services extended edge network decrease latency network congestion realize full potential fog iot paradigms real time analytics , several challenges need addressed first critical problem designing resource management techniques determine modules analytics applications edge device minimize latency maximize throughput end , need evaluation platform enables quantification performance resource management policies iot fog computing infrastructure manner paper propose simulator , called , model iot fog environments measure impact resource management techniques terms latency , network congestion , energy consumption , cost describe two case studies demonstrate modeling iot environment comparison resource management policies moreover , scalability simulation toolkit terms ram consumption execution time verified different
network issues virtual machine migration software defined networking \( sdn \) based three features control plane , programmability network functions traffic engineering network function migration poses interesting problems try solve paper content distribution network virtualization presented use case
polynomial planar graph polynomial graph g two variable polynomial \( g x , \) many interesting properties graph study complexity following problem , x given input planar graph g , determine \( g x , \) completely mapped complexity exactly computing polynomial planar graph showed problem solved polynomial time \( x , \) h q given \( x 1 \) \( 1 \) q q 1 q 2 \( x , \) one two special points \( x , \) \( 1 , 1 \) \( x , \) \( 1 , 1 \) otherwise , problem p hard paper , consider problem approximating \( g x , \) , usual sense fully polynomial randomized approximation scheme fpras roughly speaking , fpras required produce , polynomial time high probability , answer small relative error assuming np different , show fpras polynomial large portion \( x , \) plane particular , fpras x 1 , 1 , x 5 also , fpras x 5 , result shows fpras \( x , \) \( 1 q \( 1 e \) , e \) positive e open limit point e 0 , corresponds approximately counting q planar graph
security aware access model data driven system digital healthcare systems popular , provide variety helpful means monitor people 's health state well protect people health situation systems contain huge amount personal information form electronic health records allowed users hence , health data information need protected attacks paper , propose secure distributed architecture healthcare data storage analysis uses novel security model control accessing sensitive data system , well protect transmitted data distributed system servers nodes model also satisfies nist security requirements thorough experimental results show model promising
deep reinforcement learning robotic manipulation model free deep reinforcement learning shown exhibit good performance domains ranging video games simulated robotic manipulation locomotion however , model free methods known perform poorly interaction time environment limited , case real world robotic tasks paper , study maximum entropy policies trained using soft q learning applied real world robotic manipulation application method real world manipulation two important features soft q learning first , soft q learning learn multimodal exploration strategies learning policies represented expressive energy based models second , show policies learned soft q learning composed create new policies , optimality resulting policy bounded terms divergence composed policies compositionality provides especially valuable tool real world manipulation , constructing new policies existing skills provide large gain efficiency training scratch experimental evaluation demonstrates soft q learning substantially sample efficient prior model free deep reinforcement learning methods , compositionality performed simulated real world tasks
learning text retrieval recognition historical handwritten document collections chapter provides overview problems need constructing learning retrieval , recognition engine large historical document collections multiple languages , system application highly variable time , since continuous labeling end users changes concept although current advances deep learning provide huge potential application domain , scale problem , e , diverse , documents current human effort required designing developing successful deep learning systems ball principle introduced , describes evolution sparsely labeled stage addressed traditional methods nearest neighbor methods embedded vectors pre trained neural networks , end spectrum massive labeling allows reliable training deep learning methods contents introduction , expectation management , deep learning , ball principle , technical realization , work flow , quality quantity material , scalability , human effort , algorithms , object recognition , processing pipeline , performance , compositionality , conclusion
deepdpm dynamic population mapping via deep neural network dynamic high resolution data human population distribution great importance wide spectrum activities real life applications , difficult expensive obtain directly therefore , generating fine scaled population distributions coarse population data great significance however , three major challenges 1 \) complexity spatial relations high low resolution population 2 \) dependence population distributions external information 3 \) difficulty temporal distribution patterns paper , first propose idea generate dynamic population distributions full time series , design dynamic population mapping via deep neural network \( deepdpm \) , model describes spatial temporal patterns using coarse data point interest information deepdpm , utilize super resolution convolutional neural network \( \) based model directly map coarse data higher resolution data , time embedded long short term memory model effectively capture nature smooth finer scaled results previous static model perform extensive experiments real life mobile dataset collected results demonstrate deepdpm outperforms previous state art methods suite frequent data mining approaches moreover , deepdpm breaks limitation previous works time dimension dynamic predictions day time slots obtained
large scale detection non technical losses imbalanced data sets non technical losses \( \) cause significant , may range 40 total distributed detecting requires costly site accurate prediction customers using machine learning therefore crucial date , related research largely ignore two classes regular non regular customers highly imbalanced , may change mostly consider small data sets , often allowing deploy results production paper , present comprehensive approach assess three detection models different large real world data sets customers boolean rules , fuzzy logic support vector machine work resulted results deployed leading industry solution believe considerations observations made contribution necessary future smart research order report effectiveness imbalanced large real world data sets
learning see across domains modalities deep learning expectations general solution many applications indeed proven effective , also showed strong dependence large quantities data , shown , even data scarce , successful model trained prior knowledge thus , developing techniques transfer learning , definition , crucial element towards deployment effective accurate intelligent systems thesis focus family transfer learning methods applied task visual object recognition , specifically image classification transfer learning general term , specific settings given specific names learner access unlabeled data target domain labeled data different domain \( source \) , problem known unsupervised domain adaptation \( \) first part work focus three methods setting one methods deals features , one images third one uses second part focus real life issues robotic perception , specifically rgb recognition robotic platforms usually limited color perception often also carry depth camera unfortunately , depth modality rarely used visual recognition due lack pretrained models transfer little data train one scratch two methods dealing scenario presented one using synthetic data exploiting cross modality transfer learning
collaborative large scale dense 3d reconstruction online inter agent pose optimisation dense , volumetric models real world 3d scenes important many tasks , capturing large scenes take significant time , risk changes scene goes capture time increases good reasons want instead capture several smaller sub scenes make whole scene achieving traditionally difficult sub scenes may never viewed angle requires high quality camera cope novel poses , tracking drift sub scene prevent make consistent overall scene recent advances , however , significantly improved ability capture medium sized sub scenes little tracking drift real time globally consistent reconstruction systems close loops integrate scene surface fly , whilst new visual inertial odometry approaches significantly reduce tracking drift live reconstruction moreover , high quality regression forest based recently made practical introduction method allow trained used online paper , leverage advances present knowledge first system allow multiple users reconstruct dense , based models whole using consumer hardware , task traditionally time consuming dependent availability hardware using system , entire reconstructed half far lower cost previously possible
training neural audio classifiers data investigate supervised learning strategies improve training neural network audio classifiers small annotated collections particular , study whether \( \) naive regularization solution space , \( ii \) networks , \( iii \) transfer learning , \( iv \) combination , deep learning models better leverage small amount training examples end , evaluate \( iv \) tasks acoustic event recognition acoustic scene classification , considering 1 100 labeled examples per class results indicate transfer learning powerful strategy scenarios , networks show promising results one count external validation data
compact formulae sparse elimination become standard approach use theory sparse \( \) elimination , based polytope polynomial , order reveal exploit structure algebraic systems surveys compact formulae , including recent results , sparse elimination start root bounds two recent formulae generating function bound closed form expression mixed volume means matrix sparse resultant , results established rational formulae large class systems , starting closely related resultant admits compact formula except simple cases offer new formula sparse system arising computing nash equilibria introduce alternative notion compact formula , namely polytope unknown polynomial possible compute efficiently sparse , , well implicit equation parameterized variety leads us consider implicit matrix representations geometric objects
black box takes away work black box f \( cdot \) image mathbf x rightarrow f \( mathbf x \) recover image mathbf x black box might number simple complicated things linear non linear filter , app phone , etc latter good canonical example problem address given app image produced app , find image fed app run given image \( image \) app many times like , look inside \( code \) app see works first , problem lot like standard inverse problem , following sense access black box f \( cdot \) run image observe output , know block box image therefore explicit form model f \( cdot \) necessarily interested internal black box simply reverse effect particular image , extent possible call \( rather restoration \) problem , fit inverse problem \( blind otherwise \) describe general conditions possible , provide remarkably simple algorithm works black box operators principal novel take away message work surprising fact one simple algorithm reliably wide class \( \) image distortions r n higher quality paper available http url
tensor based nonlinear classifier high order data analysis paper propose tensor based nonlinear model high order data classification advantages proposed scheme \( \) significantly reduces number weight parameters , hence required training samples , \( ii \) spatial structure input samples proposed model , called rank 1 , based modification neural network \( \) , weights satisfy rank 1 canonical decomposition also introduce new learning algorithm train model , evaluate rank 1 third order hyperspectral data experimental results comparisons indicate proposed model outperforms state art classification methods , including deep learning based ones , especially cases small numbers available training samples
high performance sparse communication machine learning one main drivers behind rapid recent advances machine learning availability efficient system support comes hardware acceleration , also form efficient software frameworks programming models despite significant progress , scaling compute intensive machine learning workloads large number compute nodes still challenging task , significant latency bandwidth demands paper , address challenge , proposing , general , scalable communication layer machine learning applications built observation many distributed machine learning algorithms either naturally sparse communication , updates structured way improved performance , without convergence accuracy loss exploit insight , design implement set communication efficient protocols sparse input data , conjunction efficient machine learning algorithms leverage primitives communication protocols generalize standard collective operations , allowing processes contribute sparse input data vectors , heterogeneous sizes call operations sparse input , present efficient practical algorithms strong theoretical bounds running time communication cost generic communication layer additional features , support non \( asynchronous \) operations , support low precision data representations validate algorithmic results experimentally range large scale machine learning applications target architectures , showing leverage sparsity order magnitude runtime savings , compared state art methods frameworks
home energy management systems future smart grids present detailed review various home energy management schemes \( , \) , increase savings , reduce peak demand average ratio \( \) among various applications smart grid technologies , home energy management important one addressed various steps taken utilities efficient energy consumption new pricing schemes like time use \( \) , real time pricing \( \) , critical peak pricing \( \) , block rates \( \) etc devised future smart grids home distributed energy resources coordination \( local generation \) along different pricing schemes leads towards efficient energy consumption paper addresses various communication optimization based energy management schemes different communication networking technologies involved schemes index terms smart grid , home energy management , optimization
takes nine neural multi task learning check prediction propose multi task deep learning approach estimating check claims political given political , 2016 us ones , task predict prioritized fact checking different fact checking organizations would naturally make different choices analyzing , show learn multiple sources simultaneously \( , , , cnn , , , , , post \) multi task learning setup , even particular source chosen target evaluation shows state art results standard dataset task check prediction
known class aware self ensemble open set domain adaptation existing domain adaptation methods generally assume different domains identical label space , quite restrict real world applications paper , focus realistic challenging case open set domain adaptation particularly , open set domain adaptation , allow classes source target domains partially case , assumption conventional distribution alignment hold , due different label spaces two domains tackle challenge , propose new approach known class aware self ensemble \( \) , built upon recently developed self ensemble model , first introduce known class aware recognition \( \) module identify known unknown classes target domain , achieved encouraging low cross entropy known classes high entropy based source data unknown class , develop known class aware adaptation \( \) module better adapt source domain target adaptation loss based belong known classes unlabeled target samples predicted extensive experiments multiple benchmark datasets demonstrate effectiveness approach
zipper stack without return oriented programming \( \) typical attack technique exploit return addresses existing codes return instructions current return address mechanisms \( also known backward edge control flow integrity \) work limited threat models example , attacker cannot control whole memory , attacker knowledge secret key random values r n paper presents novel , lightweight mechanism return addresses , zipper stack , return addresses chain structure innovative design powerful full control program 's memory even know secret key hash function threat model stronger relevant works time , produces low performance overhead implemented zipper stack extending v instruction set architecture evaluation shows performance overhead zipper stack 1 86 \( vs stack platform costs 2 \) additionally , lightweight nature zipper stack makes deployment minimal modifications system need two hash module , need make changes memory allocation page attributes thus , zipper stack suitable actual deployment
multi kernel prediction networks denoising images low light short exposure image often corrupted noise longer exposure helps reduce noise , produce results due object camera motion reconstruction noise less image ill posed problem recent approaches image denoising aim predict kernels set taken images \( \) obtain clear image propose deep neural network based approach called multi kernel prediction networks \( \) image denoising predicts kernels one size varying sizes performs fusion different kernels resulting one kernel per pixel advantages method two fold \( \) different sized kernels help extracting different information image results better reconstruction \( b \) kernel fusion extracted information maintaining computational efficiency experimental results reveal outperforms state art synthetic datasets different noise levels
list decoding codes via interpolation euclidean algorithm show codes list decoded using approach consider certain module ring polynomials find minimal basis module using euclidean algorithm respect composition polynomials given received word , decoding algorithm computes list codewords closest received word respect rank metric
multiple one 1 2 efx gmms via envy cycle elimination several relaxations envy freeness , tailored fair division settings goods , introduced within last decade due lack general existence results concepts , great attention paid establishing approximation guarantees work , propose simple algorithm fair sense returns allocations good approximation guarantees respect four fairness notions particular , first algorithm achieving \( phi 1 \) approximation envy freeness good \( efx \) frac 2 phi 2 approximation share fairness \( gmms \) , phi ratio \( phi approx 1 \) best known approximation factor either one fairness notions prior work 1 2 moreover , allocation achieves envy freeness one good \( \) 2 3 approximation pairwise share fairness \( \) efx primary focus , also exhibit fine tune algorithm improve guarantees gmms r n finally , show gmms thus efx allocations always exist number goods exceed number agents two
optimal algorithm range search multidimensional points paper proposes efficient novel method address range search multidimensional points theta \( \) time , number points reported k space accomplished introducing new data structure , called bits k tree structure also supports fast takes theta \( 1 \) time insertion \( log n \) time deletion earlier best known algorithm problem \( log k n \) time machine model
learning framework high precision industrial assembly automatic assembly broad applications traditional assembly tasks utilize predefined trajectories tuned force control parameters , make automatic assembly time consuming , difficult generalize , robust uncertainties paper , propose learning framework high precision industrial assembly framework combines supervised learning reinforcement learning supervised learning utilizes trajectory optimization provide initial guidance policy , reinforcement learning utilizes actor critic algorithm establish evaluation system even accurate proposed learning framework efficient compared reinforcement learning achieves better stability performance supervised learning effectiveness method verified simulation experiment
unsupervised visual meta reinforcement learning principle , meta reinforcement learning algorithms leverage experience across many tasks learn fast reinforcement learning \( rl \) strategies transfer similar tasks however , current meta rl approaches rely manually defined distributions training tasks , hand task distributions challenging time consuming useful pre training tasks discovered unsupervised manner \? develop unsupervised algorithm adaptive meta training task distribution , e automatic curriculum , modeling unsupervised interaction visual environment task distribution parametric density model meta learner 's trajectory distribution formulate unsupervised meta rl information maximization latent task variable meta learner 's data distribution , describe practical integration recent experience task distribution meta learning updated tasks procedure leads iterative curriculum meta learner 's data distribution shifts particular , show discriminative clustering visual representation support trajectory level task acquisition exploration domains pixel observations , avoiding alternatives experiments vision based navigation manipulation domains , show algorithm allows unsupervised meta learning transfers downstream tasks specified hand crafted reward functions serves pre training efficient supervised meta learning test task distributions
towards understanding sparse filtering via information bottleneck paper examine formalization feature distribution learning \( fdl \) information theoretic terms relying analytical approach tools already used study information bottleneck \( \) behavior fdl algorithms could expressed optimization problem two information theoretic quantities mutual information data learned representations entropy learned distribution particular , formulation offered order explain success prominent fdl algorithm , sparse filtering \( sf \) conjecture , however , left work , aim providing preliminary empirical support conjecture performing experiments work done deep neural networks context research specifically , idea using information analyze behavior sf algorithm gain insights dynamics conjecture dynamics fdl may provide solid ground develop information theoretic tools assess quality learning process fdl , may extended unsupervised learning algorithms
convex density constraints computing plausible counterfactual explanations increasing deployment machine learning well legal 's cause need user friendly explanations decisions proposed machine learning models counterfactual explanations considered one popular techniques explain specific decision model computation arbitrary counterfactual explanations well studied , still open research problem efficiently compute plausible feasible counterfactual explanations build upon recent work propose study formal definition plausible counterfactual explanations particular , investigate use density estimators feasibility counterfactual explanations purpose efficient computations , propose convex density constraints ensure resulting counterfactual located region data space high density
generation concept representative symbols visual representation concepts ideas use simple shapes always explored history , origin writing focus computational generation visual symbols represent concepts aim develop system uses background knowledge world find connections among concepts , goal generating symbols given concept also interested exploring system approach visual visual conceptual great potential area graphic design tool aid projects , design
smoothness enough toward exact quantification optimization price anarchy today 's multiagent systems grown complex rely centralized controllers , increasing interest design distributed algorithms respect , game theory emerged valuable tool complement traditional techniques fundamental idea behind approach assignment agents' local cost functions , selfish minimization , provably close , global objective algorithm capable computing equilibrium corresponding game approximation ratio , worst case , equal price anarchy considered class equilibria therefore , successful application game design approach possibility quantify optimize equilibrium performance r n toward end , introduce notion generalized smoothness , show resulting efficiency bounds significantly tighter compared obtained using traditional smoothness approach leveraging newly introduced notion , quantify equilibrium performance class local resource allocation games finally , show agents' local decision rules designed order optimize efficiency corresponding equilibria , means tractable linear program
cloud resource optimization processing multiple streams visual data hundreds millions network cameras world capable providing vast amount real time data analyzing massive data generated cameras requires significant computational resources demands may vary time cloud computing shows promise provide needed resources demand paper , investigate allocate cloud resources analyzing real time data streams network cameras resource manager considers many factors affect decisions , including types analysis , number data streams , locations cameras manager selects cost efficient types cloud instances \( e g , central processing unit versus general purpose graphics processing units \) meet computational demands analyzing streams evaluate effectiveness approach using web services experiments demonstrate 50 cost reduction real workloads
gender productivity computer science faculty hiring networks women dramatically computer science levels academia account 15 track faculty understanding causes gender would inform policies intended decisions departments individuals progress direction , however , complicated complexity decentralized nature faculty hiring non independence using comprehensive data hiring outcomes scholarly productivity track faculty across departments , investigate multi dimensional nature gender inequality computer science faculty hiring network model hiring process overall , find hiring outcomes directly affected \( \) relative hiring institutions \( ii \) scholarly productivity candidates including , features , addition gender significantly reduce modeling error however , gender differences exist , e g , scholarly productivity , training rates , movements rankings , suggesting effects gender incorporated hiring decisions gender 's furthermore , find evidence highly ranked departments faculty higher expected rates , appears similar efforts lower ranked departments findings illustrate nature gender inequality faculty hiring networks provide new insights women computer science
modeling propagating cnns tree structure visual tracking present online visual tracking algorithm managing multiple target appearance models tree structure proposed algorithm employs convolutional neural networks \( cnns \) represent target , multiple cnns estimate target states determine desirable paths online model updates tree maintaining multiple cnns diverse tree structure , convenient deal multi modality target preserve model reliability smooth updates along tree paths since multiple cnns share parameters convolutional layers , takes advantage multiple models little extra cost saving memory space avoiding redundant network evaluations final target state estimated sampling target candidates around state previous frame identifying best sample terms weighted average score set active cnns algorithm performance compared state art techniques challenging datasets online tracking benchmark visual object tracking challenge
genattack practical black box attacks gradient free optimization deep neural networks vulnerable adversarial examples , even black box setting , attacker restricted solely query access existing black box approaches generating adversarial examples typically require significant number queries , either training network performing gradient estimation introduce genattack , gradient free optimization technique uses genetic algorithms adversarial examples black box setting experiments different datasets \( mnist , cifar 10 , imagenet \) show genattack successfully generate visually imperceptible adversarial examples state art image recognition models orders magnitude fewer queries previous approaches mnist cifar 10 models , genattack required roughly 2 , 2 , times fewer queries respectively , , prior state art black box attack order scale attack large scale high dimensional imagenet models , perform series optimizations improve query efficiency attack leading times fewer queries model furthermore , show genattack successfully attack state art imagenet defenses , including ensemble adversarial training non differentiable randomized input transformations results suggest evolutionary algorithms open promising area research effective black box attacks
causal logic programs appear theory practice logic programming \( \) paper propose extension logic programming \( lp \) default derived well model associated justification represented algebraic expression expression contains causal explanations \( form proof graphs built rule labels \) terms scope negation conditions enable application causal rules using examples , discuss new conditions , respectively call , related default negation essentially different nature regular cause effect relations important result formal comparison recent algebraic approaches lp provenance \( \) causal graphs \( cg \) show current approach extends cg well semantics , , also establish formal relation two approaches
likelihood ratios generative classifiers unsupervised domain detection task oriented dialog task identifying domain \( ood \) input examples directly test time seen interest recently due increased real world deployment models work , focus ood detection natural language sentence inputs task based dialog systems findings three fold first , release \( real domain sentences task oriented dialog \) dataset ood examples publicly available dataset \( et al 2019 \) contrast existing settings synthesize ood examples subset classes , examples annotators instructions domain respect sentences existing dataset second , explore likelihood ratio based approaches alternative currently paradigms specifically , reformulate apply approaches natural language inputs find match outperform latter datasets , larger improvements non artificial ood benchmarks dataset validate specifically using likelihood ratios rather plain likelihood necessary well ood domain data third , propose learning generative classifier computing marginal likelihood \( ratio \) ood detection allows us use principled likelihood time exploiting training time labels find approach outperforms simple likelihood \( ratio \) based prior approaches first investigate use generative classifiers ood detection test time
4 author attribute anonymity adversarial training neural machine translation text based analysis methods allow reveal privacy relevant author attributes gender , age identify text 's author methods compromise privacy anonymous author even author tries remove privacy sensitive content paper , propose automatic method , called adversarial author attribute anonymity neural translation \( \) , combat text based adversaries combine sequence sequence language models used machine translation generative adversarial networks author attributes unlike machine translation techniques need paired data , method trained unpaired corpora text containing different authors importantly , propose evaluate techniques impose constraints preserve semantics input text learns make minimal changes input text successfully fool author attribute classifiers , aiming maintain meaning input show experiments two different datasets three settings proposed method effective author attribute classifiers thereby improving anonymity authors
learning discriminative null space person identification existing person identification \( \) methods focus learning optimal distance metrics across camera views typically person 's appearance represented using features thousands dimensions , whilst hundreds training samples available due difficulties collecting matched training images number training samples much smaller feature dimension , existing methods thus face classic small sample size \( \) problem dimensionality reduction techniques matrix , lead loss discriminative power work , propose overcome problem distance metric learning matching people discriminative null space training data null space , images person single point thus within class extreme relative class separation simultaneously importantly , fixed dimension , closed form solution efficient compute extensive experiments carried five person identification benchmarks including , , , show simple approach state art alternatives , often big margin
computing persistent various coefficient fields single pass article introduces algorithm compute persistent complex various coefficient fields single matrix reduction algorithm output sensitive total number distinct persistent features diagrams different coefficient fields computation allows us infer prime coefficients integral groups topological space scale , hence informative description topology single coefficient field provide theoretical complexity analysis well detailed experimental results code part library , available 8
usage attribution stack code snippets github projects stack \( \) largest q website software developers , providing huge amount code snippets using snippets raises maintenance legal issues 's license \( cc sa 3 0 \) requires attribution , e , original question answer , requires derived work adopt compatible license 's license model code snippets required attribution , little known extent snippets without proper attribution present results large scale empirical study analyzing usage attribution non trivial java code snippets answers public github \( \) projects followed three different approaches estimate ratio conducted two online surveys software developers complement results different sets projects analyzed , ratio projects containing files reference 3 3 11 9 found 1 8 analyzed repositories containing code used code way compatible cc sa 3 0 moreover , estimate code snippets attributed required developers , almost one half code without attribution two aware license code snippets implications