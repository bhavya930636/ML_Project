{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672a6b12-48cf-4a65-8c54-2f83d19876d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 16:45:30.060812: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-19 16:45:30.074896: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-19 16:45:30.091742: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-19 16:45:30.095217: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-19 16:45:30.108656: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-19 16:45:30.780766: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics\n",
    "from utils import *\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce16c8e6-b58a-4ae9-b95f-afef565507ce",
   "metadata": {},
   "source": [
    "## # The load_corpus function loads the dataset, including the adjacency matrix (adj), node features (features), labels for training, validation, and testing, and their respective masks. These masks are boolean arrays indicating which nodes belong to which subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9c2859-910c-4c8f-83ee-ab02e43ad642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(944, 300) (944, 38) (228, 300) (228, 38) (5780, 300) (5780, 38)\n",
      "6008\n",
      "Adj:\n",
      " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 1667912 stored elements and shape (6008, 6008)>\n",
      "  Coords\tValues\n",
      "  (0, 1090)\t2.7447662166404823\n",
      "  (0, 1145)\t2.640625957387885\n",
      "  (0, 1158)\t14.862782659705548\n",
      "  (0, 1256)\t4.207046484738295\n",
      "  (0, 1271)\t2.87481934488868\n",
      "  (0, 1308)\t2.6081906816347313\n",
      "  (0, 1403)\t3.9734316335567894\n",
      "  (0, 1487)\t4.848900370910689\n",
      "  (0, 1488)\t1.8236092951151541\n",
      "  (0, 1535)\t3.784189633918261\n",
      "  (0, 1563)\t3.367295829986474\n",
      "  (0, 1623)\t3.033391721470971\n",
      "  (0, 1684)\t3.2196598311804094\n",
      "  (0, 1691)\t3.984860329380412\n",
      "  (0, 1695)\t4.261113706008571\n",
      "  (0, 1769)\t3.0571409016826343\n",
      "  (0, 1824)\t4.7535901911063645\n",
      "  (0, 1884)\t3.9326096390365346\n",
      "  (0, 1931)\t2.472893019285368\n",
      "  (0, 1943)\t4.060443010546419\n",
      "  (0, 2127)\t2.227229087965195\n",
      "  (0, 2195)\t1.8333654700605189\n",
      "  (0, 2220)\t4.060443010546419\n",
      "  (0, 2245)\t3.893388925883253\n",
      "  (0, 2298)\t2.536364947063476\n",
      "  :\t:\n",
      "  (6007, 4514)\t3.625124939288574\n",
      "  (6007, 4622)\t6.478924916953178\n",
      "  (6007, 4684)\t6.21686839214037\n",
      "  (6007, 4745)\t4.229065722982212\n",
      "  (6007, 4797)\t5.072043922224899\n",
      "  (6007, 4831)\t4.207046484738295\n",
      "  (6007, 4846)\t1.157524036598166\n",
      "  (6007, 4971)\t4.155753190350744\n",
      "  (6007, 5019)\t7.027798608356699\n",
      "  (6007, 5128)\t4.567902026898306\n",
      "  (6007, 5144)\t10.185261111666575\n",
      "  (6007, 5174)\t24.2114927009465\n",
      "  (6007, 5264)\t5.863955517457257\n",
      "  (6007, 5277)\t3.7502880822425797\n",
      "  (6007, 5296)\t5.205575314849422\n",
      "  (6007, 5383)\t2.5167564756750993\n",
      "  (6007, 5443)\t5.765191102784844\n",
      "  (6007, 5478)\t48.422985401893\n",
      "  (6007, 5541)\t2.9618307218783095\n",
      "  (6007, 5560)\t8.031982495951171\n",
      "  (6007, 5686)\t4.7535901911063645\n",
      "  (6007, 5718)\t3.5679665254486252\n",
      "  (6007, 5731)\t12.91667656668958\n",
      "  (6007, 5732)\t2.6971381676512274\n",
      "  (6007, 5750)\t4.378896741664954\n",
      "Features:\n",
      " <List of Lists sparse matrix of dtype 'float64'\n",
      "\twith 1802400 stored elements and shape (6008, 300)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t0.0\n",
      "  (0, 1)\t0.0\n",
      "  (0, 2)\t0.0\n",
      "  (0, 3)\t0.0\n",
      "  (0, 4)\t0.0\n",
      "  (0, 5)\t0.0\n",
      "  (0, 6)\t0.0\n",
      "  (0, 7)\t0.0\n",
      "  (0, 8)\t0.0\n",
      "  (0, 9)\t0.0\n",
      "  (0, 10)\t0.0\n",
      "  (0, 11)\t0.0\n",
      "  (0, 12)\t0.0\n",
      "  (0, 13)\t0.0\n",
      "  (0, 14)\t0.0\n",
      "  (0, 15)\t0.0\n",
      "  (0, 16)\t0.0\n",
      "  (0, 17)\t0.0\n",
      "  (0, 18)\t0.0\n",
      "  (0, 19)\t0.0\n",
      "  (0, 20)\t0.0\n",
      "  (0, 21)\t0.0\n",
      "  (0, 22)\t0.0\n",
      "  (0, 23)\t0.0\n",
      "  (0, 24)\t0.0\n",
      "  :\t:\n",
      "  (6007, 275)\t0.0\n",
      "  (6007, 276)\t0.0\n",
      "  (6007, 277)\t0.0\n",
      "  (6007, 278)\t0.0\n",
      "  (6007, 279)\t0.0\n",
      "  (6007, 280)\t0.0\n",
      "  (6007, 281)\t0.0\n",
      "  (6007, 282)\t0.0\n",
      "  (6007, 283)\t0.0\n",
      "  (6007, 284)\t0.0\n",
      "  (6007, 285)\t0.0\n",
      "  (6007, 286)\t0.0\n",
      "  (6007, 287)\t0.0\n",
      "  (6007, 288)\t0.0\n",
      "  (6007, 289)\t0.0\n",
      "  (6007, 290)\t0.0\n",
      "  (6007, 291)\t0.0\n",
      "  (6007, 292)\t0.0\n",
      "  (6007, 293)\t0.0\n",
      "  (6007, 294)\t0.0\n",
      "  (6007, 295)\t0.0\n",
      "  (6007, 296)\t0.0\n",
      "  (6007, 297)\t0.0\n",
      "  (6007, 298)\t0.0\n",
      "  (6007, 299)\t0.0\n",
      "Y_train:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Y_val:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Y_test:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Train_mask:\n",
      " [ True  True  True ... False False False]\n",
      "Val_mask:\n",
      " [False False False ... False False False]\n",
      "Test_mask:\n",
      " [False False False ...  True  True  True]\n",
      "Train_size:\n",
      " 1048\n",
      "Test_size:\n",
      " 228\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "import os\n",
    "import random\n",
    "seed = random.randint(1, 200)\n",
    "np.random.seed(seed)\n",
    "# tf.set_random_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "\n",
    "dataset = '1500'  # 'citeseer' or 'pubmed' as alternatives\n",
    "model_type = 'GCN'  # 'gcn_cheby' or 'dense' as alternatives\n",
    "learning_rate = 0.02\n",
    "epochs = 200\n",
    "hidden1 = 200\n",
    "dropout = 0.5\n",
    "weight_decay = 0  # 5e-4 can be used as well\n",
    "early_stopping = 10\n",
    "max_degree = 3\n",
    "# import argparse#########\n",
    "\n",
    "# parser = argparse.ArgumentParser()##########\n",
    "# FLAGS = parser.parse_args()############\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus(dataset)\n",
    "print(\"Adj:\\n\",adj)\n",
    "print(\"Features:\\n\",features)\n",
    "print(\"Y_train:\\n\",y_train)\n",
    "print(\"Y_val:\\n\",y_val)\n",
    "print(\"Y_test:\\n\",y_test)\n",
    "print(\"Train_mask:\\n\",train_mask)\n",
    "print(\"Val_mask:\\n\",val_mask)\n",
    "print(\"Test_mask:\\n\",test_mask)\n",
    "print(\"Train_size:\\n\",train_size)\n",
    "print(\"Test_size:\\n\",test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0a564f-0e2d-4cde-a4ae-abdb6ac11c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6008, 6008)\n",
      "(6008, 6008)\n"
     ]
    }
   ],
   "source": [
    "features = sp.identity(features.shape[0])  # featureless\n",
    "\n",
    "print(adj.shape)\n",
    "print(features.shape)\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83efdaf1-4218-4e1f-926f-0825ce69c593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/sjain/.local/share/jupyter/runtime/kernel-aa1904e1-e079-472d-ae75-9854b4501071.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjain/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from models import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c97b0e-cf41-4915-b69b-bfa2845cfec2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GCN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m support \u001b[38;5;241m=\u001b[39m [preprocess_adj(adj)]\n\u001b[1;32m     33\u001b[0m num_supports \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 34\u001b[0m model_func \u001b[38;5;241m=\u001b[39m GCN\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m###########################commented by us#########################\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# elif FLAGS.model == 'gcn_cheby':\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#     support = chebyshev_polynomials(adj, FLAGS.max_degree)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#TensorFlow Placeholders: Placeholders are created for feeding data into the model. This includes the support matrices (for GCN), input features, labels, and dropout rates.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m placeholders \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m: [tf\u001b[38;5;241m.\u001b[39msparse_placeholder(tf\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_supports)],\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m: tf\u001b[38;5;241m.\u001b[39msparse_placeholder(tf\u001b[38;5;241m.\u001b[39mfloat32, shape\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mconstant(features[\u001b[38;5;241m2\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint64)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features_nonzero\u001b[39m\u001b[38;5;124m'\u001b[39m: tf\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     58\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GCN' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Set random seed\n",
    "# seed = random.randint(1, 200)\n",
    "# np.random.seed(seed)\n",
    "# tf.set_random_seed(seed)\n",
    "\n",
    "# # Settings\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# flags = tf.app.flags\n",
    "# FLAGS = flags.FLAGS\n",
    "# # 'cora', 'citeseer', 'pubmed'\n",
    "# flags.DEFINE_string('dataset', dataset, 'Dataset string.')\n",
    "# # 'gcn', 'gcn_cheby', 'dense'\n",
    "# flags.DEFINE_string('model', 'gcn', 'Model string.')\n",
    "# flags.DEFINE_float('learning_rate', 0.02, 'Initial learning rate.')\n",
    "# flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
    "# flags.DEFINE_integer('hidden1', 200, 'Number of units in hidden layer 1.')\n",
    "# flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "# flags.DEFINE_float('weight_decay', 0,\n",
    "#                    'Weight for L2 loss on embedding matrix.')  # 5e-4\n",
    "# flags.DEFINE_integer('early_stopping', 10,\n",
    "#                      'Tolerance for early stopping (# of epochs).')\n",
    "# flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')\n",
    "\n",
    "# # Load data\n",
    "# adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus(\n",
    "#     FLAGS.dataset)\n",
    "# print(adj)\n",
    "# print(adj[0], adj[1])\n",
    "\n",
    "if FLAGS.model == 'gcn':\n",
    "    support = [preprocess_adj(adj)]\n",
    "    num_supports = 1\n",
    "    model_func = GCN\n",
    "###########################commented by us#\n",
    "# elif FLAGS.model == 'gcn_cheby':\n",
    "#     support = chebyshev_polynomials(adj, FLAGS.max_degree)\n",
    "#     num_supports = 1 + FLAGS.max_degree\n",
    "#     model_func = GCN\n",
    "# elif FLAGS.model == 'dense':\n",
    "#     support = [preprocess_adj(adj)]  # Not used\n",
    "#     num_supports = 1\n",
    "#     model_func = MLP\n",
    "# else:\n",
    "#     raise ValueError('Invalid argument for model: ' + str(FLAGS.model))\n",
    "\n",
    "# Define placeholders\n",
    "\n",
    "#TensorFlow Placeholders: Placeholders are created for feeding data into the model. This includes the support matrices (for GCN), input features, labels, and dropout rates.\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    # helper variable for sparse dropout\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)\n",
    "}\n",
    "\n",
    "# Create model\n",
    "print(features[2][1])\n",
    "model = model_func(placeholders, input_dim=features[2][1], logging=True)\n",
    "\n",
    "# Initialize session\n",
    "session_conf = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "sess = tf.Session(config=session_conf)\n",
    "\n",
    "\n",
    "# Define model evaluation function\n",
    "def evaluate(features, support, labels, mask, placeholders):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(\n",
    "        features, support, labels, mask, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy, model.pred, model.labels], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], outs_val[2], outs_val[3], (time.time() - t_test)\n",
    "\n",
    "\n",
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "cost_val = []\n",
    "\n",
    "# Train model\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(\n",
    "        features, support, y_train, train_mask, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy,\n",
    "                     model.layers[0].embedding], feed_dict=feed_dict)\n",
    "\n",
    "    # Validation\n",
    "    cost, acc, pred, labels, duration = evaluate(\n",
    "        features, support, y_val, val_mask, placeholders)\n",
    "    cost_val.append(cost)\n",
    "\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(\n",
    "              outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and cost_val[-1] > np.mean(cost_val[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Testing\n",
    "test_cost, test_acc, pred, labels, test_duration = evaluate(\n",
    "    features, support, y_test, test_mask, placeholders)\n",
    "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
    "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))\n",
    "\n",
    "test_pred = []\n",
    "test_labels = []\n",
    "print(len(test_mask))\n",
    "for i in range(len(test_mask)):\n",
    "    if test_mask[i]:\n",
    "        test_pred.append(pred[i])\n",
    "        test_labels.append(labels[i])\n",
    "\n",
    "print(\"Test Precision, Recall and F1-Score...\")\n",
    "print(metrics.classification_report(test_labels, test_pred, digits=4))\n",
    "print(\"Macro average Test Precision, Recall and F1-Score...\")\n",
    "print(metrics.precision_recall_fscore_support(test_labels, test_pred, average='macro'))\n",
    "print(\"Micro average Test Precision, Recall and F1-Score...\")\n",
    "print(metrics.precision_recall_fscore_support(test_labels, test_pred, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7d353-d3b2-4952-9c72-56f5be007a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# doc and word embeddings\n",
    "print('embeddings:')\n",
    "word_embeddings = outs[3][train_size: adj.shape[0] - test_size]\n",
    "train_doc_embeddings = outs[3][:train_size]  # include val docs\n",
    "test_doc_embeddings = outs[3][adj.shape[0] - test_size:]\n",
    "\n",
    "print(len(word_embeddings), len(train_doc_embeddings),\n",
    "      len(test_doc_embeddings))\n",
    "print(word_embeddings)\n",
    "\n",
    "f = open('data/corpus/_vocab.txt', 'r')\n",
    "words = f.readlines()\n",
    "f.close()\n",
    "\n",
    "vocab_size = len(words)\n",
    "word_vectors = []\n",
    "for i in range(vocab_size):\n",
    "    word = words[i].strip()\n",
    "    word_vector = word_embeddings[i]\n",
    "    word_vector_str = ' '.join([str(x) for x in word_vector])\n",
    "    word_vectors.append(word + ' ' + word_vector_str)\n",
    "\n",
    "word_embeddings_str = '\\n'.join(word_vectors)\n",
    "f = open('data/_word_vectors.txt', 'w')\n",
    "f.write(word_embeddings_str)\n",
    "f.close()\n",
    "\n",
    "doc_vectors = []\n",
    "doc_id = 0\n",
    "for i in range(train_size):\n",
    "    doc_vector = train_doc_embeddings[i]\n",
    "    doc_vector_str = ' '.join([str(x) for x in doc_vector])\n",
    "    doc_vectors.append('doc_' + str(doc_id) + ' ' + doc_vector_str)\n",
    "    doc_id += 1\n",
    "\n",
    "for i in range(test_size):\n",
    "    doc_vector = test_doc_embeddings[i]\n",
    "    doc_vector_str = ' '.join([str(x) for x in doc_vector])\n",
    "    doc_vectors.append('doc_' + str(doc_id) + ' ' + doc_vector_str)\n",
    "    doc_id += 1\n",
    "\n",
    "doc_embeddings_str = '\\n'.join(doc_vectors)\n",
    "f = open('data/_doc_vectors.txt', 'w')\n",
    "f.write(doc_embeddings_str)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
